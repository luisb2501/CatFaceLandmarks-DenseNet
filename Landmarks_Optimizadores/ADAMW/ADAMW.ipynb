{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 17982.1961\n",
      "Validation Loss: 15987.8258\n",
      "NME: 1.4587\n",
      "Best model saved at epoch 1 with val_loss 15987.8258\n",
      "Epoch [2/300], Loss: 10561.6879\n",
      "Validation Loss: 4950.5171\n",
      "NME: 0.7254\n",
      "Best model saved at epoch 2 with val_loss 4950.5171\n",
      "Epoch [3/300], Loss: 2990.6039\n",
      "Validation Loss: 1932.6013\n",
      "NME: 0.4025\n",
      "Best model saved at epoch 3 with val_loss 1932.6013\n",
      "Epoch [4/300], Loss: 1830.6859\n",
      "Validation Loss: 1454.0242\n",
      "NME: 0.3464\n",
      "Best model saved at epoch 4 with val_loss 1454.0242\n",
      "Epoch [5/300], Loss: 1629.3723\n",
      "Validation Loss: 1387.1694\n",
      "NME: 0.3458\n",
      "Best model saved at epoch 5 with val_loss 1387.1694\n",
      "Epoch [6/300], Loss: 1585.8330\n",
      "Validation Loss: 1382.3968\n",
      "NME: 0.3371\n",
      "Best model saved at epoch 6 with val_loss 1382.3968\n",
      "Epoch [7/300], Loss: 1554.8872\n",
      "Validation Loss: 1365.4486\n",
      "NME: 0.3414\n",
      "Best model saved at epoch 7 with val_loss 1365.4486\n",
      "Epoch [8/300], Loss: 1545.8507\n",
      "Validation Loss: 1329.1997\n",
      "NME: 0.3398\n",
      "Best model saved at epoch 8 with val_loss 1329.1997\n",
      "Epoch [9/300], Loss: 1503.8353\n",
      "Validation Loss: 1274.6926\n",
      "NME: 0.3260\n",
      "Best model saved at epoch 9 with val_loss 1274.6926\n",
      "Epoch [10/300], Loss: 1465.6904\n",
      "Validation Loss: 1149.5735\n",
      "NME: 0.3100\n",
      "Best model saved at epoch 10 with val_loss 1149.5735\n",
      "Epoch [11/300], Loss: 1293.3784\n",
      "Validation Loss: 961.6075\n",
      "NME: 0.2827\n",
      "Best model saved at epoch 11 with val_loss 961.6075\n",
      "Epoch [12/300], Loss: 1119.7159\n",
      "Validation Loss: 748.5730\n",
      "NME: 0.2527\n",
      "Best model saved at epoch 12 with val_loss 748.5730\n",
      "Epoch [13/300], Loss: 876.5469\n",
      "Validation Loss: 645.2406\n",
      "NME: 0.2323\n",
      "Best model saved at epoch 13 with val_loss 645.2406\n",
      "Epoch [14/300], Loss: 809.2775\n",
      "Validation Loss: 535.6668\n",
      "NME: 0.2057\n",
      "Best model saved at epoch 14 with val_loss 535.6668\n",
      "Epoch [15/300], Loss: 787.0381\n",
      "Validation Loss: 489.5264\n",
      "NME: 0.2183\n",
      "Best model saved at epoch 15 with val_loss 489.5264\n",
      "Epoch [16/300], Loss: 753.4720\n",
      "Validation Loss: 442.9233\n",
      "NME: 0.1962\n",
      "Best model saved at epoch 16 with val_loss 442.9233\n",
      "Epoch [17/300], Loss: 673.1591\n",
      "Validation Loss: 420.8358\n",
      "NME: 0.1950\n",
      "Best model saved at epoch 17 with val_loss 420.8358\n",
      "Epoch [18/300], Loss: 648.1503\n",
      "Validation Loss: 411.2311\n",
      "NME: 0.1887\n",
      "Best model saved at epoch 18 with val_loss 411.2311\n",
      "Epoch [19/300], Loss: 691.6025\n",
      "Validation Loss: 460.1220\n",
      "NME: 0.2087\n",
      "Epoch [20/300], Loss: 675.5181\n",
      "Validation Loss: 410.2650\n",
      "NME: 0.1885\n",
      "Best model saved at epoch 20 with val_loss 410.2650\n",
      "Epoch [21/300], Loss: 675.8837\n",
      "Validation Loss: 403.1310\n",
      "NME: 0.1855\n",
      "Best model saved at epoch 21 with val_loss 403.1310\n",
      "Epoch [22/300], Loss: 649.2225\n",
      "Validation Loss: 421.6701\n",
      "NME: 0.1893\n",
      "Epoch [23/300], Loss: 604.3027\n",
      "Validation Loss: 383.2706\n",
      "NME: 0.1836\n",
      "Best model saved at epoch 23 with val_loss 383.2706\n",
      "Epoch [24/300], Loss: 614.8725\n",
      "Validation Loss: 415.4818\n",
      "NME: 0.1855\n",
      "Epoch [25/300], Loss: 590.8868\n",
      "Validation Loss: 380.0700\n",
      "NME: 0.1718\n",
      "Best model saved at epoch 25 with val_loss 380.0700\n",
      "Epoch [26/300], Loss: 598.0412\n",
      "Validation Loss: 354.8963\n",
      "NME: 0.1629\n",
      "Best model saved at epoch 26 with val_loss 354.8963\n",
      "Epoch [27/300], Loss: 538.5702\n",
      "Validation Loss: 339.0412\n",
      "NME: 0.1557\n",
      "Best model saved at epoch 27 with val_loss 339.0412\n",
      "Epoch [28/300], Loss: 503.2858\n",
      "Validation Loss: 333.9902\n",
      "NME: 0.1552\n",
      "Best model saved at epoch 28 with val_loss 333.9902\n",
      "Epoch [29/300], Loss: 564.7209\n",
      "Validation Loss: 386.5252\n",
      "NME: 0.1609\n",
      "Epoch [30/300], Loss: 511.5191\n",
      "Validation Loss: 310.5804\n",
      "NME: 0.1498\n",
      "Best model saved at epoch 30 with val_loss 310.5804\n",
      "Epoch [31/300], Loss: 516.6050\n",
      "Validation Loss: 320.4093\n",
      "NME: 0.1531\n",
      "Epoch [32/300], Loss: 556.1294\n",
      "Validation Loss: 321.0501\n",
      "NME: 0.1550\n",
      "Epoch [33/300], Loss: 532.0267\n",
      "Validation Loss: 307.7737\n",
      "NME: 0.1483\n",
      "Best model saved at epoch 33 with val_loss 307.7737\n",
      "Epoch [34/300], Loss: 523.3201\n",
      "Validation Loss: 332.9422\n",
      "NME: 0.1592\n",
      "Epoch [35/300], Loss: 484.5402\n",
      "Validation Loss: 328.6985\n",
      "NME: 0.1510\n",
      "Epoch [36/300], Loss: 450.3049\n",
      "Validation Loss: 307.7476\n",
      "NME: 0.1423\n",
      "Best model saved at epoch 36 with val_loss 307.7476\n",
      "Epoch [37/300], Loss: 435.0811\n",
      "Validation Loss: 307.3645\n",
      "NME: 0.1419\n",
      "Best model saved at epoch 37 with val_loss 307.3645\n",
      "Epoch [38/300], Loss: 391.8052\n",
      "Validation Loss: 304.7646\n",
      "NME: 0.1444\n",
      "Best model saved at epoch 38 with val_loss 304.7646\n",
      "Epoch [39/300], Loss: 374.6592\n",
      "Validation Loss: 290.7533\n",
      "NME: 0.1309\n",
      "Best model saved at epoch 39 with val_loss 290.7533\n",
      "Epoch [40/300], Loss: 353.9894\n",
      "Validation Loss: 276.8987\n",
      "NME: 0.1300\n",
      "Best model saved at epoch 40 with val_loss 276.8987\n",
      "Epoch [41/300], Loss: 320.5797\n",
      "Validation Loss: 272.1142\n",
      "NME: 0.1350\n",
      "Best model saved at epoch 41 with val_loss 272.1142\n",
      "Epoch [42/300], Loss: 292.9088\n",
      "Validation Loss: 296.3358\n",
      "NME: 0.1357\n",
      "Epoch [43/300], Loss: 294.2352\n",
      "Validation Loss: 273.7885\n",
      "NME: 0.1321\n",
      "Epoch [44/300], Loss: 279.5474\n",
      "Validation Loss: 273.2680\n",
      "NME: 0.1323\n",
      "Epoch [45/300], Loss: 271.7911\n",
      "Validation Loss: 280.0659\n",
      "NME: 0.1351\n",
      "Epoch [46/300], Loss: 283.2592\n",
      "Validation Loss: 278.1685\n",
      "NME: 0.1349\n",
      "Epoch [47/300], Loss: 274.6965\n",
      "Validation Loss: 280.2958\n",
      "NME: 0.1286\n",
      "Epoch [48/300], Loss: 279.0662\n",
      "Validation Loss: 265.9069\n",
      "NME: 0.1254\n",
      "Best model saved at epoch 48 with val_loss 265.9069\n",
      "Epoch [49/300], Loss: 242.1621\n",
      "Validation Loss: 244.9622\n",
      "NME: 0.1285\n",
      "Best model saved at epoch 49 with val_loss 244.9622\n",
      "Epoch [50/300], Loss: 264.0365\n",
      "Validation Loss: 299.3065\n",
      "NME: 0.1340\n",
      "Epoch [51/300], Loss: 251.8948\n",
      "Validation Loss: 266.6912\n",
      "NME: 0.1265\n",
      "Epoch [52/300], Loss: 252.0813\n",
      "Validation Loss: 272.6259\n",
      "NME: 0.1285\n",
      "Epoch [53/300], Loss: 250.4795\n",
      "Validation Loss: 274.2013\n",
      "NME: 0.1292\n",
      "Epoch [54/300], Loss: 251.8452\n",
      "Validation Loss: 268.2986\n",
      "NME: 0.1284\n",
      "Epoch [55/300], Loss: 222.3444\n",
      "Validation Loss: 273.0310\n",
      "NME: 0.1235\n",
      "Epoch [56/300], Loss: 237.7370\n",
      "Validation Loss: 270.1033\n",
      "NME: 0.1282\n",
      "Epoch [57/300], Loss: 266.6482\n",
      "Validation Loss: 287.7426\n",
      "NME: 0.1286\n",
      "Epoch [58/300], Loss: 231.2432\n",
      "Validation Loss: 272.5640\n",
      "NME: 0.1277\n",
      "Epoch [59/300], Loss: 232.6513\n",
      "Validation Loss: 267.9086\n",
      "NME: 0.1261\n",
      "Epoch [60/300], Loss: 216.5922\n",
      "Validation Loss: 269.0930\n",
      "NME: 0.1203\n",
      "Epoch [61/300], Loss: 219.4097\n",
      "Validation Loss: 257.6591\n",
      "NME: 0.1222\n",
      "Epoch [62/300], Loss: 211.9511\n",
      "Validation Loss: 269.2649\n",
      "NME: 0.1207\n",
      "Epoch [63/300], Loss: 207.3477\n",
      "Validation Loss: 250.5226\n",
      "NME: 0.1229\n",
      "Epoch [64/300], Loss: 217.2263\n",
      "Validation Loss: 275.5034\n",
      "NME: 0.1267\n",
      "Epoch [65/300], Loss: 211.0057\n",
      "Validation Loss: 250.3027\n",
      "NME: 0.1206\n",
      "Epoch [66/300], Loss: 202.5265\n",
      "Validation Loss: 279.8197\n",
      "NME: 0.1229\n",
      "Epoch [67/300], Loss: 210.6908\n",
      "Validation Loss: 272.9681\n",
      "NME: 0.1240\n",
      "Epoch [68/300], Loss: 210.7812\n",
      "Validation Loss: 243.0915\n",
      "NME: 0.1228\n",
      "Best model saved at epoch 68 with val_loss 243.0915\n",
      "Epoch [69/300], Loss: 213.0365\n",
      "Validation Loss: 295.0289\n",
      "NME: 0.1261\n",
      "Epoch [70/300], Loss: 210.5900\n",
      "Validation Loss: 270.5663\n",
      "NME: 0.1226\n",
      "Epoch [71/300], Loss: 201.1203\n",
      "Validation Loss: 287.0288\n",
      "NME: 0.1274\n",
      "Epoch [72/300], Loss: 209.5810\n",
      "Validation Loss: 272.5657\n",
      "NME: 0.1266\n",
      "Epoch [73/300], Loss: 200.1957\n",
      "Validation Loss: 258.2394\n",
      "NME: 0.1194\n",
      "Epoch [74/300], Loss: 189.5779\n",
      "Validation Loss: 243.8296\n",
      "NME: 0.1193\n",
      "Epoch [75/300], Loss: 205.2412\n",
      "Validation Loss: 299.0916\n",
      "NME: 0.1273\n",
      "Epoch [76/300], Loss: 215.7205\n",
      "Validation Loss: 271.7891\n",
      "NME: 0.1222\n",
      "Epoch [77/300], Loss: 257.1767\n",
      "Validation Loss: 262.3909\n",
      "NME: 0.1247\n",
      "Epoch [78/300], Loss: 214.7758\n",
      "Validation Loss: 259.8895\n",
      "NME: 0.1198\n",
      "Epoch [79/300], Loss: 193.6893\n",
      "Validation Loss: 236.0107\n",
      "NME: 0.1152\n",
      "Best model saved at epoch 79 with val_loss 236.0107\n",
      "Epoch [80/300], Loss: 195.7662\n",
      "Validation Loss: 254.4458\n",
      "NME: 0.1179\n",
      "Epoch [81/300], Loss: 182.9580\n",
      "Validation Loss: 243.2496\n",
      "NME: 0.1163\n",
      "Epoch [82/300], Loss: 183.7472\n",
      "Validation Loss: 239.6760\n",
      "NME: 0.1157\n",
      "Epoch [83/300], Loss: 177.5788\n",
      "Validation Loss: 283.0434\n",
      "NME: 0.1154\n",
      "Epoch [84/300], Loss: 176.5750\n",
      "Validation Loss: 231.5326\n",
      "NME: 0.1120\n",
      "Best model saved at epoch 84 with val_loss 231.5326\n",
      "Epoch [85/300], Loss: 174.6996\n",
      "Validation Loss: 252.0083\n",
      "NME: 0.1131\n",
      "Epoch [86/300], Loss: 172.9935\n",
      "Validation Loss: 215.5206\n",
      "NME: 0.1083\n",
      "Best model saved at epoch 86 with val_loss 215.5206\n",
      "Epoch [87/300], Loss: 165.7282\n",
      "Validation Loss: 204.0096\n",
      "NME: 0.1073\n",
      "Best model saved at epoch 87 with val_loss 204.0096\n",
      "Epoch [88/300], Loss: 167.7972\n",
      "Validation Loss: 210.3313\n",
      "NME: 0.1075\n",
      "Epoch [89/300], Loss: 164.5776\n",
      "Validation Loss: 224.2159\n",
      "NME: 0.1088\n",
      "Epoch [90/300], Loss: 161.4876\n",
      "Validation Loss: 208.0681\n",
      "NME: 0.1023\n",
      "Epoch [91/300], Loss: 145.9400\n",
      "Validation Loss: 188.3945\n",
      "NME: 0.1008\n",
      "Best model saved at epoch 91 with val_loss 188.3945\n",
      "Epoch [92/300], Loss: 152.4942\n",
      "Validation Loss: 200.5499\n",
      "NME: 0.0996\n",
      "Epoch [93/300], Loss: 145.4963\n",
      "Validation Loss: 193.7219\n",
      "NME: 0.1001\n",
      "Epoch [94/300], Loss: 157.3773\n",
      "Validation Loss: 208.0094\n",
      "NME: 0.1017\n",
      "Epoch [95/300], Loss: 140.3042\n",
      "Validation Loss: 202.1465\n",
      "NME: 0.1011\n",
      "Epoch [96/300], Loss: 150.0879\n",
      "Validation Loss: 207.0051\n",
      "NME: 0.1011\n",
      "Epoch [97/300], Loss: 144.6371\n",
      "Validation Loss: 186.9448\n",
      "NME: 0.1058\n",
      "Best model saved at epoch 97 with val_loss 186.9448\n",
      "Epoch [98/300], Loss: 137.6989\n",
      "Validation Loss: 201.3463\n",
      "NME: 0.1001\n",
      "Epoch [99/300], Loss: 143.8637\n",
      "Validation Loss: 210.8952\n",
      "NME: 0.1020\n",
      "Epoch [100/300], Loss: 129.0418\n",
      "Validation Loss: 195.4602\n",
      "NME: 0.0964\n",
      "Epoch [101/300], Loss: 134.2764\n",
      "Validation Loss: 184.9549\n",
      "NME: 0.0968\n",
      "Best model saved at epoch 101 with val_loss 184.9549\n",
      "Epoch [102/300], Loss: 135.5585\n",
      "Validation Loss: 201.2383\n",
      "NME: 0.0998\n",
      "Epoch [103/300], Loss: 136.3538\n",
      "Validation Loss: 190.8950\n",
      "NME: 0.0999\n",
      "Epoch [104/300], Loss: 123.8202\n",
      "Validation Loss: 179.3795\n",
      "NME: 0.0963\n",
      "Best model saved at epoch 104 with val_loss 179.3795\n",
      "Epoch [105/300], Loss: 131.0957\n",
      "Validation Loss: 201.7934\n",
      "NME: 0.0975\n",
      "Epoch [106/300], Loss: 131.5619\n",
      "Validation Loss: 190.6474\n",
      "NME: 0.0976\n",
      "Epoch [107/300], Loss: 119.0201\n",
      "Validation Loss: 187.8532\n",
      "NME: 0.0967\n",
      "Epoch [108/300], Loss: 136.9908\n",
      "Validation Loss: 203.9306\n",
      "NME: 0.1084\n",
      "Epoch [109/300], Loss: 131.9785\n",
      "Validation Loss: 190.4143\n",
      "NME: 0.0991\n",
      "Epoch [110/300], Loss: 125.7110\n",
      "Validation Loss: 186.9126\n",
      "NME: 0.0961\n",
      "Epoch [111/300], Loss: 123.7919\n",
      "Validation Loss: 218.3348\n",
      "NME: 0.1007\n",
      "Epoch [112/300], Loss: 115.0349\n",
      "Validation Loss: 181.5521\n",
      "NME: 0.0953\n",
      "Epoch [113/300], Loss: 122.0671\n",
      "Validation Loss: 211.6045\n",
      "NME: 0.1014\n",
      "Epoch [114/300], Loss: 123.9947\n",
      "Validation Loss: 202.1306\n",
      "NME: 0.0991\n",
      "Epoch [115/300], Loss: 131.3988\n",
      "Validation Loss: 194.8785\n",
      "NME: 0.0974\n",
      "Epoch [116/300], Loss: 116.9156\n",
      "Validation Loss: 210.3125\n",
      "NME: 0.1022\n",
      "Epoch [117/300], Loss: 125.6775\n",
      "Validation Loss: 180.8523\n",
      "NME: 0.0971\n",
      "Epoch [118/300], Loss: 120.5133\n",
      "Validation Loss: 195.6269\n",
      "NME: 0.0956\n",
      "Epoch [119/300], Loss: 116.9859\n",
      "Validation Loss: 176.1822\n",
      "NME: 0.0949\n",
      "Best model saved at epoch 119 with val_loss 176.1822\n",
      "Epoch [120/300], Loss: 113.2853\n",
      "Validation Loss: 178.0541\n",
      "NME: 0.0977\n",
      "Epoch [121/300], Loss: 110.2358\n",
      "Validation Loss: 183.7397\n",
      "NME: 0.0914\n",
      "Epoch [122/300], Loss: 107.7719\n",
      "Validation Loss: 167.1900\n",
      "NME: 0.0941\n",
      "Best model saved at epoch 122 with val_loss 167.1900\n",
      "Epoch [123/300], Loss: 106.8320\n",
      "Validation Loss: 188.4850\n",
      "NME: 0.0965\n",
      "Epoch [124/300], Loss: 105.8322\n",
      "Validation Loss: 176.8218\n",
      "NME: 0.0950\n",
      "Epoch [125/300], Loss: 109.3643\n",
      "Validation Loss: 171.1456\n",
      "NME: 0.0975\n",
      "Epoch [126/300], Loss: 146.8279\n",
      "Validation Loss: 198.1746\n",
      "NME: 0.0972\n",
      "Epoch [127/300], Loss: 126.5740\n",
      "Validation Loss: 196.8639\n",
      "NME: 0.0984\n",
      "Epoch [128/300], Loss: 114.0340\n",
      "Validation Loss: 188.7631\n",
      "NME: 0.0927\n",
      "Epoch [129/300], Loss: 107.5535\n",
      "Validation Loss: 187.3718\n",
      "NME: 0.0947\n",
      "Epoch [130/300], Loss: 105.0000\n",
      "Validation Loss: 183.0385\n",
      "NME: 0.0952\n",
      "Epoch [131/300], Loss: 101.3845\n",
      "Validation Loss: 210.2853\n",
      "NME: 0.1025\n",
      "Epoch [132/300], Loss: 103.0659\n",
      "Validation Loss: 204.0339\n",
      "NME: 0.0935\n",
      "Epoch [133/300], Loss: 106.4366\n",
      "Validation Loss: 173.8748\n",
      "NME: 0.0936\n",
      "Epoch [134/300], Loss: 109.7418\n",
      "Validation Loss: 217.8691\n",
      "NME: 0.0999\n",
      "Epoch [135/300], Loss: 122.2994\n",
      "Validation Loss: 203.5234\n",
      "NME: 0.0972\n",
      "Epoch [136/300], Loss: 116.2884\n",
      "Validation Loss: 202.6100\n",
      "NME: 0.0939\n",
      "Epoch [137/300], Loss: 109.0961\n",
      "Validation Loss: 188.5711\n",
      "NME: 0.0942\n",
      "Epoch [138/300], Loss: 106.1773\n",
      "Validation Loss: 175.3485\n",
      "NME: 0.0933\n",
      "Epoch [139/300], Loss: 97.6673\n",
      "Validation Loss: 173.6321\n",
      "NME: 0.0917\n",
      "Epoch [140/300], Loss: 103.4173\n",
      "Validation Loss: 196.0310\n",
      "NME: 0.0947\n",
      "Epoch [141/300], Loss: 123.2935\n",
      "Validation Loss: 185.7796\n",
      "NME: 0.0981\n",
      "Epoch [142/300], Loss: 112.1647\n",
      "Validation Loss: 191.3167\n",
      "NME: 0.0964\n",
      "Epoch [143/300], Loss: 105.9802\n",
      "Validation Loss: 187.2725\n",
      "NME: 0.0933\n",
      "Epoch [144/300], Loss: 102.4807\n",
      "Validation Loss: 195.7527\n",
      "NME: 0.0954\n",
      "Epoch [145/300], Loss: 103.8577\n",
      "Validation Loss: 181.7142\n",
      "NME: 0.0966\n",
      "Epoch [146/300], Loss: 102.2610\n",
      "Validation Loss: 177.9688\n",
      "NME: 0.0919\n",
      "Epoch [147/300], Loss: 95.8180\n",
      "Validation Loss: 176.7078\n",
      "NME: 0.0940\n",
      "Epoch [148/300], Loss: 93.4743\n",
      "Validation Loss: 181.4072\n",
      "NME: 0.0952\n",
      "Epoch [149/300], Loss: 96.4363\n",
      "Validation Loss: 175.4506\n",
      "NME: 0.0943\n",
      "Epoch [150/300], Loss: 96.3217\n",
      "Validation Loss: 184.6707\n",
      "NME: 0.0950\n",
      "Epoch [151/300], Loss: 94.7587\n",
      "Validation Loss: 187.1890\n",
      "NME: 0.0965\n",
      "Epoch [152/300], Loss: 95.2968\n",
      "Validation Loss: 175.7141\n",
      "NME: 0.0939\n",
      "Epoch [153/300], Loss: 93.2984\n",
      "Validation Loss: 177.7867\n",
      "NME: 0.0933\n",
      "Epoch [154/300], Loss: 93.6998\n",
      "Validation Loss: 188.5551\n",
      "NME: 0.0955\n",
      "Epoch [155/300], Loss: 93.4427\n",
      "Validation Loss: 191.5721\n",
      "NME: 0.0958\n",
      "Epoch [156/300], Loss: 95.2940\n",
      "Validation Loss: 181.7317\n",
      "NME: 0.0969\n",
      "Epoch [157/300], Loss: 91.8829\n",
      "Validation Loss: 177.0420\n",
      "NME: 0.0927\n",
      "Epoch [158/300], Loss: 92.6575\n",
      "Validation Loss: 175.4126\n",
      "NME: 0.0931\n",
      "Epoch [159/300], Loss: 105.1170\n",
      "Validation Loss: 184.0481\n",
      "NME: 0.0971\n",
      "Epoch [160/300], Loss: 229.8181\n",
      "Validation Loss: 222.6251\n",
      "NME: 0.1067\n",
      "Epoch [161/300], Loss: 120.4804\n",
      "Validation Loss: 202.4958\n",
      "NME: 0.1026\n",
      "Epoch [162/300], Loss: 106.8898\n",
      "Validation Loss: 185.2080\n",
      "NME: 0.0953\n",
      "Epoch [163/300], Loss: 105.8593\n",
      "Validation Loss: 185.2238\n",
      "NME: 0.0938\n",
      "Epoch [164/300], Loss: 105.9790\n",
      "Validation Loss: 174.7499\n",
      "NME: 0.0958\n",
      "Epoch [165/300], Loss: 105.1753\n",
      "Validation Loss: 187.3877\n",
      "NME: 0.0944\n",
      "Epoch [166/300], Loss: 95.2358\n",
      "Validation Loss: 161.8044\n",
      "NME: 0.0908\n",
      "Best model saved at epoch 166 with val_loss 161.8044\n",
      "Epoch [167/300], Loss: 98.2240\n",
      "Validation Loss: 163.0864\n",
      "NME: 0.0927\n",
      "Epoch [168/300], Loss: 97.6007\n",
      "Validation Loss: 170.7866\n",
      "NME: 0.0925\n",
      "Epoch [169/300], Loss: 99.3317\n",
      "Validation Loss: 176.8117\n",
      "NME: 0.0950\n",
      "Epoch [170/300], Loss: 101.8432\n",
      "Validation Loss: 172.8292\n",
      "NME: 0.0963\n",
      "Epoch [171/300], Loss: 97.0576\n",
      "Validation Loss: 170.1223\n",
      "NME: 0.0892\n",
      "Epoch [172/300], Loss: 91.3145\n",
      "Validation Loss: 167.3956\n",
      "NME: 0.0910\n",
      "Epoch [173/300], Loss: 92.3206\n",
      "Validation Loss: 178.2975\n",
      "NME: 0.0916\n",
      "Epoch [174/300], Loss: 85.5169\n",
      "Validation Loss: 185.3025\n",
      "NME: 0.0961\n",
      "Epoch [175/300], Loss: 85.5142\n",
      "Validation Loss: 166.0199\n",
      "NME: 0.0920\n",
      "Epoch [176/300], Loss: 83.0410\n",
      "Validation Loss: 163.2766\n",
      "NME: 0.0896\n",
      "Epoch [177/300], Loss: 83.8002\n",
      "Validation Loss: 163.0259\n",
      "NME: 0.0893\n",
      "Epoch [178/300], Loss: 84.3192\n",
      "Validation Loss: 159.2264\n",
      "NME: 0.0898\n",
      "Best model saved at epoch 178 with val_loss 159.2264\n",
      "Epoch [179/300], Loss: 82.3413\n",
      "Validation Loss: 171.6419\n",
      "NME: 0.0881\n",
      "Epoch [180/300], Loss: 84.1882\n",
      "Validation Loss: 159.2049\n",
      "NME: 0.0869\n",
      "Best model saved at epoch 180 with val_loss 159.2049\n",
      "Epoch [181/300], Loss: 86.9723\n",
      "Validation Loss: 171.9016\n",
      "NME: 0.0908\n",
      "Epoch [182/300], Loss: 86.2575\n",
      "Validation Loss: 162.3165\n",
      "NME: 0.0898\n",
      "Epoch [183/300], Loss: 84.3994\n",
      "Validation Loss: 162.7482\n",
      "NME: 0.0914\n",
      "Epoch [184/300], Loss: 85.0211\n",
      "Validation Loss: 154.2609\n",
      "NME: 0.0894\n",
      "Best model saved at epoch 184 with val_loss 154.2609\n",
      "Epoch [185/300], Loss: 82.0068\n",
      "Validation Loss: 161.8548\n",
      "NME: 0.0896\n",
      "Epoch [186/300], Loss: 78.8515\n",
      "Validation Loss: 166.6071\n",
      "NME: 0.0898\n",
      "Epoch [187/300], Loss: 74.6357\n",
      "Validation Loss: 171.4231\n",
      "NME: 0.0899\n",
      "Epoch [188/300], Loss: 78.0070\n",
      "Validation Loss: 159.9358\n",
      "NME: 0.0868\n",
      "Epoch [189/300], Loss: 73.7161\n",
      "Validation Loss: 185.9881\n",
      "NME: 0.0930\n",
      "Epoch [190/300], Loss: 73.2345\n",
      "Validation Loss: 175.5290\n",
      "NME: 0.0874\n",
      "Epoch [191/300], Loss: 86.2960\n",
      "Validation Loss: 173.5187\n",
      "NME: 0.0899\n",
      "Epoch [192/300], Loss: 74.3292\n",
      "Validation Loss: 171.4308\n",
      "NME: 0.0882\n",
      "Epoch [193/300], Loss: 67.7449\n",
      "Validation Loss: 173.7713\n",
      "NME: 0.0890\n",
      "Epoch [194/300], Loss: 67.1853\n",
      "Validation Loss: 159.4264\n",
      "NME: 0.0871\n",
      "Epoch [195/300], Loss: 67.5837\n",
      "Validation Loss: 169.9132\n",
      "NME: 0.0892\n",
      "Epoch [196/300], Loss: 71.8036\n",
      "Validation Loss: 176.8574\n",
      "NME: 0.0942\n",
      "Epoch [197/300], Loss: 67.4334\n",
      "Validation Loss: 168.6722\n",
      "NME: 0.0892\n",
      "Epoch [198/300], Loss: 67.2715\n",
      "Validation Loss: 166.8123\n",
      "NME: 0.0930\n",
      "Epoch [199/300], Loss: 71.7543\n",
      "Validation Loss: 164.1857\n",
      "NME: 0.0907\n",
      "Epoch [200/300], Loss: 84.5839\n",
      "Validation Loss: 187.4430\n",
      "NME: 0.0987\n",
      "Epoch [201/300], Loss: 80.9574\n",
      "Validation Loss: 160.9795\n",
      "NME: 0.0896\n",
      "Epoch [202/300], Loss: 64.3764\n",
      "Validation Loss: 159.5683\n",
      "NME: 0.0868\n",
      "Epoch [203/300], Loss: 73.6318\n",
      "Validation Loss: 185.6851\n",
      "NME: 0.0921\n",
      "Epoch [204/300], Loss: 64.4451\n",
      "Validation Loss: 176.4210\n",
      "NME: 0.0910\n",
      "Epoch [205/300], Loss: 63.3670\n",
      "Validation Loss: 166.7489\n",
      "NME: 0.0872\n",
      "Epoch [206/300], Loss: 66.1109\n",
      "Validation Loss: 178.1975\n",
      "NME: 0.0881\n",
      "Epoch [207/300], Loss: 62.2716\n",
      "Validation Loss: 179.4802\n",
      "NME: 0.0894\n",
      "Epoch [208/300], Loss: 64.5718\n",
      "Validation Loss: 160.5514\n",
      "NME: 0.0909\n",
      "Epoch [209/300], Loss: 63.9597\n",
      "Validation Loss: 167.6224\n",
      "NME: 0.0913\n",
      "Epoch [210/300], Loss: 59.8948\n",
      "Validation Loss: 168.4594\n",
      "NME: 0.0883\n",
      "Epoch [211/300], Loss: 58.1676\n",
      "Validation Loss: 169.8053\n",
      "NME: 0.0909\n",
      "Epoch [212/300], Loss: 64.5649\n",
      "Validation Loss: 166.6656\n",
      "NME: 0.0919\n",
      "Epoch [213/300], Loss: 63.5966\n",
      "Validation Loss: 165.9209\n",
      "NME: 0.0874\n",
      "Epoch [214/300], Loss: 65.4477\n",
      "Validation Loss: 172.9134\n",
      "NME: 0.0873\n",
      "Epoch [215/300], Loss: 64.4250\n",
      "Validation Loss: 171.4794\n",
      "NME: 0.0879\n",
      "Epoch [216/300], Loss: 57.7718\n",
      "Validation Loss: 170.4674\n",
      "NME: 0.0883\n",
      "Epoch [217/300], Loss: 59.2694\n",
      "Validation Loss: 167.5881\n",
      "NME: 0.0901\n",
      "Epoch [218/300], Loss: 60.4161\n",
      "Validation Loss: 174.7463\n",
      "NME: 0.0889\n",
      "Epoch [219/300], Loss: 57.7107\n",
      "Validation Loss: 164.0071\n",
      "NME: 0.0861\n",
      "Epoch [220/300], Loss: 57.2289\n",
      "Validation Loss: 172.5534\n",
      "NME: 0.0890\n",
      "Epoch [221/300], Loss: 59.9641\n",
      "Validation Loss: 157.6256\n",
      "NME: 0.0893\n",
      "Epoch [222/300], Loss: 56.1176\n",
      "Validation Loss: 168.8240\n",
      "NME: 0.0908\n",
      "Epoch [223/300], Loss: 56.7991\n",
      "Validation Loss: 163.6047\n",
      "NME: 0.0879\n",
      "Epoch [224/300], Loss: 57.6907\n",
      "Validation Loss: 158.8184\n",
      "NME: 0.0860\n",
      "Epoch [225/300], Loss: 55.9130\n",
      "Validation Loss: 170.7674\n",
      "NME: 0.0899\n",
      "Epoch [226/300], Loss: 56.5223\n",
      "Validation Loss: 169.0510\n",
      "NME: 0.0886\n",
      "Epoch [227/300], Loss: 67.2056\n",
      "Validation Loss: 183.1353\n",
      "NME: 0.0881\n",
      "Epoch [228/300], Loss: 63.0244\n",
      "Validation Loss: 172.6637\n",
      "NME: 0.0919\n",
      "Epoch [229/300], Loss: 58.2209\n",
      "Validation Loss: 170.3679\n",
      "NME: 0.0882\n",
      "Epoch [230/300], Loss: 64.0258\n",
      "Validation Loss: 174.5779\n",
      "NME: 0.0948\n",
      "Epoch [231/300], Loss: 74.6666\n",
      "Validation Loss: 210.4049\n",
      "NME: 0.1010\n",
      "Epoch [232/300], Loss: 98.4258\n",
      "Validation Loss: 184.0851\n",
      "NME: 0.0946\n",
      "Epoch [233/300], Loss: 67.9736\n",
      "Validation Loss: 185.5856\n",
      "NME: 0.0947\n",
      "Epoch [234/300], Loss: 81.4344\n",
      "Validation Loss: 186.0312\n",
      "NME: 0.0933\n",
      "Epoch [235/300], Loss: 68.0825\n",
      "Validation Loss: 174.9288\n",
      "NME: 0.0893\n",
      "Epoch [236/300], Loss: 59.0269\n",
      "Validation Loss: 163.4462\n",
      "NME: 0.0870\n",
      "Epoch [237/300], Loss: 60.6037\n",
      "Validation Loss: 163.6064\n",
      "NME: 0.0870\n",
      "Epoch [238/300], Loss: 58.1097\n",
      "Validation Loss: 166.9538\n",
      "NME: 0.0864\n",
      "Epoch [239/300], Loss: 56.9241\n",
      "Validation Loss: 185.2820\n",
      "NME: 0.0886\n",
      "Epoch [240/300], Loss: 53.5064\n",
      "Validation Loss: 164.4571\n",
      "NME: 0.0875\n",
      "Epoch [241/300], Loss: 54.1857\n",
      "Validation Loss: 160.5382\n",
      "NME: 0.0853\n",
      "Epoch [242/300], Loss: 52.9654\n",
      "Validation Loss: 160.5147\n",
      "NME: 0.0866\n",
      "Epoch [243/300], Loss: 52.5062\n",
      "Validation Loss: 160.5614\n",
      "NME: 0.0863\n",
      "Epoch [244/300], Loss: 46.9048\n",
      "Validation Loss: 160.6975\n",
      "NME: 0.0877\n",
      "Epoch [245/300], Loss: 51.9258\n",
      "Validation Loss: 162.4567\n",
      "NME: 0.0867\n",
      "Epoch [246/300], Loss: 48.2569\n",
      "Validation Loss: 150.3222\n",
      "NME: 0.0860\n",
      "Best model saved at epoch 246 with val_loss 150.3222\n",
      "Epoch [247/300], Loss: 51.1577\n",
      "Validation Loss: 150.3473\n",
      "NME: 0.0867\n",
      "Epoch [248/300], Loss: 50.9185\n",
      "Validation Loss: 168.3366\n",
      "NME: 0.0885\n",
      "Epoch [249/300], Loss: 50.3369\n",
      "Validation Loss: 163.5884\n",
      "NME: 0.0876\n",
      "Epoch [250/300], Loss: 50.3222\n",
      "Validation Loss: 160.5152\n",
      "NME: 0.0890\n",
      "Epoch [251/300], Loss: 55.0497\n",
      "Validation Loss: 167.0998\n",
      "NME: 0.0887\n",
      "Epoch [252/300], Loss: 52.9951\n",
      "Validation Loss: 148.4039\n",
      "NME: 0.0850\n",
      "Best model saved at epoch 252 with val_loss 148.4039\n",
      "Epoch [253/300], Loss: 50.2419\n",
      "Validation Loss: 155.5810\n",
      "NME: 0.0862\n",
      "Epoch [254/300], Loss: 50.9386\n",
      "Validation Loss: 159.6290\n",
      "NME: 0.0870\n",
      "Epoch [255/300], Loss: 56.1279\n",
      "Validation Loss: 160.9590\n",
      "NME: 0.0873\n",
      "Epoch [256/300], Loss: 55.0132\n",
      "Validation Loss: 165.6972\n",
      "NME: 0.0900\n",
      "Epoch [257/300], Loss: 61.4855\n",
      "Validation Loss: 157.1364\n",
      "NME: 0.0885\n",
      "Epoch [258/300], Loss: 54.3471\n",
      "Validation Loss: 156.8597\n",
      "NME: 0.0885\n",
      "Epoch [259/300], Loss: 49.8731\n",
      "Validation Loss: 163.0817\n",
      "NME: 0.0876\n",
      "Epoch [260/300], Loss: 52.1315\n",
      "Validation Loss: 150.8143\n",
      "NME: 0.0856\n",
      "Epoch [261/300], Loss: 54.8110\n",
      "Validation Loss: 163.9911\n",
      "NME: 0.0876\n",
      "Epoch [262/300], Loss: 52.0973\n",
      "Validation Loss: 155.5913\n",
      "NME: 0.0847\n",
      "Epoch [263/300], Loss: 52.8504\n",
      "Validation Loss: 156.8514\n",
      "NME: 0.0875\n",
      "Epoch [264/300], Loss: 52.7098\n",
      "Validation Loss: 156.7854\n",
      "NME: 0.0860\n",
      "Epoch [265/300], Loss: 49.7593\n",
      "Validation Loss: 147.4191\n",
      "NME: 0.0853\n",
      "Best model saved at epoch 265 with val_loss 147.4191\n",
      "Epoch [266/300], Loss: 47.7854\n",
      "Validation Loss: 154.8131\n",
      "NME: 0.0857\n",
      "Epoch [267/300], Loss: 48.7820\n",
      "Validation Loss: 157.3509\n",
      "NME: 0.0863\n",
      "Epoch [268/300], Loss: 48.6117\n",
      "Validation Loss: 152.0448\n",
      "NME: 0.0839\n",
      "Epoch [269/300], Loss: 46.0307\n",
      "Validation Loss: 150.9133\n",
      "NME: 0.0864\n",
      "Epoch [270/300], Loss: 50.0994\n",
      "Validation Loss: 166.3722\n",
      "NME: 0.0872\n",
      "Epoch [271/300], Loss: 48.6382\n",
      "Validation Loss: 152.7667\n",
      "NME: 0.0863\n",
      "Epoch [272/300], Loss: 50.6362\n",
      "Validation Loss: 156.7336\n",
      "NME: 0.0874\n",
      "Epoch [273/300], Loss: 52.6632\n",
      "Validation Loss: 150.5109\n",
      "NME: 0.0835\n",
      "Epoch [274/300], Loss: 51.8780\n",
      "Validation Loss: 158.4227\n",
      "NME: 0.0835\n",
      "Epoch [275/300], Loss: 75.5608\n",
      "Validation Loss: 192.5191\n",
      "NME: 0.0979\n",
      "Epoch [276/300], Loss: 83.6176\n",
      "Validation Loss: 211.1255\n",
      "NME: 0.1113\n",
      "Epoch [277/300], Loss: 81.3724\n",
      "Validation Loss: 208.7429\n",
      "NME: 0.0973\n",
      "Epoch [278/300], Loss: 69.4191\n",
      "Validation Loss: 180.5693\n",
      "NME: 0.0942\n",
      "Epoch [279/300], Loss: 58.6645\n",
      "Validation Loss: 152.8274\n",
      "NME: 0.0867\n",
      "Epoch [280/300], Loss: 52.3468\n",
      "Validation Loss: 161.6327\n",
      "NME: 0.0867\n",
      "Epoch [281/300], Loss: 48.0046\n",
      "Validation Loss: 155.6232\n",
      "NME: 0.0852\n",
      "Epoch [282/300], Loss: 49.9963\n",
      "Validation Loss: 164.7427\n",
      "NME: 0.0852\n",
      "Epoch [283/300], Loss: 47.0915\n",
      "Validation Loss: 160.9705\n",
      "NME: 0.0880\n",
      "Epoch [284/300], Loss: 45.3172\n",
      "Validation Loss: 160.0061\n",
      "NME: 0.0847\n",
      "Epoch [285/300], Loss: 44.0083\n",
      "Validation Loss: 162.8381\n",
      "NME: 0.0862\n",
      "Epoch [286/300], Loss: 44.4249\n",
      "Validation Loss: 163.6282\n",
      "NME: 0.0860\n",
      "Epoch [287/300], Loss: 43.3949\n",
      "Validation Loss: 150.1967\n",
      "NME: 0.0849\n",
      "Epoch [288/300], Loss: 42.5488\n",
      "Validation Loss: 154.5303\n",
      "NME: 0.0848\n",
      "Epoch [289/300], Loss: 45.8592\n",
      "Validation Loss: 158.8302\n",
      "NME: 0.0850\n",
      "Epoch [290/300], Loss: 46.3775\n",
      "Validation Loss: 152.4411\n",
      "NME: 0.0834\n",
      "Epoch [291/300], Loss: 48.7136\n",
      "Validation Loss: 167.8990\n",
      "NME: 0.0858\n",
      "Epoch [292/300], Loss: 44.8895\n",
      "Validation Loss: 156.4861\n",
      "NME: 0.0843\n",
      "Epoch [293/300], Loss: 43.5668\n",
      "Validation Loss: 154.1689\n",
      "NME: 0.0836\n",
      "Epoch [294/300], Loss: 43.3548\n",
      "Validation Loss: 150.7591\n",
      "NME: 0.0821\n",
      "Epoch [295/300], Loss: 42.9219\n",
      "Validation Loss: 158.5403\n",
      "NME: 0.0839\n",
      "Epoch [296/300], Loss: 41.2759\n",
      "Validation Loss: 157.2704\n",
      "NME: 0.0844\n",
      "Epoch [297/300], Loss: 45.2052\n",
      "Validation Loss: 146.6767\n",
      "NME: 0.0833\n",
      "Best model saved at epoch 297 with val_loss 146.6767\n",
      "Epoch [298/300], Loss: 54.3144\n",
      "Validation Loss: 172.2939\n",
      "NME: 0.0840\n",
      "Epoch [299/300], Loss: 46.8239\n",
      "Validation Loss: 159.0455\n",
      "NME: 0.0849\n",
      "Epoch [300/300], Loss: 45.2633\n",
      "Validation Loss: 158.2663\n",
      "NME: 0.0837\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "oreja_izq = [27, 28, 29, 30, 31]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EarLeftDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_oreja_izq = calcular_centro_region(landmarks, oreja_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_oreja_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la oreja izquierda\n",
    "        ear_left_points = np.array([landmarks[i] for i in oreja_izq], dtype=np.float32)\n",
    "        ear_left_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(ear_left_points), 1))\n",
    "        points_ones = np.hstack([ear_left_points, ones])\n",
    "        ear_left_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la oreja izquierda\n",
    "        centro_x, centro_y = calcular_centro_region(ear_left_points_rotated, range(len(oreja_izq)))\n",
    "\n",
    "        # Definir los límites del recorte de 112x112 píxeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_ear = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_ear, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la oreja izquierda al nuevo recorte\n",
    "        ear_left_points_adjusted = [(p[0] - x1, p[1] - y1) for p in ear_left_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        ear_left_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in ear_left_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=ear_left_points_scaled)\n",
    "            image = augmented['image']\n",
    "            ear_left_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(ear_left_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EarLeftDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EarLeftDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EarLeft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EarLeft, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(oreja_izq) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EarLeft().cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para oreja izquierda)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, ear_left_points, _, _, _ in train_dataloader:\n",
    "            images, ear_left_points = images.cuda(), ear_left_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ear_left_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_ear_left_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_ear_left_points = val_images.cuda(), val_ear_left_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_ear_left_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_ear_left_points.cpu().numpy().reshape(-1, len(oreja_izq), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(oreja_izq), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(oreja_izq))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EarLeftLandmarks V4.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 15523.8694\n",
      "Validation Loss: 13076.5193\n",
      "NME: 1.1804\n",
      "Best model saved at epoch 1 with val_loss 13076.5193\n",
      "Epoch [2/300], Loss: 7981.0826\n",
      "Validation Loss: 2812.2768\n",
      "NME: 0.4925\n",
      "Best model saved at epoch 2 with val_loss 2812.2768\n",
      "Epoch [3/300], Loss: 1751.7138\n",
      "Validation Loss: 1183.1187\n",
      "NME: 0.2623\n",
      "Best model saved at epoch 3 with val_loss 1183.1187\n",
      "Epoch [4/300], Loss: 1340.1935\n",
      "Validation Loss: 1143.6206\n",
      "NME: 0.2696\n",
      "Best model saved at epoch 4 with val_loss 1143.6206\n",
      "Epoch [5/300], Loss: 1315.2226\n",
      "Validation Loss: 1111.7539\n",
      "NME: 0.2731\n",
      "Best model saved at epoch 5 with val_loss 1111.7539\n",
      "Epoch [6/300], Loss: 1287.6791\n",
      "Validation Loss: 1119.6959\n",
      "NME: 0.2646\n",
      "Epoch [7/300], Loss: 1273.9931\n",
      "Validation Loss: 1100.1614\n",
      "NME: 0.2676\n",
      "Best model saved at epoch 7 with val_loss 1100.1614\n",
      "Epoch [8/300], Loss: 1260.6853\n",
      "Validation Loss: 1101.2115\n",
      "NME: 0.2600\n",
      "Epoch [9/300], Loss: 1244.1019\n",
      "Validation Loss: 1089.7598\n",
      "NME: 0.2630\n",
      "Best model saved at epoch 9 with val_loss 1089.7598\n",
      "Epoch [10/300], Loss: 1228.8579\n",
      "Validation Loss: 1097.7408\n",
      "NME: 0.2648\n",
      "Epoch [11/300], Loss: 1218.4794\n",
      "Validation Loss: 1088.6065\n",
      "NME: 0.2666\n",
      "Best model saved at epoch 11 with val_loss 1088.6065\n",
      "Epoch [12/300], Loss: 1215.9214\n",
      "Validation Loss: 1081.3655\n",
      "NME: 0.2658\n",
      "Best model saved at epoch 12 with val_loss 1081.3655\n",
      "Epoch [13/300], Loss: 1215.4873\n",
      "Validation Loss: 1073.1811\n",
      "NME: 0.2643\n",
      "Best model saved at epoch 13 with val_loss 1073.1811\n",
      "Epoch [14/300], Loss: 1190.8414\n",
      "Validation Loss: 1053.9895\n",
      "NME: 0.2622\n",
      "Best model saved at epoch 14 with val_loss 1053.9895\n",
      "Epoch [15/300], Loss: 1157.7254\n",
      "Validation Loss: 1029.6413\n",
      "NME: 0.2576\n",
      "Best model saved at epoch 15 with val_loss 1029.6413\n",
      "Epoch [16/300], Loss: 1127.4763\n",
      "Validation Loss: 990.1275\n",
      "NME: 0.2510\n",
      "Best model saved at epoch 16 with val_loss 990.1275\n",
      "Epoch [17/300], Loss: 1072.4455\n",
      "Validation Loss: 939.8675\n",
      "NME: 0.2407\n",
      "Best model saved at epoch 17 with val_loss 939.8675\n",
      "Epoch [18/300], Loss: 982.5775\n",
      "Validation Loss: 758.5689\n",
      "NME: 0.2152\n",
      "Best model saved at epoch 18 with val_loss 758.5689\n",
      "Epoch [19/300], Loss: 866.6560\n",
      "Validation Loss: 616.5823\n",
      "NME: 0.1882\n",
      "Best model saved at epoch 19 with val_loss 616.5823\n",
      "Epoch [20/300], Loss: 740.3629\n",
      "Validation Loss: 578.1673\n",
      "NME: 0.1765\n",
      "Best model saved at epoch 20 with val_loss 578.1673\n",
      "Epoch [21/300], Loss: 706.3344\n",
      "Validation Loss: 491.1022\n",
      "NME: 0.1719\n",
      "Best model saved at epoch 21 with val_loss 491.1022\n",
      "Epoch [22/300], Loss: 656.3727\n",
      "Validation Loss: 443.3943\n",
      "NME: 0.1560\n",
      "Best model saved at epoch 22 with val_loss 443.3943\n",
      "Epoch [23/300], Loss: 655.7161\n",
      "Validation Loss: 427.9364\n",
      "NME: 0.1541\n",
      "Best model saved at epoch 23 with val_loss 427.9364\n",
      "Epoch [24/300], Loss: 579.0962\n",
      "Validation Loss: 415.0390\n",
      "NME: 0.1505\n",
      "Best model saved at epoch 24 with val_loss 415.0390\n",
      "Epoch [25/300], Loss: 554.3493\n",
      "Validation Loss: 449.9627\n",
      "NME: 0.1583\n",
      "Epoch [26/300], Loss: 569.7101\n",
      "Validation Loss: 411.1414\n",
      "NME: 0.1520\n",
      "Best model saved at epoch 26 with val_loss 411.1414\n",
      "Epoch [27/300], Loss: 564.3004\n",
      "Validation Loss: 417.2271\n",
      "NME: 0.1519\n",
      "Epoch [28/300], Loss: 558.9426\n",
      "Validation Loss: 399.5385\n",
      "NME: 0.1489\n",
      "Best model saved at epoch 28 with val_loss 399.5385\n",
      "Epoch [29/300], Loss: 588.0869\n",
      "Validation Loss: 409.1949\n",
      "NME: 0.1522\n",
      "Epoch [30/300], Loss: 540.2410\n",
      "Validation Loss: 399.4638\n",
      "NME: 0.1476\n",
      "Best model saved at epoch 30 with val_loss 399.4638\n",
      "Epoch [31/300], Loss: 552.9545\n",
      "Validation Loss: 410.4207\n",
      "NME: 0.1503\n",
      "Epoch [32/300], Loss: 539.1631\n",
      "Validation Loss: 389.9663\n",
      "NME: 0.1473\n",
      "Best model saved at epoch 32 with val_loss 389.9663\n",
      "Epoch [33/300], Loss: 539.6783\n",
      "Validation Loss: 420.9236\n",
      "NME: 0.1497\n",
      "Epoch [34/300], Loss: 527.4034\n",
      "Validation Loss: 392.9641\n",
      "NME: 0.1495\n",
      "Epoch [35/300], Loss: 533.6057\n",
      "Validation Loss: 410.9706\n",
      "NME: 0.1520\n",
      "Epoch [36/300], Loss: 548.2334\n",
      "Validation Loss: 409.5366\n",
      "NME: 0.1491\n",
      "Epoch [37/300], Loss: 513.0648\n",
      "Validation Loss: 415.8140\n",
      "NME: 0.1486\n",
      "Epoch [38/300], Loss: 530.7902\n",
      "Validation Loss: 402.0204\n",
      "NME: 0.1490\n",
      "Epoch [39/300], Loss: 505.7470\n",
      "Validation Loss: 397.7291\n",
      "NME: 0.1524\n",
      "Epoch [40/300], Loss: 515.3634\n",
      "Validation Loss: 373.5732\n",
      "NME: 0.1464\n",
      "Best model saved at epoch 40 with val_loss 373.5732\n",
      "Epoch [41/300], Loss: 517.3691\n",
      "Validation Loss: 392.7565\n",
      "NME: 0.1491\n",
      "Epoch [42/300], Loss: 502.3189\n",
      "Validation Loss: 380.8916\n",
      "NME: 0.1476\n",
      "Epoch [43/300], Loss: 513.5783\n",
      "Validation Loss: 405.4475\n",
      "NME: 0.1552\n",
      "Epoch [44/300], Loss: 504.9739\n",
      "Validation Loss: 379.8157\n",
      "NME: 0.1445\n",
      "Epoch [45/300], Loss: 490.5972\n",
      "Validation Loss: 381.9513\n",
      "NME: 0.1459\n",
      "Epoch [46/300], Loss: 464.7547\n",
      "Validation Loss: 380.0349\n",
      "NME: 0.1445\n",
      "Epoch [47/300], Loss: 488.4258\n",
      "Validation Loss: 418.2548\n",
      "NME: 0.1559\n",
      "Epoch [48/300], Loss: 467.1562\n",
      "Validation Loss: 395.2366\n",
      "NME: 0.1489\n",
      "Epoch [49/300], Loss: 413.0741\n",
      "Validation Loss: 355.2660\n",
      "NME: 0.1484\n",
      "Best model saved at epoch 49 with val_loss 355.2660\n",
      "Epoch [50/300], Loss: 380.1861\n",
      "Validation Loss: 346.4614\n",
      "NME: 0.1387\n",
      "Best model saved at epoch 50 with val_loss 346.4614\n",
      "Epoch [51/300], Loss: 349.8393\n",
      "Validation Loss: 326.6413\n",
      "NME: 0.1360\n",
      "Best model saved at epoch 51 with val_loss 326.6413\n",
      "Epoch [52/300], Loss: 351.1855\n",
      "Validation Loss: 334.8377\n",
      "NME: 0.1369\n",
      "Epoch [53/300], Loss: 319.3471\n",
      "Validation Loss: 332.5620\n",
      "NME: 0.1381\n",
      "Epoch [54/300], Loss: 329.0662\n",
      "Validation Loss: 345.1488\n",
      "NME: 0.1411\n",
      "Epoch [55/300], Loss: 321.1381\n",
      "Validation Loss: 366.4203\n",
      "NME: 0.1525\n",
      "Epoch [56/300], Loss: 323.6749\n",
      "Validation Loss: 373.6795\n",
      "NME: 0.1405\n",
      "Epoch [57/300], Loss: 317.9007\n",
      "Validation Loss: 338.2397\n",
      "NME: 0.1399\n",
      "Epoch [58/300], Loss: 278.5331\n",
      "Validation Loss: 336.8884\n",
      "NME: 0.1359\n",
      "Epoch [59/300], Loss: 266.8764\n",
      "Validation Loss: 309.2447\n",
      "NME: 0.1326\n",
      "Best model saved at epoch 59 with val_loss 309.2447\n",
      "Epoch [60/300], Loss: 269.3755\n",
      "Validation Loss: 378.5259\n",
      "NME: 0.1420\n",
      "Epoch [61/300], Loss: 261.8942\n",
      "Validation Loss: 328.6986\n",
      "NME: 0.1389\n",
      "Epoch [62/300], Loss: 250.7390\n",
      "Validation Loss: 314.7185\n",
      "NME: 0.1331\n",
      "Epoch [63/300], Loss: 259.1808\n",
      "Validation Loss: 321.7481\n",
      "NME: 0.1357\n",
      "Epoch [64/300], Loss: 245.8373\n",
      "Validation Loss: 335.6586\n",
      "NME: 0.1371\n",
      "Epoch [65/300], Loss: 245.1226\n",
      "Validation Loss: 305.3559\n",
      "NME: 0.1314\n",
      "Best model saved at epoch 65 with val_loss 305.3559\n",
      "Epoch [66/300], Loss: 243.7279\n",
      "Validation Loss: 319.7163\n",
      "NME: 0.1331\n",
      "Epoch [67/300], Loss: 240.3686\n",
      "Validation Loss: 328.1520\n",
      "NME: 0.1345\n",
      "Epoch [68/300], Loss: 247.0193\n",
      "Validation Loss: 352.5033\n",
      "NME: 0.1358\n",
      "Epoch [69/300], Loss: 236.8722\n",
      "Validation Loss: 325.6213\n",
      "NME: 0.1337\n",
      "Epoch [70/300], Loss: 243.0169\n",
      "Validation Loss: 322.7522\n",
      "NME: 0.1366\n",
      "Epoch [71/300], Loss: 236.7687\n",
      "Validation Loss: 314.4519\n",
      "NME: 0.1326\n",
      "Epoch [72/300], Loss: 235.9761\n",
      "Validation Loss: 328.3454\n",
      "NME: 0.1323\n",
      "Epoch [73/300], Loss: 223.4571\n",
      "Validation Loss: 288.7716\n",
      "NME: 0.1304\n",
      "Best model saved at epoch 73 with val_loss 288.7716\n",
      "Epoch [74/300], Loss: 221.3321\n",
      "Validation Loss: 302.5914\n",
      "NME: 0.1341\n",
      "Epoch [75/300], Loss: 244.1906\n",
      "Validation Loss: 341.4991\n",
      "NME: 0.1399\n",
      "Epoch [76/300], Loss: 235.1983\n",
      "Validation Loss: 338.7223\n",
      "NME: 0.1345\n",
      "Epoch [77/300], Loss: 227.0031\n",
      "Validation Loss: 304.0093\n",
      "NME: 0.1323\n",
      "Epoch [78/300], Loss: 218.8403\n",
      "Validation Loss: 311.8700\n",
      "NME: 0.1313\n",
      "Epoch [79/300], Loss: 226.1159\n",
      "Validation Loss: 319.9746\n",
      "NME: 0.1307\n",
      "Epoch [80/300], Loss: 222.5548\n",
      "Validation Loss: 303.7821\n",
      "NME: 0.1303\n",
      "Epoch [81/300], Loss: 218.8186\n",
      "Validation Loss: 327.8065\n",
      "NME: 0.1318\n",
      "Epoch [82/300], Loss: 221.7034\n",
      "Validation Loss: 308.8228\n",
      "NME: 0.1291\n",
      "Epoch [83/300], Loss: 215.4907\n",
      "Validation Loss: 301.2865\n",
      "NME: 0.1241\n",
      "Epoch [84/300], Loss: 218.7038\n",
      "Validation Loss: 290.3823\n",
      "NME: 0.1248\n",
      "Epoch [85/300], Loss: 206.9348\n",
      "Validation Loss: 298.1249\n",
      "NME: 0.1227\n",
      "Epoch [86/300], Loss: 201.5360\n",
      "Validation Loss: 303.1438\n",
      "NME: 0.1219\n",
      "Epoch [87/300], Loss: 200.6360\n",
      "Validation Loss: 294.4343\n",
      "NME: 0.1199\n",
      "Epoch [88/300], Loss: 213.0423\n",
      "Validation Loss: 285.5546\n",
      "NME: 0.1259\n",
      "Best model saved at epoch 88 with val_loss 285.5546\n",
      "Epoch [89/300], Loss: 206.3753\n",
      "Validation Loss: 304.3547\n",
      "NME: 0.1284\n",
      "Epoch [90/300], Loss: 207.7673\n",
      "Validation Loss: 280.8008\n",
      "NME: 0.1211\n",
      "Best model saved at epoch 90 with val_loss 280.8008\n",
      "Epoch [91/300], Loss: 194.7744\n",
      "Validation Loss: 303.0952\n",
      "NME: 0.1196\n",
      "Epoch [92/300], Loss: 199.7856\n",
      "Validation Loss: 314.4449\n",
      "NME: 0.1244\n",
      "Epoch [93/300], Loss: 189.4320\n",
      "Validation Loss: 289.1096\n",
      "NME: 0.1179\n",
      "Epoch [94/300], Loss: 188.1652\n",
      "Validation Loss: 303.3726\n",
      "NME: 0.1201\n",
      "Epoch [95/300], Loss: 184.5449\n",
      "Validation Loss: 285.6981\n",
      "NME: 0.1178\n",
      "Epoch [96/300], Loss: 187.4439\n",
      "Validation Loss: 311.6594\n",
      "NME: 0.1191\n",
      "Epoch [97/300], Loss: 202.6769\n",
      "Validation Loss: 305.9320\n",
      "NME: 0.1240\n",
      "Epoch [98/300], Loss: 206.5482\n",
      "Validation Loss: 315.3123\n",
      "NME: 0.1209\n",
      "Epoch [99/300], Loss: 195.2088\n",
      "Validation Loss: 297.7613\n",
      "NME: 0.1224\n",
      "Epoch [100/300], Loss: 189.2132\n",
      "Validation Loss: 279.3805\n",
      "NME: 0.1170\n",
      "Best model saved at epoch 100 with val_loss 279.3805\n",
      "Epoch [101/300], Loss: 183.0947\n",
      "Validation Loss: 289.5083\n",
      "NME: 0.1192\n",
      "Epoch [102/300], Loss: 181.0781\n",
      "Validation Loss: 286.9320\n",
      "NME: 0.1167\n",
      "Epoch [103/300], Loss: 176.3774\n",
      "Validation Loss: 276.0040\n",
      "NME: 0.1161\n",
      "Best model saved at epoch 103 with val_loss 276.0040\n",
      "Epoch [104/300], Loss: 170.5230\n",
      "Validation Loss: 272.7012\n",
      "NME: 0.1131\n",
      "Best model saved at epoch 104 with val_loss 272.7012\n",
      "Epoch [105/300], Loss: 178.1032\n",
      "Validation Loss: 271.5358\n",
      "NME: 0.1147\n",
      "Best model saved at epoch 105 with val_loss 271.5358\n",
      "Epoch [106/300], Loss: 170.9287\n",
      "Validation Loss: 283.7092\n",
      "NME: 0.1130\n",
      "Epoch [107/300], Loss: 176.0629\n",
      "Validation Loss: 272.8369\n",
      "NME: 0.1131\n",
      "Epoch [108/300], Loss: 192.1817\n",
      "Validation Loss: 275.5937\n",
      "NME: 0.1120\n",
      "Epoch [109/300], Loss: 167.6414\n",
      "Validation Loss: 259.2488\n",
      "NME: 0.1088\n",
      "Best model saved at epoch 109 with val_loss 259.2488\n",
      "Epoch [110/300], Loss: 161.7655\n",
      "Validation Loss: 307.0575\n",
      "NME: 0.1139\n",
      "Epoch [111/300], Loss: 171.9615\n",
      "Validation Loss: 280.7303\n",
      "NME: 0.1105\n",
      "Epoch [112/300], Loss: 167.0917\n",
      "Validation Loss: 276.2076\n",
      "NME: 0.1086\n",
      "Epoch [113/300], Loss: 165.5118\n",
      "Validation Loss: 298.7553\n",
      "NME: 0.1083\n",
      "Epoch [114/300], Loss: 163.0625\n",
      "Validation Loss: 255.0092\n",
      "NME: 0.1025\n",
      "Best model saved at epoch 114 with val_loss 255.0092\n",
      "Epoch [115/300], Loss: 147.6787\n",
      "Validation Loss: 243.5644\n",
      "NME: 0.1022\n",
      "Best model saved at epoch 115 with val_loss 243.5644\n",
      "Epoch [116/300], Loss: 135.0486\n",
      "Validation Loss: 251.0461\n",
      "NME: 0.1024\n",
      "Epoch [117/300], Loss: 131.8472\n",
      "Validation Loss: 225.3713\n",
      "NME: 0.0977\n",
      "Best model saved at epoch 117 with val_loss 225.3713\n",
      "Epoch [118/300], Loss: 129.9951\n",
      "Validation Loss: 234.1661\n",
      "NME: 0.1025\n",
      "Epoch [119/300], Loss: 134.5323\n",
      "Validation Loss: 228.6786\n",
      "NME: 0.1002\n",
      "Epoch [120/300], Loss: 124.0534\n",
      "Validation Loss: 234.0418\n",
      "NME: 0.0980\n",
      "Epoch [121/300], Loss: 128.6501\n",
      "Validation Loss: 215.8640\n",
      "NME: 0.0962\n",
      "Best model saved at epoch 121 with val_loss 215.8640\n",
      "Epoch [122/300], Loss: 124.5715\n",
      "Validation Loss: 208.5406\n",
      "NME: 0.0970\n",
      "Best model saved at epoch 122 with val_loss 208.5406\n",
      "Epoch [123/300], Loss: 116.9330\n",
      "Validation Loss: 202.3767\n",
      "NME: 0.0943\n",
      "Best model saved at epoch 123 with val_loss 202.3767\n",
      "Epoch [124/300], Loss: 117.0969\n",
      "Validation Loss: 218.8111\n",
      "NME: 0.0990\n",
      "Epoch [125/300], Loss: 115.0357\n",
      "Validation Loss: 228.3079\n",
      "NME: 0.0951\n",
      "Epoch [126/300], Loss: 124.3958\n",
      "Validation Loss: 221.1359\n",
      "NME: 0.0965\n",
      "Epoch [127/300], Loss: 114.5190\n",
      "Validation Loss: 224.5206\n",
      "NME: 0.0970\n",
      "Epoch [128/300], Loss: 119.9307\n",
      "Validation Loss: 239.6411\n",
      "NME: 0.0987\n",
      "Epoch [129/300], Loss: 112.7277\n",
      "Validation Loss: 227.7353\n",
      "NME: 0.0985\n",
      "Epoch [130/300], Loss: 103.2890\n",
      "Validation Loss: 220.8833\n",
      "NME: 0.0974\n",
      "Epoch [131/300], Loss: 105.5975\n",
      "Validation Loss: 213.2867\n",
      "NME: 0.0936\n",
      "Epoch [132/300], Loss: 98.9850\n",
      "Validation Loss: 212.4175\n",
      "NME: 0.0935\n",
      "Epoch [133/300], Loss: 97.1953\n",
      "Validation Loss: 207.3982\n",
      "NME: 0.0909\n",
      "Epoch [134/300], Loss: 106.2126\n",
      "Validation Loss: 212.6695\n",
      "NME: 0.0941\n",
      "Epoch [135/300], Loss: 118.9357\n",
      "Validation Loss: 230.6827\n",
      "NME: 0.0942\n",
      "Epoch [136/300], Loss: 117.0239\n",
      "Validation Loss: 236.1189\n",
      "NME: 0.0966\n",
      "Epoch [137/300], Loss: 109.5347\n",
      "Validation Loss: 219.2687\n",
      "NME: 0.0936\n",
      "Epoch [138/300], Loss: 138.7927\n",
      "Validation Loss: 282.3778\n",
      "NME: 0.1086\n",
      "Epoch [139/300], Loss: 133.6740\n",
      "Validation Loss: 251.2126\n",
      "NME: 0.1011\n",
      "Epoch [140/300], Loss: 113.4784\n",
      "Validation Loss: 231.8880\n",
      "NME: 0.0974\n",
      "Epoch [141/300], Loss: 101.9317\n",
      "Validation Loss: 249.8093\n",
      "NME: 0.0966\n",
      "Epoch [142/300], Loss: 115.0071\n",
      "Validation Loss: 242.3088\n",
      "NME: 0.0981\n",
      "Epoch [143/300], Loss: 102.6701\n",
      "Validation Loss: 226.7817\n",
      "NME: 0.0936\n",
      "Epoch [144/300], Loss: 98.3067\n",
      "Validation Loss: 222.8882\n",
      "NME: 0.0945\n",
      "Epoch [145/300], Loss: 101.1165\n",
      "Validation Loss: 232.0656\n",
      "NME: 0.0954\n",
      "Epoch [146/300], Loss: 102.2463\n",
      "Validation Loss: 214.5952\n",
      "NME: 0.0919\n",
      "Epoch [147/300], Loss: 99.2428\n",
      "Validation Loss: 231.5163\n",
      "NME: 0.0939\n",
      "Epoch [148/300], Loss: 101.5797\n",
      "Validation Loss: 226.3673\n",
      "NME: 0.0932\n",
      "Epoch [149/300], Loss: 94.2089\n",
      "Validation Loss: 214.5391\n",
      "NME: 0.0922\n",
      "Epoch [150/300], Loss: 94.6729\n",
      "Validation Loss: 229.1523\n",
      "NME: 0.0946\n",
      "Epoch [151/300], Loss: 89.4894\n",
      "Validation Loss: 212.2844\n",
      "NME: 0.0927\n",
      "Epoch [152/300], Loss: 87.4775\n",
      "Validation Loss: 218.2229\n",
      "NME: 0.0907\n",
      "Epoch [153/300], Loss: 93.2191\n",
      "Validation Loss: 220.6090\n",
      "NME: 0.0936\n",
      "Epoch [154/300], Loss: 95.6339\n",
      "Validation Loss: 214.5346\n",
      "NME: 0.0923\n",
      "Epoch [155/300], Loss: 90.6762\n",
      "Validation Loss: 214.9095\n",
      "NME: 0.0961\n",
      "Epoch [156/300], Loss: 83.5447\n",
      "Validation Loss: 201.8663\n",
      "NME: 0.0906\n",
      "Best model saved at epoch 156 with val_loss 201.8663\n",
      "Epoch [157/300], Loss: 85.5547\n",
      "Validation Loss: 203.2164\n",
      "NME: 0.0898\n",
      "Epoch [158/300], Loss: 87.3999\n",
      "Validation Loss: 215.0640\n",
      "NME: 0.0902\n",
      "Epoch [159/300], Loss: 80.8162\n",
      "Validation Loss: 214.8631\n",
      "NME: 0.0910\n",
      "Epoch [160/300], Loss: 78.2236\n",
      "Validation Loss: 204.9469\n",
      "NME: 0.0917\n",
      "Epoch [161/300], Loss: 83.6685\n",
      "Validation Loss: 210.3023\n",
      "NME: 0.0907\n",
      "Epoch [162/300], Loss: 88.8550\n",
      "Validation Loss: 221.2707\n",
      "NME: 0.0928\n",
      "Epoch [163/300], Loss: 84.9921\n",
      "Validation Loss: 235.0176\n",
      "NME: 0.0911\n",
      "Epoch [164/300], Loss: 81.1385\n",
      "Validation Loss: 203.9244\n",
      "NME: 0.0886\n",
      "Epoch [165/300], Loss: 77.8066\n",
      "Validation Loss: 217.9116\n",
      "NME: 0.0932\n",
      "Epoch [166/300], Loss: 79.3344\n",
      "Validation Loss: 208.9668\n",
      "NME: 0.0907\n",
      "Epoch [167/300], Loss: 75.2441\n",
      "Validation Loss: 215.7227\n",
      "NME: 0.0886\n",
      "Epoch [168/300], Loss: 80.3353\n",
      "Validation Loss: 228.9042\n",
      "NME: 0.0941\n",
      "Epoch [169/300], Loss: 81.5225\n",
      "Validation Loss: 211.4523\n",
      "NME: 0.0918\n",
      "Epoch [170/300], Loss: 90.8887\n",
      "Validation Loss: 218.5653\n",
      "NME: 0.0943\n",
      "Epoch [171/300], Loss: 79.6939\n",
      "Validation Loss: 199.9673\n",
      "NME: 0.0880\n",
      "Best model saved at epoch 171 with val_loss 199.9673\n",
      "Epoch [172/300], Loss: 80.4389\n",
      "Validation Loss: 240.8348\n",
      "NME: 0.1073\n",
      "Epoch [173/300], Loss: 159.0695\n",
      "Validation Loss: 241.7183\n",
      "NME: 0.1015\n",
      "Epoch [174/300], Loss: 95.6684\n",
      "Validation Loss: 214.9568\n",
      "NME: 0.0948\n",
      "Epoch [175/300], Loss: 88.4557\n",
      "Validation Loss: 230.8620\n",
      "NME: 0.0948\n",
      "Epoch [176/300], Loss: 81.1462\n",
      "Validation Loss: 211.2440\n",
      "NME: 0.0931\n",
      "Epoch [177/300], Loss: 80.4128\n",
      "Validation Loss: 210.0999\n",
      "NME: 0.0907\n",
      "Epoch [178/300], Loss: 68.6393\n",
      "Validation Loss: 211.2841\n",
      "NME: 0.0879\n",
      "Epoch [179/300], Loss: 69.7955\n",
      "Validation Loss: 205.6316\n",
      "NME: 0.0889\n",
      "Epoch [180/300], Loss: 64.5425\n",
      "Validation Loss: 207.2202\n",
      "NME: 0.0880\n",
      "Epoch [181/300], Loss: 67.6858\n",
      "Validation Loss: 207.0003\n",
      "NME: 0.0898\n",
      "Epoch [182/300], Loss: 65.2307\n",
      "Validation Loss: 193.5524\n",
      "NME: 0.0876\n",
      "Best model saved at epoch 182 with val_loss 193.5524\n",
      "Epoch [183/300], Loss: 67.4130\n",
      "Validation Loss: 207.2183\n",
      "NME: 0.0893\n",
      "Epoch [184/300], Loss: 68.4028\n",
      "Validation Loss: 205.9279\n",
      "NME: 0.0880\n",
      "Epoch [185/300], Loss: 63.4412\n",
      "Validation Loss: 195.8195\n",
      "NME: 0.0898\n",
      "Epoch [186/300], Loss: 63.0744\n",
      "Validation Loss: 193.3172\n",
      "NME: 0.0889\n",
      "Best model saved at epoch 186 with val_loss 193.3172\n",
      "Epoch [187/300], Loss: 63.3227\n",
      "Validation Loss: 207.6081\n",
      "NME: 0.0881\n",
      "Epoch [188/300], Loss: 65.2535\n",
      "Validation Loss: 208.0954\n",
      "NME: 0.0881\n",
      "Epoch [189/300], Loss: 63.7439\n",
      "Validation Loss: 226.6234\n",
      "NME: 0.0950\n",
      "Epoch [190/300], Loss: 66.7628\n",
      "Validation Loss: 192.6857\n",
      "NME: 0.0884\n",
      "Best model saved at epoch 190 with val_loss 192.6857\n",
      "Epoch [191/300], Loss: 63.4828\n",
      "Validation Loss: 209.9422\n",
      "NME: 0.0887\n",
      "Epoch [192/300], Loss: 61.3624\n",
      "Validation Loss: 205.6858\n",
      "NME: 0.0896\n",
      "Epoch [193/300], Loss: 64.5602\n",
      "Validation Loss: 207.5009\n",
      "NME: 0.0881\n",
      "Epoch [194/300], Loss: 58.6763\n",
      "Validation Loss: 196.9891\n",
      "NME: 0.0882\n",
      "Epoch [195/300], Loss: 60.5638\n",
      "Validation Loss: 204.3430\n",
      "NME: 0.0888\n",
      "Epoch [196/300], Loss: 59.2053\n",
      "Validation Loss: 203.8844\n",
      "NME: 0.0871\n",
      "Epoch [197/300], Loss: 59.0359\n",
      "Validation Loss: 194.5817\n",
      "NME: 0.0861\n",
      "Epoch [198/300], Loss: 61.3661\n",
      "Validation Loss: 205.9675\n",
      "NME: 0.0883\n",
      "Epoch [199/300], Loss: 64.6968\n",
      "Validation Loss: 209.3947\n",
      "NME: 0.0901\n",
      "Epoch [200/300], Loss: 63.7920\n",
      "Validation Loss: 206.1840\n",
      "NME: 0.0867\n",
      "Epoch [201/300], Loss: 58.8741\n",
      "Validation Loss: 193.8990\n",
      "NME: 0.0866\n",
      "Epoch [202/300], Loss: 57.9252\n",
      "Validation Loss: 203.9433\n",
      "NME: 0.0871\n",
      "Epoch [203/300], Loss: 56.6820\n",
      "Validation Loss: 194.3738\n",
      "NME: 0.0868\n",
      "Epoch [204/300], Loss: 56.2302\n",
      "Validation Loss: 190.8752\n",
      "NME: 0.0866\n",
      "Best model saved at epoch 204 with val_loss 190.8752\n",
      "Epoch [205/300], Loss: 57.9957\n",
      "Validation Loss: 209.5123\n",
      "NME: 0.0916\n",
      "Epoch [206/300], Loss: 64.4004\n",
      "Validation Loss: 219.1726\n",
      "NME: 0.0886\n",
      "Epoch [207/300], Loss: 66.3297\n",
      "Validation Loss: 201.8847\n",
      "NME: 0.0877\n",
      "Epoch [208/300], Loss: 60.9138\n",
      "Validation Loss: 203.7783\n",
      "NME: 0.0891\n",
      "Epoch [209/300], Loss: 54.8564\n",
      "Validation Loss: 203.6776\n",
      "NME: 0.0856\n",
      "Epoch [210/300], Loss: 71.6492\n",
      "Validation Loss: 210.4023\n",
      "NME: 0.0875\n",
      "Epoch [211/300], Loss: 64.3177\n",
      "Validation Loss: 213.3069\n",
      "NME: 0.0904\n",
      "Epoch [212/300], Loss: 61.0198\n",
      "Validation Loss: 207.7475\n",
      "NME: 0.0885\n",
      "Epoch [213/300], Loss: 60.2161\n",
      "Validation Loss: 203.2498\n",
      "NME: 0.0865\n",
      "Epoch [214/300], Loss: 93.4656\n",
      "Validation Loss: 212.2702\n",
      "NME: 0.0895\n",
      "Epoch [215/300], Loss: 73.3863\n",
      "Validation Loss: 214.3045\n",
      "NME: 0.0910\n",
      "Epoch [216/300], Loss: 63.1104\n",
      "Validation Loss: 201.5031\n",
      "NME: 0.0872\n",
      "Epoch [217/300], Loss: 60.6303\n",
      "Validation Loss: 203.3662\n",
      "NME: 0.0873\n",
      "Epoch [218/300], Loss: 67.3852\n",
      "Validation Loss: 200.0837\n",
      "NME: 0.0875\n",
      "Epoch [219/300], Loss: 56.6219\n",
      "Validation Loss: 199.2683\n",
      "NME: 0.0854\n",
      "Epoch [220/300], Loss: 58.6180\n",
      "Validation Loss: 217.4963\n",
      "NME: 0.0870\n",
      "Epoch [221/300], Loss: 59.3717\n",
      "Validation Loss: 202.0312\n",
      "NME: 0.0871\n",
      "Epoch [222/300], Loss: 55.5719\n",
      "Validation Loss: 199.7378\n",
      "NME: 0.0887\n",
      "Epoch [223/300], Loss: 56.8338\n",
      "Validation Loss: 197.0696\n",
      "NME: 0.0855\n",
      "Epoch [224/300], Loss: 57.1493\n",
      "Validation Loss: 195.5742\n",
      "NME: 0.0865\n",
      "Epoch [225/300], Loss: 55.4022\n",
      "Validation Loss: 193.3686\n",
      "NME: 0.0848\n",
      "Epoch [226/300], Loss: 72.1794\n",
      "Validation Loss: 224.1113\n",
      "NME: 0.0903\n",
      "Epoch [227/300], Loss: 67.0346\n",
      "Validation Loss: 222.8273\n",
      "NME: 0.0962\n",
      "Epoch [228/300], Loss: 58.5084\n",
      "Validation Loss: 200.0209\n",
      "NME: 0.0875\n",
      "Epoch [229/300], Loss: 57.6593\n",
      "Validation Loss: 206.4467\n",
      "NME: 0.0906\n",
      "Epoch [230/300], Loss: 53.8169\n",
      "Validation Loss: 209.7029\n",
      "NME: 0.0883\n",
      "Epoch [231/300], Loss: 54.2135\n",
      "Validation Loss: 214.1186\n",
      "NME: 0.0902\n",
      "Epoch [232/300], Loss: 57.6561\n",
      "Validation Loss: 212.3946\n",
      "NME: 0.0888\n",
      "Epoch [233/300], Loss: 65.4692\n",
      "Validation Loss: 223.8502\n",
      "NME: 0.0910\n",
      "Epoch [234/300], Loss: 59.5385\n",
      "Validation Loss: 187.8633\n",
      "NME: 0.0876\n",
      "Best model saved at epoch 234 with val_loss 187.8633\n",
      "Epoch [235/300], Loss: 57.6613\n",
      "Validation Loss: 197.2815\n",
      "NME: 0.0877\n",
      "Epoch [236/300], Loss: 55.7252\n",
      "Validation Loss: 212.0392\n",
      "NME: 0.0937\n",
      "Epoch [237/300], Loss: 55.2820\n",
      "Validation Loss: 198.8220\n",
      "NME: 0.0891\n",
      "Epoch [238/300], Loss: 52.8135\n",
      "Validation Loss: 200.1981\n",
      "NME: 0.0891\n",
      "Epoch [239/300], Loss: 52.1796\n",
      "Validation Loss: 202.5054\n",
      "NME: 0.0873\n",
      "Epoch [240/300], Loss: 55.8549\n",
      "Validation Loss: 206.5044\n",
      "NME: 0.0897\n",
      "Epoch [241/300], Loss: 51.6938\n",
      "Validation Loss: 206.7917\n",
      "NME: 0.0877\n",
      "Epoch [242/300], Loss: 51.3036\n",
      "Validation Loss: 201.7232\n",
      "NME: 0.0866\n",
      "Epoch [243/300], Loss: 51.8350\n",
      "Validation Loss: 194.8944\n",
      "NME: 0.0864\n",
      "Epoch [244/300], Loss: 50.3755\n",
      "Validation Loss: 206.8036\n",
      "NME: 0.0877\n",
      "Epoch [245/300], Loss: 49.5671\n",
      "Validation Loss: 205.4419\n",
      "NME: 0.0862\n",
      "Epoch [246/300], Loss: 49.6765\n",
      "Validation Loss: 201.9847\n",
      "NME: 0.0872\n",
      "Epoch [247/300], Loss: 50.5034\n",
      "Validation Loss: 203.0766\n",
      "NME: 0.0868\n",
      "Epoch [248/300], Loss: 49.9453\n",
      "Validation Loss: 196.5663\n",
      "NME: 0.0866\n",
      "Epoch [249/300], Loss: 50.4880\n",
      "Validation Loss: 200.8727\n",
      "NME: 0.0860\n",
      "Epoch [250/300], Loss: 50.0535\n",
      "Validation Loss: 202.7180\n",
      "NME: 0.0868\n",
      "Epoch [251/300], Loss: 51.5674\n",
      "Validation Loss: 194.4510\n",
      "NME: 0.0873\n",
      "Epoch [252/300], Loss: 49.6091\n",
      "Validation Loss: 204.4051\n",
      "NME: 0.0874\n",
      "Epoch [253/300], Loss: 56.1639\n",
      "Validation Loss: 196.7353\n",
      "NME: 0.0861\n",
      "Epoch [254/300], Loss: 61.2945\n",
      "Validation Loss: 207.1713\n",
      "NME: 0.0875\n",
      "Epoch [255/300], Loss: 59.6110\n",
      "Validation Loss: 212.5053\n",
      "NME: 0.0874\n",
      "Epoch [256/300], Loss: 52.2465\n",
      "Validation Loss: 203.0571\n",
      "NME: 0.0862\n",
      "Epoch [257/300], Loss: 57.1321\n",
      "Validation Loss: 215.0353\n",
      "NME: 0.0897\n",
      "Epoch [258/300], Loss: 55.6624\n",
      "Validation Loss: 209.2397\n",
      "NME: 0.0856\n",
      "Epoch [259/300], Loss: 59.6350\n",
      "Validation Loss: 209.8217\n",
      "NME: 0.0876\n",
      "Epoch [260/300], Loss: 57.3007\n",
      "Validation Loss: 204.7456\n",
      "NME: 0.0854\n",
      "Epoch [261/300], Loss: 49.5185\n",
      "Validation Loss: 207.4991\n",
      "NME: 0.0864\n",
      "Epoch [262/300], Loss: 50.3076\n",
      "Validation Loss: 202.2305\n",
      "NME: 0.0850\n",
      "Epoch [263/300], Loss: 47.3841\n",
      "Validation Loss: 198.1321\n",
      "NME: 0.0850\n",
      "Epoch [264/300], Loss: 52.2948\n",
      "Validation Loss: 203.8527\n",
      "NME: 0.0877\n",
      "Epoch [265/300], Loss: 54.8363\n",
      "Validation Loss: 211.0287\n",
      "NME: 0.0872\n",
      "Epoch [266/300], Loss: 52.0115\n",
      "Validation Loss: 209.6189\n",
      "NME: 0.0856\n",
      "Epoch [267/300], Loss: 51.0569\n",
      "Validation Loss: 215.2088\n",
      "NME: 0.0855\n",
      "Epoch [268/300], Loss: 50.2447\n",
      "Validation Loss: 202.7623\n",
      "NME: 0.0872\n",
      "Epoch [269/300], Loss: 50.8283\n",
      "Validation Loss: 207.7075\n",
      "NME: 0.0865\n",
      "Epoch [270/300], Loss: 46.6506\n",
      "Validation Loss: 204.4436\n",
      "NME: 0.0851\n",
      "Epoch [271/300], Loss: 50.6977\n",
      "Validation Loss: 206.2458\n",
      "NME: 0.0860\n",
      "Epoch [272/300], Loss: 51.7245\n",
      "Validation Loss: 198.3671\n",
      "NME: 0.0853\n",
      "Epoch [273/300], Loss: 50.4520\n",
      "Validation Loss: 208.2052\n",
      "NME: 0.0880\n",
      "Epoch [274/300], Loss: 51.2927\n",
      "Validation Loss: 200.8184\n",
      "NME: 0.0918\n",
      "Epoch [275/300], Loss: 53.9520\n",
      "Validation Loss: 193.2578\n",
      "NME: 0.0892\n",
      "Epoch [276/300], Loss: 50.3746\n",
      "Validation Loss: 202.2326\n",
      "NME: 0.0865\n",
      "Epoch [277/300], Loss: 47.3462\n",
      "Validation Loss: 189.8414\n",
      "NME: 0.0859\n",
      "Epoch [278/300], Loss: 51.3770\n",
      "Validation Loss: 203.3993\n",
      "NME: 0.0890\n",
      "Epoch [279/300], Loss: 47.2567\n",
      "Validation Loss: 193.6805\n",
      "NME: 0.0851\n",
      "Epoch [280/300], Loss: 49.3018\n",
      "Validation Loss: 208.7498\n",
      "NME: 0.0865\n",
      "Epoch [281/300], Loss: 49.7891\n",
      "Validation Loss: 193.6705\n",
      "NME: 0.0862\n",
      "Epoch [282/300], Loss: 48.1594\n",
      "Validation Loss: 194.1966\n",
      "NME: 0.0874\n",
      "Epoch [283/300], Loss: 48.6282\n",
      "Validation Loss: 202.9384\n",
      "NME: 0.0876\n",
      "Epoch [284/300], Loss: 50.7923\n",
      "Validation Loss: 193.8804\n",
      "NME: 0.0850\n",
      "Epoch [285/300], Loss: 47.2312\n",
      "Validation Loss: 199.6647\n",
      "NME: 0.0870\n",
      "Epoch [286/300], Loss: 48.9627\n",
      "Validation Loss: 195.2258\n",
      "NME: 0.0851\n",
      "Epoch [287/300], Loss: 46.6517\n",
      "Validation Loss: 197.9270\n",
      "NME: 0.0875\n",
      "Epoch [288/300], Loss: 50.0174\n",
      "Validation Loss: 195.3038\n",
      "NME: 0.0859\n",
      "Epoch [289/300], Loss: 54.0355\n",
      "Validation Loss: 207.0702\n",
      "NME: 0.0874\n",
      "Epoch [290/300], Loss: 48.3252\n",
      "Validation Loss: 200.9920\n",
      "NME: 0.0873\n",
      "Epoch [291/300], Loss: 48.7953\n",
      "Validation Loss: 205.9163\n",
      "NME: 0.0861\n",
      "Epoch [292/300], Loss: 50.7263\n",
      "Validation Loss: 206.5096\n",
      "NME: 0.0901\n",
      "Epoch [293/300], Loss: 49.7608\n",
      "Validation Loss: 199.5810\n",
      "NME: 0.0848\n",
      "Epoch [294/300], Loss: 47.0394\n",
      "Validation Loss: 211.3558\n",
      "NME: 0.0910\n",
      "Epoch [295/300], Loss: 48.6572\n",
      "Validation Loss: 201.5870\n",
      "NME: 0.0851\n",
      "Epoch [296/300], Loss: 45.4933\n",
      "Validation Loss: 205.8428\n",
      "NME: 0.0858\n",
      "Epoch [297/300], Loss: 49.2311\n",
      "Validation Loss: 194.2838\n",
      "NME: 0.0843\n",
      "Epoch [298/300], Loss: 46.3025\n",
      "Validation Loss: 214.4805\n",
      "NME: 0.0891\n",
      "Epoch [299/300], Loss: 50.4427\n",
      "Validation Loss: 205.8307\n",
      "NME: 0.0871\n",
      "Epoch [300/300], Loss: 46.6409\n",
      "Validation Loss: 195.1337\n",
      "NME: 0.0859\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "oreja_der = [22, 23, 24, 25, 26]  # Cambiado a oreja derecha\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EarRightDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_oreja_der = calcular_centro_region(landmarks, oreja_der)  # Cambiado a oreja derecha\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_oreja_der -= np.array([x_min, y_min])  # Cambiado a oreja derecha\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la oreja derecha\n",
    "        ear_right_points = np.array([landmarks[i] for i in oreja_der], dtype=np.float32)  # Cambiado a oreja derecha\n",
    "        ear_right_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(ear_right_points), 1))\n",
    "        points_ones = np.hstack([ear_right_points, ones])\n",
    "        ear_right_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la oreja derecha\n",
    "        centro_x, centro_y = calcular_centro_region(ear_right_points_rotated, range(len(oreja_der)))  # Cambiado a oreja derecha\n",
    "\n",
    "        # Definir los límites del recorte de 112x112 píxeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_ear = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_ear, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la oreja derecha al nuevo recorte\n",
    "        ear_right_points_adjusted = [(p[0] - x1, p[1] - y1) for p in ear_right_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        ear_right_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in ear_right_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=ear_right_points_scaled)\n",
    "            image = augmented['image']\n",
    "            ear_right_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(ear_right_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EarRightDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EarRightDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EarRight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EarRight, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(oreja_der) * 2)  # Cambiado a oreja derecha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EarRight().cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para oreja derecha)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, ear_right_points, _, _, _ in train_dataloader:  # Cambiado a oreja derecha\n",
    "            images, ear_right_points = images.cuda(), ear_right_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ear_right_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_ear_right_points, _, _, _ in val_dataloader:  # Cambiado a oreja derecha\n",
    "                    val_images, val_ear_right_points = val_images.cuda(), val_ear_right_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_ear_right_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_ear_right_points.cpu().numpy().reshape(-1, len(oreja_der), 2))  # Cambiado a oreja derecha\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(oreja_der), 2))  # Cambiado a oreja derecha\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(oreja_der))  # Cambiado a oreja derecha\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EarRightLandmarks V4.pth')  # Cambiado a oreja derecha\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14416.8105\n",
      "Validation Loss: 12798.8743\n",
      "NME: 6.9950\n",
      "Best model saved at epoch 1 with val_loss 12798.8743\n",
      "Epoch [2/300], Loss: 8507.8556\n",
      "Validation Loss: 3531.4210\n",
      "NME: 3.3208\n",
      "Best model saved at epoch 2 with val_loss 3531.4210\n",
      "Epoch [3/300], Loss: 1677.0004\n",
      "Validation Loss: 845.0300\n",
      "NME: 1.1346\n",
      "Best model saved at epoch 3 with val_loss 845.0300\n",
      "Epoch [4/300], Loss: 721.7680\n",
      "Validation Loss: 595.2252\n",
      "NME: 0.9572\n",
      "Best model saved at epoch 4 with val_loss 595.2252\n",
      "Epoch [5/300], Loss: 626.4071\n",
      "Validation Loss: 572.0977\n",
      "NME: 1.0285\n",
      "Best model saved at epoch 5 with val_loss 572.0977\n",
      "Epoch [6/300], Loss: 618.7731\n",
      "Validation Loss: 561.6694\n",
      "NME: 1.0372\n",
      "Best model saved at epoch 6 with val_loss 561.6694\n",
      "Epoch [7/300], Loss: 617.4756\n",
      "Validation Loss: 558.6201\n",
      "NME: 1.0241\n",
      "Best model saved at epoch 7 with val_loss 558.6201\n",
      "Epoch [8/300], Loss: 614.1722\n",
      "Validation Loss: 556.6554\n",
      "NME: 1.0366\n",
      "Best model saved at epoch 8 with val_loss 556.6554\n",
      "Epoch [9/300], Loss: 614.4481\n",
      "Validation Loss: 554.1183\n",
      "NME: 1.0173\n",
      "Best model saved at epoch 9 with val_loss 554.1183\n",
      "Epoch [10/300], Loss: 610.1196\n",
      "Validation Loss: 554.4253\n",
      "NME: 1.0397\n",
      "Epoch [11/300], Loss: 610.9058\n",
      "Validation Loss: 545.4559\n",
      "NME: 1.0120\n",
      "Best model saved at epoch 11 with val_loss 545.4559\n",
      "Epoch [12/300], Loss: 596.4703\n",
      "Validation Loss: 539.6524\n",
      "NME: 1.0146\n",
      "Best model saved at epoch 12 with val_loss 539.6524\n",
      "Epoch [13/300], Loss: 591.0460\n",
      "Validation Loss: 522.4135\n",
      "NME: 0.9677\n",
      "Best model saved at epoch 13 with val_loss 522.4135\n",
      "Epoch [14/300], Loss: 542.1624\n",
      "Validation Loss: 428.2572\n",
      "NME: 0.9199\n",
      "Best model saved at epoch 14 with val_loss 428.2572\n",
      "Epoch [15/300], Loss: 427.5423\n",
      "Validation Loss: 282.3507\n",
      "NME: 0.7844\n",
      "Best model saved at epoch 15 with val_loss 282.3507\n",
      "Epoch [16/300], Loss: 343.8285\n",
      "Validation Loss: 225.0523\n",
      "NME: 0.6516\n",
      "Best model saved at epoch 16 with val_loss 225.0523\n",
      "Epoch [17/300], Loss: 308.8456\n",
      "Validation Loss: 159.3272\n",
      "NME: 0.5475\n",
      "Best model saved at epoch 17 with val_loss 159.3272\n",
      "Epoch [18/300], Loss: 289.4221\n",
      "Validation Loss: 151.5965\n",
      "NME: 0.5155\n",
      "Best model saved at epoch 18 with val_loss 151.5965\n",
      "Epoch [19/300], Loss: 249.1369\n",
      "Validation Loss: 142.8898\n",
      "NME: 0.4805\n",
      "Best model saved at epoch 19 with val_loss 142.8898\n",
      "Epoch [20/300], Loss: 232.6988\n",
      "Validation Loss: 123.4052\n",
      "NME: 0.4585\n",
      "Best model saved at epoch 20 with val_loss 123.4052\n",
      "Epoch [21/300], Loss: 221.8873\n",
      "Validation Loss: 125.5968\n",
      "NME: 0.4453\n",
      "Epoch [22/300], Loss: 228.7867\n",
      "Validation Loss: 119.6537\n",
      "NME: 0.4427\n",
      "Best model saved at epoch 22 with val_loss 119.6537\n",
      "Epoch [23/300], Loss: 218.2567\n",
      "Validation Loss: 114.2326\n",
      "NME: 0.4246\n",
      "Best model saved at epoch 23 with val_loss 114.2326\n",
      "Epoch [24/300], Loss: 216.0529\n",
      "Validation Loss: 112.6815\n",
      "NME: 0.4315\n",
      "Best model saved at epoch 24 with val_loss 112.6815\n",
      "Epoch [25/300], Loss: 210.6366\n",
      "Validation Loss: 116.0065\n",
      "NME: 0.4233\n",
      "Epoch [26/300], Loss: 194.9927\n",
      "Validation Loss: 112.3500\n",
      "NME: 0.4238\n",
      "Best model saved at epoch 26 with val_loss 112.3500\n",
      "Epoch [27/300], Loss: 194.0086\n",
      "Validation Loss: 110.1448\n",
      "NME: 0.4306\n",
      "Best model saved at epoch 27 with val_loss 110.1448\n",
      "Epoch [28/300], Loss: 192.0874\n",
      "Validation Loss: 113.4951\n",
      "NME: 0.4380\n",
      "Epoch [29/300], Loss: 193.0593\n",
      "Validation Loss: 112.0314\n",
      "NME: 0.4251\n",
      "Epoch [30/300], Loss: 187.8446\n",
      "Validation Loss: 112.8775\n",
      "NME: 0.4335\n",
      "Epoch [31/300], Loss: 185.5196\n",
      "Validation Loss: 108.3978\n",
      "NME: 0.4140\n",
      "Best model saved at epoch 31 with val_loss 108.3978\n",
      "Epoch [32/300], Loss: 194.1747\n",
      "Validation Loss: 112.7325\n",
      "NME: 0.4157\n",
      "Epoch [33/300], Loss: 201.8614\n",
      "Validation Loss: 125.2890\n",
      "NME: 0.4239\n",
      "Epoch [34/300], Loss: 181.2294\n",
      "Validation Loss: 114.8720\n",
      "NME: 0.4235\n",
      "Epoch [35/300], Loss: 196.2044\n",
      "Validation Loss: 116.4975\n",
      "NME: 0.4325\n",
      "Epoch [36/300], Loss: 196.7798\n",
      "Validation Loss: 108.9234\n",
      "NME: 0.4068\n",
      "Epoch [37/300], Loss: 191.5535\n",
      "Validation Loss: 109.9769\n",
      "NME: 0.4100\n",
      "Epoch [38/300], Loss: 198.0897\n",
      "Validation Loss: 111.2485\n",
      "NME: 0.4212\n",
      "Epoch [39/300], Loss: 185.8455\n",
      "Validation Loss: 114.2203\n",
      "NME: 0.4126\n",
      "Epoch [40/300], Loss: 189.0635\n",
      "Validation Loss: 123.0631\n",
      "NME: 0.4248\n",
      "Epoch [41/300], Loss: 185.8073\n",
      "Validation Loss: 116.2836\n",
      "NME: 0.4230\n",
      "Epoch [42/300], Loss: 196.0632\n",
      "Validation Loss: 147.0847\n",
      "NME: 0.4414\n",
      "Epoch [43/300], Loss: 190.8739\n",
      "Validation Loss: 109.8114\n",
      "NME: 0.4096\n",
      "Epoch [44/300], Loss: 199.2889\n",
      "Validation Loss: 107.9462\n",
      "NME: 0.4084\n",
      "Best model saved at epoch 44 with val_loss 107.9462\n",
      "Epoch [45/300], Loss: 183.1936\n",
      "Validation Loss: 110.2812\n",
      "NME: 0.3964\n",
      "Epoch [46/300], Loss: 185.1017\n",
      "Validation Loss: 110.7118\n",
      "NME: 0.4134\n",
      "Epoch [47/300], Loss: 179.2986\n",
      "Validation Loss: 114.3141\n",
      "NME: 0.4444\n",
      "Epoch [48/300], Loss: 190.6182\n",
      "Validation Loss: 113.9580\n",
      "NME: 0.4395\n",
      "Epoch [49/300], Loss: 190.5519\n",
      "Validation Loss: 118.7151\n",
      "NME: 0.4368\n",
      "Epoch [50/300], Loss: 179.0149\n",
      "Validation Loss: 111.6270\n",
      "NME: 0.4182\n",
      "Epoch [51/300], Loss: 188.9935\n",
      "Validation Loss: 114.7556\n",
      "NME: 0.4110\n",
      "Epoch [52/300], Loss: 195.6956\n",
      "Validation Loss: 109.1769\n",
      "NME: 0.4050\n",
      "Epoch [53/300], Loss: 192.6259\n",
      "Validation Loss: 114.2638\n",
      "NME: 0.4299\n",
      "Epoch [54/300], Loss: 208.0955\n",
      "Validation Loss: 117.0217\n",
      "NME: 0.4290\n",
      "Epoch [55/300], Loss: 197.6631\n",
      "Validation Loss: 113.9733\n",
      "NME: 0.4303\n",
      "Epoch [56/300], Loss: 195.4177\n",
      "Validation Loss: 113.4988\n",
      "NME: 0.4286\n",
      "Epoch [57/300], Loss: 175.3273\n",
      "Validation Loss: 109.4343\n",
      "NME: 0.4078\n",
      "Epoch [58/300], Loss: 194.0762\n",
      "Validation Loss: 113.3278\n",
      "NME: 0.4340\n",
      "Epoch [59/300], Loss: 185.3985\n",
      "Validation Loss: 110.6593\n",
      "NME: 0.3968\n",
      "Epoch [60/300], Loss: 178.2195\n",
      "Validation Loss: 109.7366\n",
      "NME: 0.4122\n",
      "Epoch [61/300], Loss: 187.6970\n",
      "Validation Loss: 113.8957\n",
      "NME: 0.4408\n",
      "Epoch [62/300], Loss: 177.6782\n",
      "Validation Loss: 106.7889\n",
      "NME: 0.4161\n",
      "Best model saved at epoch 62 with val_loss 106.7889\n",
      "Epoch [63/300], Loss: 168.5845\n",
      "Validation Loss: 111.9884\n",
      "NME: 0.4021\n",
      "Epoch [64/300], Loss: 175.1479\n",
      "Validation Loss: 118.6533\n",
      "NME: 0.4186\n",
      "Epoch [65/300], Loss: 160.6485\n",
      "Validation Loss: 110.0603\n",
      "NME: 0.4074\n",
      "Epoch [66/300], Loss: 163.4799\n",
      "Validation Loss: 121.0008\n",
      "NME: 0.4709\n",
      "Epoch [67/300], Loss: 150.6110\n",
      "Validation Loss: 107.2101\n",
      "NME: 0.4061\n",
      "Epoch [68/300], Loss: 139.0762\n",
      "Validation Loss: 105.6538\n",
      "NME: 0.4102\n",
      "Best model saved at epoch 68 with val_loss 105.6538\n",
      "Epoch [69/300], Loss: 136.3361\n",
      "Validation Loss: 109.0682\n",
      "NME: 0.4180\n",
      "Epoch [70/300], Loss: 135.0951\n",
      "Validation Loss: 106.6502\n",
      "NME: 0.3945\n",
      "Epoch [71/300], Loss: 123.6742\n",
      "Validation Loss: 120.7694\n",
      "NME: 0.4123\n",
      "Epoch [72/300], Loss: 120.5567\n",
      "Validation Loss: 107.3770\n",
      "NME: 0.4103\n",
      "Epoch [73/300], Loss: 127.1511\n",
      "Validation Loss: 104.2593\n",
      "NME: 0.3996\n",
      "Best model saved at epoch 73 with val_loss 104.2593\n",
      "Epoch [74/300], Loss: 118.0380\n",
      "Validation Loss: 108.0233\n",
      "NME: 0.4212\n",
      "Epoch [75/300], Loss: 112.7778\n",
      "Validation Loss: 115.3655\n",
      "NME: 0.4246\n",
      "Epoch [76/300], Loss: 109.7037\n",
      "Validation Loss: 100.6257\n",
      "NME: 0.3999\n",
      "Best model saved at epoch 76 with val_loss 100.6257\n",
      "Epoch [77/300], Loss: 103.1917\n",
      "Validation Loss: 100.5769\n",
      "NME: 0.4052\n",
      "Best model saved at epoch 77 with val_loss 100.5769\n",
      "Epoch [78/300], Loss: 110.0333\n",
      "Validation Loss: 117.3008\n",
      "NME: 0.4254\n",
      "Epoch [79/300], Loss: 118.6959\n",
      "Validation Loss: 102.9176\n",
      "NME: 0.3895\n",
      "Epoch [80/300], Loss: 116.4367\n",
      "Validation Loss: 116.3989\n",
      "NME: 0.4115\n",
      "Epoch [81/300], Loss: 106.5962\n",
      "Validation Loss: 98.2047\n",
      "NME: 0.4048\n",
      "Best model saved at epoch 81 with val_loss 98.2047\n",
      "Epoch [82/300], Loss: 96.3270\n",
      "Validation Loss: 91.5531\n",
      "NME: 0.3815\n",
      "Best model saved at epoch 82 with val_loss 91.5531\n",
      "Epoch [83/300], Loss: 94.5203\n",
      "Validation Loss: 99.3552\n",
      "NME: 0.3803\n",
      "Epoch [84/300], Loss: 104.1524\n",
      "Validation Loss: 94.8679\n",
      "NME: 0.3896\n",
      "Epoch [85/300], Loss: 89.6219\n",
      "Validation Loss: 88.7852\n",
      "NME: 0.3694\n",
      "Best model saved at epoch 85 with val_loss 88.7852\n",
      "Epoch [86/300], Loss: 89.2281\n",
      "Validation Loss: 89.8116\n",
      "NME: 0.3703\n",
      "Epoch [87/300], Loss: 87.9215\n",
      "Validation Loss: 90.7450\n",
      "NME: 0.3647\n",
      "Epoch [88/300], Loss: 84.6072\n",
      "Validation Loss: 87.8766\n",
      "NME: 0.3673\n",
      "Best model saved at epoch 88 with val_loss 87.8766\n",
      "Epoch [89/300], Loss: 89.2302\n",
      "Validation Loss: 91.5604\n",
      "NME: 0.4012\n",
      "Epoch [90/300], Loss: 93.1125\n",
      "Validation Loss: 88.2090\n",
      "NME: 0.3692\n",
      "Epoch [91/300], Loss: 83.4358\n",
      "Validation Loss: 86.3598\n",
      "NME: 0.3804\n",
      "Best model saved at epoch 91 with val_loss 86.3598\n",
      "Epoch [92/300], Loss: 91.6506\n",
      "Validation Loss: 98.1995\n",
      "NME: 0.3831\n",
      "Epoch [93/300], Loss: 85.3521\n",
      "Validation Loss: 89.1424\n",
      "NME: 0.3650\n",
      "Epoch [94/300], Loss: 91.9330\n",
      "Validation Loss: 89.1100\n",
      "NME: 0.3634\n",
      "Epoch [95/300], Loss: 83.7493\n",
      "Validation Loss: 85.8605\n",
      "NME: 0.3616\n",
      "Best model saved at epoch 95 with val_loss 85.8605\n",
      "Epoch [96/300], Loss: 80.8016\n",
      "Validation Loss: 83.2751\n",
      "NME: 0.3605\n",
      "Best model saved at epoch 96 with val_loss 83.2751\n",
      "Epoch [97/300], Loss: 80.8184\n",
      "Validation Loss: 83.3154\n",
      "NME: 0.3626\n",
      "Epoch [98/300], Loss: 77.8364\n",
      "Validation Loss: 79.4883\n",
      "NME: 0.3463\n",
      "Best model saved at epoch 98 with val_loss 79.4883\n",
      "Epoch [99/300], Loss: 77.6086\n",
      "Validation Loss: 81.0759\n",
      "NME: 0.3537\n",
      "Epoch [100/300], Loss: 73.5316\n",
      "Validation Loss: 78.9071\n",
      "NME: 0.3433\n",
      "Best model saved at epoch 100 with val_loss 78.9071\n",
      "Epoch [101/300], Loss: 72.5683\n",
      "Validation Loss: 78.8150\n",
      "NME: 0.3436\n",
      "Best model saved at epoch 101 with val_loss 78.8150\n",
      "Epoch [102/300], Loss: 75.4080\n",
      "Validation Loss: 82.0088\n",
      "NME: 0.3422\n",
      "Epoch [103/300], Loss: 78.8930\n",
      "Validation Loss: 81.6288\n",
      "NME: 0.3500\n",
      "Epoch [104/300], Loss: 71.6745\n",
      "Validation Loss: 78.1894\n",
      "NME: 0.3495\n",
      "Best model saved at epoch 104 with val_loss 78.1894\n",
      "Epoch [105/300], Loss: 69.5329\n",
      "Validation Loss: 75.3800\n",
      "NME: 0.3289\n",
      "Best model saved at epoch 105 with val_loss 75.3800\n",
      "Epoch [106/300], Loss: 74.7423\n",
      "Validation Loss: 77.7328\n",
      "NME: 0.3393\n",
      "Epoch [107/300], Loss: 70.7053\n",
      "Validation Loss: 77.8631\n",
      "NME: 0.3220\n",
      "Epoch [108/300], Loss: 68.5828\n",
      "Validation Loss: 81.8248\n",
      "NME: 0.3636\n",
      "Epoch [109/300], Loss: 63.8794\n",
      "Validation Loss: 77.8445\n",
      "NME: 0.3275\n",
      "Epoch [110/300], Loss: 76.3538\n",
      "Validation Loss: 71.2426\n",
      "NME: 0.3247\n",
      "Best model saved at epoch 110 with val_loss 71.2426\n",
      "Epoch [111/300], Loss: 65.4532\n",
      "Validation Loss: 71.7001\n",
      "NME: 0.3311\n",
      "Epoch [112/300], Loss: 65.8662\n",
      "Validation Loss: 73.2864\n",
      "NME: 0.3290\n",
      "Epoch [113/300], Loss: 63.0179\n",
      "Validation Loss: 70.9223\n",
      "NME: 0.3158\n",
      "Best model saved at epoch 113 with val_loss 70.9223\n",
      "Epoch [114/300], Loss: 61.8071\n",
      "Validation Loss: 68.4425\n",
      "NME: 0.3154\n",
      "Best model saved at epoch 114 with val_loss 68.4425\n",
      "Epoch [115/300], Loss: 61.0792\n",
      "Validation Loss: 72.5981\n",
      "NME: 0.3165\n",
      "Epoch [116/300], Loss: 65.5433\n",
      "Validation Loss: 74.0651\n",
      "NME: 0.3279\n",
      "Epoch [117/300], Loss: 61.4808\n",
      "Validation Loss: 69.4091\n",
      "NME: 0.3202\n",
      "Epoch [118/300], Loss: 63.8126\n",
      "Validation Loss: 76.7162\n",
      "NME: 0.3153\n",
      "Epoch [119/300], Loss: 64.4630\n",
      "Validation Loss: 77.0898\n",
      "NME: 0.3200\n",
      "Epoch [120/300], Loss: 62.0520\n",
      "Validation Loss: 71.3061\n",
      "NME: 0.3371\n",
      "Epoch [121/300], Loss: 61.7711\n",
      "Validation Loss: 72.5790\n",
      "NME: 0.3268\n",
      "Epoch [122/300], Loss: 60.4629\n",
      "Validation Loss: 74.5686\n",
      "NME: 0.3284\n",
      "Epoch [123/300], Loss: 61.3558\n",
      "Validation Loss: 73.5336\n",
      "NME: 0.3300\n",
      "Epoch [124/300], Loss: 59.4398\n",
      "Validation Loss: 72.6059\n",
      "NME: 0.3291\n",
      "Epoch [125/300], Loss: 55.1596\n",
      "Validation Loss: 72.1186\n",
      "NME: 0.3113\n",
      "Epoch [126/300], Loss: 54.6044\n",
      "Validation Loss: 71.3726\n",
      "NME: 0.3171\n",
      "Epoch [127/300], Loss: 58.4560\n",
      "Validation Loss: 71.3825\n",
      "NME: 0.3138\n",
      "Epoch [128/300], Loss: 53.5375\n",
      "Validation Loss: 67.5400\n",
      "NME: 0.3028\n",
      "Best model saved at epoch 128 with val_loss 67.5400\n",
      "Epoch [129/300], Loss: 55.4256\n",
      "Validation Loss: 75.6587\n",
      "NME: 0.3138\n",
      "Epoch [130/300], Loss: 55.4486\n",
      "Validation Loss: 72.8349\n",
      "NME: 0.3115\n",
      "Epoch [131/300], Loss: 54.2897\n",
      "Validation Loss: 69.2318\n",
      "NME: 0.3310\n",
      "Epoch [132/300], Loss: 55.7729\n",
      "Validation Loss: 71.6790\n",
      "NME: 0.3172\n",
      "Epoch [133/300], Loss: 52.8718\n",
      "Validation Loss: 66.9907\n",
      "NME: 0.3114\n",
      "Best model saved at epoch 133 with val_loss 66.9907\n",
      "Epoch [134/300], Loss: 52.7255\n",
      "Validation Loss: 68.5466\n",
      "NME: 0.3134\n",
      "Epoch [135/300], Loss: 53.5915\n",
      "Validation Loss: 68.9012\n",
      "NME: 0.3182\n",
      "Epoch [136/300], Loss: 51.1496\n",
      "Validation Loss: 69.1020\n",
      "NME: 0.3228\n",
      "Epoch [137/300], Loss: 54.9179\n",
      "Validation Loss: 71.2614\n",
      "NME: 0.3096\n",
      "Epoch [138/300], Loss: 51.5199\n",
      "Validation Loss: 70.4056\n",
      "NME: 0.3132\n",
      "Epoch [139/300], Loss: 55.4451\n",
      "Validation Loss: 76.9539\n",
      "NME: 0.3419\n",
      "Epoch [140/300], Loss: 56.8566\n",
      "Validation Loss: 67.2247\n",
      "NME: 0.3083\n",
      "Epoch [141/300], Loss: 55.3558\n",
      "Validation Loss: 73.6557\n",
      "NME: 0.3250\n",
      "Epoch [142/300], Loss: 52.2538\n",
      "Validation Loss: 69.4171\n",
      "NME: 0.3163\n",
      "Epoch [143/300], Loss: 53.8194\n",
      "Validation Loss: 68.3096\n",
      "NME: 0.3228\n",
      "Epoch [144/300], Loss: 52.2602\n",
      "Validation Loss: 69.7804\n",
      "NME: 0.3091\n",
      "Epoch [145/300], Loss: 50.8111\n",
      "Validation Loss: 68.7741\n",
      "NME: 0.3153\n",
      "Epoch [146/300], Loss: 51.5154\n",
      "Validation Loss: 72.6062\n",
      "NME: 0.3179\n",
      "Epoch [147/300], Loss: 51.1243\n",
      "Validation Loss: 70.2708\n",
      "NME: 0.3114\n",
      "Epoch [148/300], Loss: 49.6182\n",
      "Validation Loss: 70.6675\n",
      "NME: 0.3184\n",
      "Epoch [149/300], Loss: 50.7253\n",
      "Validation Loss: 68.9641\n",
      "NME: 0.3124\n",
      "Epoch [150/300], Loss: 51.0005\n",
      "Validation Loss: 70.8253\n",
      "NME: 0.3186\n",
      "Epoch [151/300], Loss: 54.7778\n",
      "Validation Loss: 72.7497\n",
      "NME: 0.3311\n",
      "Epoch [152/300], Loss: 52.9521\n",
      "Validation Loss: 77.8726\n",
      "NME: 0.3400\n",
      "Epoch [153/300], Loss: 54.6563\n",
      "Validation Loss: 70.2945\n",
      "NME: 0.3185\n",
      "Epoch [154/300], Loss: 50.4465\n",
      "Validation Loss: 70.0476\n",
      "NME: 0.3163\n",
      "Epoch [155/300], Loss: 50.3224\n",
      "Validation Loss: 81.8418\n",
      "NME: 0.3384\n",
      "Epoch [156/300], Loss: 50.9429\n",
      "Validation Loss: 71.3878\n",
      "NME: 0.3291\n",
      "Epoch [157/300], Loss: 50.0326\n",
      "Validation Loss: 71.6372\n",
      "NME: 0.3197\n",
      "Epoch [158/300], Loss: 49.8109\n",
      "Validation Loss: 73.3082\n",
      "NME: 0.3252\n",
      "Epoch [159/300], Loss: 50.0962\n",
      "Validation Loss: 73.2667\n",
      "NME: 0.3292\n",
      "Epoch [160/300], Loss: 60.6940\n",
      "Validation Loss: 75.7476\n",
      "NME: 0.3239\n",
      "Epoch [161/300], Loss: 51.2830\n",
      "Validation Loss: 69.9298\n",
      "NME: 0.3250\n",
      "Epoch [162/300], Loss: 49.1001\n",
      "Validation Loss: 70.6877\n",
      "NME: 0.3118\n",
      "Epoch [163/300], Loss: 49.3748\n",
      "Validation Loss: 67.5816\n",
      "NME: 0.3052\n",
      "Epoch [164/300], Loss: 47.6175\n",
      "Validation Loss: 69.0123\n",
      "NME: 0.3096\n",
      "Epoch [165/300], Loss: 48.9942\n",
      "Validation Loss: 69.3479\n",
      "NME: 0.3165\n",
      "Epoch [166/300], Loss: 46.7446\n",
      "Validation Loss: 67.9856\n",
      "NME: 0.2991\n",
      "Epoch [167/300], Loss: 47.2983\n",
      "Validation Loss: 71.4650\n",
      "NME: 0.3181\n",
      "Epoch [168/300], Loss: 48.5263\n",
      "Validation Loss: 70.1263\n",
      "NME: 0.3220\n",
      "Epoch [169/300], Loss: 52.2249\n",
      "Validation Loss: 68.5076\n",
      "NME: 0.3141\n",
      "Epoch [170/300], Loss: 47.9675\n",
      "Validation Loss: 66.7168\n",
      "NME: 0.3114\n",
      "Best model saved at epoch 170 with val_loss 66.7168\n",
      "Epoch [171/300], Loss: 46.8141\n",
      "Validation Loss: 69.5383\n",
      "NME: 0.3197\n",
      "Epoch [172/300], Loss: 49.8496\n",
      "Validation Loss: 66.8548\n",
      "NME: 0.3011\n",
      "Epoch [173/300], Loss: 49.7892\n",
      "Validation Loss: 65.8656\n",
      "NME: 0.3009\n",
      "Best model saved at epoch 173 with val_loss 65.8656\n",
      "Epoch [174/300], Loss: 45.7512\n",
      "Validation Loss: 66.6328\n",
      "NME: 0.3126\n",
      "Epoch [175/300], Loss: 45.8547\n",
      "Validation Loss: 67.0001\n",
      "NME: 0.3165\n",
      "Epoch [176/300], Loss: 46.5719\n",
      "Validation Loss: 68.8121\n",
      "NME: 0.3037\n",
      "Epoch [177/300], Loss: 45.8408\n",
      "Validation Loss: 67.6233\n",
      "NME: 0.3065\n",
      "Epoch [178/300], Loss: 44.6214\n",
      "Validation Loss: 68.6710\n",
      "NME: 0.3113\n",
      "Epoch [179/300], Loss: 44.0236\n",
      "Validation Loss: 65.9325\n",
      "NME: 0.3018\n",
      "Epoch [180/300], Loss: 46.9417\n",
      "Validation Loss: 68.7243\n",
      "NME: 0.3041\n",
      "Epoch [181/300], Loss: 51.1138\n",
      "Validation Loss: 70.3285\n",
      "NME: 0.3086\n",
      "Epoch [182/300], Loss: 50.7766\n",
      "Validation Loss: 70.5534\n",
      "NME: 0.3151\n",
      "Epoch [183/300], Loss: 47.8236\n",
      "Validation Loss: 68.3841\n",
      "NME: 0.3102\n",
      "Epoch [184/300], Loss: 48.1841\n",
      "Validation Loss: 66.9472\n",
      "NME: 0.3133\n",
      "Epoch [185/300], Loss: 44.8919\n",
      "Validation Loss: 64.2805\n",
      "NME: 0.2968\n",
      "Best model saved at epoch 185 with val_loss 64.2805\n",
      "Epoch [186/300], Loss: 43.7930\n",
      "Validation Loss: 65.1903\n",
      "NME: 0.3072\n",
      "Epoch [187/300], Loss: 43.2911\n",
      "Validation Loss: 65.4344\n",
      "NME: 0.2976\n",
      "Epoch [188/300], Loss: 42.6598\n",
      "Validation Loss: 64.4681\n",
      "NME: 0.2997\n",
      "Epoch [189/300], Loss: 42.8773\n",
      "Validation Loss: 65.4460\n",
      "NME: 0.2992\n",
      "Epoch [190/300], Loss: 43.3330\n",
      "Validation Loss: 65.9791\n",
      "NME: 0.3047\n",
      "Epoch [191/300], Loss: 42.6425\n",
      "Validation Loss: 65.2778\n",
      "NME: 0.3044\n",
      "Epoch [192/300], Loss: 41.2463\n",
      "Validation Loss: 65.4955\n",
      "NME: 0.3045\n",
      "Epoch [193/300], Loss: 42.1203\n",
      "Validation Loss: 67.6995\n",
      "NME: 0.3017\n",
      "Epoch [194/300], Loss: 41.6331\n",
      "Validation Loss: 63.7163\n",
      "NME: 0.3039\n",
      "Best model saved at epoch 194 with val_loss 63.7163\n",
      "Epoch [195/300], Loss: 44.7683\n",
      "Validation Loss: 65.7448\n",
      "NME: 0.3077\n",
      "Epoch [196/300], Loss: 44.0787\n",
      "Validation Loss: 64.4606\n",
      "NME: 0.2984\n",
      "Epoch [197/300], Loss: 43.3101\n",
      "Validation Loss: 67.1373\n",
      "NME: 0.3022\n",
      "Epoch [198/300], Loss: 41.5778\n",
      "Validation Loss: 63.5160\n",
      "NME: 0.2982\n",
      "Best model saved at epoch 198 with val_loss 63.5160\n",
      "Epoch [199/300], Loss: 40.0713\n",
      "Validation Loss: 64.0376\n",
      "NME: 0.3016\n",
      "Epoch [200/300], Loss: 39.3114\n",
      "Validation Loss: 62.6168\n",
      "NME: 0.2913\n",
      "Best model saved at epoch 200 with val_loss 62.6168\n",
      "Epoch [201/300], Loss: 39.0532\n",
      "Validation Loss: 63.5246\n",
      "NME: 0.2969\n",
      "Epoch [202/300], Loss: 40.7249\n",
      "Validation Loss: 66.4358\n",
      "NME: 0.2998\n",
      "Epoch [203/300], Loss: 38.9423\n",
      "Validation Loss: 63.8238\n",
      "NME: 0.3005\n",
      "Epoch [204/300], Loss: 38.9106\n",
      "Validation Loss: 62.5984\n",
      "NME: 0.3085\n",
      "Best model saved at epoch 204 with val_loss 62.5984\n",
      "Epoch [205/300], Loss: 38.7594\n",
      "Validation Loss: 64.0290\n",
      "NME: 0.3004\n",
      "Epoch [206/300], Loss: 39.0618\n",
      "Validation Loss: 62.1490\n",
      "NME: 0.2973\n",
      "Best model saved at epoch 206 with val_loss 62.1490\n",
      "Epoch [207/300], Loss: 37.7378\n",
      "Validation Loss: 63.8386\n",
      "NME: 0.2954\n",
      "Epoch [208/300], Loss: 40.7587\n",
      "Validation Loss: 64.9156\n",
      "NME: 0.3073\n",
      "Epoch [209/300], Loss: 37.0419\n",
      "Validation Loss: 62.9218\n",
      "NME: 0.2903\n",
      "Epoch [210/300], Loss: 37.1634\n",
      "Validation Loss: 64.5200\n",
      "NME: 0.2963\n",
      "Epoch [211/300], Loss: 36.9581\n",
      "Validation Loss: 61.8312\n",
      "NME: 0.2963\n",
      "Best model saved at epoch 211 with val_loss 61.8312\n",
      "Epoch [212/300], Loss: 37.6608\n",
      "Validation Loss: 62.6337\n",
      "NME: 0.3037\n",
      "Epoch [213/300], Loss: 37.8813\n",
      "Validation Loss: 63.0219\n",
      "NME: 0.2985\n",
      "Epoch [214/300], Loss: 37.6680\n",
      "Validation Loss: 63.0248\n",
      "NME: 0.2927\n",
      "Epoch [215/300], Loss: 38.0678\n",
      "Validation Loss: 63.7814\n",
      "NME: 0.3039\n",
      "Epoch [216/300], Loss: 36.9625\n",
      "Validation Loss: 63.3899\n",
      "NME: 0.3023\n",
      "Epoch [217/300], Loss: 35.9214\n",
      "Validation Loss: 60.0704\n",
      "NME: 0.2966\n",
      "Best model saved at epoch 217 with val_loss 60.0704\n",
      "Epoch [218/300], Loss: 36.2671\n",
      "Validation Loss: 59.9971\n",
      "NME: 0.2955\n",
      "Best model saved at epoch 218 with val_loss 59.9971\n",
      "Epoch [219/300], Loss: 36.2191\n",
      "Validation Loss: 60.3759\n",
      "NME: 0.2971\n",
      "Epoch [220/300], Loss: 38.4672\n",
      "Validation Loss: 60.0950\n",
      "NME: 0.2936\n",
      "Epoch [221/300], Loss: 39.2265\n",
      "Validation Loss: 64.0874\n",
      "NME: 0.3109\n",
      "Epoch [222/300], Loss: 36.5168\n",
      "Validation Loss: 63.9013\n",
      "NME: 0.3019\n",
      "Epoch [223/300], Loss: 36.9883\n",
      "Validation Loss: 60.7248\n",
      "NME: 0.2960\n",
      "Epoch [224/300], Loss: 34.6123\n",
      "Validation Loss: 60.6290\n",
      "NME: 0.3038\n",
      "Epoch [225/300], Loss: 34.2096\n",
      "Validation Loss: 59.3929\n",
      "NME: 0.2929\n",
      "Best model saved at epoch 225 with val_loss 59.3929\n",
      "Epoch [226/300], Loss: 35.2738\n",
      "Validation Loss: 59.8396\n",
      "NME: 0.2943\n",
      "Epoch [227/300], Loss: 33.2797\n",
      "Validation Loss: 59.1292\n",
      "NME: 0.2912\n",
      "Best model saved at epoch 227 with val_loss 59.1292\n",
      "Epoch [228/300], Loss: 33.4587\n",
      "Validation Loss: 59.5532\n",
      "NME: 0.2926\n",
      "Epoch [229/300], Loss: 36.3447\n",
      "Validation Loss: 65.7040\n",
      "NME: 0.3036\n",
      "Epoch [230/300], Loss: 50.8300\n",
      "Validation Loss: 91.4532\n",
      "NME: 0.3507\n",
      "Epoch [231/300], Loss: 52.1518\n",
      "Validation Loss: 68.7447\n",
      "NME: 0.3064\n",
      "Epoch [232/300], Loss: 39.5081\n",
      "Validation Loss: 63.3284\n",
      "NME: 0.3025\n",
      "Epoch [233/300], Loss: 37.0670\n",
      "Validation Loss: 63.8521\n",
      "NME: 0.3000\n",
      "Epoch [234/300], Loss: 34.6935\n",
      "Validation Loss: 61.2185\n",
      "NME: 0.3022\n",
      "Epoch [235/300], Loss: 34.4208\n",
      "Validation Loss: 61.7331\n",
      "NME: 0.2962\n",
      "Epoch [236/300], Loss: 33.8838\n",
      "Validation Loss: 62.6932\n",
      "NME: 0.3007\n",
      "Epoch [237/300], Loss: 32.7729\n",
      "Validation Loss: 62.0400\n",
      "NME: 0.3104\n",
      "Epoch [238/300], Loss: 33.9626\n",
      "Validation Loss: 61.3303\n",
      "NME: 0.2928\n",
      "Epoch [239/300], Loss: 33.0497\n",
      "Validation Loss: 61.9654\n",
      "NME: 0.3013\n",
      "Epoch [240/300], Loss: 33.1428\n",
      "Validation Loss: 60.6899\n",
      "NME: 0.2964\n",
      "Epoch [241/300], Loss: 32.4519\n",
      "Validation Loss: 61.6873\n",
      "NME: 0.2931\n",
      "Epoch [242/300], Loss: 32.9351\n",
      "Validation Loss: 60.9592\n",
      "NME: 0.2971\n",
      "Epoch [243/300], Loss: 31.7453\n",
      "Validation Loss: 58.6849\n",
      "NME: 0.2912\n",
      "Best model saved at epoch 243 with val_loss 58.6849\n",
      "Epoch [244/300], Loss: 32.3065\n",
      "Validation Loss: 60.4971\n",
      "NME: 0.2944\n",
      "Epoch [245/300], Loss: 33.1440\n",
      "Validation Loss: 60.9512\n",
      "NME: 0.2952\n",
      "Epoch [246/300], Loss: 32.4457\n",
      "Validation Loss: 59.7284\n",
      "NME: 0.2923\n",
      "Epoch [247/300], Loss: 33.0419\n",
      "Validation Loss: 61.4381\n",
      "NME: 0.2995\n",
      "Epoch [248/300], Loss: 31.4375\n",
      "Validation Loss: 61.5168\n",
      "NME: 0.2922\n",
      "Epoch [249/300], Loss: 32.9142\n",
      "Validation Loss: 62.4569\n",
      "NME: 0.2996\n",
      "Epoch [250/300], Loss: 31.8033\n",
      "Validation Loss: 59.9716\n",
      "NME: 0.2886\n",
      "Epoch [251/300], Loss: 31.4139\n",
      "Validation Loss: 61.4717\n",
      "NME: 0.2895\n",
      "Epoch [252/300], Loss: 32.2810\n",
      "Validation Loss: 59.7903\n",
      "NME: 0.2908\n",
      "Epoch [253/300], Loss: 32.7868\n",
      "Validation Loss: 61.9116\n",
      "NME: 0.3027\n",
      "Epoch [254/300], Loss: 32.7068\n",
      "Validation Loss: 59.2703\n",
      "NME: 0.2982\n",
      "Epoch [255/300], Loss: 31.5407\n",
      "Validation Loss: 59.4766\n",
      "NME: 0.2886\n",
      "Epoch [256/300], Loss: 33.8541\n",
      "Validation Loss: 60.4507\n",
      "NME: 0.2932\n",
      "Epoch [257/300], Loss: 34.5798\n",
      "Validation Loss: 62.0381\n",
      "NME: 0.2975\n",
      "Epoch [258/300], Loss: 34.7499\n",
      "Validation Loss: 61.8987\n",
      "NME: 0.2909\n",
      "Epoch [259/300], Loss: 33.1963\n",
      "Validation Loss: 59.5437\n",
      "NME: 0.2959\n",
      "Epoch [260/300], Loss: 34.1206\n",
      "Validation Loss: 63.2217\n",
      "NME: 0.3063\n",
      "Epoch [261/300], Loss: 35.0587\n",
      "Validation Loss: 69.0896\n",
      "NME: 0.3171\n",
      "Epoch [262/300], Loss: 38.4512\n",
      "Validation Loss: 68.7020\n",
      "NME: 0.3122\n",
      "Epoch [263/300], Loss: 36.6974\n",
      "Validation Loss: 62.7695\n",
      "NME: 0.2939\n",
      "Epoch [264/300], Loss: 34.0748\n",
      "Validation Loss: 61.0690\n",
      "NME: 0.2915\n",
      "Epoch [265/300], Loss: 32.9360\n",
      "Validation Loss: 59.5791\n",
      "NME: 0.2988\n",
      "Epoch [266/300], Loss: 31.8105\n",
      "Validation Loss: 61.4781\n",
      "NME: 0.2941\n",
      "Epoch [267/300], Loss: 31.8464\n",
      "Validation Loss: 59.7980\n",
      "NME: 0.2881\n",
      "Epoch [268/300], Loss: 31.6228\n",
      "Validation Loss: 62.4998\n",
      "NME: 0.2954\n",
      "Epoch [269/300], Loss: 31.1417\n",
      "Validation Loss: 62.0163\n",
      "NME: 0.2945\n",
      "Epoch [270/300], Loss: 31.3764\n",
      "Validation Loss: 59.3261\n",
      "NME: 0.2919\n",
      "Epoch [271/300], Loss: 36.6169\n",
      "Validation Loss: 60.3982\n",
      "NME: 0.2893\n",
      "Epoch [272/300], Loss: 32.3796\n",
      "Validation Loss: 59.8755\n",
      "NME: 0.2905\n",
      "Epoch [273/300], Loss: 30.9308\n",
      "Validation Loss: 60.6063\n",
      "NME: 0.2860\n",
      "Epoch [274/300], Loss: 31.6092\n",
      "Validation Loss: 59.0489\n",
      "NME: 0.2858\n",
      "Epoch [275/300], Loss: 36.0079\n",
      "Validation Loss: 63.1020\n",
      "NME: 0.2976\n",
      "Epoch [276/300], Loss: 32.9421\n",
      "Validation Loss: 79.1779\n",
      "NME: 0.2970\n",
      "Epoch [277/300], Loss: 33.4349\n",
      "Validation Loss: 64.3298\n",
      "NME: 0.2995\n",
      "Epoch [278/300], Loss: 33.7518\n",
      "Validation Loss: 62.8828\n",
      "NME: 0.3004\n",
      "Epoch [279/300], Loss: 33.1490\n",
      "Validation Loss: 61.4975\n",
      "NME: 0.3029\n",
      "Epoch [280/300], Loss: 31.7808\n",
      "Validation Loss: 59.9887\n",
      "NME: 0.2930\n",
      "Epoch [281/300], Loss: 31.5807\n",
      "Validation Loss: 59.8151\n",
      "NME: 0.2953\n",
      "Epoch [282/300], Loss: 31.0360\n",
      "Validation Loss: 59.1826\n",
      "NME: 0.2847\n",
      "Epoch [283/300], Loss: 30.0955\n",
      "Validation Loss: 60.4243\n",
      "NME: 0.2859\n",
      "Epoch [284/300], Loss: 31.0862\n",
      "Validation Loss: 61.6194\n",
      "NME: 0.2924\n",
      "Epoch [285/300], Loss: 31.3434\n",
      "Validation Loss: 62.5490\n",
      "NME: 0.2975\n",
      "Epoch [286/300], Loss: 30.4507\n",
      "Validation Loss: 63.0444\n",
      "NME: 0.2944\n",
      "Epoch [287/300], Loss: 30.0283\n",
      "Validation Loss: 61.3499\n",
      "NME: 0.2932\n",
      "Epoch [288/300], Loss: 30.4814\n",
      "Validation Loss: 61.5359\n",
      "NME: 0.3045\n",
      "Epoch [289/300], Loss: 30.8869\n",
      "Validation Loss: 60.7094\n",
      "NME: 0.2886\n",
      "Epoch [290/300], Loss: 29.7006\n",
      "Validation Loss: 61.5468\n",
      "NME: 0.2972\n",
      "Epoch [291/300], Loss: 29.7919\n",
      "Validation Loss: 61.5320\n",
      "NME: 0.2928\n",
      "Epoch [292/300], Loss: 30.6178\n",
      "Validation Loss: 62.3323\n",
      "NME: 0.2918\n",
      "Epoch [293/300], Loss: 30.9016\n",
      "Validation Loss: 61.9662\n",
      "NME: 0.2906\n",
      "Epoch [294/300], Loss: 29.0443\n",
      "Validation Loss: 60.5056\n",
      "NME: 0.2886\n",
      "Epoch [295/300], Loss: 33.8274\n",
      "Validation Loss: 66.7474\n",
      "NME: 0.3070\n",
      "Epoch [296/300], Loss: 31.7847\n",
      "Validation Loss: 61.6881\n",
      "NME: 0.2936\n",
      "Epoch [297/300], Loss: 30.6465\n",
      "Validation Loss: 61.4081\n",
      "NME: 0.2947\n",
      "Epoch [298/300], Loss: 31.0358\n",
      "Validation Loss: 63.6207\n",
      "NME: 0.2955\n",
      "Epoch [299/300], Loss: 30.1716\n",
      "Validation Loss: 61.4731\n",
      "NME: 0.2940\n",
      "Epoch [300/300], Loss: 31.7569\n",
      "Validation Loss: 71.2471\n",
      "NME: 0.3132\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EyeLeftDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave del ojo izquierdo\n",
    "        eye_left_points = np.array([landmarks[i] for i in ojo_izq], dtype=np.float32)\n",
    "        eye_left_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(eye_left_points), 1))\n",
    "        points_ones = np.hstack([eye_left_points, ones])\n",
    "        eye_left_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado del ojo izquierdo\n",
    "        centro_x, centro_y = calcular_centro_region(eye_left_points_rotated, range(len(ojo_izq)))\n",
    "\n",
    "        # Definir los límites del recorte de 56x56 píxeles\n",
    "        half_crop_size = 28\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_eye = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_eye, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales del ojo izquierdo al nuevo recorte\n",
    "        eye_left_points_adjusted = [(p[0] - x1, p[1] - y1) for p in eye_left_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        eye_left_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in eye_left_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=eye_left_points_scaled)\n",
    "            image = augmented['image']\n",
    "            eye_left_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(eye_left_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EyeLeftDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EyeLeftDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EyeLeft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EyeLeft, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(ojo_izq) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EyeLeft().cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para ojo izquierdo)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, eye_left_points, _, _, _ in train_dataloader:\n",
    "            images, eye_left_points = images.cuda(), eye_left_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, eye_left_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_eye_left_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_eye_left_points = val_images.cuda(), val_eye_left_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_eye_left_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_eye_left_points.cpu().numpy().reshape(-1, len(ojo_izq), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(ojo_izq), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(ojo_izq))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EyeLeftLandmarks V4.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14571.5090\n",
      "Validation Loss: 13211.5468\n",
      "NME: 7.0548\n",
      "Best model saved at epoch 1 with val_loss 13211.5468\n",
      "Epoch [2/300], Loss: 9226.8351\n",
      "Validation Loss: 4418.2021\n",
      "NME: 3.6847\n",
      "Best model saved at epoch 2 with val_loss 4418.2021\n",
      "Epoch [3/300], Loss: 2134.2458\n",
      "Validation Loss: 1037.6224\n",
      "NME: 1.2995\n",
      "Best model saved at epoch 3 with val_loss 1037.6224\n",
      "Epoch [4/300], Loss: 865.8629\n",
      "Validation Loss: 657.7015\n",
      "NME: 1.0058\n",
      "Best model saved at epoch 4 with val_loss 657.7015\n",
      "Epoch [5/300], Loss: 677.6547\n",
      "Validation Loss: 589.8464\n",
      "NME: 1.0135\n",
      "Best model saved at epoch 5 with val_loss 589.8464\n",
      "Epoch [6/300], Loss: 646.9063\n",
      "Validation Loss: 566.6760\n",
      "NME: 1.0232\n",
      "Best model saved at epoch 6 with val_loss 566.6760\n",
      "Epoch [7/300], Loss: 630.8436\n",
      "Validation Loss: 554.2906\n",
      "NME: 1.0097\n",
      "Best model saved at epoch 7 with val_loss 554.2906\n",
      "Epoch [8/300], Loss: 631.0438\n",
      "Validation Loss: 555.5191\n",
      "NME: 1.0194\n",
      "Epoch [9/300], Loss: 617.0227\n",
      "Validation Loss: 542.5481\n",
      "NME: 1.0172\n",
      "Best model saved at epoch 9 with val_loss 542.5481\n",
      "Epoch [10/300], Loss: 614.6330\n",
      "Validation Loss: 527.5592\n",
      "NME: 0.9818\n",
      "Best model saved at epoch 10 with val_loss 527.5592\n",
      "Epoch [11/300], Loss: 597.7601\n",
      "Validation Loss: 510.1372\n",
      "NME: 0.9742\n",
      "Best model saved at epoch 11 with val_loss 510.1372\n",
      "Epoch [12/300], Loss: 577.7464\n",
      "Validation Loss: 480.1462\n",
      "NME: 0.9187\n",
      "Best model saved at epoch 12 with val_loss 480.1462\n",
      "Epoch [13/300], Loss: 523.0636\n",
      "Validation Loss: 393.8812\n",
      "NME: 0.8573\n",
      "Best model saved at epoch 13 with val_loss 393.8812\n",
      "Epoch [14/300], Loss: 425.3365\n",
      "Validation Loss: 274.9460\n",
      "NME: 0.7455\n",
      "Best model saved at epoch 14 with val_loss 274.9460\n",
      "Epoch [15/300], Loss: 354.7004\n",
      "Validation Loss: 207.3414\n",
      "NME: 0.5834\n",
      "Best model saved at epoch 15 with val_loss 207.3414\n",
      "Epoch [16/300], Loss: 295.4561\n",
      "Validation Loss: 167.1602\n",
      "NME: 0.5471\n",
      "Best model saved at epoch 16 with val_loss 167.1602\n",
      "Epoch [17/300], Loss: 288.6510\n",
      "Validation Loss: 157.8985\n",
      "NME: 0.5667\n",
      "Best model saved at epoch 17 with val_loss 157.8985\n",
      "Epoch [18/300], Loss: 247.5820\n",
      "Validation Loss: 127.8713\n",
      "NME: 0.4485\n",
      "Best model saved at epoch 18 with val_loss 127.8713\n",
      "Epoch [19/300], Loss: 233.8853\n",
      "Validation Loss: 126.2737\n",
      "NME: 0.4639\n",
      "Best model saved at epoch 19 with val_loss 126.2737\n",
      "Epoch [20/300], Loss: 240.6986\n",
      "Validation Loss: 121.8037\n",
      "NME: 0.4542\n",
      "Best model saved at epoch 20 with val_loss 121.8037\n",
      "Epoch [21/300], Loss: 221.8244\n",
      "Validation Loss: 126.8245\n",
      "NME: 0.4648\n",
      "Epoch [22/300], Loss: 215.6270\n",
      "Validation Loss: 118.6268\n",
      "NME: 0.4456\n",
      "Best model saved at epoch 22 with val_loss 118.6268\n",
      "Epoch [23/300], Loss: 203.5314\n",
      "Validation Loss: 115.9894\n",
      "NME: 0.4400\n",
      "Best model saved at epoch 23 with val_loss 115.9894\n",
      "Epoch [24/300], Loss: 211.2764\n",
      "Validation Loss: 119.4490\n",
      "NME: 0.4298\n",
      "Epoch [25/300], Loss: 200.4280\n",
      "Validation Loss: 135.7917\n",
      "NME: 0.4903\n",
      "Epoch [26/300], Loss: 227.7167\n",
      "Validation Loss: 129.7383\n",
      "NME: 0.4896\n",
      "Epoch [27/300], Loss: 212.3779\n",
      "Validation Loss: 125.2519\n",
      "NME: 0.4570\n",
      "Epoch [28/300], Loss: 186.7436\n",
      "Validation Loss: 110.0147\n",
      "NME: 0.4457\n",
      "Best model saved at epoch 28 with val_loss 110.0147\n",
      "Epoch [29/300], Loss: 212.8774\n",
      "Validation Loss: 133.8607\n",
      "NME: 0.5254\n",
      "Epoch [30/300], Loss: 204.0642\n",
      "Validation Loss: 127.5985\n",
      "NME: 0.5194\n",
      "Epoch [31/300], Loss: 211.8079\n",
      "Validation Loss: 121.3729\n",
      "NME: 0.4758\n",
      "Epoch [32/300], Loss: 187.5135\n",
      "Validation Loss: 121.1394\n",
      "NME: 0.4524\n",
      "Epoch [33/300], Loss: 181.0985\n",
      "Validation Loss: 120.8518\n",
      "NME: 0.4703\n",
      "Epoch [34/300], Loss: 194.2446\n",
      "Validation Loss: 117.2202\n",
      "NME: 0.4541\n",
      "Epoch [35/300], Loss: 186.7233\n",
      "Validation Loss: 121.7069\n",
      "NME: 0.4659\n",
      "Epoch [36/300], Loss: 194.3527\n",
      "Validation Loss: 119.6428\n",
      "NME: 0.4535\n",
      "Epoch [37/300], Loss: 177.5586\n",
      "Validation Loss: 124.9229\n",
      "NME: 0.4840\n",
      "Epoch [38/300], Loss: 181.9531\n",
      "Validation Loss: 122.1949\n",
      "NME: 0.4723\n",
      "Epoch [39/300], Loss: 196.8956\n",
      "Validation Loss: 116.9157\n",
      "NME: 0.4348\n",
      "Epoch [40/300], Loss: 186.7359\n",
      "Validation Loss: 117.3040\n",
      "NME: 0.4531\n",
      "Epoch [41/300], Loss: 184.6813\n",
      "Validation Loss: 116.6520\n",
      "NME: 0.4609\n",
      "Epoch [42/300], Loss: 186.9509\n",
      "Validation Loss: 120.8384\n",
      "NME: 0.4847\n",
      "Epoch [43/300], Loss: 188.6110\n",
      "Validation Loss: 111.6149\n",
      "NME: 0.4249\n",
      "Epoch [44/300], Loss: 179.5136\n",
      "Validation Loss: 107.1152\n",
      "NME: 0.4246\n",
      "Best model saved at epoch 44 with val_loss 107.1152\n",
      "Epoch [45/300], Loss: 193.5130\n",
      "Validation Loss: 115.0955\n",
      "NME: 0.4239\n",
      "Epoch [46/300], Loss: 172.7620\n",
      "Validation Loss: 112.8204\n",
      "NME: 0.4486\n",
      "Epoch [47/300], Loss: 175.2705\n",
      "Validation Loss: 112.0988\n",
      "NME: 0.4462\n",
      "Epoch [48/300], Loss: 182.5953\n",
      "Validation Loss: 113.3138\n",
      "NME: 0.4303\n",
      "Epoch [49/300], Loss: 183.1188\n",
      "Validation Loss: 111.9369\n",
      "NME: 0.4353\n",
      "Epoch [50/300], Loss: 174.8360\n",
      "Validation Loss: 110.8085\n",
      "NME: 0.4335\n",
      "Epoch [51/300], Loss: 181.9615\n",
      "Validation Loss: 110.5601\n",
      "NME: 0.4281\n",
      "Epoch [52/300], Loss: 176.7749\n",
      "Validation Loss: 107.4042\n",
      "NME: 0.4217\n",
      "Epoch [53/300], Loss: 166.5817\n",
      "Validation Loss: 112.4878\n",
      "NME: 0.4603\n",
      "Epoch [54/300], Loss: 168.5215\n",
      "Validation Loss: 111.7979\n",
      "NME: 0.4450\n",
      "Epoch [55/300], Loss: 145.2789\n",
      "Validation Loss: 107.3498\n",
      "NME: 0.4098\n",
      "Epoch [56/300], Loss: 157.3626\n",
      "Validation Loss: 105.9444\n",
      "NME: 0.4116\n",
      "Best model saved at epoch 56 with val_loss 105.9444\n",
      "Epoch [57/300], Loss: 142.1689\n",
      "Validation Loss: 107.4314\n",
      "NME: 0.4324\n",
      "Epoch [58/300], Loss: 149.6195\n",
      "Validation Loss: 110.3800\n",
      "NME: 0.4291\n",
      "Epoch [59/300], Loss: 137.4063\n",
      "Validation Loss: 131.5194\n",
      "NME: 0.4616\n",
      "Epoch [60/300], Loss: 139.8454\n",
      "Validation Loss: 125.8132\n",
      "NME: 0.4464\n",
      "Epoch [61/300], Loss: 134.7340\n",
      "Validation Loss: 112.9811\n",
      "NME: 0.4267\n",
      "Epoch [62/300], Loss: 128.6232\n",
      "Validation Loss: 123.3987\n",
      "NME: 0.4398\n",
      "Epoch [63/300], Loss: 122.3245\n",
      "Validation Loss: 106.0677\n",
      "NME: 0.4267\n",
      "Epoch [64/300], Loss: 109.9007\n",
      "Validation Loss: 102.7460\n",
      "NME: 0.4113\n",
      "Best model saved at epoch 64 with val_loss 102.7460\n",
      "Epoch [65/300], Loss: 110.5420\n",
      "Validation Loss: 115.6539\n",
      "NME: 0.4399\n",
      "Epoch [66/300], Loss: 111.4551\n",
      "Validation Loss: 113.1734\n",
      "NME: 0.4342\n",
      "Epoch [67/300], Loss: 118.3609\n",
      "Validation Loss: 104.2771\n",
      "NME: 0.4177\n",
      "Epoch [68/300], Loss: 111.6379\n",
      "Validation Loss: 106.6154\n",
      "NME: 0.4087\n",
      "Epoch [69/300], Loss: 107.1235\n",
      "Validation Loss: 101.9606\n",
      "NME: 0.4119\n",
      "Best model saved at epoch 69 with val_loss 101.9606\n",
      "Epoch [70/300], Loss: 99.9033\n",
      "Validation Loss: 104.1961\n",
      "NME: 0.4041\n",
      "Epoch [71/300], Loss: 99.2650\n",
      "Validation Loss: 101.9695\n",
      "NME: 0.4086\n",
      "Epoch [72/300], Loss: 101.7108\n",
      "Validation Loss: 104.8188\n",
      "NME: 0.4314\n",
      "Epoch [73/300], Loss: 101.1508\n",
      "Validation Loss: 124.3457\n",
      "NME: 0.4282\n",
      "Epoch [74/300], Loss: 103.8123\n",
      "Validation Loss: 109.8822\n",
      "NME: 0.4172\n",
      "Epoch [75/300], Loss: 102.8749\n",
      "Validation Loss: 108.9094\n",
      "NME: 0.4141\n",
      "Epoch [76/300], Loss: 98.6889\n",
      "Validation Loss: 101.8242\n",
      "NME: 0.4123\n",
      "Best model saved at epoch 76 with val_loss 101.8242\n",
      "Epoch [77/300], Loss: 99.2151\n",
      "Validation Loss: 106.0458\n",
      "NME: 0.4334\n",
      "Epoch [78/300], Loss: 97.7437\n",
      "Validation Loss: 105.3642\n",
      "NME: 0.4229\n",
      "Epoch [79/300], Loss: 97.9526\n",
      "Validation Loss: 99.3033\n",
      "NME: 0.4035\n",
      "Best model saved at epoch 79 with val_loss 99.3033\n",
      "Epoch [80/300], Loss: 96.3391\n",
      "Validation Loss: 102.7696\n",
      "NME: 0.4142\n",
      "Epoch [81/300], Loss: 100.0890\n",
      "Validation Loss: 129.8368\n",
      "NME: 0.4281\n",
      "Epoch [82/300], Loss: 130.3527\n",
      "Validation Loss: 138.2443\n",
      "NME: 0.4341\n",
      "Epoch [83/300], Loss: 110.0890\n",
      "Validation Loss: 105.6434\n",
      "NME: 0.4160\n",
      "Epoch [84/300], Loss: 106.7326\n",
      "Validation Loss: 103.6863\n",
      "NME: 0.4166\n",
      "Epoch [85/300], Loss: 98.3663\n",
      "Validation Loss: 106.5333\n",
      "NME: 0.4171\n",
      "Epoch [86/300], Loss: 96.7131\n",
      "Validation Loss: 105.8100\n",
      "NME: 0.4149\n",
      "Epoch [87/300], Loss: 101.6863\n",
      "Validation Loss: 99.3086\n",
      "NME: 0.3952\n",
      "Epoch [88/300], Loss: 97.2795\n",
      "Validation Loss: 96.7202\n",
      "NME: 0.3941\n",
      "Best model saved at epoch 88 with val_loss 96.7202\n",
      "Epoch [89/300], Loss: 106.4699\n",
      "Validation Loss: 97.6918\n",
      "NME: 0.4008\n",
      "Epoch [90/300], Loss: 99.4485\n",
      "Validation Loss: 100.4001\n",
      "NME: 0.4133\n",
      "Epoch [91/300], Loss: 92.6138\n",
      "Validation Loss: 92.2963\n",
      "NME: 0.3900\n",
      "Best model saved at epoch 91 with val_loss 92.2963\n",
      "Epoch [92/300], Loss: 88.3196\n",
      "Validation Loss: 88.8191\n",
      "NME: 0.3846\n",
      "Best model saved at epoch 92 with val_loss 88.8191\n",
      "Epoch [93/300], Loss: 88.1032\n",
      "Validation Loss: 88.5073\n",
      "NME: 0.3662\n",
      "Best model saved at epoch 93 with val_loss 88.5073\n",
      "Epoch [94/300], Loss: 84.4631\n",
      "Validation Loss: 98.9464\n",
      "NME: 0.3718\n",
      "Epoch [95/300], Loss: 88.1931\n",
      "Validation Loss: 86.7212\n",
      "NME: 0.3711\n",
      "Best model saved at epoch 95 with val_loss 86.7212\n",
      "Epoch [96/300], Loss: 83.8908\n",
      "Validation Loss: 89.9480\n",
      "NME: 0.3945\n",
      "Epoch [97/300], Loss: 81.1828\n",
      "Validation Loss: 84.1774\n",
      "NME: 0.3681\n",
      "Best model saved at epoch 97 with val_loss 84.1774\n",
      "Epoch [98/300], Loss: 74.7123\n",
      "Validation Loss: 82.6377\n",
      "NME: 0.3581\n",
      "Best model saved at epoch 98 with val_loss 82.6377\n",
      "Epoch [99/300], Loss: 77.2947\n",
      "Validation Loss: 79.9723\n",
      "NME: 0.3528\n",
      "Best model saved at epoch 99 with val_loss 79.9723\n",
      "Epoch [100/300], Loss: 74.4396\n",
      "Validation Loss: 82.0034\n",
      "NME: 0.3606\n",
      "Epoch [101/300], Loss: 78.1752\n",
      "Validation Loss: 89.7837\n",
      "NME: 0.3812\n",
      "Epoch [102/300], Loss: 73.6055\n",
      "Validation Loss: 80.7186\n",
      "NME: 0.3505\n",
      "Epoch [103/300], Loss: 72.5817\n",
      "Validation Loss: 83.5484\n",
      "NME: 0.3459\n",
      "Epoch [104/300], Loss: 70.2325\n",
      "Validation Loss: 81.9124\n",
      "NME: 0.3533\n",
      "Epoch [105/300], Loss: 71.3592\n",
      "Validation Loss: 79.8135\n",
      "NME: 0.3564\n",
      "Best model saved at epoch 105 with val_loss 79.8135\n",
      "Epoch [106/300], Loss: 66.5737\n",
      "Validation Loss: 81.3997\n",
      "NME: 0.3600\n",
      "Epoch [107/300], Loss: 68.4053\n",
      "Validation Loss: 77.3435\n",
      "NME: 0.3503\n",
      "Best model saved at epoch 107 with val_loss 77.3435\n",
      "Epoch [108/300], Loss: 71.5889\n",
      "Validation Loss: 75.5395\n",
      "NME: 0.3352\n",
      "Best model saved at epoch 108 with val_loss 75.5395\n",
      "Epoch [109/300], Loss: 67.7550\n",
      "Validation Loss: 75.6227\n",
      "NME: 0.3291\n",
      "Epoch [110/300], Loss: 66.9482\n",
      "Validation Loss: 78.0085\n",
      "NME: 0.3532\n",
      "Epoch [111/300], Loss: 64.1658\n",
      "Validation Loss: 71.8550\n",
      "NME: 0.3310\n",
      "Best model saved at epoch 111 with val_loss 71.8550\n",
      "Epoch [112/300], Loss: 63.5437\n",
      "Validation Loss: 76.1522\n",
      "NME: 0.3319\n",
      "Epoch [113/300], Loss: 78.1853\n",
      "Validation Loss: 79.7713\n",
      "NME: 0.3453\n",
      "Epoch [114/300], Loss: 64.6939\n",
      "Validation Loss: 77.3763\n",
      "NME: 0.3419\n",
      "Epoch [115/300], Loss: 66.7562\n",
      "Validation Loss: 80.3521\n",
      "NME: 0.3440\n",
      "Epoch [116/300], Loss: 67.7440\n",
      "Validation Loss: 76.9741\n",
      "NME: 0.3386\n",
      "Epoch [117/300], Loss: 71.2148\n",
      "Validation Loss: 72.4024\n",
      "NME: 0.3252\n",
      "Epoch [118/300], Loss: 62.5605\n",
      "Validation Loss: 72.8215\n",
      "NME: 0.3370\n",
      "Epoch [119/300], Loss: 62.6653\n",
      "Validation Loss: 72.3300\n",
      "NME: 0.3474\n",
      "Epoch [120/300], Loss: 58.5206\n",
      "Validation Loss: 71.5230\n",
      "NME: 0.3219\n",
      "Best model saved at epoch 120 with val_loss 71.5230\n",
      "Epoch [121/300], Loss: 55.8424\n",
      "Validation Loss: 71.9990\n",
      "NME: 0.3250\n",
      "Epoch [122/300], Loss: 58.5830\n",
      "Validation Loss: 69.1759\n",
      "NME: 0.3194\n",
      "Best model saved at epoch 122 with val_loss 69.1759\n",
      "Epoch [123/300], Loss: 58.3020\n",
      "Validation Loss: 71.6317\n",
      "NME: 0.3284\n",
      "Epoch [124/300], Loss: 55.8256\n",
      "Validation Loss: 72.5342\n",
      "NME: 0.3285\n",
      "Epoch [125/300], Loss: 55.8634\n",
      "Validation Loss: 68.8507\n",
      "NME: 0.3103\n",
      "Best model saved at epoch 125 with val_loss 68.8507\n",
      "Epoch [126/300], Loss: 67.0890\n",
      "Validation Loss: 68.5339\n",
      "NME: 0.3166\n",
      "Best model saved at epoch 126 with val_loss 68.5339\n",
      "Epoch [127/300], Loss: 58.3199\n",
      "Validation Loss: 69.4845\n",
      "NME: 0.3287\n",
      "Epoch [128/300], Loss: 56.4856\n",
      "Validation Loss: 72.4035\n",
      "NME: 0.3316\n",
      "Epoch [129/300], Loss: 54.4362\n",
      "Validation Loss: 68.2780\n",
      "NME: 0.3217\n",
      "Best model saved at epoch 129 with val_loss 68.2780\n",
      "Epoch [130/300], Loss: 50.7876\n",
      "Validation Loss: 66.9580\n",
      "NME: 0.3067\n",
      "Best model saved at epoch 130 with val_loss 66.9580\n",
      "Epoch [131/300], Loss: 55.5114\n",
      "Validation Loss: 69.4164\n",
      "NME: 0.3135\n",
      "Epoch [132/300], Loss: 52.2521\n",
      "Validation Loss: 72.5156\n",
      "NME: 0.3258\n",
      "Epoch [133/300], Loss: 49.7410\n",
      "Validation Loss: 68.5336\n",
      "NME: 0.3082\n",
      "Epoch [134/300], Loss: 52.3417\n",
      "Validation Loss: 68.9336\n",
      "NME: 0.3095\n",
      "Epoch [135/300], Loss: 50.6319\n",
      "Validation Loss: 69.1689\n",
      "NME: 0.3183\n",
      "Epoch [136/300], Loss: 50.9676\n",
      "Validation Loss: 69.2953\n",
      "NME: 0.3201\n",
      "Epoch [137/300], Loss: 49.0926\n",
      "Validation Loss: 69.9426\n",
      "NME: 0.3177\n",
      "Epoch [138/300], Loss: 51.4092\n",
      "Validation Loss: 69.8567\n",
      "NME: 0.3151\n",
      "Epoch [139/300], Loss: 50.2290\n",
      "Validation Loss: 70.6059\n",
      "NME: 0.3315\n",
      "Epoch [140/300], Loss: 49.5869\n",
      "Validation Loss: 68.3047\n",
      "NME: 0.3261\n",
      "Epoch [141/300], Loss: 47.3693\n",
      "Validation Loss: 68.7254\n",
      "NME: 0.3125\n",
      "Epoch [142/300], Loss: 45.2100\n",
      "Validation Loss: 68.2762\n",
      "NME: 0.3114\n",
      "Epoch [143/300], Loss: 46.0349\n",
      "Validation Loss: 70.1805\n",
      "NME: 0.3112\n",
      "Epoch [144/300], Loss: 53.0890\n",
      "Validation Loss: 70.2436\n",
      "NME: 0.3285\n",
      "Epoch [145/300], Loss: 50.1846\n",
      "Validation Loss: 67.2052\n",
      "NME: 0.3178\n",
      "Epoch [146/300], Loss: 47.3230\n",
      "Validation Loss: 68.7957\n",
      "NME: 0.3182\n",
      "Epoch [147/300], Loss: 48.4319\n",
      "Validation Loss: 68.5307\n",
      "NME: 0.3150\n",
      "Epoch [148/300], Loss: 44.1307\n",
      "Validation Loss: 67.7485\n",
      "NME: 0.3115\n",
      "Epoch [149/300], Loss: 48.5748\n",
      "Validation Loss: 69.8494\n",
      "NME: 0.3288\n",
      "Epoch [150/300], Loss: 45.0058\n",
      "Validation Loss: 67.9377\n",
      "NME: 0.3096\n",
      "Epoch [151/300], Loss: 44.7397\n",
      "Validation Loss: 68.1111\n",
      "NME: 0.3194\n",
      "Epoch [152/300], Loss: 46.7865\n",
      "Validation Loss: 70.4180\n",
      "NME: 0.3235\n",
      "Epoch [153/300], Loss: 46.8939\n",
      "Validation Loss: 67.3001\n",
      "NME: 0.3090\n",
      "Epoch [154/300], Loss: 55.4965\n",
      "Validation Loss: 71.4352\n",
      "NME: 0.3298\n",
      "Epoch [155/300], Loss: 70.7621\n",
      "Validation Loss: 73.7048\n",
      "NME: 0.3262\n",
      "Epoch [156/300], Loss: 52.4185\n",
      "Validation Loss: 67.4913\n",
      "NME: 0.3104\n",
      "Epoch [157/300], Loss: 51.0456\n",
      "Validation Loss: 65.9999\n",
      "NME: 0.3127\n",
      "Best model saved at epoch 157 with val_loss 65.9999\n",
      "Epoch [158/300], Loss: 50.2323\n",
      "Validation Loss: 68.8834\n",
      "NME: 0.3175\n",
      "Epoch [159/300], Loss: 46.3729\n",
      "Validation Loss: 66.7601\n",
      "NME: 0.3109\n",
      "Epoch [160/300], Loss: 43.5234\n",
      "Validation Loss: 68.0361\n",
      "NME: 0.3059\n",
      "Epoch [161/300], Loss: 44.6685\n",
      "Validation Loss: 66.5667\n",
      "NME: 0.3140\n",
      "Epoch [162/300], Loss: 43.0765\n",
      "Validation Loss: 66.9214\n",
      "NME: 0.3070\n",
      "Epoch [163/300], Loss: 44.2691\n",
      "Validation Loss: 67.3965\n",
      "NME: 0.3098\n",
      "Epoch [164/300], Loss: 43.8203\n",
      "Validation Loss: 66.4605\n",
      "NME: 0.3133\n",
      "Epoch [165/300], Loss: 44.9147\n",
      "Validation Loss: 68.9014\n",
      "NME: 0.3097\n",
      "Epoch [166/300], Loss: 44.5756\n",
      "Validation Loss: 67.0371\n",
      "NME: 0.3132\n",
      "Epoch [167/300], Loss: 43.4056\n",
      "Validation Loss: 72.9994\n",
      "NME: 0.3365\n",
      "Epoch [168/300], Loss: 42.3759\n",
      "Validation Loss: 68.9888\n",
      "NME: 0.3168\n",
      "Epoch [169/300], Loss: 41.2241\n",
      "Validation Loss: 67.9014\n",
      "NME: 0.3170\n",
      "Epoch [170/300], Loss: 41.6592\n",
      "Validation Loss: 68.0406\n",
      "NME: 0.3104\n",
      "Epoch [171/300], Loss: 43.1129\n",
      "Validation Loss: 65.8271\n",
      "NME: 0.3023\n",
      "Best model saved at epoch 171 with val_loss 65.8271\n",
      "Epoch [172/300], Loss: 45.3700\n",
      "Validation Loss: 70.0700\n",
      "NME: 0.3177\n",
      "Epoch [173/300], Loss: 43.4496\n",
      "Validation Loss: 67.3851\n",
      "NME: 0.3203\n",
      "Epoch [174/300], Loss: 44.9307\n",
      "Validation Loss: 73.8429\n",
      "NME: 0.3171\n",
      "Epoch [175/300], Loss: 45.7969\n",
      "Validation Loss: 68.4047\n",
      "NME: 0.3033\n",
      "Epoch [176/300], Loss: 41.8488\n",
      "Validation Loss: 68.2679\n",
      "NME: 0.3161\n",
      "Epoch [177/300], Loss: 41.1765\n",
      "Validation Loss: 66.9591\n",
      "NME: 0.3119\n",
      "Epoch [178/300], Loss: 43.3378\n",
      "Validation Loss: 66.4812\n",
      "NME: 0.3016\n",
      "Epoch [179/300], Loss: 40.5182\n",
      "Validation Loss: 65.7073\n",
      "NME: 0.3026\n",
      "Best model saved at epoch 179 with val_loss 65.7073\n",
      "Epoch [180/300], Loss: 39.8867\n",
      "Validation Loss: 63.7267\n",
      "NME: 0.3041\n",
      "Best model saved at epoch 180 with val_loss 63.7267\n",
      "Epoch [181/300], Loss: 38.6745\n",
      "Validation Loss: 65.8359\n",
      "NME: 0.3040\n",
      "Epoch [182/300], Loss: 37.9639\n",
      "Validation Loss: 64.5076\n",
      "NME: 0.2988\n",
      "Epoch [183/300], Loss: 39.3936\n",
      "Validation Loss: 66.6669\n",
      "NME: 0.3159\n",
      "Epoch [184/300], Loss: 47.2138\n",
      "Validation Loss: 71.2222\n",
      "NME: 0.3185\n",
      "Epoch [185/300], Loss: 41.2645\n",
      "Validation Loss: 67.8325\n",
      "NME: 0.3280\n",
      "Epoch [186/300], Loss: 39.7260\n",
      "Validation Loss: 66.2912\n",
      "NME: 0.3138\n",
      "Epoch [187/300], Loss: 39.7930\n",
      "Validation Loss: 68.0150\n",
      "NME: 0.3149\n",
      "Epoch [188/300], Loss: 47.3278\n",
      "Validation Loss: 67.1724\n",
      "NME: 0.3119\n",
      "Epoch [189/300], Loss: 39.9851\n",
      "Validation Loss: 66.9525\n",
      "NME: 0.3074\n",
      "Epoch [190/300], Loss: 40.5180\n",
      "Validation Loss: 66.1811\n",
      "NME: 0.3139\n",
      "Epoch [191/300], Loss: 38.5981\n",
      "Validation Loss: 63.3739\n",
      "NME: 0.3028\n",
      "Best model saved at epoch 191 with val_loss 63.3739\n",
      "Epoch [192/300], Loss: 36.6527\n",
      "Validation Loss: 67.2005\n",
      "NME: 0.3017\n",
      "Epoch [193/300], Loss: 36.6198\n",
      "Validation Loss: 64.2078\n",
      "NME: 0.3095\n",
      "Epoch [194/300], Loss: 35.8696\n",
      "Validation Loss: 64.5725\n",
      "NME: 0.3087\n",
      "Epoch [195/300], Loss: 34.8679\n",
      "Validation Loss: 63.7972\n",
      "NME: 0.3058\n",
      "Epoch [196/300], Loss: 35.8421\n",
      "Validation Loss: 65.2506\n",
      "NME: 0.3067\n",
      "Epoch [197/300], Loss: 36.6078\n",
      "Validation Loss: 65.6214\n",
      "NME: 0.3114\n",
      "Epoch [198/300], Loss: 34.8901\n",
      "Validation Loss: 65.9716\n",
      "NME: 0.3003\n",
      "Epoch [199/300], Loss: 34.7339\n",
      "Validation Loss: 64.7378\n",
      "NME: 0.3039\n",
      "Epoch [200/300], Loss: 34.4291\n",
      "Validation Loss: 64.0879\n",
      "NME: 0.3015\n",
      "Epoch [201/300], Loss: 34.5188\n",
      "Validation Loss: 65.0402\n",
      "NME: 0.3064\n",
      "Epoch [202/300], Loss: 34.4068\n",
      "Validation Loss: 63.3278\n",
      "NME: 0.2948\n",
      "Best model saved at epoch 202 with val_loss 63.3278\n",
      "Epoch [203/300], Loss: 34.3048\n",
      "Validation Loss: 66.5010\n",
      "NME: 0.3026\n",
      "Epoch [204/300], Loss: 34.3304\n",
      "Validation Loss: 66.5372\n",
      "NME: 0.3148\n",
      "Epoch [205/300], Loss: 35.0313\n",
      "Validation Loss: 63.8882\n",
      "NME: 0.2969\n",
      "Epoch [206/300], Loss: 59.0721\n",
      "Validation Loss: 80.5235\n",
      "NME: 0.3377\n",
      "Epoch [207/300], Loss: 47.6250\n",
      "Validation Loss: 65.5056\n",
      "NME: 0.3077\n",
      "Epoch [208/300], Loss: 45.2291\n",
      "Validation Loss: 67.7734\n",
      "NME: 0.3177\n",
      "Epoch [209/300], Loss: 40.4601\n",
      "Validation Loss: 69.1440\n",
      "NME: 0.3133\n",
      "Epoch [210/300], Loss: 38.7956\n",
      "Validation Loss: 65.6075\n",
      "NME: 0.3133\n",
      "Epoch [211/300], Loss: 38.9140\n",
      "Validation Loss: 65.7745\n",
      "NME: 0.3017\n",
      "Epoch [212/300], Loss: 35.5764\n",
      "Validation Loss: 65.6343\n",
      "NME: 0.3151\n",
      "Epoch [213/300], Loss: 31.9388\n",
      "Validation Loss: 63.8542\n",
      "NME: 0.2970\n",
      "Epoch [214/300], Loss: 32.7209\n",
      "Validation Loss: 62.8610\n",
      "NME: 0.3023\n",
      "Best model saved at epoch 214 with val_loss 62.8610\n",
      "Epoch [215/300], Loss: 32.4882\n",
      "Validation Loss: 64.0368\n",
      "NME: 0.3006\n",
      "Epoch [216/300], Loss: 32.7472\n",
      "Validation Loss: 64.3396\n",
      "NME: 0.3026\n",
      "Epoch [217/300], Loss: 33.7036\n",
      "Validation Loss: 60.1299\n",
      "NME: 0.2943\n",
      "Best model saved at epoch 217 with val_loss 60.1299\n",
      "Epoch [218/300], Loss: 32.0508\n",
      "Validation Loss: 62.9949\n",
      "NME: 0.2968\n",
      "Epoch [219/300], Loss: 39.2356\n",
      "Validation Loss: 70.3910\n",
      "NME: 0.3236\n",
      "Epoch [220/300], Loss: 37.8696\n",
      "Validation Loss: 64.7507\n",
      "NME: 0.2984\n",
      "Epoch [221/300], Loss: 33.8673\n",
      "Validation Loss: 64.8455\n",
      "NME: 0.2986\n",
      "Epoch [222/300], Loss: 32.6960\n",
      "Validation Loss: 64.0702\n",
      "NME: 0.2966\n",
      "Epoch [223/300], Loss: 32.8498\n",
      "Validation Loss: 64.1413\n",
      "NME: 0.3004\n",
      "Epoch [224/300], Loss: 33.8618\n",
      "Validation Loss: 64.7912\n",
      "NME: 0.3013\n",
      "Epoch [225/300], Loss: 32.2443\n",
      "Validation Loss: 64.5144\n",
      "NME: 0.3018\n",
      "Epoch [226/300], Loss: 30.6364\n",
      "Validation Loss: 63.6098\n",
      "NME: 0.2979\n",
      "Epoch [227/300], Loss: 31.0491\n",
      "Validation Loss: 62.4524\n",
      "NME: 0.2967\n",
      "Epoch [228/300], Loss: 32.2703\n",
      "Validation Loss: 67.8145\n",
      "NME: 0.3132\n",
      "Epoch [229/300], Loss: 31.0813\n",
      "Validation Loss: 63.7697\n",
      "NME: 0.2992\n",
      "Epoch [230/300], Loss: 30.9923\n",
      "Validation Loss: 62.4714\n",
      "NME: 0.3040\n",
      "Epoch [231/300], Loss: 30.1447\n",
      "Validation Loss: 61.7911\n",
      "NME: 0.3010\n",
      "Epoch [232/300], Loss: 31.9560\n",
      "Validation Loss: 63.9940\n",
      "NME: 0.3108\n",
      "Epoch [233/300], Loss: 41.3450\n",
      "Validation Loss: 73.0317\n",
      "NME: 0.3206\n",
      "Epoch [234/300], Loss: 45.6886\n",
      "Validation Loss: 68.3676\n",
      "NME: 0.3231\n",
      "Epoch [235/300], Loss: 45.1820\n",
      "Validation Loss: 63.7009\n",
      "NME: 0.3080\n",
      "Epoch [236/300], Loss: 40.8473\n",
      "Validation Loss: 65.7364\n",
      "NME: 0.3089\n",
      "Epoch [237/300], Loss: 34.9692\n",
      "Validation Loss: 65.9284\n",
      "NME: 0.3178\n",
      "Epoch [238/300], Loss: 33.4069\n",
      "Validation Loss: 61.6259\n",
      "NME: 0.2943\n",
      "Epoch [239/300], Loss: 31.7876\n",
      "Validation Loss: 62.8699\n",
      "NME: 0.2930\n",
      "Epoch [240/300], Loss: 31.7501\n",
      "Validation Loss: 62.5952\n",
      "NME: 0.3028\n",
      "Epoch [241/300], Loss: 31.6343\n",
      "Validation Loss: 62.2012\n",
      "NME: 0.3027\n",
      "Epoch [242/300], Loss: 31.2143\n",
      "Validation Loss: 62.9268\n",
      "NME: 0.2932\n",
      "Epoch [243/300], Loss: 31.0351\n",
      "Validation Loss: 66.0579\n",
      "NME: 0.3024\n",
      "Epoch [244/300], Loss: 33.3762\n",
      "Validation Loss: 66.0486\n",
      "NME: 0.2986\n",
      "Epoch [245/300], Loss: 33.5452\n",
      "Validation Loss: 66.3768\n",
      "NME: 0.3046\n",
      "Epoch [246/300], Loss: 30.8719\n",
      "Validation Loss: 63.5300\n",
      "NME: 0.2924\n",
      "Epoch [247/300], Loss: 30.7381\n",
      "Validation Loss: 63.2974\n",
      "NME: 0.3059\n",
      "Epoch [248/300], Loss: 30.0956\n",
      "Validation Loss: 63.7824\n",
      "NME: 0.3025\n",
      "Epoch [249/300], Loss: 29.9856\n",
      "Validation Loss: 64.3912\n",
      "NME: 0.3051\n",
      "Epoch [250/300], Loss: 30.4861\n",
      "Validation Loss: 64.5356\n",
      "NME: 0.3033\n",
      "Epoch [251/300], Loss: 36.8933\n",
      "Validation Loss: 63.4377\n",
      "NME: 0.3005\n",
      "Epoch [252/300], Loss: 31.4112\n",
      "Validation Loss: 62.3215\n",
      "NME: 0.3011\n",
      "Epoch [253/300], Loss: 29.6842\n",
      "Validation Loss: 62.4412\n",
      "NME: 0.2985\n",
      "Epoch [254/300], Loss: 31.0339\n",
      "Validation Loss: 63.3661\n",
      "NME: 0.3013\n",
      "Epoch [255/300], Loss: 33.3706\n",
      "Validation Loss: 62.7649\n",
      "NME: 0.3039\n",
      "Epoch [256/300], Loss: 30.1627\n",
      "Validation Loss: 60.4045\n",
      "NME: 0.2929\n",
      "Epoch [257/300], Loss: 29.5454\n",
      "Validation Loss: 61.4031\n",
      "NME: 0.2969\n",
      "Epoch [258/300], Loss: 28.7349\n",
      "Validation Loss: 61.6018\n",
      "NME: 0.3003\n",
      "Epoch [259/300], Loss: 28.3583\n",
      "Validation Loss: 64.6301\n",
      "NME: 0.3063\n",
      "Epoch [260/300], Loss: 29.1687\n",
      "Validation Loss: 64.3579\n",
      "NME: 0.3006\n",
      "Epoch [261/300], Loss: 29.0762\n",
      "Validation Loss: 63.0234\n",
      "NME: 0.2984\n",
      "Epoch [262/300], Loss: 28.3117\n",
      "Validation Loss: 62.9172\n",
      "NME: 0.2914\n",
      "Epoch [263/300], Loss: 28.1285\n",
      "Validation Loss: 61.3155\n",
      "NME: 0.2978\n",
      "Epoch [264/300], Loss: 27.1646\n",
      "Validation Loss: 61.8094\n",
      "NME: 0.2973\n",
      "Epoch [265/300], Loss: 28.4601\n",
      "Validation Loss: 61.8806\n",
      "NME: 0.2918\n",
      "Epoch [266/300], Loss: 27.8216\n",
      "Validation Loss: 60.8973\n",
      "NME: 0.2959\n",
      "Epoch [267/300], Loss: 30.1482\n",
      "Validation Loss: 64.3923\n",
      "NME: 0.2977\n",
      "Epoch [268/300], Loss: 32.3345\n",
      "Validation Loss: 65.0895\n",
      "NME: 0.3008\n",
      "Epoch [269/300], Loss: 31.8180\n",
      "Validation Loss: 63.8164\n",
      "NME: 0.2922\n",
      "Epoch [270/300], Loss: 29.7906\n",
      "Validation Loss: 63.1947\n",
      "NME: 0.2913\n",
      "Epoch [271/300], Loss: 28.2983\n",
      "Validation Loss: 62.8502\n",
      "NME: 0.3021\n",
      "Epoch [272/300], Loss: 27.1737\n",
      "Validation Loss: 62.3425\n",
      "NME: 0.2965\n",
      "Epoch [273/300], Loss: 27.1482\n",
      "Validation Loss: 63.0840\n",
      "NME: 0.2987\n",
      "Epoch [274/300], Loss: 26.6964\n",
      "Validation Loss: 64.4783\n",
      "NME: 0.2982\n",
      "Epoch [275/300], Loss: 28.0925\n",
      "Validation Loss: 62.0651\n",
      "NME: 0.2986\n",
      "Epoch [276/300], Loss: 27.8845\n",
      "Validation Loss: 62.4879\n",
      "NME: 0.2948\n",
      "Epoch [277/300], Loss: 28.3001\n",
      "Validation Loss: 63.7380\n",
      "NME: 0.3020\n",
      "Epoch [278/300], Loss: 28.1021\n",
      "Validation Loss: 62.1458\n",
      "NME: 0.2996\n",
      "Epoch [279/300], Loss: 26.9470\n",
      "Validation Loss: 62.0177\n",
      "NME: 0.2922\n",
      "Epoch [280/300], Loss: 28.3003\n",
      "Validation Loss: 64.0074\n",
      "NME: 0.2909\n",
      "Epoch [281/300], Loss: 25.6988\n",
      "Validation Loss: 64.0691\n",
      "NME: 0.2954\n",
      "Epoch [282/300], Loss: 27.1760\n",
      "Validation Loss: 63.6745\n",
      "NME: 0.2962\n",
      "Epoch [283/300], Loss: 25.9843\n",
      "Validation Loss: 61.8987\n",
      "NME: 0.2880\n",
      "Epoch [284/300], Loss: 25.9502\n",
      "Validation Loss: 62.0716\n",
      "NME: 0.2878\n",
      "Epoch [285/300], Loss: 30.3518\n",
      "Validation Loss: 67.1410\n",
      "NME: 0.3097\n",
      "Epoch [286/300], Loss: 31.2858\n",
      "Validation Loss: 63.1847\n",
      "NME: 0.2909\n",
      "Epoch [287/300], Loss: 27.1997\n",
      "Validation Loss: 63.0121\n",
      "NME: 0.2976\n",
      "Epoch [288/300], Loss: 25.0565\n",
      "Validation Loss: 61.9420\n",
      "NME: 0.2856\n",
      "Epoch [289/300], Loss: 24.6948\n",
      "Validation Loss: 64.8585\n",
      "NME: 0.3060\n",
      "Epoch [290/300], Loss: 23.4906\n",
      "Validation Loss: 62.9608\n",
      "NME: 0.2912\n",
      "Epoch [291/300], Loss: 25.6810\n",
      "Validation Loss: 61.9936\n",
      "NME: 0.2956\n",
      "Epoch [292/300], Loss: 23.5003\n",
      "Validation Loss: 61.3047\n",
      "NME: 0.2908\n",
      "Epoch [293/300], Loss: 23.8384\n",
      "Validation Loss: 61.1761\n",
      "NME: 0.2888\n",
      "Epoch [294/300], Loss: 23.5863\n",
      "Validation Loss: 60.3764\n",
      "NME: 0.2872\n",
      "Epoch [295/300], Loss: 21.5884\n",
      "Validation Loss: 59.9389\n",
      "NME: 0.2878\n",
      "Best model saved at epoch 295 with val_loss 59.9389\n",
      "Epoch [296/300], Loss: 21.4743\n",
      "Validation Loss: 59.6402\n",
      "NME: 0.2869\n",
      "Best model saved at epoch 296 with val_loss 59.6402\n",
      "Epoch [297/300], Loss: 21.3220\n",
      "Validation Loss: 59.9913\n",
      "NME: 0.2862\n",
      "Epoch [298/300], Loss: 20.5873\n",
      "Validation Loss: 60.3443\n",
      "NME: 0.2868\n",
      "Epoch [299/300], Loss: 21.6513\n",
      "Validation Loss: 60.3598\n",
      "NME: 0.2874\n",
      "Epoch [300/300], Loss: 20.2657\n",
      "Validation Loss: 59.9366\n",
      "NME: 0.2889\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EyeRightDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave del ojo derecho\n",
    "        eye_right_points = np.array([landmarks[i] for i in ojo_der], dtype=np.float32)\n",
    "        eye_right_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(eye_right_points), 1))\n",
    "        points_ones = np.hstack([eye_right_points, ones])\n",
    "        eye_right_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado del ojo derecho\n",
    "        centro_x, centro_y = calcular_centro_region(eye_right_points_rotated, range(len(ojo_der)))\n",
    "\n",
    "        # Definir los límites del recorte de 56x56 píxeles\n",
    "        half_crop_size = 28\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_eye = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_eye, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales del ojo derecho al nuevo recorte\n",
    "        eye_right_points_adjusted = [(p[0] - x1, p[1] - y1) for p in eye_right_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        eye_right_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in eye_right_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=eye_right_points_scaled)\n",
    "            image = augmented['image']\n",
    "            eye_right_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(eye_right_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EyeRightDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EyeRightDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EyeRight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EyeRight, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(ojo_der) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EyeRight().cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para ojo derecho)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, eye_right_points, _, _, _ in train_dataloader:\n",
    "            images, eye_right_points = images.cuda(), eye_right_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, eye_right_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_eye_right_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_eye_right_points = val_images.cuda(), val_eye_right_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_eye_right_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_eye_right_points.cpu().numpy().reshape(-1, len(ojo_der), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(ojo_der), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(ojo_der))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EyeRightLandmarks V4.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 16322.7618\n",
      "Validation Loss: 14718.1610\n",
      "NME: 3.3054\n",
      "Best model saved at epoch 1 with val_loss 14718.1610\n",
      "Epoch [2/300], Loss: 9639.4928\n",
      "Validation Loss: 3998.1435\n",
      "NME: 1.4770\n",
      "Best model saved at epoch 2 with val_loss 3998.1435\n",
      "Epoch [3/300], Loss: 2025.5064\n",
      "Validation Loss: 1166.2557\n",
      "NME: 0.6302\n",
      "Best model saved at epoch 3 with val_loss 1166.2557\n",
      "Epoch [4/300], Loss: 1034.8240\n",
      "Validation Loss: 899.3866\n",
      "NME: 0.5494\n",
      "Best model saved at epoch 4 with val_loss 899.3866\n",
      "Epoch [5/300], Loss: 937.6587\n",
      "Validation Loss: 862.7673\n",
      "NME: 0.5445\n",
      "Best model saved at epoch 5 with val_loss 862.7673\n",
      "Epoch [6/300], Loss: 927.2605\n",
      "Validation Loss: 852.6251\n",
      "NME: 0.5440\n",
      "Best model saved at epoch 6 with val_loss 852.6251\n",
      "Epoch [7/300], Loss: 906.8241\n",
      "Validation Loss: 843.2822\n",
      "NME: 0.5400\n",
      "Best model saved at epoch 7 with val_loss 843.2822\n",
      "Epoch [8/300], Loss: 900.3095\n",
      "Validation Loss: 837.0300\n",
      "NME: 0.5363\n",
      "Best model saved at epoch 8 with val_loss 837.0300\n",
      "Epoch [9/300], Loss: 887.5826\n",
      "Validation Loss: 825.1173\n",
      "NME: 0.5322\n",
      "Best model saved at epoch 9 with val_loss 825.1173\n",
      "Epoch [10/300], Loss: 872.8059\n",
      "Validation Loss: 793.6102\n",
      "NME: 0.5332\n",
      "Best model saved at epoch 10 with val_loss 793.6102\n",
      "Epoch [11/300], Loss: 830.2684\n",
      "Validation Loss: 746.7864\n",
      "NME: 0.4789\n",
      "Best model saved at epoch 11 with val_loss 746.7864\n",
      "Epoch [12/300], Loss: 782.6274\n",
      "Validation Loss: 674.2265\n",
      "NME: 0.4477\n",
      "Best model saved at epoch 12 with val_loss 674.2265\n",
      "Epoch [13/300], Loss: 694.1078\n",
      "Validation Loss: 564.7958\n",
      "NME: 0.4027\n",
      "Best model saved at epoch 13 with val_loss 564.7958\n",
      "Epoch [14/300], Loss: 608.0630\n",
      "Validation Loss: 472.7889\n",
      "NME: 0.3486\n",
      "Best model saved at epoch 14 with val_loss 472.7889\n",
      "Epoch [15/300], Loss: 526.4803\n",
      "Validation Loss: 396.3321\n",
      "NME: 0.3229\n",
      "Best model saved at epoch 15 with val_loss 396.3321\n",
      "Epoch [16/300], Loss: 466.6234\n",
      "Validation Loss: 335.8225\n",
      "NME: 0.3100\n",
      "Best model saved at epoch 16 with val_loss 335.8225\n",
      "Epoch [17/300], Loss: 416.5515\n",
      "Validation Loss: 279.8066\n",
      "NME: 0.2737\n",
      "Best model saved at epoch 17 with val_loss 279.8066\n",
      "Epoch [18/300], Loss: 387.9184\n",
      "Validation Loss: 255.1347\n",
      "NME: 0.2633\n",
      "Best model saved at epoch 18 with val_loss 255.1347\n",
      "Epoch [19/300], Loss: 353.1420\n",
      "Validation Loss: 228.5059\n",
      "NME: 0.2539\n",
      "Best model saved at epoch 19 with val_loss 228.5059\n",
      "Epoch [20/300], Loss: 354.0352\n",
      "Validation Loss: 227.2383\n",
      "NME: 0.2540\n",
      "Best model saved at epoch 20 with val_loss 227.2383\n",
      "Epoch [21/300], Loss: 346.5103\n",
      "Validation Loss: 208.2625\n",
      "NME: 0.2657\n",
      "Best model saved at epoch 21 with val_loss 208.2625\n",
      "Epoch [22/300], Loss: 322.5794\n",
      "Validation Loss: 202.0475\n",
      "NME: 0.2557\n",
      "Best model saved at epoch 22 with val_loss 202.0475\n",
      "Epoch [23/300], Loss: 308.8825\n",
      "Validation Loss: 210.2863\n",
      "NME: 0.2894\n",
      "Epoch [24/300], Loss: 298.1707\n",
      "Validation Loss: 189.5035\n",
      "NME: 0.2482\n",
      "Best model saved at epoch 24 with val_loss 189.5035\n",
      "Epoch [25/300], Loss: 316.5490\n",
      "Validation Loss: 192.2375\n",
      "NME: 0.2552\n",
      "Epoch [26/300], Loss: 297.4963\n",
      "Validation Loss: 208.0489\n",
      "NME: 0.2835\n",
      "Epoch [27/300], Loss: 272.4218\n",
      "Validation Loss: 196.4032\n",
      "NME: 0.2687\n",
      "Epoch [28/300], Loss: 298.5584\n",
      "Validation Loss: 187.7496\n",
      "NME: 0.2678\n",
      "Best model saved at epoch 28 with val_loss 187.7496\n",
      "Epoch [29/300], Loss: 285.4398\n",
      "Validation Loss: 207.7513\n",
      "NME: 0.2711\n",
      "Epoch [30/300], Loss: 256.1841\n",
      "Validation Loss: 182.5263\n",
      "NME: 0.2564\n",
      "Best model saved at epoch 30 with val_loss 182.5263\n",
      "Epoch [31/300], Loss: 258.3489\n",
      "Validation Loss: 171.3484\n",
      "NME: 0.2480\n",
      "Best model saved at epoch 31 with val_loss 171.3484\n",
      "Epoch [32/300], Loss: 253.8104\n",
      "Validation Loss: 160.9989\n",
      "NME: 0.2291\n",
      "Best model saved at epoch 32 with val_loss 160.9989\n",
      "Epoch [33/300], Loss: 259.2236\n",
      "Validation Loss: 160.1203\n",
      "NME: 0.2334\n",
      "Best model saved at epoch 33 with val_loss 160.1203\n",
      "Epoch [34/300], Loss: 242.1172\n",
      "Validation Loss: 179.8339\n",
      "NME: 0.2659\n",
      "Epoch [35/300], Loss: 241.0977\n",
      "Validation Loss: 150.3384\n",
      "NME: 0.2221\n",
      "Best model saved at epoch 35 with val_loss 150.3384\n",
      "Epoch [36/300], Loss: 255.2391\n",
      "Validation Loss: 163.7482\n",
      "NME: 0.2448\n",
      "Epoch [37/300], Loss: 223.9317\n",
      "Validation Loss: 181.3037\n",
      "NME: 0.2524\n",
      "Epoch [38/300], Loss: 262.3667\n",
      "Validation Loss: 165.9749\n",
      "NME: 0.2347\n",
      "Epoch [39/300], Loss: 265.8718\n",
      "Validation Loss: 154.5735\n",
      "NME: 0.2157\n",
      "Epoch [40/300], Loss: 242.4726\n",
      "Validation Loss: 173.8351\n",
      "NME: 0.2322\n",
      "Epoch [41/300], Loss: 243.2769\n",
      "Validation Loss: 159.9593\n",
      "NME: 0.2083\n",
      "Epoch [42/300], Loss: 232.2355\n",
      "Validation Loss: 153.5666\n",
      "NME: 0.2134\n",
      "Epoch [43/300], Loss: 220.0217\n",
      "Validation Loss: 145.5647\n",
      "NME: 0.2090\n",
      "Best model saved at epoch 43 with val_loss 145.5647\n",
      "Epoch [44/300], Loss: 231.0489\n",
      "Validation Loss: 165.8042\n",
      "NME: 0.2430\n",
      "Epoch [45/300], Loss: 234.1264\n",
      "Validation Loss: 157.8207\n",
      "NME: 0.2337\n",
      "Epoch [46/300], Loss: 235.9946\n",
      "Validation Loss: 151.2627\n",
      "NME: 0.2253\n",
      "Epoch [47/300], Loss: 225.2774\n",
      "Validation Loss: 152.3354\n",
      "NME: 0.2023\n",
      "Epoch [48/300], Loss: 228.8794\n",
      "Validation Loss: 165.2829\n",
      "NME: 0.2341\n",
      "Epoch [49/300], Loss: 242.1069\n",
      "Validation Loss: 205.7143\n",
      "NME: 0.2836\n",
      "Epoch [50/300], Loss: 232.5379\n",
      "Validation Loss: 157.7943\n",
      "NME: 0.2186\n",
      "Epoch [51/300], Loss: 237.0629\n",
      "Validation Loss: 148.1185\n",
      "NME: 0.1990\n",
      "Epoch [52/300], Loss: 228.3396\n",
      "Validation Loss: 166.6278\n",
      "NME: 0.2213\n",
      "Epoch [53/300], Loss: 220.0426\n",
      "Validation Loss: 141.5805\n",
      "NME: 0.1993\n",
      "Best model saved at epoch 53 with val_loss 141.5805\n",
      "Epoch [54/300], Loss: 233.1013\n",
      "Validation Loss: 154.1987\n",
      "NME: 0.2000\n",
      "Epoch [55/300], Loss: 226.9861\n",
      "Validation Loss: 142.4936\n",
      "NME: 0.1922\n",
      "Epoch [56/300], Loss: 219.9668\n",
      "Validation Loss: 144.6040\n",
      "NME: 0.2020\n",
      "Epoch [57/300], Loss: 224.9354\n",
      "Validation Loss: 151.4769\n",
      "NME: 0.2091\n",
      "Epoch [58/300], Loss: 213.6000\n",
      "Validation Loss: 157.5564\n",
      "NME: 0.2275\n",
      "Epoch [59/300], Loss: 199.8306\n",
      "Validation Loss: 160.7302\n",
      "NME: 0.2134\n",
      "Epoch [60/300], Loss: 223.4843\n",
      "Validation Loss: 148.0162\n",
      "NME: 0.1862\n",
      "Epoch [61/300], Loss: 202.3351\n",
      "Validation Loss: 151.4202\n",
      "NME: 0.2030\n",
      "Epoch [62/300], Loss: 208.0026\n",
      "Validation Loss: 170.0404\n",
      "NME: 0.2022\n",
      "Epoch [63/300], Loss: 213.7417\n",
      "Validation Loss: 142.6117\n",
      "NME: 0.2037\n",
      "Epoch [64/300], Loss: 196.1920\n",
      "Validation Loss: 142.0521\n",
      "NME: 0.1981\n",
      "Epoch [65/300], Loss: 183.1649\n",
      "Validation Loss: 145.1712\n",
      "NME: 0.2052\n",
      "Epoch [66/300], Loss: 180.4768\n",
      "Validation Loss: 150.4709\n",
      "NME: 0.1969\n",
      "Epoch [67/300], Loss: 185.1099\n",
      "Validation Loss: 157.0071\n",
      "NME: 0.2049\n",
      "Epoch [68/300], Loss: 166.6924\n",
      "Validation Loss: 155.3749\n",
      "NME: 0.2121\n",
      "Epoch [69/300], Loss: 154.9302\n",
      "Validation Loss: 145.2195\n",
      "NME: 0.2012\n",
      "Epoch [70/300], Loss: 156.9543\n",
      "Validation Loss: 147.1577\n",
      "NME: 0.2113\n",
      "Epoch [71/300], Loss: 145.4992\n",
      "Validation Loss: 141.7504\n",
      "NME: 0.1897\n",
      "Epoch [72/300], Loss: 141.8310\n",
      "Validation Loss: 157.6700\n",
      "NME: 0.1976\n",
      "Epoch [73/300], Loss: 137.6564\n",
      "Validation Loss: 149.0306\n",
      "NME: 0.2011\n",
      "Epoch [74/300], Loss: 139.4192\n",
      "Validation Loss: 166.1061\n",
      "NME: 0.2096\n",
      "Epoch [75/300], Loss: 145.7404\n",
      "Validation Loss: 159.0422\n",
      "NME: 0.1959\n",
      "Epoch [76/300], Loss: 138.3202\n",
      "Validation Loss: 153.7180\n",
      "NME: 0.1923\n",
      "Epoch [77/300], Loss: 126.0823\n",
      "Validation Loss: 147.8549\n",
      "NME: 0.1885\n",
      "Epoch [78/300], Loss: 133.0339\n",
      "Validation Loss: 147.2489\n",
      "NME: 0.1909\n",
      "Epoch [79/300], Loss: 124.9241\n",
      "Validation Loss: 144.5464\n",
      "NME: 0.1984\n",
      "Epoch [80/300], Loss: 122.8743\n",
      "Validation Loss: 141.3947\n",
      "NME: 0.1913\n",
      "Best model saved at epoch 80 with val_loss 141.3947\n",
      "Epoch [81/300], Loss: 125.2296\n",
      "Validation Loss: 137.1684\n",
      "NME: 0.1877\n",
      "Best model saved at epoch 81 with val_loss 137.1684\n",
      "Epoch [82/300], Loss: 122.7850\n",
      "Validation Loss: 138.9846\n",
      "NME: 0.1858\n",
      "Epoch [83/300], Loss: 119.5399\n",
      "Validation Loss: 135.4442\n",
      "NME: 0.1833\n",
      "Best model saved at epoch 83 with val_loss 135.4442\n",
      "Epoch [84/300], Loss: 125.1109\n",
      "Validation Loss: 146.2802\n",
      "NME: 0.1899\n",
      "Epoch [85/300], Loss: 127.0522\n",
      "Validation Loss: 150.3769\n",
      "NME: 0.2053\n",
      "Epoch [86/300], Loss: 121.0418\n",
      "Validation Loss: 135.1592\n",
      "NME: 0.1814\n",
      "Best model saved at epoch 86 with val_loss 135.1592\n",
      "Epoch [87/300], Loss: 118.8060\n",
      "Validation Loss: 132.7398\n",
      "NME: 0.1775\n",
      "Best model saved at epoch 87 with val_loss 132.7398\n",
      "Epoch [88/300], Loss: 117.7537\n",
      "Validation Loss: 137.6579\n",
      "NME: 0.1821\n",
      "Epoch [89/300], Loss: 114.0965\n",
      "Validation Loss: 141.1360\n",
      "NME: 0.1909\n",
      "Epoch [90/300], Loss: 116.2521\n",
      "Validation Loss: 143.8362\n",
      "NME: 0.1993\n",
      "Epoch [91/300], Loss: 118.7235\n",
      "Validation Loss: 141.1908\n",
      "NME: 0.1835\n",
      "Epoch [92/300], Loss: 115.1101\n",
      "Validation Loss: 136.8298\n",
      "NME: 0.1826\n",
      "Epoch [93/300], Loss: 113.7567\n",
      "Validation Loss: 137.6296\n",
      "NME: 0.1894\n",
      "Epoch [94/300], Loss: 113.0143\n",
      "Validation Loss: 145.9713\n",
      "NME: 0.1922\n",
      "Epoch [95/300], Loss: 116.2091\n",
      "Validation Loss: 140.9460\n",
      "NME: 0.1761\n",
      "Epoch [96/300], Loss: 112.5371\n",
      "Validation Loss: 140.7015\n",
      "NME: 0.1832\n",
      "Epoch [97/300], Loss: 112.3868\n",
      "Validation Loss: 140.8767\n",
      "NME: 0.1838\n",
      "Epoch [98/300], Loss: 114.5112\n",
      "Validation Loss: 141.4782\n",
      "NME: 0.1887\n",
      "Epoch [99/300], Loss: 112.5242\n",
      "Validation Loss: 138.2600\n",
      "NME: 0.1850\n",
      "Epoch [100/300], Loss: 109.8896\n",
      "Validation Loss: 135.1169\n",
      "NME: 0.1788\n",
      "Epoch [101/300], Loss: 111.6762\n",
      "Validation Loss: 135.7205\n",
      "NME: 0.1738\n",
      "Epoch [102/300], Loss: 110.9138\n",
      "Validation Loss: 136.5070\n",
      "NME: 0.1815\n",
      "Epoch [103/300], Loss: 108.3491\n",
      "Validation Loss: 137.6653\n",
      "NME: 0.1853\n",
      "Epoch [104/300], Loss: 106.5742\n",
      "Validation Loss: 128.8436\n",
      "NME: 0.1706\n",
      "Best model saved at epoch 104 with val_loss 128.8436\n",
      "Epoch [105/300], Loss: 108.0034\n",
      "Validation Loss: 136.9256\n",
      "NME: 0.1750\n",
      "Epoch [106/300], Loss: 113.2449\n",
      "Validation Loss: 138.8457\n",
      "NME: 0.1754\n",
      "Epoch [107/300], Loss: 107.1657\n",
      "Validation Loss: 135.4033\n",
      "NME: 0.1805\n",
      "Epoch [108/300], Loss: 107.1564\n",
      "Validation Loss: 129.7292\n",
      "NME: 0.1713\n",
      "Epoch [109/300], Loss: 104.8428\n",
      "Validation Loss: 131.6175\n",
      "NME: 0.1685\n",
      "Epoch [110/300], Loss: 104.2099\n",
      "Validation Loss: 129.5235\n",
      "NME: 0.1758\n",
      "Epoch [111/300], Loss: 105.8836\n",
      "Validation Loss: 130.5903\n",
      "NME: 0.1781\n",
      "Epoch [112/300], Loss: 107.5277\n",
      "Validation Loss: 127.9506\n",
      "NME: 0.1722\n",
      "Best model saved at epoch 112 with val_loss 127.9506\n",
      "Epoch [113/300], Loss: 106.3484\n",
      "Validation Loss: 137.7998\n",
      "NME: 0.1889\n",
      "Epoch [114/300], Loss: 113.9261\n",
      "Validation Loss: 140.2376\n",
      "NME: 0.1887\n",
      "Epoch [115/300], Loss: 113.4768\n",
      "Validation Loss: 137.9310\n",
      "NME: 0.1763\n",
      "Epoch [116/300], Loss: 102.0476\n",
      "Validation Loss: 132.0454\n",
      "NME: 0.1723\n",
      "Epoch [117/300], Loss: 98.3439\n",
      "Validation Loss: 127.3120\n",
      "NME: 0.1720\n",
      "Best model saved at epoch 117 with val_loss 127.3120\n",
      "Epoch [118/300], Loss: 97.5067\n",
      "Validation Loss: 127.7300\n",
      "NME: 0.1731\n",
      "Epoch [119/300], Loss: 98.6067\n",
      "Validation Loss: 127.1630\n",
      "NME: 0.1684\n",
      "Best model saved at epoch 119 with val_loss 127.1630\n",
      "Epoch [120/300], Loss: 98.3368\n",
      "Validation Loss: 119.3088\n",
      "NME: 0.1632\n",
      "Best model saved at epoch 120 with val_loss 119.3088\n",
      "Epoch [121/300], Loss: 95.3788\n",
      "Validation Loss: 117.1459\n",
      "NME: 0.1601\n",
      "Best model saved at epoch 121 with val_loss 117.1459\n",
      "Epoch [122/300], Loss: 94.5091\n",
      "Validation Loss: 124.6223\n",
      "NME: 0.1690\n",
      "Epoch [123/300], Loss: 96.5135\n",
      "Validation Loss: 120.5412\n",
      "NME: 0.1657\n",
      "Epoch [124/300], Loss: 95.9748\n",
      "Validation Loss: 114.6077\n",
      "NME: 0.1676\n",
      "Best model saved at epoch 124 with val_loss 114.6077\n",
      "Epoch [125/300], Loss: 92.0938\n",
      "Validation Loss: 117.5903\n",
      "NME: 0.1657\n",
      "Epoch [126/300], Loss: 94.4366\n",
      "Validation Loss: 125.4067\n",
      "NME: 0.1669\n",
      "Epoch [127/300], Loss: 90.6707\n",
      "Validation Loss: 113.9890\n",
      "NME: 0.1665\n",
      "Best model saved at epoch 127 with val_loss 113.9890\n",
      "Epoch [128/300], Loss: 87.9289\n",
      "Validation Loss: 112.4427\n",
      "NME: 0.1592\n",
      "Best model saved at epoch 128 with val_loss 112.4427\n",
      "Epoch [129/300], Loss: 89.2747\n",
      "Validation Loss: 116.4270\n",
      "NME: 0.1638\n",
      "Epoch [130/300], Loss: 88.3943\n",
      "Validation Loss: 112.3780\n",
      "NME: 0.1631\n",
      "Best model saved at epoch 130 with val_loss 112.3780\n",
      "Epoch [131/300], Loss: 87.4608\n",
      "Validation Loss: 113.2329\n",
      "NME: 0.1686\n",
      "Epoch [132/300], Loss: 86.5471\n",
      "Validation Loss: 111.3324\n",
      "NME: 0.1660\n",
      "Best model saved at epoch 132 with val_loss 111.3324\n",
      "Epoch [133/300], Loss: 86.8207\n",
      "Validation Loss: 111.6305\n",
      "NME: 0.1626\n",
      "Epoch [134/300], Loss: 85.1124\n",
      "Validation Loss: 109.8581\n",
      "NME: 0.1589\n",
      "Best model saved at epoch 134 with val_loss 109.8581\n",
      "Epoch [135/300], Loss: 83.8732\n",
      "Validation Loss: 108.9571\n",
      "NME: 0.1566\n",
      "Best model saved at epoch 135 with val_loss 108.9571\n",
      "Epoch [136/300], Loss: 83.8182\n",
      "Validation Loss: 106.0769\n",
      "NME: 0.1603\n",
      "Best model saved at epoch 136 with val_loss 106.0769\n",
      "Epoch [137/300], Loss: 84.8418\n",
      "Validation Loss: 109.3018\n",
      "NME: 0.1638\n",
      "Epoch [138/300], Loss: 82.2743\n",
      "Validation Loss: 108.3902\n",
      "NME: 0.1595\n",
      "Epoch [139/300], Loss: 84.3325\n",
      "Validation Loss: 110.6823\n",
      "NME: 0.1587\n",
      "Epoch [140/300], Loss: 82.1632\n",
      "Validation Loss: 108.9501\n",
      "NME: 0.1530\n",
      "Epoch [141/300], Loss: 82.6635\n",
      "Validation Loss: 109.5974\n",
      "NME: 0.1513\n",
      "Epoch [142/300], Loss: 82.4772\n",
      "Validation Loss: 114.2344\n",
      "NME: 0.1662\n",
      "Epoch [143/300], Loss: 83.3359\n",
      "Validation Loss: 112.7984\n",
      "NME: 0.1618\n",
      "Epoch [144/300], Loss: 80.2884\n",
      "Validation Loss: 107.1655\n",
      "NME: 0.1593\n",
      "Epoch [145/300], Loss: 98.7690\n",
      "Validation Loss: 158.8069\n",
      "NME: 0.2088\n",
      "Epoch [146/300], Loss: 96.4073\n",
      "Validation Loss: 105.8032\n",
      "NME: 0.1539\n",
      "Best model saved at epoch 146 with val_loss 105.8032\n",
      "Epoch [147/300], Loss: 85.3490\n",
      "Validation Loss: 105.1892\n",
      "NME: 0.1533\n",
      "Best model saved at epoch 147 with val_loss 105.1892\n",
      "Epoch [148/300], Loss: 86.6215\n",
      "Validation Loss: 115.0367\n",
      "NME: 0.1657\n",
      "Epoch [149/300], Loss: 85.6821\n",
      "Validation Loss: 106.3454\n",
      "NME: 0.1604\n",
      "Epoch [150/300], Loss: 82.5192\n",
      "Validation Loss: 114.0206\n",
      "NME: 0.1669\n",
      "Epoch [151/300], Loss: 82.4896\n",
      "Validation Loss: 102.4383\n",
      "NME: 0.1565\n",
      "Best model saved at epoch 151 with val_loss 102.4383\n",
      "Epoch [152/300], Loss: 78.7985\n",
      "Validation Loss: 98.5113\n",
      "NME: 0.1483\n",
      "Best model saved at epoch 152 with val_loss 98.5113\n",
      "Epoch [153/300], Loss: 80.1270\n",
      "Validation Loss: 102.7277\n",
      "NME: 0.1514\n",
      "Epoch [154/300], Loss: 77.6677\n",
      "Validation Loss: 105.5044\n",
      "NME: 0.1552\n",
      "Epoch [155/300], Loss: 78.6322\n",
      "Validation Loss: 101.1745\n",
      "NME: 0.1479\n",
      "Epoch [156/300], Loss: 75.2306\n",
      "Validation Loss: 103.4583\n",
      "NME: 0.1532\n",
      "Epoch [157/300], Loss: 74.9967\n",
      "Validation Loss: 99.0935\n",
      "NME: 0.1476\n",
      "Epoch [158/300], Loss: 73.9609\n",
      "Validation Loss: 101.0229\n",
      "NME: 0.1470\n",
      "Epoch [159/300], Loss: 74.0604\n",
      "Validation Loss: 93.7397\n",
      "NME: 0.1422\n",
      "Best model saved at epoch 159 with val_loss 93.7397\n",
      "Epoch [160/300], Loss: 72.9014\n",
      "Validation Loss: 96.8685\n",
      "NME: 0.1449\n",
      "Epoch [161/300], Loss: 71.7460\n",
      "Validation Loss: 95.2332\n",
      "NME: 0.1468\n",
      "Epoch [162/300], Loss: 70.8438\n",
      "Validation Loss: 91.9441\n",
      "NME: 0.1448\n",
      "Best model saved at epoch 162 with val_loss 91.9441\n",
      "Epoch [163/300], Loss: 69.5446\n",
      "Validation Loss: 86.8159\n",
      "NME: 0.1425\n",
      "Best model saved at epoch 163 with val_loss 86.8159\n",
      "Epoch [164/300], Loss: 68.9107\n",
      "Validation Loss: 88.7165\n",
      "NME: 0.1443\n",
      "Epoch [165/300], Loss: 67.4868\n",
      "Validation Loss: 88.1067\n",
      "NME: 0.1437\n",
      "Epoch [166/300], Loss: 66.3084\n",
      "Validation Loss: 88.1016\n",
      "NME: 0.1486\n",
      "Epoch [167/300], Loss: 64.3744\n",
      "Validation Loss: 85.2354\n",
      "NME: 0.1443\n",
      "Best model saved at epoch 167 with val_loss 85.2354\n",
      "Epoch [168/300], Loss: 64.7084\n",
      "Validation Loss: 89.8832\n",
      "NME: 0.1490\n",
      "Epoch [169/300], Loss: 64.0026\n",
      "Validation Loss: 85.3020\n",
      "NME: 0.1399\n",
      "Epoch [170/300], Loss: 60.9675\n",
      "Validation Loss: 83.8766\n",
      "NME: 0.1392\n",
      "Best model saved at epoch 170 with val_loss 83.8766\n",
      "Epoch [171/300], Loss: 61.4750\n",
      "Validation Loss: 83.4485\n",
      "NME: 0.1376\n",
      "Best model saved at epoch 171 with val_loss 83.4485\n",
      "Epoch [172/300], Loss: 59.8820\n",
      "Validation Loss: 87.7123\n",
      "NME: 0.1435\n",
      "Epoch [173/300], Loss: 59.9020\n",
      "Validation Loss: 81.2462\n",
      "NME: 0.1391\n",
      "Best model saved at epoch 173 with val_loss 81.2462\n",
      "Epoch [174/300], Loss: 58.6216\n",
      "Validation Loss: 83.0558\n",
      "NME: 0.1385\n",
      "Epoch [175/300], Loss: 57.8779\n",
      "Validation Loss: 82.3336\n",
      "NME: 0.1343\n",
      "Epoch [176/300], Loss: 66.5161\n",
      "Validation Loss: 93.5128\n",
      "NME: 0.1536\n",
      "Epoch [177/300], Loss: 71.5887\n",
      "Validation Loss: 91.2759\n",
      "NME: 0.1637\n",
      "Epoch [178/300], Loss: 66.7177\n",
      "Validation Loss: 81.0110\n",
      "NME: 0.1358\n",
      "Best model saved at epoch 178 with val_loss 81.0110\n",
      "Epoch [179/300], Loss: 58.4859\n",
      "Validation Loss: 78.4126\n",
      "NME: 0.1368\n",
      "Best model saved at epoch 179 with val_loss 78.4126\n",
      "Epoch [180/300], Loss: 58.3494\n",
      "Validation Loss: 76.0033\n",
      "NME: 0.1378\n",
      "Best model saved at epoch 180 with val_loss 76.0033\n",
      "Epoch [181/300], Loss: 61.8322\n",
      "Validation Loss: 78.3505\n",
      "NME: 0.1304\n",
      "Epoch [182/300], Loss: 75.2184\n",
      "Validation Loss: 90.0781\n",
      "NME: 0.1476\n",
      "Epoch [183/300], Loss: 64.2640\n",
      "Validation Loss: 88.4154\n",
      "NME: 0.1353\n",
      "Epoch [184/300], Loss: 58.3585\n",
      "Validation Loss: 79.4811\n",
      "NME: 0.1348\n",
      "Epoch [185/300], Loss: 55.8518\n",
      "Validation Loss: 83.1281\n",
      "NME: 0.1356\n",
      "Epoch [186/300], Loss: 55.1410\n",
      "Validation Loss: 75.6772\n",
      "NME: 0.1381\n",
      "Best model saved at epoch 186 with val_loss 75.6772\n",
      "Epoch [187/300], Loss: 53.5607\n",
      "Validation Loss: 77.8713\n",
      "NME: 0.1344\n",
      "Epoch [188/300], Loss: 54.7322\n",
      "Validation Loss: 75.1778\n",
      "NME: 0.1299\n",
      "Best model saved at epoch 188 with val_loss 75.1778\n",
      "Epoch [189/300], Loss: 54.2626\n",
      "Validation Loss: 74.8767\n",
      "NME: 0.1298\n",
      "Best model saved at epoch 189 with val_loss 74.8767\n",
      "Epoch [190/300], Loss: 57.6345\n",
      "Validation Loss: 78.8112\n",
      "NME: 0.1424\n",
      "Epoch [191/300], Loss: 53.6445\n",
      "Validation Loss: 75.0728\n",
      "NME: 0.1298\n",
      "Epoch [192/300], Loss: 52.4419\n",
      "Validation Loss: 75.8205\n",
      "NME: 0.1328\n",
      "Epoch [193/300], Loss: 52.9096\n",
      "Validation Loss: 75.8024\n",
      "NME: 0.1287\n",
      "Epoch [194/300], Loss: 51.5290\n",
      "Validation Loss: 77.4559\n",
      "NME: 0.1345\n",
      "Epoch [195/300], Loss: 51.2220\n",
      "Validation Loss: 78.2614\n",
      "NME: 0.1325\n",
      "Epoch [196/300], Loss: 51.1313\n",
      "Validation Loss: 76.9623\n",
      "NME: 0.1344\n",
      "Epoch [197/300], Loss: 51.0944\n",
      "Validation Loss: 76.5569\n",
      "NME: 0.1390\n",
      "Epoch [198/300], Loss: 50.8443\n",
      "Validation Loss: 73.0776\n",
      "NME: 0.1297\n",
      "Best model saved at epoch 198 with val_loss 73.0776\n",
      "Epoch [199/300], Loss: 56.8765\n",
      "Validation Loss: 79.5049\n",
      "NME: 0.1401\n",
      "Epoch [200/300], Loss: 53.6210\n",
      "Validation Loss: 77.0361\n",
      "NME: 0.1354\n",
      "Epoch [201/300], Loss: 53.2202\n",
      "Validation Loss: 76.1847\n",
      "NME: 0.1363\n",
      "Epoch [202/300], Loss: 50.4878\n",
      "Validation Loss: 72.6457\n",
      "NME: 0.1322\n",
      "Best model saved at epoch 202 with val_loss 72.6457\n",
      "Epoch [203/300], Loss: 51.5135\n",
      "Validation Loss: 73.7917\n",
      "NME: 0.1279\n",
      "Epoch [204/300], Loss: 50.0297\n",
      "Validation Loss: 79.5021\n",
      "NME: 0.1345\n",
      "Epoch [205/300], Loss: 49.2633\n",
      "Validation Loss: 73.5678\n",
      "NME: 0.1285\n",
      "Epoch [206/300], Loss: 51.2733\n",
      "Validation Loss: 71.4413\n",
      "NME: 0.1262\n",
      "Best model saved at epoch 206 with val_loss 71.4413\n",
      "Epoch [207/300], Loss: 49.9549\n",
      "Validation Loss: 73.3427\n",
      "NME: 0.1322\n",
      "Epoch [208/300], Loss: 50.8494\n",
      "Validation Loss: 80.6865\n",
      "NME: 0.1378\n",
      "Epoch [209/300], Loss: 50.0794\n",
      "Validation Loss: 73.6324\n",
      "NME: 0.1271\n",
      "Epoch [210/300], Loss: 49.8051\n",
      "Validation Loss: 75.5578\n",
      "NME: 0.1311\n",
      "Epoch [211/300], Loss: 49.9284\n",
      "Validation Loss: 76.1097\n",
      "NME: 0.1379\n",
      "Epoch [212/300], Loss: 48.6212\n",
      "Validation Loss: 75.4822\n",
      "NME: 0.1277\n",
      "Epoch [213/300], Loss: 49.4512\n",
      "Validation Loss: 73.9170\n",
      "NME: 0.1257\n",
      "Epoch [214/300], Loss: 51.7085\n",
      "Validation Loss: 78.1349\n",
      "NME: 0.1295\n",
      "Epoch [215/300], Loss: 54.0637\n",
      "Validation Loss: 82.0207\n",
      "NME: 0.1371\n",
      "Epoch [216/300], Loss: 57.8288\n",
      "Validation Loss: 74.5208\n",
      "NME: 0.1274\n",
      "Epoch [217/300], Loss: 50.6084\n",
      "Validation Loss: 74.1002\n",
      "NME: 0.1281\n",
      "Epoch [218/300], Loss: 50.0799\n",
      "Validation Loss: 72.0018\n",
      "NME: 0.1263\n",
      "Epoch [219/300], Loss: 51.3118\n",
      "Validation Loss: 70.6594\n",
      "NME: 0.1254\n",
      "Best model saved at epoch 219 with val_loss 70.6594\n",
      "Epoch [220/300], Loss: 49.4214\n",
      "Validation Loss: 75.8241\n",
      "NME: 0.1376\n",
      "Epoch [221/300], Loss: 49.5428\n",
      "Validation Loss: 72.2268\n",
      "NME: 0.1242\n",
      "Epoch [222/300], Loss: 48.5023\n",
      "Validation Loss: 75.3528\n",
      "NME: 0.1305\n",
      "Epoch [223/300], Loss: 48.9168\n",
      "Validation Loss: 74.0098\n",
      "NME: 0.1283\n",
      "Epoch [224/300], Loss: 48.1541\n",
      "Validation Loss: 74.6682\n",
      "NME: 0.1282\n",
      "Epoch [225/300], Loss: 50.5822\n",
      "Validation Loss: 71.5710\n",
      "NME: 0.1248\n",
      "Epoch [226/300], Loss: 50.5425\n",
      "Validation Loss: 74.1154\n",
      "NME: 0.1276\n",
      "Epoch [227/300], Loss: 49.0750\n",
      "Validation Loss: 67.6432\n",
      "NME: 0.1231\n",
      "Best model saved at epoch 227 with val_loss 67.6432\n",
      "Epoch [228/300], Loss: 47.5070\n",
      "Validation Loss: 73.6800\n",
      "NME: 0.1300\n",
      "Epoch [229/300], Loss: 49.1217\n",
      "Validation Loss: 73.9290\n",
      "NME: 0.1245\n",
      "Epoch [230/300], Loss: 48.3422\n",
      "Validation Loss: 72.5857\n",
      "NME: 0.1299\n",
      "Epoch [231/300], Loss: 48.8727\n",
      "Validation Loss: 72.6110\n",
      "NME: 0.1279\n",
      "Epoch [232/300], Loss: 49.5672\n",
      "Validation Loss: 70.3484\n",
      "NME: 0.1266\n",
      "Epoch [233/300], Loss: 50.1851\n",
      "Validation Loss: 75.6451\n",
      "NME: 0.1326\n",
      "Epoch [234/300], Loss: 49.6674\n",
      "Validation Loss: 73.1435\n",
      "NME: 0.1266\n",
      "Epoch [235/300], Loss: 48.1607\n",
      "Validation Loss: 74.2638\n",
      "NME: 0.1343\n",
      "Epoch [236/300], Loss: 47.5923\n",
      "Validation Loss: 71.6181\n",
      "NME: 0.1250\n",
      "Epoch [237/300], Loss: 49.2669\n",
      "Validation Loss: 74.6144\n",
      "NME: 0.1303\n",
      "Epoch [238/300], Loss: 48.8624\n",
      "Validation Loss: 70.0496\n",
      "NME: 0.1253\n",
      "Epoch [239/300], Loss: 48.1594\n",
      "Validation Loss: 72.8220\n",
      "NME: 0.1302\n",
      "Epoch [240/300], Loss: 59.3083\n",
      "Validation Loss: 74.2210\n",
      "NME: 0.1357\n",
      "Epoch [241/300], Loss: 53.0154\n",
      "Validation Loss: 78.4705\n",
      "NME: 0.1360\n",
      "Epoch [242/300], Loss: 50.9456\n",
      "Validation Loss: 72.8700\n",
      "NME: 0.1293\n",
      "Epoch [243/300], Loss: 49.0200\n",
      "Validation Loss: 72.0325\n",
      "NME: 0.1262\n",
      "Epoch [244/300], Loss: 49.8155\n",
      "Validation Loss: 73.8992\n",
      "NME: 0.1267\n",
      "Epoch [245/300], Loss: 47.9082\n",
      "Validation Loss: 71.7172\n",
      "NME: 0.1247\n",
      "Epoch [246/300], Loss: 46.8430\n",
      "Validation Loss: 70.1321\n",
      "NME: 0.1227\n",
      "Epoch [247/300], Loss: 47.2840\n",
      "Validation Loss: 75.6958\n",
      "NME: 0.1267\n",
      "Epoch [248/300], Loss: 47.7284\n",
      "Validation Loss: 73.4426\n",
      "NME: 0.1270\n",
      "Epoch [249/300], Loss: 47.4044\n",
      "Validation Loss: 75.7968\n",
      "NME: 0.1291\n",
      "Epoch [250/300], Loss: 46.7561\n",
      "Validation Loss: 69.6419\n",
      "NME: 0.1241\n",
      "Epoch [251/300], Loss: 47.2297\n",
      "Validation Loss: 70.3332\n",
      "NME: 0.1249\n",
      "Epoch [252/300], Loss: 47.7463\n",
      "Validation Loss: 69.6187\n",
      "NME: 0.1220\n",
      "Epoch [253/300], Loss: 46.0466\n",
      "Validation Loss: 74.0249\n",
      "NME: 0.1348\n",
      "Epoch [254/300], Loss: 46.7797\n",
      "Validation Loss: 70.9376\n",
      "NME: 0.1224\n",
      "Epoch [255/300], Loss: 46.8750\n",
      "Validation Loss: 69.7896\n",
      "NME: 0.1264\n",
      "Epoch [256/300], Loss: 46.6257\n",
      "Validation Loss: 69.2668\n",
      "NME: 0.1240\n",
      "Epoch [257/300], Loss: 46.3692\n",
      "Validation Loss: 71.3284\n",
      "NME: 0.1249\n",
      "Epoch [258/300], Loss: 47.1111\n",
      "Validation Loss: 72.2634\n",
      "NME: 0.1244\n",
      "Epoch [259/300], Loss: 47.7543\n",
      "Validation Loss: 74.7443\n",
      "NME: 0.1311\n",
      "Epoch [260/300], Loss: 47.0380\n",
      "Validation Loss: 72.2638\n",
      "NME: 0.1265\n",
      "Epoch [261/300], Loss: 47.4783\n",
      "Validation Loss: 72.9808\n",
      "NME: 0.1291\n",
      "Epoch [262/300], Loss: 47.8473\n",
      "Validation Loss: 71.9139\n",
      "NME: 0.1262\n",
      "Epoch [263/300], Loss: 46.4882\n",
      "Validation Loss: 72.4592\n",
      "NME: 0.1333\n",
      "Epoch [264/300], Loss: 48.4512\n",
      "Validation Loss: 73.5392\n",
      "NME: 0.1307\n",
      "Epoch [265/300], Loss: 48.4217\n",
      "Validation Loss: 76.6769\n",
      "NME: 0.1290\n",
      "Epoch [266/300], Loss: 48.9425\n",
      "Validation Loss: 79.1276\n",
      "NME: 0.1335\n",
      "Epoch [267/300], Loss: 48.6199\n",
      "Validation Loss: 74.4831\n",
      "NME: 0.1285\n",
      "Epoch [268/300], Loss: 47.0837\n",
      "Validation Loss: 74.6625\n",
      "NME: 0.1229\n",
      "Epoch [269/300], Loss: 45.4531\n",
      "Validation Loss: 74.1171\n",
      "NME: 0.1248\n",
      "Epoch [270/300], Loss: 45.5649\n",
      "Validation Loss: 76.5118\n",
      "NME: 0.1302\n",
      "Epoch [271/300], Loss: 45.4689\n",
      "Validation Loss: 72.8780\n",
      "NME: 0.1252\n",
      "Epoch [272/300], Loss: 44.6210\n",
      "Validation Loss: 73.5648\n",
      "NME: 0.1266\n",
      "Epoch [273/300], Loss: 45.7975\n",
      "Validation Loss: 74.5006\n",
      "NME: 0.1242\n",
      "Epoch [274/300], Loss: 45.4345\n",
      "Validation Loss: 72.7003\n",
      "NME: 0.1270\n",
      "Epoch [275/300], Loss: 45.7159\n",
      "Validation Loss: 71.2650\n",
      "NME: 0.1274\n",
      "Epoch [276/300], Loss: 45.5731\n",
      "Validation Loss: 70.2692\n",
      "NME: 0.1243\n",
      "Epoch [277/300], Loss: 43.9355\n",
      "Validation Loss: 72.5190\n",
      "NME: 0.1253\n",
      "Epoch [278/300], Loss: 43.9387\n",
      "Validation Loss: 72.6031\n",
      "NME: 0.1286\n",
      "Epoch [279/300], Loss: 44.6945\n",
      "Validation Loss: 75.3234\n",
      "NME: 0.1257\n",
      "Epoch [280/300], Loss: 44.2571\n",
      "Validation Loss: 68.5052\n",
      "NME: 0.1265\n",
      "Epoch [281/300], Loss: 58.5815\n",
      "Validation Loss: 84.0462\n",
      "NME: 0.1440\n",
      "Epoch [282/300], Loss: 50.0037\n",
      "Validation Loss: 71.9941\n",
      "NME: 0.1324\n",
      "Epoch [283/300], Loss: 45.7216\n",
      "Validation Loss: 73.9758\n",
      "NME: 0.1299\n",
      "Epoch [284/300], Loss: 44.9946\n",
      "Validation Loss: 72.5303\n",
      "NME: 0.1282\n",
      "Epoch [285/300], Loss: 45.0758\n",
      "Validation Loss: 71.5817\n",
      "NME: 0.1286\n",
      "Epoch [286/300], Loss: 43.8612\n",
      "Validation Loss: 70.5118\n",
      "NME: 0.1240\n",
      "Epoch [287/300], Loss: 42.5960\n",
      "Validation Loss: 72.2881\n",
      "NME: 0.1273\n",
      "Epoch [288/300], Loss: 43.7910\n",
      "Validation Loss: 76.3780\n",
      "NME: 0.1260\n",
      "Epoch [289/300], Loss: 45.8465\n",
      "Validation Loss: 76.9693\n",
      "NME: 0.1283\n",
      "Epoch [290/300], Loss: 43.6282\n",
      "Validation Loss: 71.7555\n",
      "NME: 0.1295\n",
      "Epoch [291/300], Loss: 42.5910\n",
      "Validation Loss: 69.8487\n",
      "NME: 0.1240\n",
      "Epoch [292/300], Loss: 41.6935\n",
      "Validation Loss: 68.5099\n",
      "NME: 0.1251\n",
      "Epoch [293/300], Loss: 42.1609\n",
      "Validation Loss: 71.6036\n",
      "NME: 0.1291\n",
      "Epoch [294/300], Loss: 41.4541\n",
      "Validation Loss: 68.7111\n",
      "NME: 0.1223\n",
      "Epoch [295/300], Loss: 41.6311\n",
      "Validation Loss: 70.7117\n",
      "NME: 0.1245\n",
      "Epoch [296/300], Loss: 41.2949\n",
      "Validation Loss: 72.5025\n",
      "NME: 0.1301\n",
      "Epoch [297/300], Loss: 42.4245\n",
      "Validation Loss: 70.9215\n",
      "NME: 0.1293\n",
      "Epoch [298/300], Loss: 40.6346\n",
      "Validation Loss: 70.0305\n",
      "NME: 0.1294\n",
      "Epoch [299/300], Loss: 40.1175\n",
      "Validation Loss: 71.1808\n",
      "NME: 0.1277\n",
      "Epoch [300/300], Loss: 39.4931\n",
      "Validation Loss: 71.7542\n",
      "NME: 0.1290\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "nariz = [0, 2, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 32, 33, 34, 35, 42, 43, 44, 45, 46, 47]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class NoseDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos y la nariz\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_nariz = calcular_centro_region(landmarks, nariz)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_nariz -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la nariz\n",
    "        nose_points = np.array([landmarks[i] for i in nariz], dtype=np.float32)\n",
    "        nose_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(nose_points), 1))\n",
    "        points_ones = np.hstack([nose_points, ones])\n",
    "        nose_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la nariz\n",
    "        centro_x, centro_y = calcular_centro_region(nose_points_rotated, range(len(nariz)))\n",
    "\n",
    "        # Definir los límites del recorte de 112x112 píxeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_nose = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_nose, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la nariz al nuevo recorte\n",
    "        nose_points_adjusted = [(p[0] - x1, p[1] - y1) for p in nose_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        nose_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in nose_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=nose_points_scaled)\n",
    "            image = augmented['image']\n",
    "            nose_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(nose_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = NoseDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = NoseDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121Nose(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121Nose, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(nariz) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121Nose().cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para nariz)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, nose_points, _, _, _ in train_dataloader:\n",
    "            images, nose_points = images.cuda(), nose_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, nose_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_nose_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_nose_points = val_images.cuda(), val_nose_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_nose_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_nose_points.cpu().numpy().reshape(-1, len(nariz), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(nariz), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(nariz))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'NoseAreaLandmarks V4.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
