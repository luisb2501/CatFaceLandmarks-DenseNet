{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos divididos y copiados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Directorios originales\n",
    "img_dir = r'C:\\CatFLW dataset\\images'\n",
    "labels_dir = r'C:\\CatFLW dataset\\labels'\n",
    "\n",
    "# Directorios de destino\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Crear directorios de destino si no existen\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "os.makedirs(val_img_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "# Obtener lista de archivos de im치genes\n",
    "image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "# Dividir en entrenamiento y validaci칩n (80% - 20%)\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funci칩n para copiar archivos\n",
    "def copy_files(file_list, src_img_dir, src_labels_dir, dest_img_dir, dest_labels_dir):\n",
    "    for file_name in file_list:\n",
    "        shutil.copy(os.path.join(src_img_dir, file_name), os.path.join(dest_img_dir, file_name))\n",
    "        label_name = file_name.replace('.png', '.json')\n",
    "        shutil.copy(os.path.join(src_labels_dir, label_name), os.path.join(dest_labels_dir, label_name))\n",
    "\n",
    "# Copiar archivos de entrenamiento\n",
    "copy_files(train_files, img_dir, labels_dir, train_img_dir, train_labels_dir)\n",
    "\n",
    "# Copiar archivos de validaci칩n\n",
    "copy_files(val_files, img_dir, labels_dir, val_img_dir, val_labels_dir)\n",
    "\n",
    "print(\"Archivos divididos y copiados exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 17954.9333\n",
      "Validation Loss: 15458.0908\n",
      "NME: 1.4174\n",
      "Best model saved at epoch 1 with val_loss 15458.0908\n",
      "Epoch [2/300], Loss: 9575.6536\n",
      "Validation Loss: 3547.8036\n",
      "NME: 0.6036\n",
      "Best model saved at epoch 2 with val_loss 3547.8036\n",
      "Epoch [3/300], Loss: 2145.3656\n",
      "Validation Loss: 1493.0034\n",
      "NME: 0.3450\n",
      "Best model saved at epoch 3 with val_loss 1493.0034\n",
      "Epoch [4/300], Loss: 1642.2495\n",
      "Validation Loss: 1402.8177\n",
      "NME: 0.3424\n",
      "Best model saved at epoch 4 with val_loss 1402.8177\n",
      "Epoch [5/300], Loss: 1591.5684\n",
      "Validation Loss: 1368.2254\n",
      "NME: 0.3445\n",
      "Best model saved at epoch 5 with val_loss 1368.2254\n",
      "Epoch [6/300], Loss: 1558.3180\n",
      "Validation Loss: 1349.9158\n",
      "NME: 0.3421\n",
      "Best model saved at epoch 6 with val_loss 1349.9158\n",
      "Epoch [7/300], Loss: 1545.3773\n",
      "Validation Loss: 1324.5729\n",
      "NME: 0.3350\n",
      "Best model saved at epoch 7 with val_loss 1324.5729\n",
      "Epoch [8/300], Loss: 1536.6972\n",
      "Validation Loss: 1293.7827\n",
      "NME: 0.3307\n",
      "Best model saved at epoch 8 with val_loss 1293.7827\n",
      "Epoch [9/300], Loss: 1472.8649\n",
      "Validation Loss: 1215.4418\n",
      "NME: 0.3155\n",
      "Best model saved at epoch 9 with val_loss 1215.4418\n",
      "Epoch [10/300], Loss: 1385.3940\n",
      "Validation Loss: 1127.2762\n",
      "NME: 0.3011\n",
      "Best model saved at epoch 10 with val_loss 1127.2762\n",
      "Epoch [11/300], Loss: 1245.2689\n",
      "Validation Loss: 909.4426\n",
      "NME: 0.2726\n",
      "Best model saved at epoch 11 with val_loss 909.4426\n",
      "Epoch [12/300], Loss: 1067.5494\n",
      "Validation Loss: 712.0642\n",
      "NME: 0.2432\n",
      "Best model saved at epoch 12 with val_loss 712.0642\n",
      "Epoch [13/300], Loss: 930.1113\n",
      "Validation Loss: 569.6138\n",
      "NME: 0.2244\n",
      "Best model saved at epoch 13 with val_loss 569.6138\n",
      "Epoch [14/300], Loss: 845.6979\n",
      "Validation Loss: 488.1923\n",
      "NME: 0.2113\n",
      "Best model saved at epoch 14 with val_loss 488.1923\n",
      "Epoch [15/300], Loss: 784.0078\n",
      "Validation Loss: 457.8050\n",
      "NME: 0.2024\n",
      "Best model saved at epoch 15 with val_loss 457.8050\n",
      "Epoch [16/300], Loss: 747.5790\n",
      "Validation Loss: 519.4868\n",
      "NME: 0.2076\n",
      "Epoch [17/300], Loss: 721.6556\n",
      "Validation Loss: 456.9770\n",
      "NME: 0.1978\n",
      "Best model saved at epoch 17 with val_loss 456.9770\n",
      "Epoch [18/300], Loss: 664.5947\n",
      "Validation Loss: 430.6972\n",
      "NME: 0.1951\n",
      "Best model saved at epoch 18 with val_loss 430.6972\n",
      "Epoch [19/300], Loss: 687.7569\n",
      "Validation Loss: 405.3724\n",
      "NME: 0.1917\n",
      "Best model saved at epoch 19 with val_loss 405.3724\n",
      "Epoch [20/300], Loss: 687.5291\n",
      "Validation Loss: 408.2758\n",
      "NME: 0.1952\n",
      "Epoch [21/300], Loss: 699.7020\n",
      "Validation Loss: 403.5419\n",
      "NME: 0.1904\n",
      "Best model saved at epoch 21 with val_loss 403.5419\n",
      "Epoch [22/300], Loss: 663.8162\n",
      "Validation Loss: 411.1161\n",
      "NME: 0.1937\n",
      "Epoch [23/300], Loss: 615.1456\n",
      "Validation Loss: 419.6888\n",
      "NME: 0.1924\n",
      "Epoch [24/300], Loss: 656.1551\n",
      "Validation Loss: 394.5130\n",
      "NME: 0.1874\n",
      "Best model saved at epoch 24 with val_loss 394.5130\n",
      "Epoch [25/300], Loss: 611.6762\n",
      "Validation Loss: 412.2643\n",
      "NME: 0.1940\n",
      "Epoch [26/300], Loss: 654.6684\n",
      "Validation Loss: 414.8449\n",
      "NME: 0.1903\n",
      "Epoch [27/300], Loss: 630.3302\n",
      "Validation Loss: 369.4335\n",
      "NME: 0.1842\n",
      "Best model saved at epoch 27 with val_loss 369.4335\n",
      "Epoch [28/300], Loss: 562.3396\n",
      "Validation Loss: 358.7216\n",
      "NME: 0.1792\n",
      "Best model saved at epoch 28 with val_loss 358.7216\n",
      "Epoch [29/300], Loss: 588.8314\n",
      "Validation Loss: 388.4759\n",
      "NME: 0.1870\n",
      "Epoch [30/300], Loss: 592.8995\n",
      "Validation Loss: 418.5493\n",
      "NME: 0.1767\n",
      "Epoch [31/300], Loss: 572.2034\n",
      "Validation Loss: 377.7520\n",
      "NME: 0.1710\n",
      "Epoch [32/300], Loss: 534.3839\n",
      "Validation Loss: 346.1787\n",
      "NME: 0.1675\n",
      "Best model saved at epoch 32 with val_loss 346.1787\n",
      "Epoch [33/300], Loss: 569.4521\n",
      "Validation Loss: 411.1829\n",
      "NME: 0.1794\n",
      "Epoch [34/300], Loss: 508.3622\n",
      "Validation Loss: 331.9858\n",
      "NME: 0.1549\n",
      "Best model saved at epoch 34 with val_loss 331.9858\n",
      "Epoch [35/300], Loss: 534.6825\n",
      "Validation Loss: 326.4997\n",
      "NME: 0.1515\n",
      "Best model saved at epoch 35 with val_loss 326.4997\n",
      "Epoch [36/300], Loss: 486.8108\n",
      "Validation Loss: 332.1067\n",
      "NME: 0.1528\n",
      "Epoch [37/300], Loss: 518.2133\n",
      "Validation Loss: 311.8700\n",
      "NME: 0.1462\n",
      "Best model saved at epoch 37 with val_loss 311.8700\n",
      "Epoch [38/300], Loss: 483.3195\n",
      "Validation Loss: 321.2434\n",
      "NME: 0.1453\n",
      "Epoch [39/300], Loss: 446.5628\n",
      "Validation Loss: 333.1890\n",
      "NME: 0.1442\n",
      "Epoch [40/300], Loss: 463.5139\n",
      "Validation Loss: 312.3441\n",
      "NME: 0.1454\n",
      "Epoch [41/300], Loss: 465.1118\n",
      "Validation Loss: 311.7377\n",
      "NME: 0.1416\n",
      "Best model saved at epoch 41 with val_loss 311.7377\n",
      "Epoch [42/300], Loss: 445.0492\n",
      "Validation Loss: 312.6812\n",
      "NME: 0.1373\n",
      "Epoch [43/300], Loss: 408.0739\n",
      "Validation Loss: 307.5913\n",
      "NME: 0.1421\n",
      "Best model saved at epoch 43 with val_loss 307.5913\n",
      "Epoch [44/300], Loss: 356.0006\n",
      "Validation Loss: 304.5371\n",
      "NME: 0.1408\n",
      "Best model saved at epoch 44 with val_loss 304.5371\n",
      "Epoch [45/300], Loss: 371.9580\n",
      "Validation Loss: 315.4303\n",
      "NME: 0.1331\n",
      "Epoch [46/300], Loss: 371.5054\n",
      "Validation Loss: 289.9743\n",
      "NME: 0.1369\n",
      "Best model saved at epoch 46 with val_loss 289.9743\n",
      "Epoch [47/300], Loss: 314.7419\n",
      "Validation Loss: 346.1286\n",
      "NME: 0.1448\n",
      "Epoch [48/300], Loss: 303.4875\n",
      "Validation Loss: 289.9461\n",
      "NME: 0.1309\n",
      "Best model saved at epoch 48 with val_loss 289.9461\n",
      "Epoch [49/300], Loss: 309.4255\n",
      "Validation Loss: 282.4105\n",
      "NME: 0.1321\n",
      "Best model saved at epoch 49 with val_loss 282.4105\n",
      "Epoch [50/300], Loss: 293.8153\n",
      "Validation Loss: 272.9754\n",
      "NME: 0.1241\n",
      "Best model saved at epoch 50 with val_loss 272.9754\n",
      "Epoch [51/300], Loss: 273.6007\n",
      "Validation Loss: 292.2079\n",
      "NME: 0.1334\n",
      "Epoch [52/300], Loss: 276.5648\n",
      "Validation Loss: 301.0769\n",
      "NME: 0.1339\n",
      "Epoch [53/300], Loss: 257.9796\n",
      "Validation Loss: 295.1453\n",
      "NME: 0.1232\n",
      "Epoch [54/300], Loss: 245.4636\n",
      "Validation Loss: 260.1827\n",
      "NME: 0.1227\n",
      "Best model saved at epoch 54 with val_loss 260.1827\n",
      "Epoch [55/300], Loss: 240.7472\n",
      "Validation Loss: 283.1258\n",
      "NME: 0.1262\n",
      "Epoch [56/300], Loss: 248.4905\n",
      "Validation Loss: 273.7309\n",
      "NME: 0.1247\n",
      "Epoch [57/300], Loss: 251.5190\n",
      "Validation Loss: 284.3050\n",
      "NME: 0.1289\n",
      "Epoch [58/300], Loss: 234.2780\n",
      "Validation Loss: 310.4315\n",
      "NME: 0.1275\n",
      "Epoch [59/300], Loss: 242.2817\n",
      "Validation Loss: 270.8184\n",
      "NME: 0.1228\n",
      "Epoch [60/300], Loss: 234.9755\n",
      "Validation Loss: 276.6555\n",
      "NME: 0.1301\n",
      "Epoch [61/300], Loss: 226.3826\n",
      "Validation Loss: 278.0069\n",
      "NME: 0.1211\n",
      "Epoch [62/300], Loss: 233.7963\n",
      "Validation Loss: 256.5335\n",
      "NME: 0.1332\n",
      "Best model saved at epoch 62 with val_loss 256.5335\n",
      "Epoch [63/300], Loss: 230.8882\n",
      "Validation Loss: 269.9232\n",
      "NME: 0.1312\n",
      "Epoch [64/300], Loss: 244.6895\n",
      "Validation Loss: 281.5168\n",
      "NME: 0.1236\n",
      "Epoch [65/300], Loss: 226.2931\n",
      "Validation Loss: 283.4397\n",
      "NME: 0.1294\n",
      "Epoch [66/300], Loss: 239.0096\n",
      "Validation Loss: 294.9454\n",
      "NME: 0.1256\n",
      "Epoch [67/300], Loss: 263.9510\n",
      "Validation Loss: 283.6095\n",
      "NME: 0.1275\n",
      "Epoch [68/300], Loss: 231.3027\n",
      "Validation Loss: 305.4680\n",
      "NME: 0.1411\n",
      "Epoch [69/300], Loss: 236.5670\n",
      "Validation Loss: 308.5826\n",
      "NME: 0.1276\n",
      "Epoch [70/300], Loss: 232.5140\n",
      "Validation Loss: 300.4164\n",
      "NME: 0.1235\n",
      "Epoch [71/300], Loss: 222.8296\n",
      "Validation Loss: 301.1339\n",
      "NME: 0.1205\n",
      "Epoch [72/300], Loss: 208.6098\n",
      "Validation Loss: 270.3980\n",
      "NME: 0.1208\n",
      "Epoch [73/300], Loss: 220.9352\n",
      "Validation Loss: 254.7674\n",
      "NME: 0.1191\n",
      "Best model saved at epoch 73 with val_loss 254.7674\n",
      "Epoch [74/300], Loss: 207.5460\n",
      "Validation Loss: 276.3718\n",
      "NME: 0.1184\n",
      "Epoch [75/300], Loss: 200.0483\n",
      "Validation Loss: 270.3512\n",
      "NME: 0.1208\n",
      "Epoch [76/300], Loss: 200.8955\n",
      "Validation Loss: 264.6869\n",
      "NME: 0.1190\n",
      "Epoch [77/300], Loss: 202.0165\n",
      "Validation Loss: 265.9214\n",
      "NME: 0.1206\n",
      "Epoch [78/300], Loss: 217.7911\n",
      "Validation Loss: 265.1931\n",
      "NME: 0.1236\n",
      "Epoch [79/300], Loss: 204.8344\n",
      "Validation Loss: 264.9542\n",
      "NME: 0.1259\n",
      "Epoch [80/300], Loss: 205.2860\n",
      "Validation Loss: 259.4704\n",
      "NME: 0.1199\n",
      "Epoch [81/300], Loss: 229.9738\n",
      "Validation Loss: 264.5012\n",
      "NME: 0.1288\n",
      "Epoch [82/300], Loss: 210.8145\n",
      "Validation Loss: 251.2390\n",
      "NME: 0.1178\n",
      "Best model saved at epoch 82 with val_loss 251.2390\n",
      "Epoch [83/300], Loss: 232.3117\n",
      "Validation Loss: 271.7316\n",
      "NME: 0.1189\n",
      "Epoch [84/300], Loss: 217.5670\n",
      "Validation Loss: 254.7845\n",
      "NME: 0.1211\n",
      "Epoch [85/300], Loss: 204.0977\n",
      "Validation Loss: 277.1991\n",
      "NME: 0.1240\n",
      "Epoch [86/300], Loss: 201.8977\n",
      "Validation Loss: 259.4652\n",
      "NME: 0.1195\n",
      "Epoch [87/300], Loss: 204.7657\n",
      "Validation Loss: 263.5293\n",
      "NME: 0.1230\n",
      "Epoch [88/300], Loss: 194.3972\n",
      "Validation Loss: 246.6130\n",
      "NME: 0.1184\n",
      "Best model saved at epoch 88 with val_loss 246.6130\n",
      "Epoch [89/300], Loss: 214.5508\n",
      "Validation Loss: 318.9722\n",
      "NME: 0.1357\n",
      "Epoch [90/300], Loss: 204.6636\n",
      "Validation Loss: 249.7371\n",
      "NME: 0.1159\n",
      "Epoch [91/300], Loss: 184.5156\n",
      "Validation Loss: 243.7194\n",
      "NME: 0.1171\n",
      "Best model saved at epoch 91 with val_loss 243.7194\n",
      "Epoch [92/300], Loss: 187.1057\n",
      "Validation Loss: 263.1064\n",
      "NME: 0.1148\n",
      "Epoch [93/300], Loss: 180.5362\n",
      "Validation Loss: 224.3481\n",
      "NME: 0.1110\n",
      "Best model saved at epoch 93 with val_loss 224.3481\n",
      "Epoch [94/300], Loss: 168.6368\n",
      "Validation Loss: 216.6053\n",
      "NME: 0.1085\n",
      "Best model saved at epoch 94 with val_loss 216.6053\n",
      "Epoch [95/300], Loss: 169.6946\n",
      "Validation Loss: 223.2089\n",
      "NME: 0.1076\n",
      "Epoch [96/300], Loss: 171.2491\n",
      "Validation Loss: 224.0004\n",
      "NME: 0.1078\n",
      "Epoch [97/300], Loss: 158.8125\n",
      "Validation Loss: 232.8092\n",
      "NME: 0.1065\n",
      "Epoch [98/300], Loss: 159.7179\n",
      "Validation Loss: 220.6282\n",
      "NME: 0.1033\n",
      "Epoch [99/300], Loss: 163.0454\n",
      "Validation Loss: 224.7929\n",
      "NME: 0.1103\n",
      "Epoch [100/300], Loss: 158.9466\n",
      "Validation Loss: 214.9174\n",
      "NME: 0.1021\n",
      "Best model saved at epoch 100 with val_loss 214.9174\n",
      "Epoch [101/300], Loss: 159.0995\n",
      "Validation Loss: 206.0578\n",
      "NME: 0.0994\n",
      "Best model saved at epoch 101 with val_loss 206.0578\n",
      "Epoch [102/300], Loss: 154.5492\n",
      "Validation Loss: 285.4369\n",
      "NME: 0.1209\n",
      "Epoch [103/300], Loss: 159.0384\n",
      "Validation Loss: 217.5779\n",
      "NME: 0.1011\n",
      "Epoch [104/300], Loss: 148.9799\n",
      "Validation Loss: 202.1351\n",
      "NME: 0.0970\n",
      "Best model saved at epoch 104 with val_loss 202.1351\n",
      "Epoch [105/300], Loss: 145.7083\n",
      "Validation Loss: 189.3420\n",
      "NME: 0.0989\n",
      "Best model saved at epoch 105 with val_loss 189.3420\n",
      "Epoch [106/300], Loss: 141.2904\n",
      "Validation Loss: 205.0407\n",
      "NME: 0.0976\n",
      "Epoch [107/300], Loss: 143.6599\n",
      "Validation Loss: 193.3554\n",
      "NME: 0.0969\n",
      "Epoch [108/300], Loss: 130.3482\n",
      "Validation Loss: 188.6920\n",
      "NME: 0.0975\n",
      "Best model saved at epoch 108 with val_loss 188.6920\n",
      "Epoch [109/300], Loss: 126.1004\n",
      "Validation Loss: 203.5434\n",
      "NME: 0.0959\n",
      "Epoch [110/300], Loss: 124.7478\n",
      "Validation Loss: 186.8324\n",
      "NME: 0.0942\n",
      "Best model saved at epoch 110 with val_loss 186.8324\n",
      "Epoch [111/300], Loss: 133.0424\n",
      "Validation Loss: 199.6459\n",
      "NME: 0.0995\n",
      "Epoch [112/300], Loss: 122.3897\n",
      "Validation Loss: 184.5868\n",
      "NME: 0.0939\n",
      "Best model saved at epoch 112 with val_loss 184.5868\n",
      "Epoch [113/300], Loss: 140.1554\n",
      "Validation Loss: 204.2714\n",
      "NME: 0.0979\n",
      "Epoch [114/300], Loss: 154.8054\n",
      "Validation Loss: 241.8949\n",
      "NME: 0.1042\n",
      "Epoch [115/300], Loss: 142.3369\n",
      "Validation Loss: 196.3576\n",
      "NME: 0.1007\n",
      "Epoch [116/300], Loss: 128.7799\n",
      "Validation Loss: 203.2599\n",
      "NME: 0.1007\n",
      "Epoch [117/300], Loss: 160.9166\n",
      "Validation Loss: 182.5485\n",
      "NME: 0.0984\n",
      "Best model saved at epoch 117 with val_loss 182.5485\n",
      "Epoch [118/300], Loss: 130.7652\n",
      "Validation Loss: 185.7538\n",
      "NME: 0.0948\n",
      "Epoch [119/300], Loss: 127.7445\n",
      "Validation Loss: 188.0902\n",
      "NME: 0.0955\n",
      "Epoch [120/300], Loss: 118.3965\n",
      "Validation Loss: 184.9820\n",
      "NME: 0.0946\n",
      "Epoch [121/300], Loss: 114.0436\n",
      "Validation Loss: 184.1206\n",
      "NME: 0.0930\n",
      "Epoch [122/300], Loss: 117.6762\n",
      "Validation Loss: 168.8821\n",
      "NME: 0.0914\n",
      "Best model saved at epoch 122 with val_loss 168.8821\n",
      "Epoch [123/300], Loss: 108.4675\n",
      "Validation Loss: 185.7016\n",
      "NME: 0.0915\n",
      "Epoch [124/300], Loss: 111.0902\n",
      "Validation Loss: 179.1095\n",
      "NME: 0.0941\n",
      "Epoch [125/300], Loss: 105.8655\n",
      "Validation Loss: 184.3961\n",
      "NME: 0.0920\n",
      "Epoch [126/300], Loss: 106.0330\n",
      "Validation Loss: 172.7438\n",
      "NME: 0.0929\n",
      "Epoch [127/300], Loss: 113.5757\n",
      "Validation Loss: 193.2246\n",
      "NME: 0.0949\n",
      "Epoch [128/300], Loss: 105.0522\n",
      "Validation Loss: 173.2869\n",
      "NME: 0.0934\n",
      "Epoch [129/300], Loss: 108.8893\n",
      "Validation Loss: 171.1348\n",
      "NME: 0.0912\n",
      "Epoch [130/300], Loss: 104.7590\n",
      "Validation Loss: 175.9739\n",
      "NME: 0.0907\n",
      "Epoch [131/300], Loss: 99.7260\n",
      "Validation Loss: 186.8927\n",
      "NME: 0.0927\n",
      "Epoch [132/300], Loss: 100.5840\n",
      "Validation Loss: 175.6869\n",
      "NME: 0.0915\n",
      "Epoch [133/300], Loss: 106.0348\n",
      "Validation Loss: 187.2587\n",
      "NME: 0.0925\n",
      "Epoch [134/300], Loss: 104.4941\n",
      "Validation Loss: 228.1687\n",
      "NME: 0.1005\n",
      "Epoch [135/300], Loss: 104.8495\n",
      "Validation Loss: 199.2160\n",
      "NME: 0.0931\n",
      "Epoch [136/300], Loss: 103.7663\n",
      "Validation Loss: 196.8504\n",
      "NME: 0.0936\n",
      "Epoch [137/300], Loss: 100.2819\n",
      "Validation Loss: 194.7073\n",
      "NME: 0.0923\n",
      "Epoch [138/300], Loss: 100.5537\n",
      "Validation Loss: 169.5800\n",
      "NME: 0.0937\n",
      "Epoch [139/300], Loss: 100.2511\n",
      "Validation Loss: 186.2494\n",
      "NME: 0.0938\n",
      "Epoch [140/300], Loss: 98.2858\n",
      "Validation Loss: 209.5845\n",
      "NME: 0.0941\n",
      "Epoch [141/300], Loss: 97.0651\n",
      "Validation Loss: 175.3159\n",
      "NME: 0.0941\n",
      "Epoch [142/300], Loss: 102.2670\n",
      "Validation Loss: 174.7803\n",
      "NME: 0.0919\n",
      "Epoch [143/300], Loss: 96.4391\n",
      "Validation Loss: 173.6983\n",
      "NME: 0.0925\n",
      "Epoch [144/300], Loss: 92.2476\n",
      "Validation Loss: 177.9621\n",
      "NME: 0.0917\n",
      "Epoch [145/300], Loss: 100.2586\n",
      "Validation Loss: 189.6383\n",
      "NME: 0.0940\n",
      "Epoch [146/300], Loss: 93.6352\n",
      "Validation Loss: 189.6157\n",
      "NME: 0.0920\n",
      "Epoch [147/300], Loss: 98.8058\n",
      "Validation Loss: 185.4596\n",
      "NME: 0.0969\n",
      "Epoch [148/300], Loss: 100.0111\n",
      "Validation Loss: 173.1101\n",
      "NME: 0.0907\n",
      "Epoch [149/300], Loss: 97.0827\n",
      "Validation Loss: 175.8611\n",
      "NME: 0.0887\n",
      "Epoch [150/300], Loss: 87.4295\n",
      "Validation Loss: 170.2110\n",
      "NME: 0.0896\n",
      "Epoch [151/300], Loss: 82.0117\n",
      "Validation Loss: 166.2150\n",
      "NME: 0.0888\n",
      "Best model saved at epoch 151 with val_loss 166.2150\n",
      "Epoch [152/300], Loss: 89.3338\n",
      "Validation Loss: 168.6788\n",
      "NME: 0.0915\n",
      "Epoch [153/300], Loss: 101.5921\n",
      "Validation Loss: 191.4950\n",
      "NME: 0.0970\n",
      "Epoch [154/300], Loss: 91.5463\n",
      "Validation Loss: 184.3214\n",
      "NME: 0.0883\n",
      "Epoch [155/300], Loss: 81.4652\n",
      "Validation Loss: 185.7820\n",
      "NME: 0.0870\n",
      "Epoch [156/300], Loss: 78.7612\n",
      "Validation Loss: 180.2954\n",
      "NME: 0.0927\n",
      "Epoch [157/300], Loss: 83.5600\n",
      "Validation Loss: 179.8531\n",
      "NME: 0.0974\n",
      "Epoch [158/300], Loss: 86.7417\n",
      "Validation Loss: 181.5698\n",
      "NME: 0.0876\n",
      "Epoch [159/300], Loss: 76.5381\n",
      "Validation Loss: 171.5536\n",
      "NME: 0.0906\n",
      "Epoch [160/300], Loss: 73.0301\n",
      "Validation Loss: 173.7612\n",
      "NME: 0.0887\n",
      "Epoch [161/300], Loss: 75.0803\n",
      "Validation Loss: 170.8600\n",
      "NME: 0.0898\n",
      "Epoch [162/300], Loss: 75.1846\n",
      "Validation Loss: 182.7817\n",
      "NME: 0.0889\n",
      "Epoch [163/300], Loss: 66.2031\n",
      "Validation Loss: 174.8457\n",
      "NME: 0.0871\n",
      "Epoch [164/300], Loss: 69.5372\n",
      "Validation Loss: 174.7964\n",
      "NME: 0.0892\n",
      "Epoch [165/300], Loss: 76.9327\n",
      "Validation Loss: 159.9650\n",
      "NME: 0.0877\n",
      "Best model saved at epoch 165 with val_loss 159.9650\n",
      "Epoch [166/300], Loss: 68.7389\n",
      "Validation Loss: 170.4474\n",
      "NME: 0.0889\n",
      "Epoch [167/300], Loss: 67.1601\n",
      "Validation Loss: 172.1520\n",
      "NME: 0.0890\n",
      "Epoch [168/300], Loss: 69.5131\n",
      "Validation Loss: 169.9634\n",
      "NME: 0.0884\n",
      "Epoch [169/300], Loss: 68.1158\n",
      "Validation Loss: 177.8692\n",
      "NME: 0.0900\n",
      "Epoch [170/300], Loss: 70.4188\n",
      "Validation Loss: 172.7240\n",
      "NME: 0.0912\n",
      "Epoch [171/300], Loss: 91.1362\n",
      "Validation Loss: 231.3162\n",
      "NME: 0.0950\n",
      "Epoch [172/300], Loss: 90.9208\n",
      "Validation Loss: 181.6212\n",
      "NME: 0.0947\n",
      "Epoch [173/300], Loss: 87.3047\n",
      "Validation Loss: 193.5981\n",
      "NME: 0.1008\n",
      "Epoch [174/300], Loss: 105.3792\n",
      "Validation Loss: 266.8081\n",
      "NME: 0.1054\n",
      "Epoch [175/300], Loss: 83.2903\n",
      "Validation Loss: 174.7976\n",
      "NME: 0.0929\n",
      "Epoch [176/300], Loss: 72.4125\n",
      "Validation Loss: 169.2926\n",
      "NME: 0.0957\n",
      "Epoch [177/300], Loss: 75.0919\n",
      "Validation Loss: 182.6041\n",
      "NME: 0.0906\n",
      "Epoch [178/300], Loss: 65.5395\n",
      "Validation Loss: 172.5943\n",
      "NME: 0.0888\n",
      "Epoch [179/300], Loss: 68.4521\n",
      "Validation Loss: 183.2145\n",
      "NME: 0.0900\n",
      "Epoch [180/300], Loss: 68.9508\n",
      "Validation Loss: 187.6570\n",
      "NME: 0.0889\n",
      "Epoch [181/300], Loss: 74.6145\n",
      "Validation Loss: 186.0926\n",
      "NME: 0.0896\n",
      "Epoch [182/300], Loss: 64.5231\n",
      "Validation Loss: 180.0420\n",
      "NME: 0.0883\n",
      "Epoch [183/300], Loss: 73.8119\n",
      "Validation Loss: 174.7715\n",
      "NME: 0.0932\n",
      "Epoch [184/300], Loss: 64.2990\n",
      "Validation Loss: 172.2918\n",
      "NME: 0.0880\n",
      "Epoch [185/300], Loss: 63.3224\n",
      "Validation Loss: 175.3400\n",
      "NME: 0.0910\n",
      "Epoch [186/300], Loss: 63.7518\n",
      "Validation Loss: 211.5575\n",
      "NME: 0.0935\n",
      "Epoch [187/300], Loss: 75.0029\n",
      "Validation Loss: 178.8978\n",
      "NME: 0.0908\n",
      "Epoch [188/300], Loss: 64.0196\n",
      "Validation Loss: 178.5587\n",
      "NME: 0.0893\n",
      "Epoch [189/300], Loss: 68.3217\n",
      "Validation Loss: 190.5585\n",
      "NME: 0.0948\n",
      "Epoch [190/300], Loss: 69.8339\n",
      "Validation Loss: 167.6231\n",
      "NME: 0.0875\n",
      "Epoch [191/300], Loss: 64.0284\n",
      "Validation Loss: 184.6949\n",
      "NME: 0.0912\n",
      "Epoch [192/300], Loss: 62.9150\n",
      "Validation Loss: 172.8885\n",
      "NME: 0.0924\n",
      "Epoch [193/300], Loss: 63.5695\n",
      "Validation Loss: 221.9350\n",
      "NME: 0.0907\n",
      "Epoch [194/300], Loss: 66.2962\n",
      "Validation Loss: 175.7057\n",
      "NME: 0.0873\n",
      "Epoch [195/300], Loss: 61.8922\n",
      "Validation Loss: 167.7128\n",
      "NME: 0.0883\n",
      "Epoch [196/300], Loss: 61.2218\n",
      "Validation Loss: 182.2357\n",
      "NME: 0.0915\n",
      "Epoch [197/300], Loss: 61.6072\n",
      "Validation Loss: 165.6686\n",
      "NME: 0.0888\n",
      "Epoch [198/300], Loss: 60.2552\n",
      "Validation Loss: 159.5811\n",
      "NME: 0.0863\n",
      "Best model saved at epoch 198 with val_loss 159.5811\n",
      "Epoch [199/300], Loss: 57.8901\n",
      "Validation Loss: 167.8090\n",
      "NME: 0.0860\n",
      "Epoch [200/300], Loss: 53.8797\n",
      "Validation Loss: 172.6164\n",
      "NME: 0.0862\n",
      "Epoch [201/300], Loss: 56.7235\n",
      "Validation Loss: 167.5308\n",
      "NME: 0.0870\n",
      "Epoch [202/300], Loss: 53.0281\n",
      "Validation Loss: 162.1160\n",
      "NME: 0.0862\n",
      "Epoch [203/300], Loss: 53.5318\n",
      "Validation Loss: 170.6912\n",
      "NME: 0.0862\n",
      "Epoch [204/300], Loss: 56.7137\n",
      "Validation Loss: 155.1644\n",
      "NME: 0.0843\n",
      "Best model saved at epoch 204 with val_loss 155.1644\n",
      "Epoch [205/300], Loss: 52.8615\n",
      "Validation Loss: 164.0745\n",
      "NME: 0.0869\n",
      "Epoch [206/300], Loss: 56.6170\n",
      "Validation Loss: 168.6193\n",
      "NME: 0.0884\n",
      "Epoch [207/300], Loss: 55.8906\n",
      "Validation Loss: 175.3563\n",
      "NME: 0.0852\n",
      "Epoch [208/300], Loss: 54.8842\n",
      "Validation Loss: 184.2097\n",
      "NME: 0.0857\n",
      "Epoch [209/300], Loss: 59.7419\n",
      "Validation Loss: 171.7076\n",
      "NME: 0.0868\n",
      "Epoch [210/300], Loss: 57.5058\n",
      "Validation Loss: 156.2708\n",
      "NME: 0.0862\n",
      "Epoch [211/300], Loss: 55.9143\n",
      "Validation Loss: 167.9105\n",
      "NME: 0.0851\n",
      "Epoch [212/300], Loss: 59.3205\n",
      "Validation Loss: 164.7437\n",
      "NME: 0.0848\n",
      "Epoch [213/300], Loss: 56.1322\n",
      "Validation Loss: 157.3499\n",
      "NME: 0.0864\n",
      "Epoch [214/300], Loss: 53.9252\n",
      "Validation Loss: 176.4708\n",
      "NME: 0.0863\n",
      "Epoch [215/300], Loss: 54.5653\n",
      "Validation Loss: 171.7310\n",
      "NME: 0.0861\n",
      "Epoch [216/300], Loss: 55.3977\n",
      "Validation Loss: 162.9376\n",
      "NME: 0.0862\n",
      "Epoch [217/300], Loss: 55.6456\n",
      "Validation Loss: 152.9032\n",
      "NME: 0.0846\n",
      "Best model saved at epoch 217 with val_loss 152.9032\n",
      "Epoch [218/300], Loss: 55.0717\n",
      "Validation Loss: 167.6414\n",
      "NME: 0.0844\n",
      "Epoch [219/300], Loss: 54.0777\n",
      "Validation Loss: 171.2933\n",
      "NME: 0.0887\n",
      "Epoch [220/300], Loss: 53.8529\n",
      "Validation Loss: 174.7363\n",
      "NME: 0.0870\n",
      "Epoch [221/300], Loss: 54.1787\n",
      "Validation Loss: 172.3983\n",
      "NME: 0.0846\n",
      "Epoch [222/300], Loss: 58.8270\n",
      "Validation Loss: 178.9554\n",
      "NME: 0.0870\n",
      "Epoch [223/300], Loss: 56.1772\n",
      "Validation Loss: 174.3460\n",
      "NME: 0.0869\n",
      "Epoch [224/300], Loss: 56.7488\n",
      "Validation Loss: 173.2163\n",
      "NME: 0.0872\n",
      "Epoch [225/300], Loss: 66.8439\n",
      "Validation Loss: 181.3221\n",
      "NME: 0.0889\n",
      "Epoch [226/300], Loss: 56.7774\n",
      "Validation Loss: 175.2303\n",
      "NME: 0.0858\n",
      "Epoch [227/300], Loss: 56.4082\n",
      "Validation Loss: 173.4734\n",
      "NME: 0.0857\n",
      "Epoch [228/300], Loss: 53.0758\n",
      "Validation Loss: 173.2153\n",
      "NME: 0.0846\n",
      "Epoch [229/300], Loss: 52.9247\n",
      "Validation Loss: 182.9003\n",
      "NME: 0.0890\n",
      "Epoch [230/300], Loss: 53.0644\n",
      "Validation Loss: 157.8534\n",
      "NME: 0.0864\n",
      "Epoch [231/300], Loss: 53.4359\n",
      "Validation Loss: 176.4592\n",
      "NME: 0.0865\n",
      "Epoch [232/300], Loss: 55.9644\n",
      "Validation Loss: 194.6696\n",
      "NME: 0.0867\n",
      "Epoch [233/300], Loss: 54.0010\n",
      "Validation Loss: 176.3237\n",
      "NME: 0.0854\n",
      "Epoch [234/300], Loss: 53.1617\n",
      "Validation Loss: 183.6846\n",
      "NME: 0.0887\n",
      "Epoch [235/300], Loss: 49.9221\n",
      "Validation Loss: 181.2008\n",
      "NME: 0.0854\n",
      "Epoch [236/300], Loss: 52.3712\n",
      "Validation Loss: 202.3343\n",
      "NME: 0.0858\n",
      "Epoch [237/300], Loss: 54.9663\n",
      "Validation Loss: 190.6026\n",
      "NME: 0.0906\n",
      "Epoch [238/300], Loss: 53.0366\n",
      "Validation Loss: 166.2147\n",
      "NME: 0.0863\n",
      "Epoch [239/300], Loss: 51.4847\n",
      "Validation Loss: 183.5841\n",
      "NME: 0.0870\n",
      "Epoch [240/300], Loss: 51.3095\n",
      "Validation Loss: 176.7788\n",
      "NME: 0.0875\n",
      "Epoch [241/300], Loss: 57.0928\n",
      "Validation Loss: 182.0096\n",
      "NME: 0.0862\n",
      "Epoch [242/300], Loss: 55.5973\n",
      "Validation Loss: 164.0470\n",
      "NME: 0.0865\n",
      "Epoch [243/300], Loss: 53.7457\n",
      "Validation Loss: 160.3404\n",
      "NME: 0.0850\n",
      "Epoch [244/300], Loss: 63.9090\n",
      "Validation Loss: 213.5622\n",
      "NME: 0.0962\n",
      "Epoch [245/300], Loss: 71.3246\n",
      "Validation Loss: 225.4113\n",
      "NME: 0.0883\n",
      "Epoch [246/300], Loss: 87.5935\n",
      "Validation Loss: 213.4069\n",
      "NME: 0.0946\n",
      "Epoch [247/300], Loss: 66.7016\n",
      "Validation Loss: 168.8189\n",
      "NME: 0.0902\n",
      "Epoch [248/300], Loss: 61.3684\n",
      "Validation Loss: 183.8106\n",
      "NME: 0.0878\n",
      "Epoch [249/300], Loss: 58.4021\n",
      "Validation Loss: 179.0875\n",
      "NME: 0.0936\n",
      "Epoch [250/300], Loss: 55.1215\n",
      "Validation Loss: 183.2476\n",
      "NME: 0.0918\n",
      "Epoch [251/300], Loss: 52.0110\n",
      "Validation Loss: 178.3728\n",
      "NME: 0.0883\n",
      "Epoch [252/300], Loss: 48.5904\n",
      "Validation Loss: 172.7506\n",
      "NME: 0.0864\n",
      "Epoch [253/300], Loss: 50.1802\n",
      "Validation Loss: 149.3963\n",
      "NME: 0.0854\n",
      "Best model saved at epoch 253 with val_loss 149.3963\n",
      "Epoch [254/300], Loss: 49.0997\n",
      "Validation Loss: 164.2406\n",
      "NME: 0.0834\n",
      "Epoch [255/300], Loss: 47.3936\n",
      "Validation Loss: 162.5902\n",
      "NME: 0.0827\n",
      "Epoch [256/300], Loss: 51.8657\n",
      "Validation Loss: 163.3646\n",
      "NME: 0.0840\n",
      "Epoch [257/300], Loss: 50.4071\n",
      "Validation Loss: 162.7033\n",
      "NME: 0.0853\n",
      "Epoch [258/300], Loss: 45.8534\n",
      "Validation Loss: 159.5128\n",
      "NME: 0.0823\n",
      "Epoch [259/300], Loss: 46.0530\n",
      "Validation Loss: 164.7496\n",
      "NME: 0.0817\n",
      "Epoch [260/300], Loss: 46.0218\n",
      "Validation Loss: 165.0105\n",
      "NME: 0.0834\n",
      "Epoch [261/300], Loss: 47.1257\n",
      "Validation Loss: 157.9136\n",
      "NME: 0.0827\n",
      "Epoch [262/300], Loss: 48.7277\n",
      "Validation Loss: 154.3167\n",
      "NME: 0.0831\n",
      "Epoch [263/300], Loss: 46.8873\n",
      "Validation Loss: 164.4325\n",
      "NME: 0.0834\n",
      "Epoch [264/300], Loss: 44.0666\n",
      "Validation Loss: 165.5073\n",
      "NME: 0.0836\n",
      "Epoch [265/300], Loss: 43.1359\n",
      "Validation Loss: 161.8252\n",
      "NME: 0.0826\n",
      "Epoch [266/300], Loss: 45.6884\n",
      "Validation Loss: 173.3008\n",
      "NME: 0.0834\n",
      "Epoch [267/300], Loss: 45.7906\n",
      "Validation Loss: 163.7691\n",
      "NME: 0.0822\n",
      "Epoch [268/300], Loss: 48.1955\n",
      "Validation Loss: 157.8906\n",
      "NME: 0.0840\n",
      "Epoch [269/300], Loss: 48.5842\n",
      "Validation Loss: 173.6648\n",
      "NME: 0.0836\n",
      "Epoch [270/300], Loss: 45.8565\n",
      "Validation Loss: 153.5669\n",
      "NME: 0.0830\n",
      "Epoch [271/300], Loss: 50.4418\n",
      "Validation Loss: 153.4396\n",
      "NME: 0.0827\n",
      "Epoch [272/300], Loss: 49.3121\n",
      "Validation Loss: 165.9444\n",
      "NME: 0.0864\n",
      "Epoch [273/300], Loss: 48.2867\n",
      "Validation Loss: 155.1607\n",
      "NME: 0.0828\n",
      "Epoch [274/300], Loss: 46.8922\n",
      "Validation Loss: 159.7586\n",
      "NME: 0.0849\n",
      "Epoch [275/300], Loss: 63.2271\n",
      "Validation Loss: 229.0835\n",
      "NME: 0.0965\n",
      "Epoch [276/300], Loss: 75.3326\n",
      "Validation Loss: 198.6402\n",
      "NME: 0.0912\n",
      "Epoch [277/300], Loss: 87.4479\n",
      "Validation Loss: 222.5058\n",
      "NME: 0.0994\n",
      "Epoch [278/300], Loss: 124.2987\n",
      "Validation Loss: 247.9147\n",
      "NME: 0.1018\n",
      "Epoch [279/300], Loss: 63.5117\n",
      "Validation Loss: 186.7834\n",
      "NME: 0.0856\n",
      "Epoch [280/300], Loss: 52.3348\n",
      "Validation Loss: 178.8517\n",
      "NME: 0.0848\n",
      "Epoch [281/300], Loss: 48.7234\n",
      "Validation Loss: 184.9785\n",
      "NME: 0.0854\n",
      "Epoch [282/300], Loss: 46.2943\n",
      "Validation Loss: 171.8378\n",
      "NME: 0.0836\n",
      "Epoch [283/300], Loss: 44.8856\n",
      "Validation Loss: 164.8157\n",
      "NME: 0.0836\n",
      "Epoch [284/300], Loss: 44.7908\n",
      "Validation Loss: 166.9038\n",
      "NME: 0.0840\n",
      "Epoch [285/300], Loss: 44.2096\n",
      "Validation Loss: 166.0012\n",
      "NME: 0.0829\n",
      "Epoch [286/300], Loss: 42.3363\n",
      "Validation Loss: 165.1976\n",
      "NME: 0.0816\n",
      "Epoch [287/300], Loss: 41.5787\n",
      "Validation Loss: 162.5996\n",
      "NME: 0.0827\n",
      "Epoch [288/300], Loss: 46.2261\n",
      "Validation Loss: 174.6913\n",
      "NME: 0.0897\n",
      "Epoch [289/300], Loss: 53.5373\n",
      "Validation Loss: 169.4441\n",
      "NME: 0.0836\n",
      "Epoch [290/300], Loss: 47.7619\n",
      "Validation Loss: 161.5016\n",
      "NME: 0.0851\n",
      "Epoch [291/300], Loss: 45.3890\n",
      "Validation Loss: 165.7259\n",
      "NME: 0.0871\n",
      "Epoch [292/300], Loss: 44.3476\n",
      "Validation Loss: 163.1423\n",
      "NME: 0.0833\n",
      "Epoch [293/300], Loss: 44.0776\n",
      "Validation Loss: 160.7059\n",
      "NME: 0.0826\n",
      "Epoch [294/300], Loss: 44.4239\n",
      "Validation Loss: 169.3938\n",
      "NME: 0.0826\n",
      "Epoch [295/300], Loss: 42.2984\n",
      "Validation Loss: 175.8192\n",
      "NME: 0.0846\n",
      "Epoch [296/300], Loss: 43.0034\n",
      "Validation Loss: 162.1371\n",
      "NME: 0.0832\n",
      "Epoch [297/300], Loss: 45.0316\n",
      "Validation Loss: 180.0848\n",
      "NME: 0.0862\n",
      "Epoch [298/300], Loss: 44.6911\n",
      "Validation Loss: 146.0527\n",
      "NME: 0.0830\n",
      "Best model saved at epoch 298 with val_loss 146.0527\n",
      "Epoch [299/300], Loss: 42.8437\n",
      "Validation Loss: 167.3019\n",
      "NME: 0.0823\n",
      "Epoch [300/300], Loss: 41.3387\n",
      "Validation Loss: 156.3553\n",
      "NME: 0.0827\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los 칤ndices de las regiones seg칰n los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "oreja_izq = [27, 28, 29, 30, 31]\n",
    "\n",
    "# Funci칩n para calcular el punto promedio de una regi칩n\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EarLeftDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_oreja_izq = calcular_centro_region(landmarks, oreja_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_oreja_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el 치ngulo de rotaci칩n\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotaci칩n\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la oreja izquierda\n",
    "        ear_left_points = np.array([landmarks[i] for i in oreja_izq], dtype=np.float32)\n",
    "        ear_left_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotaci칩n\n",
    "        ones = np.ones(shape=(len(ear_left_points), 1))\n",
    "        points_ones = np.hstack([ear_left_points, ones])\n",
    "        ear_left_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la oreja izquierda\n",
    "        centro_x, centro_y = calcular_centro_region(ear_left_points_rotated, range(len(oreja_izq)))\n",
    "\n",
    "        # Definir los l칤mites del recorte de 112x112 p칤xeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_ear = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_ear, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la oreja izquierda al nuevo recorte\n",
    "        ear_left_points_adjusted = [(p[0] - x1, p[1] - y1) for p in ear_left_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        ear_left_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in ear_left_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=ear_left_points_scaled)\n",
    "            image = augmented['image']\n",
    "            ear_left_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(ear_left_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotaci칩n aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicaci칩n de m치scaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validaci칩n\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validaci칩n\n",
    "train_dataset = EarLeftDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EarLeftDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EarLeft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EarLeft, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(oreja_izq) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuraci칩n y entrenamiento\n",
    "model = DenseNet121EarLeft().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la f칩rmula espec칤fica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tama침o (N, M, 2), donde\n",
    "                        N es el n칰mero de im치genes, M el n칰mero de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tama침o que predictions.\n",
    "    :param num_landmarks: N칰mero de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los 칤ndices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para oreja izquierda)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la f칩rmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, ear_left_points, _, _, _ in train_dataloader:\n",
    "            images, ear_left_points = images.cuda(), ear_left_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ear_left_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validaci칩n y c치lculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_ear_left_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_ear_left_points = val_images.cuda(), val_ear_left_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_ear_left_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el c치lculo de NME\n",
    "                    all_labels.append(val_ear_left_points.cpu().numpy().reshape(-1, len(oreja_izq), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(oreja_izq), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(oreja_izq))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EarLeftLandmarks V2.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 15668.7481\n",
      "Validation Loss: 13677.4727\n",
      "NME: 1.1790\n",
      "Best model saved at epoch 1 with val_loss 13677.4727\n",
      "Epoch [2/300], Loss: 8574.2104\n",
      "Validation Loss: 3927.0695\n",
      "NME: 0.5627\n",
      "Best model saved at epoch 2 with val_loss 3927.0695\n",
      "Epoch [3/300], Loss: 2143.7017\n",
      "Validation Loss: 1310.6911\n",
      "NME: 0.2688\n",
      "Best model saved at epoch 3 with val_loss 1310.6911\n",
      "Epoch [4/300], Loss: 1344.7225\n",
      "Validation Loss: 1147.6663\n",
      "NME: 0.2661\n",
      "Best model saved at epoch 4 with val_loss 1147.6663\n",
      "Epoch [5/300], Loss: 1284.9474\n",
      "Validation Loss: 1095.6877\n",
      "NME: 0.2677\n",
      "Best model saved at epoch 5 with val_loss 1095.6877\n",
      "Epoch [6/300], Loss: 1262.4926\n",
      "Validation Loss: 1087.1326\n",
      "NME: 0.2678\n",
      "Best model saved at epoch 6 with val_loss 1087.1326\n",
      "Epoch [7/300], Loss: 1240.9988\n",
      "Validation Loss: 1072.7133\n",
      "NME: 0.2524\n",
      "Best model saved at epoch 7 with val_loss 1072.7133\n",
      "Epoch [8/300], Loss: 1209.9801\n",
      "Validation Loss: 1029.8412\n",
      "NME: 0.2564\n",
      "Best model saved at epoch 8 with val_loss 1029.8412\n",
      "Epoch [9/300], Loss: 1161.9431\n",
      "Validation Loss: 995.7995\n",
      "NME: 0.2493\n",
      "Best model saved at epoch 9 with val_loss 995.7995\n",
      "Epoch [10/300], Loss: 1113.6034\n",
      "Validation Loss: 884.2538\n",
      "NME: 0.2321\n",
      "Best model saved at epoch 10 with val_loss 884.2538\n",
      "Epoch [11/300], Loss: 953.5123\n",
      "Validation Loss: 726.7124\n",
      "NME: 0.2105\n",
      "Best model saved at epoch 11 with val_loss 726.7124\n",
      "Epoch [12/300], Loss: 863.1045\n",
      "Validation Loss: 605.6411\n",
      "NME: 0.1847\n",
      "Best model saved at epoch 12 with val_loss 605.6411\n",
      "Epoch [13/300], Loss: 720.6901\n",
      "Validation Loss: 503.0775\n",
      "NME: 0.1673\n",
      "Best model saved at epoch 13 with val_loss 503.0775\n",
      "Epoch [14/300], Loss: 716.2991\n",
      "Validation Loss: 468.6590\n",
      "NME: 0.1614\n",
      "Best model saved at epoch 14 with val_loss 468.6590\n",
      "Epoch [15/300], Loss: 660.5789\n",
      "Validation Loss: 441.1071\n",
      "NME: 0.1576\n",
      "Best model saved at epoch 15 with val_loss 441.1071\n",
      "Epoch [16/300], Loss: 582.2113\n",
      "Validation Loss: 419.9751\n",
      "NME: 0.1558\n",
      "Best model saved at epoch 16 with val_loss 419.9751\n",
      "Epoch [17/300], Loss: 604.2088\n",
      "Validation Loss: 458.5643\n",
      "NME: 0.1577\n",
      "Epoch [18/300], Loss: 597.4311\n",
      "Validation Loss: 459.7079\n",
      "NME: 0.1615\n",
      "Epoch [19/300], Loss: 591.5438\n",
      "Validation Loss: 435.3552\n",
      "NME: 0.1602\n",
      "Epoch [20/300], Loss: 606.1437\n",
      "Validation Loss: 440.0042\n",
      "NME: 0.1547\n",
      "Epoch [21/300], Loss: 570.1333\n",
      "Validation Loss: 401.2519\n",
      "NME: 0.1485\n",
      "Best model saved at epoch 21 with val_loss 401.2519\n",
      "Epoch [22/300], Loss: 539.1977\n",
      "Validation Loss: 395.1547\n",
      "NME: 0.1500\n",
      "Best model saved at epoch 22 with val_loss 395.1547\n",
      "Epoch [23/300], Loss: 553.8006\n",
      "Validation Loss: 409.7419\n",
      "NME: 0.1509\n",
      "Epoch [24/300], Loss: 573.9247\n",
      "Validation Loss: 389.8211\n",
      "NME: 0.1515\n",
      "Best model saved at epoch 24 with val_loss 389.8211\n",
      "Epoch [25/300], Loss: 557.4619\n",
      "Validation Loss: 399.9305\n",
      "NME: 0.1522\n",
      "Epoch [26/300], Loss: 535.5864\n",
      "Validation Loss: 389.8233\n",
      "NME: 0.1488\n",
      "Epoch [27/300], Loss: 538.6186\n",
      "Validation Loss: 420.9844\n",
      "NME: 0.1582\n",
      "Epoch [28/300], Loss: 569.5611\n",
      "Validation Loss: 416.3041\n",
      "NME: 0.1519\n",
      "Epoch [29/300], Loss: 511.0963\n",
      "Validation Loss: 410.6412\n",
      "NME: 0.1520\n",
      "Epoch [30/300], Loss: 498.7622\n",
      "Validation Loss: 389.4154\n",
      "NME: 0.1448\n",
      "Best model saved at epoch 30 with val_loss 389.4154\n",
      "Epoch [31/300], Loss: 516.5835\n",
      "Validation Loss: 390.6284\n",
      "NME: 0.1461\n",
      "Epoch [32/300], Loss: 513.7106\n",
      "Validation Loss: 392.0194\n",
      "NME: 0.1451\n",
      "Epoch [33/300], Loss: 533.6901\n",
      "Validation Loss: 400.8973\n",
      "NME: 0.1453\n",
      "Epoch [34/300], Loss: 554.1774\n",
      "Validation Loss: 380.3450\n",
      "NME: 0.1458\n",
      "Best model saved at epoch 34 with val_loss 380.3450\n",
      "Epoch [35/300], Loss: 512.4026\n",
      "Validation Loss: 369.0848\n",
      "NME: 0.1419\n",
      "Best model saved at epoch 35 with val_loss 369.0848\n",
      "Epoch [36/300], Loss: 455.4549\n",
      "Validation Loss: 357.4372\n",
      "NME: 0.1412\n",
      "Best model saved at epoch 36 with val_loss 357.4372\n",
      "Epoch [37/300], Loss: 468.0648\n",
      "Validation Loss: 446.8223\n",
      "NME: 0.1586\n",
      "Epoch [38/300], Loss: 452.6806\n",
      "Validation Loss: 374.1418\n",
      "NME: 0.1429\n",
      "Epoch [39/300], Loss: 398.7024\n",
      "Validation Loss: 350.3268\n",
      "NME: 0.1381\n",
      "Best model saved at epoch 39 with val_loss 350.3268\n",
      "Epoch [40/300], Loss: 348.9453\n",
      "Validation Loss: 342.3996\n",
      "NME: 0.1376\n",
      "Best model saved at epoch 40 with val_loss 342.3996\n",
      "Epoch [41/300], Loss: 354.6317\n",
      "Validation Loss: 349.1471\n",
      "NME: 0.1383\n",
      "Epoch [42/300], Loss: 328.6601\n",
      "Validation Loss: 345.3934\n",
      "NME: 0.1410\n",
      "Epoch [43/300], Loss: 314.2635\n",
      "Validation Loss: 320.4469\n",
      "NME: 0.1361\n",
      "Best model saved at epoch 43 with val_loss 320.4469\n",
      "Epoch [44/300], Loss: 322.2403\n",
      "Validation Loss: 369.2072\n",
      "NME: 0.1392\n",
      "Epoch [45/300], Loss: 297.9515\n",
      "Validation Loss: 326.8827\n",
      "NME: 0.1343\n",
      "Epoch [46/300], Loss: 296.4680\n",
      "Validation Loss: 331.3815\n",
      "NME: 0.1374\n",
      "Epoch [47/300], Loss: 295.2227\n",
      "Validation Loss: 318.2098\n",
      "NME: 0.1354\n",
      "Best model saved at epoch 47 with val_loss 318.2098\n",
      "Epoch [48/300], Loss: 290.3209\n",
      "Validation Loss: 333.4354\n",
      "NME: 0.1365\n",
      "Epoch [49/300], Loss: 295.1589\n",
      "Validation Loss: 346.1400\n",
      "NME: 0.1364\n",
      "Epoch [50/300], Loss: 287.4659\n",
      "Validation Loss: 346.3145\n",
      "NME: 0.1419\n",
      "Epoch [51/300], Loss: 265.2516\n",
      "Validation Loss: 323.7950\n",
      "NME: 0.1339\n",
      "Epoch [52/300], Loss: 252.8916\n",
      "Validation Loss: 320.3372\n",
      "NME: 0.1351\n",
      "Epoch [53/300], Loss: 254.8162\n",
      "Validation Loss: 328.3708\n",
      "NME: 0.1344\n",
      "Epoch [54/300], Loss: 268.3629\n",
      "Validation Loss: 365.1701\n",
      "NME: 0.1440\n",
      "Epoch [55/300], Loss: 255.0660\n",
      "Validation Loss: 315.6325\n",
      "NME: 0.1327\n",
      "Best model saved at epoch 55 with val_loss 315.6325\n",
      "Epoch [56/300], Loss: 254.4337\n",
      "Validation Loss: 315.0849\n",
      "NME: 0.1343\n",
      "Best model saved at epoch 56 with val_loss 315.0849\n",
      "Epoch [57/300], Loss: 256.2544\n",
      "Validation Loss: 331.0995\n",
      "NME: 0.1363\n",
      "Epoch [58/300], Loss: 240.9039\n",
      "Validation Loss: 304.3513\n",
      "NME: 0.1311\n",
      "Best model saved at epoch 58 with val_loss 304.3513\n",
      "Epoch [59/300], Loss: 257.8937\n",
      "Validation Loss: 329.6894\n",
      "NME: 0.1330\n",
      "Epoch [60/300], Loss: 240.5820\n",
      "Validation Loss: 307.3231\n",
      "NME: 0.1362\n",
      "Epoch [61/300], Loss: 244.1515\n",
      "Validation Loss: 322.2229\n",
      "NME: 0.1322\n",
      "Epoch [62/300], Loss: 235.1141\n",
      "Validation Loss: 310.1688\n",
      "NME: 0.1300\n",
      "Epoch [63/300], Loss: 252.8073\n",
      "Validation Loss: 321.8962\n",
      "NME: 0.1304\n",
      "Epoch [64/300], Loss: 240.1650\n",
      "Validation Loss: 313.6332\n",
      "NME: 0.1303\n",
      "Epoch [65/300], Loss: 242.2790\n",
      "Validation Loss: 304.1217\n",
      "NME: 0.1288\n",
      "Best model saved at epoch 65 with val_loss 304.1217\n",
      "Epoch [66/300], Loss: 243.4816\n",
      "Validation Loss: 332.2730\n",
      "NME: 0.1301\n",
      "Epoch [67/300], Loss: 255.1272\n",
      "Validation Loss: 300.2020\n",
      "NME: 0.1341\n",
      "Best model saved at epoch 67 with val_loss 300.2020\n",
      "Epoch [68/300], Loss: 235.5342\n",
      "Validation Loss: 323.0347\n",
      "NME: 0.1318\n",
      "Epoch [69/300], Loss: 252.3189\n",
      "Validation Loss: 308.6577\n",
      "NME: 0.1303\n",
      "Epoch [70/300], Loss: 227.2822\n",
      "Validation Loss: 311.2978\n",
      "NME: 0.1273\n",
      "Epoch [71/300], Loss: 222.9614\n",
      "Validation Loss: 311.0180\n",
      "NME: 0.1274\n",
      "Epoch [72/300], Loss: 214.4956\n",
      "Validation Loss: 306.6534\n",
      "NME: 0.1253\n",
      "Epoch [73/300], Loss: 212.6680\n",
      "Validation Loss: 289.3206\n",
      "NME: 0.1236\n",
      "Best model saved at epoch 73 with val_loss 289.3206\n",
      "Epoch [74/300], Loss: 212.4594\n",
      "Validation Loss: 294.0641\n",
      "NME: 0.1230\n",
      "Epoch [75/300], Loss: 211.1353\n",
      "Validation Loss: 302.4138\n",
      "NME: 0.1215\n",
      "Epoch [76/300], Loss: 218.4004\n",
      "Validation Loss: 298.0691\n",
      "NME: 0.1219\n",
      "Epoch [77/300], Loss: 202.9682\n",
      "Validation Loss: 294.9720\n",
      "NME: 0.1190\n",
      "Epoch [78/300], Loss: 198.5772\n",
      "Validation Loss: 284.8763\n",
      "NME: 0.1175\n",
      "Best model saved at epoch 78 with val_loss 284.8763\n",
      "Epoch [79/300], Loss: 196.7659\n",
      "Validation Loss: 288.7018\n",
      "NME: 0.1182\n",
      "Epoch [80/300], Loss: 206.6002\n",
      "Validation Loss: 304.9919\n",
      "NME: 0.1203\n",
      "Epoch [81/300], Loss: 201.3018\n",
      "Validation Loss: 298.3464\n",
      "NME: 0.1222\n",
      "Epoch [82/300], Loss: 197.9074\n",
      "Validation Loss: 288.4066\n",
      "NME: 0.1156\n",
      "Epoch [83/300], Loss: 188.1775\n",
      "Validation Loss: 279.5536\n",
      "NME: 0.1175\n",
      "Best model saved at epoch 83 with val_loss 279.5536\n",
      "Epoch [84/300], Loss: 192.6898\n",
      "Validation Loss: 295.1060\n",
      "NME: 0.1141\n",
      "Epoch [85/300], Loss: 194.7340\n",
      "Validation Loss: 262.9546\n",
      "NME: 0.1129\n",
      "Best model saved at epoch 85 with val_loss 262.9546\n",
      "Epoch [86/300], Loss: 200.3433\n",
      "Validation Loss: 303.4118\n",
      "NME: 0.1192\n",
      "Epoch [87/300], Loss: 179.5162\n",
      "Validation Loss: 255.7292\n",
      "NME: 0.1148\n",
      "Best model saved at epoch 87 with val_loss 255.7292\n",
      "Epoch [88/300], Loss: 171.5088\n",
      "Validation Loss: 261.7624\n",
      "NME: 0.1114\n",
      "Epoch [89/300], Loss: 173.3962\n",
      "Validation Loss: 270.2269\n",
      "NME: 0.1107\n",
      "Epoch [90/300], Loss: 176.1438\n",
      "Validation Loss: 265.7633\n",
      "NME: 0.1107\n",
      "Epoch [91/300], Loss: 180.5873\n",
      "Validation Loss: 286.6967\n",
      "NME: 0.1149\n",
      "Epoch [92/300], Loss: 180.7768\n",
      "Validation Loss: 277.4196\n",
      "NME: 0.1070\n",
      "Epoch [93/300], Loss: 171.5496\n",
      "Validation Loss: 250.8238\n",
      "NME: 0.1081\n",
      "Best model saved at epoch 93 with val_loss 250.8238\n",
      "Epoch [94/300], Loss: 157.3334\n",
      "Validation Loss: 239.4844\n",
      "NME: 0.1036\n",
      "Best model saved at epoch 94 with val_loss 239.4844\n",
      "Epoch [95/300], Loss: 156.2211\n",
      "Validation Loss: 246.2264\n",
      "NME: 0.1051\n",
      "Epoch [96/300], Loss: 164.3177\n",
      "Validation Loss: 252.9171\n",
      "NME: 0.1041\n",
      "Epoch [97/300], Loss: 150.3652\n",
      "Validation Loss: 239.9310\n",
      "NME: 0.1009\n",
      "Epoch [98/300], Loss: 149.2483\n",
      "Validation Loss: 235.3212\n",
      "NME: 0.1002\n",
      "Best model saved at epoch 98 with val_loss 235.3212\n",
      "Epoch [99/300], Loss: 143.9253\n",
      "Validation Loss: 234.7624\n",
      "NME: 0.0992\n",
      "Best model saved at epoch 99 with val_loss 234.7624\n",
      "Epoch [100/300], Loss: 138.8009\n",
      "Validation Loss: 244.1706\n",
      "NME: 0.1005\n",
      "Epoch [101/300], Loss: 135.2129\n",
      "Validation Loss: 227.9319\n",
      "NME: 0.0944\n",
      "Best model saved at epoch 101 with val_loss 227.9319\n",
      "Epoch [102/300], Loss: 131.3318\n",
      "Validation Loss: 217.5142\n",
      "NME: 0.0940\n",
      "Best model saved at epoch 102 with val_loss 217.5142\n",
      "Epoch [103/300], Loss: 132.7245\n",
      "Validation Loss: 216.9092\n",
      "NME: 0.0947\n",
      "Best model saved at epoch 103 with val_loss 216.9092\n",
      "Epoch [104/300], Loss: 121.2852\n",
      "Validation Loss: 231.5691\n",
      "NME: 0.0933\n",
      "Epoch [105/300], Loss: 124.0668\n",
      "Validation Loss: 212.2322\n",
      "NME: 0.0925\n",
      "Best model saved at epoch 105 with val_loss 212.2322\n",
      "Epoch [106/300], Loss: 126.6083\n",
      "Validation Loss: 210.8753\n",
      "NME: 0.0939\n",
      "Best model saved at epoch 106 with val_loss 210.8753\n",
      "Epoch [107/300], Loss: 126.9912\n",
      "Validation Loss: 220.1039\n",
      "NME: 0.0953\n",
      "Epoch [108/300], Loss: 132.9058\n",
      "Validation Loss: 251.5015\n",
      "NME: 0.0998\n",
      "Epoch [109/300], Loss: 132.4106\n",
      "Validation Loss: 238.1692\n",
      "NME: 0.0963\n",
      "Epoch [110/300], Loss: 132.8484\n",
      "Validation Loss: 219.7267\n",
      "NME: 0.0967\n",
      "Epoch [111/300], Loss: 113.5268\n",
      "Validation Loss: 203.3220\n",
      "NME: 0.0936\n",
      "Best model saved at epoch 111 with val_loss 203.3220\n",
      "Epoch [112/300], Loss: 124.9363\n",
      "Validation Loss: 233.5211\n",
      "NME: 0.1011\n",
      "Epoch [113/300], Loss: 136.9769\n",
      "Validation Loss: 204.9967\n",
      "NME: 0.0963\n",
      "Epoch [114/300], Loss: 148.7671\n",
      "Validation Loss: 258.6099\n",
      "NME: 0.1078\n",
      "Epoch [115/300], Loss: 129.6408\n",
      "Validation Loss: 214.2636\n",
      "NME: 0.0941\n",
      "Epoch [116/300], Loss: 123.7354\n",
      "Validation Loss: 201.0031\n",
      "NME: 0.0938\n",
      "Best model saved at epoch 116 with val_loss 201.0031\n",
      "Epoch [117/300], Loss: 114.3604\n",
      "Validation Loss: 203.2841\n",
      "NME: 0.0910\n",
      "Epoch [118/300], Loss: 109.3144\n",
      "Validation Loss: 201.3013\n",
      "NME: 0.0924\n",
      "Epoch [119/300], Loss: 108.3950\n",
      "Validation Loss: 197.9064\n",
      "NME: 0.0920\n",
      "Best model saved at epoch 119 with val_loss 197.9064\n",
      "Epoch [120/300], Loss: 109.2835\n",
      "Validation Loss: 215.0617\n",
      "NME: 0.0922\n",
      "Epoch [121/300], Loss: 106.4004\n",
      "Validation Loss: 213.9312\n",
      "NME: 0.0939\n",
      "Epoch [122/300], Loss: 112.9083\n",
      "Validation Loss: 208.0324\n",
      "NME: 0.0919\n",
      "Epoch [123/300], Loss: 104.7625\n",
      "Validation Loss: 207.9848\n",
      "NME: 0.0911\n",
      "Epoch [124/300], Loss: 98.1443\n",
      "Validation Loss: 205.2165\n",
      "NME: 0.0916\n",
      "Epoch [125/300], Loss: 107.9401\n",
      "Validation Loss: 219.5995\n",
      "NME: 0.0958\n",
      "Epoch [126/300], Loss: 108.4608\n",
      "Validation Loss: 211.0508\n",
      "NME: 0.0938\n",
      "Epoch [127/300], Loss: 102.2500\n",
      "Validation Loss: 217.0256\n",
      "NME: 0.0935\n",
      "Epoch [128/300], Loss: 104.5319\n",
      "Validation Loss: 201.4929\n",
      "NME: 0.0918\n",
      "Epoch [129/300], Loss: 101.4444\n",
      "Validation Loss: 194.5656\n",
      "NME: 0.0914\n",
      "Best model saved at epoch 129 with val_loss 194.5656\n",
      "Epoch [130/300], Loss: 102.2490\n",
      "Validation Loss: 197.5838\n",
      "NME: 0.0926\n",
      "Epoch [131/300], Loss: 108.5176\n",
      "Validation Loss: 216.8969\n",
      "NME: 0.0940\n",
      "Epoch [132/300], Loss: 101.6644\n",
      "Validation Loss: 208.2921\n",
      "NME: 0.0910\n",
      "Epoch [133/300], Loss: 94.7030\n",
      "Validation Loss: 209.8014\n",
      "NME: 0.0923\n",
      "Epoch [134/300], Loss: 93.9320\n",
      "Validation Loss: 200.0077\n",
      "NME: 0.0908\n",
      "Epoch [135/300], Loss: 97.0429\n",
      "Validation Loss: 202.5067\n",
      "NME: 0.0934\n",
      "Epoch [136/300], Loss: 105.4785\n",
      "Validation Loss: 201.5313\n",
      "NME: 0.0932\n",
      "Epoch [137/300], Loss: 98.9715\n",
      "Validation Loss: 202.8547\n",
      "NME: 0.0914\n",
      "Epoch [138/300], Loss: 99.2108\n",
      "Validation Loss: 212.6074\n",
      "NME: 0.0929\n",
      "Epoch [139/300], Loss: 100.1539\n",
      "Validation Loss: 207.7711\n",
      "NME: 0.0940\n",
      "Epoch [140/300], Loss: 95.9749\n",
      "Validation Loss: 217.3856\n",
      "NME: 0.0972\n",
      "Epoch [141/300], Loss: 96.1943\n",
      "Validation Loss: 204.7257\n",
      "NME: 0.0923\n",
      "Epoch [142/300], Loss: 93.8403\n",
      "Validation Loss: 205.7096\n",
      "NME: 0.0898\n",
      "Epoch [143/300], Loss: 97.2251\n",
      "Validation Loss: 206.5414\n",
      "NME: 0.0907\n",
      "Epoch [144/300], Loss: 91.1612\n",
      "Validation Loss: 199.8520\n",
      "NME: 0.0904\n",
      "Epoch [145/300], Loss: 91.7859\n",
      "Validation Loss: 189.7595\n",
      "NME: 0.0893\n",
      "Best model saved at epoch 145 with val_loss 189.7595\n",
      "Epoch [146/300], Loss: 96.7196\n",
      "Validation Loss: 203.8082\n",
      "NME: 0.0911\n",
      "Epoch [147/300], Loss: 96.5648\n",
      "Validation Loss: 195.6648\n",
      "NME: 0.0927\n",
      "Epoch [148/300], Loss: 89.8101\n",
      "Validation Loss: 216.0297\n",
      "NME: 0.0906\n",
      "Epoch [149/300], Loss: 88.3180\n",
      "Validation Loss: 204.9662\n",
      "NME: 0.0897\n",
      "Epoch [150/300], Loss: 88.6365\n",
      "Validation Loss: 196.5416\n",
      "NME: 0.0899\n",
      "Epoch [151/300], Loss: 93.1960\n",
      "Validation Loss: 218.3205\n",
      "NME: 0.0948\n",
      "Epoch [152/300], Loss: 98.2261\n",
      "Validation Loss: 204.9916\n",
      "NME: 0.0911\n",
      "Epoch [153/300], Loss: 87.8750\n",
      "Validation Loss: 208.7101\n",
      "NME: 0.0882\n",
      "Epoch [154/300], Loss: 80.4375\n",
      "Validation Loss: 211.8688\n",
      "NME: 0.0889\n",
      "Epoch [155/300], Loss: 81.1611\n",
      "Validation Loss: 227.9976\n",
      "NME: 0.0994\n",
      "Epoch [156/300], Loss: 88.7937\n",
      "Validation Loss: 204.4061\n",
      "NME: 0.0870\n",
      "Epoch [157/300], Loss: 76.9697\n",
      "Validation Loss: 195.9358\n",
      "NME: 0.0876\n",
      "Epoch [158/300], Loss: 77.3184\n",
      "Validation Loss: 188.4515\n",
      "NME: 0.0883\n",
      "Best model saved at epoch 158 with val_loss 188.4515\n",
      "Epoch [159/300], Loss: 72.4445\n",
      "Validation Loss: 199.2019\n",
      "NME: 0.0863\n",
      "Epoch [160/300], Loss: 69.1533\n",
      "Validation Loss: 189.9190\n",
      "NME: 0.0861\n",
      "Epoch [161/300], Loss: 70.7444\n",
      "Validation Loss: 203.3788\n",
      "NME: 0.0870\n",
      "Epoch [162/300], Loss: 71.1598\n",
      "Validation Loss: 186.9782\n",
      "NME: 0.0854\n",
      "Best model saved at epoch 162 with val_loss 186.9782\n",
      "Epoch [163/300], Loss: 69.7038\n",
      "Validation Loss: 189.9760\n",
      "NME: 0.0856\n",
      "Epoch [164/300], Loss: 71.8538\n",
      "Validation Loss: 204.8937\n",
      "NME: 0.0853\n",
      "Epoch [165/300], Loss: 72.5889\n",
      "Validation Loss: 202.2234\n",
      "NME: 0.0887\n",
      "Epoch [166/300], Loss: 73.0859\n",
      "Validation Loss: 189.2105\n",
      "NME: 0.0889\n",
      "Epoch [167/300], Loss: 71.6459\n",
      "Validation Loss: 187.3130\n",
      "NME: 0.0877\n",
      "Epoch [168/300], Loss: 71.9478\n",
      "Validation Loss: 196.3335\n",
      "NME: 0.0874\n",
      "Epoch [169/300], Loss: 75.6906\n",
      "Validation Loss: 218.1511\n",
      "NME: 0.0880\n",
      "Epoch [170/300], Loss: 71.3057\n",
      "Validation Loss: 192.7407\n",
      "NME: 0.0865\n",
      "Epoch [171/300], Loss: 69.5701\n",
      "Validation Loss: 209.5264\n",
      "NME: 0.0898\n",
      "Epoch [172/300], Loss: 75.8303\n",
      "Validation Loss: 189.6142\n",
      "NME: 0.0893\n",
      "Epoch [173/300], Loss: 74.9654\n",
      "Validation Loss: 185.7741\n",
      "NME: 0.0857\n",
      "Best model saved at epoch 173 with val_loss 185.7741\n",
      "Epoch [174/300], Loss: 68.0599\n",
      "Validation Loss: 198.5223\n",
      "NME: 0.0875\n",
      "Epoch [175/300], Loss: 65.7341\n",
      "Validation Loss: 203.2317\n",
      "NME: 0.0889\n",
      "Epoch [176/300], Loss: 73.0369\n",
      "Validation Loss: 196.0817\n",
      "NME: 0.0861\n",
      "Epoch [177/300], Loss: 70.1305\n",
      "Validation Loss: 206.0052\n",
      "NME: 0.0893\n",
      "Epoch [178/300], Loss: 63.7557\n",
      "Validation Loss: 194.8401\n",
      "NME: 0.0849\n",
      "Epoch [179/300], Loss: 60.9270\n",
      "Validation Loss: 205.4854\n",
      "NME: 0.0872\n",
      "Epoch [180/300], Loss: 58.5739\n",
      "Validation Loss: 203.3157\n",
      "NME: 0.0876\n",
      "Epoch [181/300], Loss: 64.9121\n",
      "Validation Loss: 194.8724\n",
      "NME: 0.0853\n",
      "Epoch [182/300], Loss: 64.3742\n",
      "Validation Loss: 193.0528\n",
      "NME: 0.0862\n",
      "Epoch [183/300], Loss: 67.4486\n",
      "Validation Loss: 212.5301\n",
      "NME: 0.0937\n",
      "Epoch [184/300], Loss: 68.3410\n",
      "Validation Loss: 185.6400\n",
      "NME: 0.0856\n",
      "Best model saved at epoch 184 with val_loss 185.6400\n",
      "Epoch [185/300], Loss: 60.2380\n",
      "Validation Loss: 188.8348\n",
      "NME: 0.0837\n",
      "Epoch [186/300], Loss: 60.0568\n",
      "Validation Loss: 186.4565\n",
      "NME: 0.0842\n",
      "Epoch [187/300], Loss: 61.0189\n",
      "Validation Loss: 191.8584\n",
      "NME: 0.0888\n",
      "Epoch [188/300], Loss: 61.9473\n",
      "Validation Loss: 188.5627\n",
      "NME: 0.0852\n",
      "Epoch [189/300], Loss: 60.0686\n",
      "Validation Loss: 200.1579\n",
      "NME: 0.0863\n",
      "Epoch [190/300], Loss: 64.2430\n",
      "Validation Loss: 196.7455\n",
      "NME: 0.0853\n",
      "Epoch [191/300], Loss: 64.9899\n",
      "Validation Loss: 204.5955\n",
      "NME: 0.0861\n",
      "Epoch [192/300], Loss: 65.4253\n",
      "Validation Loss: 213.3853\n",
      "NME: 0.0858\n",
      "Epoch [193/300], Loss: 62.5881\n",
      "Validation Loss: 199.1238\n",
      "NME: 0.0852\n",
      "Epoch [194/300], Loss: 58.5724\n",
      "Validation Loss: 198.9657\n",
      "NME: 0.0856\n",
      "Epoch [195/300], Loss: 57.8688\n",
      "Validation Loss: 200.1270\n",
      "NME: 0.0876\n",
      "Epoch [196/300], Loss: 60.8083\n",
      "Validation Loss: 179.7319\n",
      "NME: 0.0854\n",
      "Best model saved at epoch 196 with val_loss 179.7319\n",
      "Epoch [197/300], Loss: 57.7504\n",
      "Validation Loss: 190.5699\n",
      "NME: 0.0850\n",
      "Epoch [198/300], Loss: 59.7033\n",
      "Validation Loss: 185.4185\n",
      "NME: 0.0848\n",
      "Epoch [199/300], Loss: 55.7466\n",
      "Validation Loss: 192.5772\n",
      "NME: 0.0853\n",
      "Epoch [200/300], Loss: 56.0586\n",
      "Validation Loss: 190.8892\n",
      "NME: 0.0858\n",
      "Epoch [201/300], Loss: 59.9824\n",
      "Validation Loss: 206.1454\n",
      "NME: 0.0888\n",
      "Epoch [202/300], Loss: 63.4920\n",
      "Validation Loss: 200.8259\n",
      "NME: 0.0888\n",
      "Epoch [203/300], Loss: 100.9097\n",
      "Validation Loss: 272.6959\n",
      "NME: 0.1112\n",
      "Epoch [204/300], Loss: 87.9198\n",
      "Validation Loss: 200.0870\n",
      "NME: 0.0909\n",
      "Epoch [205/300], Loss: 61.0407\n",
      "Validation Loss: 190.7087\n",
      "NME: 0.0853\n",
      "Epoch [206/300], Loss: 58.3016\n",
      "Validation Loss: 191.5388\n",
      "NME: 0.0856\n",
      "Epoch [207/300], Loss: 58.3044\n",
      "Validation Loss: 189.0513\n",
      "NME: 0.0862\n",
      "Epoch [208/300], Loss: 55.9257\n",
      "Validation Loss: 193.7922\n",
      "NME: 0.0852\n",
      "Epoch [209/300], Loss: 52.5120\n",
      "Validation Loss: 192.4968\n",
      "NME: 0.0856\n",
      "Epoch [210/300], Loss: 54.0574\n",
      "Validation Loss: 191.6489\n",
      "NME: 0.0885\n",
      "Epoch [211/300], Loss: 54.3470\n",
      "Validation Loss: 211.1011\n",
      "NME: 0.0851\n",
      "Epoch [212/300], Loss: 63.0822\n",
      "Validation Loss: 203.1418\n",
      "NME: 0.0929\n",
      "Epoch [213/300], Loss: 71.8860\n",
      "Validation Loss: 297.9589\n",
      "NME: 0.1024\n",
      "Epoch [214/300], Loss: 80.5531\n",
      "Validation Loss: 214.3694\n",
      "NME: 0.0912\n",
      "Epoch [215/300], Loss: 59.7620\n",
      "Validation Loss: 204.2454\n",
      "NME: 0.0854\n",
      "Epoch [216/300], Loss: 56.0541\n",
      "Validation Loss: 198.1727\n",
      "NME: 0.0858\n",
      "Epoch [217/300], Loss: 59.2022\n",
      "Validation Loss: 205.0448\n",
      "NME: 0.0892\n",
      "Epoch [218/300], Loss: 57.1670\n",
      "Validation Loss: 197.5944\n",
      "NME: 0.0868\n",
      "Epoch [219/300], Loss: 53.6264\n",
      "Validation Loss: 194.1134\n",
      "NME: 0.0850\n",
      "Epoch [220/300], Loss: 53.3744\n",
      "Validation Loss: 195.1541\n",
      "NME: 0.0855\n",
      "Epoch [221/300], Loss: 50.9433\n",
      "Validation Loss: 201.1793\n",
      "NME: 0.0863\n",
      "Epoch [222/300], Loss: 53.1326\n",
      "Validation Loss: 192.0826\n",
      "NME: 0.0844\n",
      "Epoch [223/300], Loss: 50.3017\n",
      "Validation Loss: 191.8093\n",
      "NME: 0.0848\n",
      "Epoch [224/300], Loss: 51.7815\n",
      "Validation Loss: 195.6130\n",
      "NME: 0.0855\n",
      "Epoch [225/300], Loss: 53.4666\n",
      "Validation Loss: 196.4869\n",
      "NME: 0.0853\n",
      "Epoch [226/300], Loss: 49.5232\n",
      "Validation Loss: 194.6611\n",
      "NME: 0.0840\n",
      "Epoch [227/300], Loss: 50.9799\n",
      "Validation Loss: 191.3764\n",
      "NME: 0.0861\n",
      "Epoch [228/300], Loss: 51.2257\n",
      "Validation Loss: 194.3561\n",
      "NME: 0.0844\n",
      "Epoch [229/300], Loss: 51.1024\n",
      "Validation Loss: 192.2514\n",
      "NME: 0.0862\n",
      "Epoch [230/300], Loss: 50.9866\n",
      "Validation Loss: 190.7462\n",
      "NME: 0.0843\n",
      "Epoch [231/300], Loss: 52.8132\n",
      "Validation Loss: 191.8609\n",
      "NME: 0.0861\n",
      "Epoch [232/300], Loss: 52.2871\n",
      "Validation Loss: 202.1569\n",
      "NME: 0.0846\n",
      "Epoch [233/300], Loss: 52.8170\n",
      "Validation Loss: 199.0099\n",
      "NME: 0.0869\n",
      "Epoch [234/300], Loss: 52.7423\n",
      "Validation Loss: 194.0496\n",
      "NME: 0.0860\n",
      "Epoch [235/300], Loss: 50.3583\n",
      "Validation Loss: 191.7373\n",
      "NME: 0.0847\n",
      "Epoch [236/300], Loss: 53.4817\n",
      "Validation Loss: 192.0536\n",
      "NME: 0.0833\n",
      "Epoch [237/300], Loss: 49.9377\n",
      "Validation Loss: 198.8401\n",
      "NME: 0.0862\n",
      "Epoch [238/300], Loss: 51.3378\n",
      "Validation Loss: 194.8182\n",
      "NME: 0.0846\n",
      "Epoch [239/300], Loss: 51.2691\n",
      "Validation Loss: 200.6744\n",
      "NME: 0.0868\n",
      "Epoch [240/300], Loss: 53.4537\n",
      "Validation Loss: 198.1947\n",
      "NME: 0.0848\n",
      "Epoch [241/300], Loss: 52.0602\n",
      "Validation Loss: 209.7820\n",
      "NME: 0.0850\n",
      "Epoch [242/300], Loss: 56.3961\n",
      "Validation Loss: 208.4815\n",
      "NME: 0.0869\n",
      "Epoch [243/300], Loss: 57.3691\n",
      "Validation Loss: 210.6608\n",
      "NME: 0.0870\n",
      "Epoch [244/300], Loss: 65.3244\n",
      "Validation Loss: 219.2330\n",
      "NME: 0.0902\n",
      "Epoch [245/300], Loss: 56.5750\n",
      "Validation Loss: 204.8967\n",
      "NME: 0.0861\n",
      "Epoch [246/300], Loss: 59.4878\n",
      "Validation Loss: 197.0039\n",
      "NME: 0.0863\n",
      "Epoch [247/300], Loss: 53.7257\n",
      "Validation Loss: 193.5851\n",
      "NME: 0.0839\n",
      "Epoch [248/300], Loss: 52.5690\n",
      "Validation Loss: 206.2871\n",
      "NME: 0.0848\n",
      "Epoch [249/300], Loss: 54.1274\n",
      "Validation Loss: 207.2949\n",
      "NME: 0.0846\n",
      "Epoch [250/300], Loss: 53.0470\n",
      "Validation Loss: 200.1086\n",
      "NME: 0.0840\n",
      "Epoch [251/300], Loss: 56.8653\n",
      "Validation Loss: 197.0123\n",
      "NME: 0.0881\n",
      "Epoch [252/300], Loss: 49.3088\n",
      "Validation Loss: 197.1757\n",
      "NME: 0.0832\n",
      "Epoch [253/300], Loss: 54.7354\n",
      "Validation Loss: 210.6184\n",
      "NME: 0.0853\n",
      "Epoch [254/300], Loss: 53.0749\n",
      "Validation Loss: 192.4366\n",
      "NME: 0.0869\n",
      "Epoch [255/300], Loss: 53.9933\n",
      "Validation Loss: 198.8025\n",
      "NME: 0.0846\n",
      "Epoch [256/300], Loss: 47.6027\n",
      "Validation Loss: 199.3927\n",
      "NME: 0.0855\n",
      "Epoch [257/300], Loss: 49.2106\n",
      "Validation Loss: 202.1853\n",
      "NME: 0.0858\n",
      "Epoch [258/300], Loss: 50.8258\n",
      "Validation Loss: 194.6364\n",
      "NME: 0.0856\n",
      "Epoch [259/300], Loss: 48.9489\n",
      "Validation Loss: 191.2923\n",
      "NME: 0.0848\n",
      "Epoch [260/300], Loss: 49.0798\n",
      "Validation Loss: 198.4089\n",
      "NME: 0.0866\n",
      "Epoch [261/300], Loss: 48.9253\n",
      "Validation Loss: 195.6065\n",
      "NME: 0.0833\n",
      "Epoch [262/300], Loss: 47.9839\n",
      "Validation Loss: 192.1284\n",
      "NME: 0.0843\n",
      "Epoch [263/300], Loss: 50.4498\n",
      "Validation Loss: 195.7624\n",
      "NME: 0.0831\n",
      "Epoch [264/300], Loss: 48.2104\n",
      "Validation Loss: 198.6569\n",
      "NME: 0.0866\n",
      "Epoch [265/300], Loss: 50.6664\n",
      "Validation Loss: 208.0364\n",
      "NME: 0.0859\n",
      "Epoch [266/300], Loss: 49.3504\n",
      "Validation Loss: 203.8552\n",
      "NME: 0.0850\n",
      "Epoch [267/300], Loss: 50.2395\n",
      "Validation Loss: 207.2876\n",
      "NME: 0.0857\n",
      "Epoch [268/300], Loss: 50.7279\n",
      "Validation Loss: 195.9232\n",
      "NME: 0.0848\n",
      "Epoch [269/300], Loss: 46.1980\n",
      "Validation Loss: 195.0807\n",
      "NME: 0.0838\n",
      "Epoch [270/300], Loss: 46.6623\n",
      "Validation Loss: 191.6803\n",
      "NME: 0.0842\n",
      "Epoch [271/300], Loss: 46.5345\n",
      "Validation Loss: 200.3273\n",
      "NME: 0.0854\n",
      "Epoch [272/300], Loss: 47.0196\n",
      "Validation Loss: 195.8182\n",
      "NME: 0.0846\n",
      "Epoch [273/300], Loss: 43.9048\n",
      "Validation Loss: 190.9303\n",
      "NME: 0.0827\n",
      "Epoch [274/300], Loss: 42.5207\n",
      "Validation Loss: 190.4251\n",
      "NME: 0.0821\n",
      "Epoch [275/300], Loss: 41.1052\n",
      "Validation Loss: 187.5702\n",
      "NME: 0.0818\n",
      "Epoch [276/300], Loss: 40.2210\n",
      "Validation Loss: 186.0614\n",
      "NME: 0.0813\n",
      "Epoch [277/300], Loss: 40.4480\n",
      "Validation Loss: 186.2748\n",
      "NME: 0.0814\n",
      "Epoch [278/300], Loss: 40.3999\n",
      "Validation Loss: 185.2690\n",
      "NME: 0.0813\n",
      "Epoch [279/300], Loss: 38.3939\n",
      "Validation Loss: 183.4124\n",
      "NME: 0.0814\n",
      "Epoch [280/300], Loss: 38.8278\n",
      "Validation Loss: 188.0964\n",
      "NME: 0.0812\n",
      "Epoch [281/300], Loss: 39.3038\n",
      "Validation Loss: 186.8180\n",
      "NME: 0.0813\n",
      "Epoch [282/300], Loss: 37.9919\n",
      "Validation Loss: 185.2518\n",
      "NME: 0.0811\n",
      "Epoch [283/300], Loss: 40.4653\n",
      "Validation Loss: 185.1675\n",
      "NME: 0.0813\n",
      "Epoch [284/300], Loss: 40.9477\n",
      "Validation Loss: 184.0781\n",
      "NME: 0.0812\n",
      "Epoch [285/300], Loss: 38.0780\n",
      "Validation Loss: 183.3405\n",
      "NME: 0.0808\n",
      "Epoch [286/300], Loss: 38.2996\n",
      "Validation Loss: 183.9252\n",
      "NME: 0.0808\n",
      "Epoch [287/300], Loss: 38.1285\n",
      "Validation Loss: 183.8337\n",
      "NME: 0.0811\n",
      "Epoch [288/300], Loss: 38.2710\n",
      "Validation Loss: 188.1496\n",
      "NME: 0.0816\n",
      "Epoch [289/300], Loss: 37.3598\n",
      "Validation Loss: 183.8002\n",
      "NME: 0.0811\n",
      "Epoch [290/300], Loss: 38.1791\n",
      "Validation Loss: 182.9811\n",
      "NME: 0.0810\n",
      "Epoch [291/300], Loss: 37.8287\n",
      "Validation Loss: 181.8195\n",
      "NME: 0.0809\n",
      "Epoch [292/300], Loss: 39.0156\n",
      "Validation Loss: 182.7972\n",
      "NME: 0.0812\n",
      "Epoch [293/300], Loss: 37.4680\n",
      "Validation Loss: 183.2503\n",
      "NME: 0.0812\n",
      "Epoch [294/300], Loss: 39.3716\n",
      "Validation Loss: 184.3346\n",
      "NME: 0.0816\n",
      "Epoch [295/300], Loss: 38.1991\n",
      "Validation Loss: 182.3211\n",
      "NME: 0.0805\n",
      "Epoch [296/300], Loss: 37.5785\n",
      "Validation Loss: 186.4037\n",
      "NME: 0.0814\n",
      "Epoch [297/300], Loss: 37.7201\n",
      "Validation Loss: 184.2590\n",
      "NME: 0.0807\n",
      "Epoch [298/300], Loss: 37.2386\n",
      "Validation Loss: 183.1423\n",
      "NME: 0.0805\n",
      "Epoch [299/300], Loss: 38.2819\n",
      "Validation Loss: 186.1158\n",
      "NME: 0.0809\n",
      "Epoch [300/300], Loss: 38.1419\n",
      "Validation Loss: 186.5309\n",
      "NME: 0.0806\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los 칤ndices de las regiones seg칰n los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "oreja_der = [22, 23, 24, 25, 26]  # Cambiado a oreja derecha\n",
    "\n",
    "# Funci칩n para calcular el punto promedio de una regi칩n\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EarRightDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_oreja_der = calcular_centro_region(landmarks, oreja_der)  # Cambiado a oreja derecha\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_oreja_der -= np.array([x_min, y_min])  # Cambiado a oreja derecha\n",
    "        \n",
    "        # Calcular el 치ngulo de rotaci칩n\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotaci칩n\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la oreja derecha\n",
    "        ear_right_points = np.array([landmarks[i] for i in oreja_der], dtype=np.float32)  # Cambiado a oreja derecha\n",
    "        ear_right_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotaci칩n\n",
    "        ones = np.ones(shape=(len(ear_right_points), 1))\n",
    "        points_ones = np.hstack([ear_right_points, ones])\n",
    "        ear_right_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la oreja derecha\n",
    "        centro_x, centro_y = calcular_centro_region(ear_right_points_rotated, range(len(oreja_der)))  # Cambiado a oreja derecha\n",
    "\n",
    "        # Definir los l칤mites del recorte de 112x112 p칤xeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_ear = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_ear, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la oreja derecha al nuevo recorte\n",
    "        ear_right_points_adjusted = [(p[0] - x1, p[1] - y1) for p in ear_right_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        ear_right_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in ear_right_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=ear_right_points_scaled)\n",
    "            image = augmented['image']\n",
    "            ear_right_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(ear_right_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotaci칩n aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicaci칩n de m치scaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validaci칩n\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validaci칩n\n",
    "train_dataset = EarRightDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EarRightDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EarRight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EarRight, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(oreja_der) * 2)  # Cambiado a oreja derecha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuraci칩n y entrenamiento\n",
    "model = DenseNet121EarRight().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la f칩rmula espec칤fica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tama침o (N, M, 2), donde\n",
    "                        N es el n칰mero de im치genes, M el n칰mero de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tama침o que predictions.\n",
    "    :param num_landmarks: N칰mero de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los 칤ndices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para oreja derecha)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la f칩rmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, ear_right_points, _, _, _ in train_dataloader:  # Cambiado a oreja derecha\n",
    "            images, ear_right_points = images.cuda(), ear_right_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ear_right_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validaci칩n y c치lculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_ear_right_points, _, _, _ in val_dataloader:  # Cambiado a oreja derecha\n",
    "                    val_images, val_ear_right_points = val_images.cuda(), val_ear_right_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_ear_right_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el c치lculo de NME\n",
    "                    all_labels.append(val_ear_right_points.cpu().numpy().reshape(-1, len(oreja_der), 2))  # Cambiado a oreja derecha\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(oreja_der), 2))  # Cambiado a oreja derecha\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(oreja_der))  # Cambiado a oreja derecha\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EarRightLandmarks V2.pth')  # Cambiado a oreja derecha\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14254.8805\n",
      "Validation Loss: 12328.7725\n",
      "NME: 6.8208\n",
      "Best model saved at epoch 1 with val_loss 12328.7725\n",
      "Epoch [2/300], Loss: 7159.9013\n",
      "Validation Loss: 2474.5272\n",
      "NME: 2.4992\n",
      "Best model saved at epoch 2 with val_loss 2474.5272\n",
      "Epoch [3/300], Loss: 1371.1002\n",
      "Validation Loss: 874.0512\n",
      "NME: 1.1930\n",
      "Best model saved at epoch 3 with val_loss 874.0512\n",
      "Epoch [4/300], Loss: 778.6536\n",
      "Validation Loss: 645.4695\n",
      "NME: 1.0322\n",
      "Best model saved at epoch 4 with val_loss 645.4695\n",
      "Epoch [5/300], Loss: 656.3076\n",
      "Validation Loss: 579.3322\n",
      "NME: 1.0196\n",
      "Best model saved at epoch 5 with val_loss 579.3322\n",
      "Epoch [6/300], Loss: 625.2623\n",
      "Validation Loss: 566.0329\n",
      "NME: 1.0107\n",
      "Best model saved at epoch 6 with val_loss 566.0329\n",
      "Epoch [7/300], Loss: 620.6083\n",
      "Validation Loss: 557.9990\n",
      "NME: 1.0220\n",
      "Best model saved at epoch 7 with val_loss 557.9990\n",
      "Epoch [8/300], Loss: 614.4968\n",
      "Validation Loss: 557.1649\n",
      "NME: 1.0200\n",
      "Best model saved at epoch 8 with val_loss 557.1649\n",
      "Epoch [9/300], Loss: 611.4090\n",
      "Validation Loss: 555.3965\n",
      "NME: 1.0362\n",
      "Best model saved at epoch 9 with val_loss 555.3965\n",
      "Epoch [10/300], Loss: 613.2833\n",
      "Validation Loss: 549.0193\n",
      "NME: 1.0091\n",
      "Best model saved at epoch 10 with val_loss 549.0193\n",
      "Epoch [11/300], Loss: 603.7924\n",
      "Validation Loss: 539.5805\n",
      "NME: 1.0157\n",
      "Best model saved at epoch 11 with val_loss 539.5805\n",
      "Epoch [12/300], Loss: 592.1570\n",
      "Validation Loss: 526.2874\n",
      "NME: 0.9887\n",
      "Best model saved at epoch 12 with val_loss 526.2874\n",
      "Epoch [13/300], Loss: 575.2720\n",
      "Validation Loss: 501.5901\n",
      "NME: 0.9705\n",
      "Best model saved at epoch 13 with val_loss 501.5901\n",
      "Epoch [14/300], Loss: 546.0363\n",
      "Validation Loss: 457.1169\n",
      "NME: 0.9121\n",
      "Best model saved at epoch 14 with val_loss 457.1169\n",
      "Epoch [15/300], Loss: 502.6574\n",
      "Validation Loss: 395.0507\n",
      "NME: 0.8314\n",
      "Best model saved at epoch 15 with val_loss 395.0507\n",
      "Epoch [16/300], Loss: 432.7792\n",
      "Validation Loss: 316.2003\n",
      "NME: 0.7213\n",
      "Best model saved at epoch 16 with val_loss 316.2003\n",
      "Epoch [17/300], Loss: 366.8532\n",
      "Validation Loss: 226.2687\n",
      "NME: 0.5987\n",
      "Best model saved at epoch 17 with val_loss 226.2687\n",
      "Epoch [18/300], Loss: 310.7735\n",
      "Validation Loss: 183.4440\n",
      "NME: 0.5230\n",
      "Best model saved at epoch 18 with val_loss 183.4440\n",
      "Epoch [19/300], Loss: 271.6381\n",
      "Validation Loss: 163.0316\n",
      "NME: 0.4856\n",
      "Best model saved at epoch 19 with val_loss 163.0316\n",
      "Epoch [20/300], Loss: 242.4535\n",
      "Validation Loss: 146.7127\n",
      "NME: 0.5208\n",
      "Best model saved at epoch 20 with val_loss 146.7127\n",
      "Epoch [21/300], Loss: 247.9263\n",
      "Validation Loss: 125.5794\n",
      "NME: 0.4390\n",
      "Best model saved at epoch 21 with val_loss 125.5794\n",
      "Epoch [22/300], Loss: 234.2437\n",
      "Validation Loss: 130.8035\n",
      "NME: 0.4406\n",
      "Epoch [23/300], Loss: 230.4280\n",
      "Validation Loss: 127.9184\n",
      "NME: 0.4550\n",
      "Epoch [24/300], Loss: 220.1192\n",
      "Validation Loss: 124.6948\n",
      "NME: 0.4486\n",
      "Best model saved at epoch 24 with val_loss 124.6948\n",
      "Epoch [25/300], Loss: 213.3134\n",
      "Validation Loss: 125.8391\n",
      "NME: 0.4702\n",
      "Epoch [26/300], Loss: 198.2714\n",
      "Validation Loss: 124.5778\n",
      "NME: 0.4436\n",
      "Best model saved at epoch 26 with val_loss 124.5778\n",
      "Epoch [27/300], Loss: 197.4756\n",
      "Validation Loss: 128.0626\n",
      "NME: 0.4674\n",
      "Epoch [28/300], Loss: 203.2665\n",
      "Validation Loss: 129.9137\n",
      "NME: 0.4692\n",
      "Epoch [29/300], Loss: 192.7167\n",
      "Validation Loss: 139.1513\n",
      "NME: 0.5173\n",
      "Epoch [30/300], Loss: 212.1988\n",
      "Validation Loss: 129.0093\n",
      "NME: 0.4976\n",
      "Epoch [31/300], Loss: 199.5253\n",
      "Validation Loss: 131.3805\n",
      "NME: 0.5292\n",
      "Epoch [32/300], Loss: 193.4516\n",
      "Validation Loss: 117.5969\n",
      "NME: 0.4546\n",
      "Best model saved at epoch 32 with val_loss 117.5969\n",
      "Epoch [33/300], Loss: 199.9232\n",
      "Validation Loss: 116.6900\n",
      "NME: 0.4302\n",
      "Best model saved at epoch 33 with val_loss 116.6900\n",
      "Epoch [34/300], Loss: 197.6633\n",
      "Validation Loss: 130.5584\n",
      "NME: 0.5067\n",
      "Epoch [35/300], Loss: 197.9451\n",
      "Validation Loss: 130.7343\n",
      "NME: 0.4998\n",
      "Epoch [36/300], Loss: 183.2936\n",
      "Validation Loss: 118.1882\n",
      "NME: 0.4483\n",
      "Epoch [37/300], Loss: 205.0183\n",
      "Validation Loss: 130.1519\n",
      "NME: 0.5087\n",
      "Epoch [38/300], Loss: 192.9946\n",
      "Validation Loss: 130.7283\n",
      "NME: 0.4960\n",
      "Epoch [39/300], Loss: 202.3030\n",
      "Validation Loss: 141.3686\n",
      "NME: 0.5439\n",
      "Epoch [40/300], Loss: 196.3332\n",
      "Validation Loss: 135.3536\n",
      "NME: 0.4910\n",
      "Epoch [41/300], Loss: 199.2340\n",
      "Validation Loss: 123.5375\n",
      "NME: 0.4705\n",
      "Epoch [42/300], Loss: 188.9984\n",
      "Validation Loss: 124.2948\n",
      "NME: 0.4794\n",
      "Epoch [43/300], Loss: 182.2111\n",
      "Validation Loss: 117.5686\n",
      "NME: 0.4246\n",
      "Epoch [44/300], Loss: 188.9402\n",
      "Validation Loss: 128.9557\n",
      "NME: 0.4834\n",
      "Epoch [45/300], Loss: 207.0631\n",
      "Validation Loss: 130.9027\n",
      "NME: 0.4879\n",
      "Epoch [46/300], Loss: 194.5821\n",
      "Validation Loss: 140.6365\n",
      "NME: 0.5058\n",
      "Epoch [47/300], Loss: 192.3635\n",
      "Validation Loss: 115.5004\n",
      "NME: 0.4279\n",
      "Best model saved at epoch 47 with val_loss 115.5004\n",
      "Epoch [48/300], Loss: 205.4915\n",
      "Validation Loss: 125.9384\n",
      "NME: 0.4361\n",
      "Epoch [49/300], Loss: 192.2042\n",
      "Validation Loss: 134.3727\n",
      "NME: 0.5154\n",
      "Epoch [50/300], Loss: 179.3364\n",
      "Validation Loss: 120.7873\n",
      "NME: 0.4502\n",
      "Epoch [51/300], Loss: 204.2614\n",
      "Validation Loss: 127.1794\n",
      "NME: 0.4546\n",
      "Epoch [52/300], Loss: 192.9127\n",
      "Validation Loss: 133.3733\n",
      "NME: 0.4802\n",
      "Epoch [53/300], Loss: 193.6087\n",
      "Validation Loss: 120.6034\n",
      "NME: 0.4336\n",
      "Epoch [54/300], Loss: 197.9314\n",
      "Validation Loss: 134.8479\n",
      "NME: 0.4724\n",
      "Epoch [55/300], Loss: 191.6513\n",
      "Validation Loss: 133.7667\n",
      "NME: 0.4953\n",
      "Epoch [56/300], Loss: 187.8560\n",
      "Validation Loss: 124.7841\n",
      "NME: 0.4477\n",
      "Epoch [57/300], Loss: 187.1923\n",
      "Validation Loss: 135.0896\n",
      "NME: 0.5139\n",
      "Epoch [58/300], Loss: 194.6874\n",
      "Validation Loss: 123.9956\n",
      "NME: 0.4296\n",
      "Epoch [59/300], Loss: 183.0837\n",
      "Validation Loss: 124.6321\n",
      "NME: 0.4442\n",
      "Epoch [60/300], Loss: 191.2363\n",
      "Validation Loss: 128.1093\n",
      "NME: 0.4586\n",
      "Epoch [61/300], Loss: 185.8067\n",
      "Validation Loss: 129.4383\n",
      "NME: 0.4662\n",
      "Epoch [62/300], Loss: 178.2087\n",
      "Validation Loss: 121.4739\n",
      "NME: 0.4420\n",
      "Epoch [63/300], Loss: 174.1996\n",
      "Validation Loss: 111.1693\n",
      "NME: 0.4197\n",
      "Best model saved at epoch 63 with val_loss 111.1693\n",
      "Epoch [64/300], Loss: 171.5478\n",
      "Validation Loss: 106.8500\n",
      "NME: 0.4181\n",
      "Best model saved at epoch 64 with val_loss 106.8500\n",
      "Epoch [65/300], Loss: 169.6518\n",
      "Validation Loss: 113.3403\n",
      "NME: 0.4346\n",
      "Epoch [66/300], Loss: 153.9198\n",
      "Validation Loss: 112.2676\n",
      "NME: 0.4465\n",
      "Epoch [67/300], Loss: 158.2951\n",
      "Validation Loss: 118.0302\n",
      "NME: 0.4280\n",
      "Epoch [68/300], Loss: 140.1204\n",
      "Validation Loss: 112.9768\n",
      "NME: 0.4258\n",
      "Epoch [69/300], Loss: 131.3048\n",
      "Validation Loss: 117.0341\n",
      "NME: 0.4426\n",
      "Epoch [70/300], Loss: 128.9343\n",
      "Validation Loss: 113.2328\n",
      "NME: 0.4492\n",
      "Epoch [71/300], Loss: 127.6838\n",
      "Validation Loss: 115.7648\n",
      "NME: 0.4328\n",
      "Epoch [72/300], Loss: 126.0789\n",
      "Validation Loss: 107.8508\n",
      "NME: 0.4423\n",
      "Epoch [73/300], Loss: 118.6903\n",
      "Validation Loss: 110.2546\n",
      "NME: 0.4292\n",
      "Epoch [74/300], Loss: 126.0705\n",
      "Validation Loss: 118.4639\n",
      "NME: 0.4267\n",
      "Epoch [75/300], Loss: 117.7626\n",
      "Validation Loss: 117.1198\n",
      "NME: 0.4491\n",
      "Epoch [76/300], Loss: 130.0630\n",
      "Validation Loss: 120.1575\n",
      "NME: 0.4493\n",
      "Epoch [77/300], Loss: 115.4589\n",
      "Validation Loss: 107.4359\n",
      "NME: 0.4170\n",
      "Epoch [78/300], Loss: 107.8132\n",
      "Validation Loss: 110.5296\n",
      "NME: 0.4335\n",
      "Epoch [79/300], Loss: 112.0540\n",
      "Validation Loss: 103.1901\n",
      "NME: 0.4138\n",
      "Best model saved at epoch 79 with val_loss 103.1901\n",
      "Epoch [80/300], Loss: 103.4617\n",
      "Validation Loss: 99.2242\n",
      "NME: 0.4017\n",
      "Best model saved at epoch 80 with val_loss 99.2242\n",
      "Epoch [81/300], Loss: 102.0569\n",
      "Validation Loss: 104.8977\n",
      "NME: 0.4213\n",
      "Epoch [82/300], Loss: 102.8053\n",
      "Validation Loss: 102.2341\n",
      "NME: 0.4202\n",
      "Epoch [83/300], Loss: 103.2355\n",
      "Validation Loss: 105.3595\n",
      "NME: 0.4100\n",
      "Epoch [84/300], Loss: 98.5111\n",
      "Validation Loss: 102.0238\n",
      "NME: 0.4093\n",
      "Epoch [85/300], Loss: 92.5110\n",
      "Validation Loss: 89.9744\n",
      "NME: 0.3691\n",
      "Best model saved at epoch 85 with val_loss 89.9744\n",
      "Epoch [86/300], Loss: 91.2967\n",
      "Validation Loss: 93.4452\n",
      "NME: 0.3931\n",
      "Epoch [87/300], Loss: 89.9862\n",
      "Validation Loss: 89.5415\n",
      "NME: 0.3863\n",
      "Best model saved at epoch 87 with val_loss 89.5415\n",
      "Epoch [88/300], Loss: 86.7609\n",
      "Validation Loss: 86.8951\n",
      "NME: 0.3801\n",
      "Best model saved at epoch 88 with val_loss 86.8951\n",
      "Epoch [89/300], Loss: 89.8664\n",
      "Validation Loss: 86.7489\n",
      "NME: 0.3704\n",
      "Best model saved at epoch 89 with val_loss 86.7489\n",
      "Epoch [90/300], Loss: 87.1088\n",
      "Validation Loss: 83.6061\n",
      "NME: 0.3617\n",
      "Best model saved at epoch 90 with val_loss 83.6061\n",
      "Epoch [91/300], Loss: 82.7634\n",
      "Validation Loss: 85.1856\n",
      "NME: 0.3638\n",
      "Epoch [92/300], Loss: 83.2322\n",
      "Validation Loss: 84.7472\n",
      "NME: 0.3656\n",
      "Epoch [93/300], Loss: 81.6348\n",
      "Validation Loss: 82.2309\n",
      "NME: 0.3449\n",
      "Best model saved at epoch 93 with val_loss 82.2309\n",
      "Epoch [94/300], Loss: 78.0035\n",
      "Validation Loss: 79.6409\n",
      "NME: 0.3475\n",
      "Best model saved at epoch 94 with val_loss 79.6409\n",
      "Epoch [95/300], Loss: 75.4114\n",
      "Validation Loss: 78.4119\n",
      "NME: 0.3424\n",
      "Best model saved at epoch 95 with val_loss 78.4119\n",
      "Epoch [96/300], Loss: 80.1236\n",
      "Validation Loss: 83.2904\n",
      "NME: 0.3711\n",
      "Epoch [97/300], Loss: 76.1481\n",
      "Validation Loss: 79.6107\n",
      "NME: 0.3510\n",
      "Epoch [98/300], Loss: 79.5248\n",
      "Validation Loss: 86.2689\n",
      "NME: 0.3550\n",
      "Epoch [99/300], Loss: 74.9327\n",
      "Validation Loss: 77.7669\n",
      "NME: 0.3395\n",
      "Best model saved at epoch 99 with val_loss 77.7669\n",
      "Epoch [100/300], Loss: 69.2334\n",
      "Validation Loss: 81.5503\n",
      "NME: 0.3568\n",
      "Epoch [101/300], Loss: 69.6687\n",
      "Validation Loss: 79.0179\n",
      "NME: 0.3502\n",
      "Epoch [102/300], Loss: 71.0605\n",
      "Validation Loss: 77.3844\n",
      "NME: 0.3386\n",
      "Best model saved at epoch 102 with val_loss 77.3844\n",
      "Epoch [103/300], Loss: 67.1104\n",
      "Validation Loss: 73.8129\n",
      "NME: 0.3283\n",
      "Best model saved at epoch 103 with val_loss 73.8129\n",
      "Epoch [104/300], Loss: 62.4094\n",
      "Validation Loss: 74.2880\n",
      "NME: 0.3347\n",
      "Epoch [105/300], Loss: 64.3739\n",
      "Validation Loss: 77.3105\n",
      "NME: 0.3329\n",
      "Epoch [106/300], Loss: 65.6289\n",
      "Validation Loss: 75.8545\n",
      "NME: 0.3367\n",
      "Epoch [107/300], Loss: 65.5688\n",
      "Validation Loss: 79.2150\n",
      "NME: 0.3276\n",
      "Epoch [108/300], Loss: 64.6486\n",
      "Validation Loss: 76.8016\n",
      "NME: 0.3347\n",
      "Epoch [109/300], Loss: 64.9767\n",
      "Validation Loss: 84.1116\n",
      "NME: 0.3683\n",
      "Epoch [110/300], Loss: 64.0940\n",
      "Validation Loss: 71.8175\n",
      "NME: 0.3272\n",
      "Best model saved at epoch 110 with val_loss 71.8175\n",
      "Epoch [111/300], Loss: 64.4509\n",
      "Validation Loss: 75.6507\n",
      "NME: 0.3345\n",
      "Epoch [112/300], Loss: 60.8411\n",
      "Validation Loss: 77.3087\n",
      "NME: 0.3341\n",
      "Epoch [113/300], Loss: 58.3125\n",
      "Validation Loss: 72.4612\n",
      "NME: 0.3241\n",
      "Epoch [114/300], Loss: 63.0485\n",
      "Validation Loss: 76.8528\n",
      "NME: 0.3360\n",
      "Epoch [115/300], Loss: 59.4060\n",
      "Validation Loss: 73.5381\n",
      "NME: 0.3163\n",
      "Epoch [116/300], Loss: 56.1925\n",
      "Validation Loss: 72.5753\n",
      "NME: 0.3248\n",
      "Epoch [117/300], Loss: 82.4318\n",
      "Validation Loss: 94.6129\n",
      "NME: 0.3771\n",
      "Epoch [118/300], Loss: 88.2577\n",
      "Validation Loss: 78.0811\n",
      "NME: 0.3444\n",
      "Epoch [119/300], Loss: 67.5535\n",
      "Validation Loss: 73.9935\n",
      "NME: 0.3298\n",
      "Epoch [120/300], Loss: 60.3325\n",
      "Validation Loss: 70.0821\n",
      "NME: 0.3188\n",
      "Best model saved at epoch 120 with val_loss 70.0821\n",
      "Epoch [121/300], Loss: 64.3789\n",
      "Validation Loss: 74.1351\n",
      "NME: 0.3233\n",
      "Epoch [122/300], Loss: 58.3734\n",
      "Validation Loss: 73.8072\n",
      "NME: 0.3249\n",
      "Epoch [123/300], Loss: 66.6467\n",
      "Validation Loss: 80.4076\n",
      "NME: 0.3337\n",
      "Epoch [124/300], Loss: 61.2122\n",
      "Validation Loss: 76.3565\n",
      "NME: 0.3200\n",
      "Epoch [125/300], Loss: 56.7275\n",
      "Validation Loss: 73.4871\n",
      "NME: 0.3226\n",
      "Epoch [126/300], Loss: 57.6978\n",
      "Validation Loss: 70.4303\n",
      "NME: 0.3180\n",
      "Epoch [127/300], Loss: 56.5438\n",
      "Validation Loss: 70.4137\n",
      "NME: 0.3134\n",
      "Epoch [128/300], Loss: 56.9976\n",
      "Validation Loss: 71.2144\n",
      "NME: 0.3187\n",
      "Epoch [129/300], Loss: 53.0476\n",
      "Validation Loss: 73.8011\n",
      "NME: 0.3254\n",
      "Epoch [130/300], Loss: 51.9559\n",
      "Validation Loss: 71.2737\n",
      "NME: 0.3123\n",
      "Epoch [131/300], Loss: 58.1069\n",
      "Validation Loss: 70.6427\n",
      "NME: 0.3192\n",
      "Epoch [132/300], Loss: 53.1407\n",
      "Validation Loss: 72.8226\n",
      "NME: 0.3239\n",
      "Epoch [133/300], Loss: 55.7094\n",
      "Validation Loss: 72.5070\n",
      "NME: 0.3160\n",
      "Epoch [134/300], Loss: 54.5596\n",
      "Validation Loss: 75.7387\n",
      "NME: 0.3357\n",
      "Epoch [135/300], Loss: 55.7390\n",
      "Validation Loss: 73.0049\n",
      "NME: 0.3187\n",
      "Epoch [136/300], Loss: 52.3353\n",
      "Validation Loss: 74.1155\n",
      "NME: 0.3110\n",
      "Epoch [137/300], Loss: 52.3317\n",
      "Validation Loss: 73.3931\n",
      "NME: 0.3146\n",
      "Epoch [138/300], Loss: 53.1586\n",
      "Validation Loss: 71.5289\n",
      "NME: 0.3244\n",
      "Epoch [139/300], Loss: 50.3154\n",
      "Validation Loss: 72.0348\n",
      "NME: 0.3164\n",
      "Epoch [140/300], Loss: 51.5491\n",
      "Validation Loss: 77.3347\n",
      "NME: 0.3252\n",
      "Epoch [141/300], Loss: 52.8063\n",
      "Validation Loss: 68.4629\n",
      "NME: 0.3048\n",
      "Best model saved at epoch 141 with val_loss 68.4629\n",
      "Epoch [142/300], Loss: 51.6611\n",
      "Validation Loss: 71.2285\n",
      "NME: 0.3242\n",
      "Epoch [143/300], Loss: 52.2868\n",
      "Validation Loss: 74.6211\n",
      "NME: 0.3292\n",
      "Epoch [144/300], Loss: 54.8665\n",
      "Validation Loss: 71.9873\n",
      "NME: 0.3120\n",
      "Epoch [145/300], Loss: 50.6216\n",
      "Validation Loss: 70.0909\n",
      "NME: 0.3156\n",
      "Epoch [146/300], Loss: 49.5922\n",
      "Validation Loss: 70.0016\n",
      "NME: 0.3093\n",
      "Epoch [147/300], Loss: 49.6736\n",
      "Validation Loss: 68.8841\n",
      "NME: 0.3116\n",
      "Epoch [148/300], Loss: 52.2441\n",
      "Validation Loss: 74.2038\n",
      "NME: 0.3339\n",
      "Epoch [149/300], Loss: 51.7591\n",
      "Validation Loss: 70.9729\n",
      "NME: 0.3239\n",
      "Epoch [150/300], Loss: 51.4252\n",
      "Validation Loss: 71.8534\n",
      "NME: 0.3080\n",
      "Epoch [151/300], Loss: 48.3755\n",
      "Validation Loss: 70.1617\n",
      "NME: 0.3109\n",
      "Epoch [152/300], Loss: 49.6415\n",
      "Validation Loss: 84.6571\n",
      "NME: 0.3359\n",
      "Epoch [153/300], Loss: 49.2369\n",
      "Validation Loss: 69.9819\n",
      "NME: 0.3077\n",
      "Epoch [154/300], Loss: 48.0570\n",
      "Validation Loss: 71.2989\n",
      "NME: 0.3175\n",
      "Epoch [155/300], Loss: 49.4667\n",
      "Validation Loss: 71.2326\n",
      "NME: 0.3219\n",
      "Epoch [156/300], Loss: 50.5053\n",
      "Validation Loss: 75.0139\n",
      "NME: 0.3194\n",
      "Epoch [157/300], Loss: 49.6497\n",
      "Validation Loss: 69.7079\n",
      "NME: 0.3131\n",
      "Epoch [158/300], Loss: 51.5353\n",
      "Validation Loss: 72.1129\n",
      "NME: 0.3228\n",
      "Epoch [159/300], Loss: 49.8099\n",
      "Validation Loss: 73.7995\n",
      "NME: 0.3223\n",
      "Epoch [160/300], Loss: 50.8763\n",
      "Validation Loss: 68.9578\n",
      "NME: 0.3062\n",
      "Epoch [161/300], Loss: 50.1944\n",
      "Validation Loss: 77.7178\n",
      "NME: 0.3249\n",
      "Epoch [162/300], Loss: 54.2575\n",
      "Validation Loss: 76.7415\n",
      "NME: 0.3171\n",
      "Epoch [163/300], Loss: 53.3745\n",
      "Validation Loss: 69.2545\n",
      "NME: 0.3092\n",
      "Epoch [164/300], Loss: 52.4118\n",
      "Validation Loss: 68.3583\n",
      "NME: 0.3146\n",
      "Best model saved at epoch 164 with val_loss 68.3583\n",
      "Epoch [165/300], Loss: 50.5560\n",
      "Validation Loss: 72.6246\n",
      "NME: 0.3163\n",
      "Epoch [166/300], Loss: 48.8534\n",
      "Validation Loss: 69.7628\n",
      "NME: 0.3126\n",
      "Epoch [167/300], Loss: 50.3050\n",
      "Validation Loss: 69.1762\n",
      "NME: 0.3066\n",
      "Epoch [168/300], Loss: 49.9030\n",
      "Validation Loss: 69.5455\n",
      "NME: 0.3121\n",
      "Epoch [169/300], Loss: 48.8450\n",
      "Validation Loss: 66.8736\n",
      "NME: 0.3002\n",
      "Best model saved at epoch 169 with val_loss 66.8736\n",
      "Epoch [170/300], Loss: 46.4495\n",
      "Validation Loss: 70.1511\n",
      "NME: 0.3156\n",
      "Epoch [171/300], Loss: 52.4089\n",
      "Validation Loss: 76.7964\n",
      "NME: 0.3354\n",
      "Epoch [172/300], Loss: 48.1739\n",
      "Validation Loss: 69.5743\n",
      "NME: 0.3200\n",
      "Epoch [173/300], Loss: 48.1961\n",
      "Validation Loss: 74.3692\n",
      "NME: 0.3321\n",
      "Epoch [174/300], Loss: 55.4713\n",
      "Validation Loss: 77.7932\n",
      "NME: 0.3147\n",
      "Epoch [175/300], Loss: 49.5218\n",
      "Validation Loss: 69.6901\n",
      "NME: 0.3135\n",
      "Epoch [176/300], Loss: 45.0864\n",
      "Validation Loss: 70.0875\n",
      "NME: 0.3184\n",
      "Epoch [177/300], Loss: 43.7711\n",
      "Validation Loss: 69.1454\n",
      "NME: 0.3015\n",
      "Epoch [178/300], Loss: 45.4876\n",
      "Validation Loss: 67.2587\n",
      "NME: 0.3063\n",
      "Epoch [179/300], Loss: 44.6840\n",
      "Validation Loss: 67.5788\n",
      "NME: 0.3075\n",
      "Epoch [180/300], Loss: 44.2260\n",
      "Validation Loss: 67.6888\n",
      "NME: 0.3117\n",
      "Epoch [181/300], Loss: 44.1305\n",
      "Validation Loss: 64.8225\n",
      "NME: 0.2985\n",
      "Best model saved at epoch 181 with val_loss 64.8225\n",
      "Epoch [182/300], Loss: 42.7495\n",
      "Validation Loss: 66.5778\n",
      "NME: 0.3044\n",
      "Epoch [183/300], Loss: 42.1762\n",
      "Validation Loss: 66.0226\n",
      "NME: 0.3029\n",
      "Epoch [184/300], Loss: 53.9177\n",
      "Validation Loss: 78.5934\n",
      "NME: 0.3470\n",
      "Epoch [185/300], Loss: 48.8420\n",
      "Validation Loss: 66.9214\n",
      "NME: 0.3079\n",
      "Epoch [186/300], Loss: 46.6663\n",
      "Validation Loss: 71.2639\n",
      "NME: 0.3055\n",
      "Epoch [187/300], Loss: 45.3999\n",
      "Validation Loss: 66.7154\n",
      "NME: 0.3001\n",
      "Epoch [188/300], Loss: 43.5932\n",
      "Validation Loss: 66.7002\n",
      "NME: 0.3056\n",
      "Epoch [189/300], Loss: 43.5660\n",
      "Validation Loss: 65.7700\n",
      "NME: 0.3069\n",
      "Epoch [190/300], Loss: 41.5217\n",
      "Validation Loss: 67.9692\n",
      "NME: 0.3041\n",
      "Epoch [191/300], Loss: 43.3547\n",
      "Validation Loss: 66.2941\n",
      "NME: 0.3077\n",
      "Epoch [192/300], Loss: 43.3995\n",
      "Validation Loss: 65.7203\n",
      "NME: 0.3079\n",
      "Epoch [193/300], Loss: 41.3843\n",
      "Validation Loss: 65.9789\n",
      "NME: 0.3088\n",
      "Epoch [194/300], Loss: 41.4797\n",
      "Validation Loss: 66.1899\n",
      "NME: 0.3025\n",
      "Epoch [195/300], Loss: 39.6314\n",
      "Validation Loss: 69.5319\n",
      "NME: 0.3103\n",
      "Epoch [196/300], Loss: 40.1542\n",
      "Validation Loss: 65.8775\n",
      "NME: 0.3066\n",
      "Epoch [197/300], Loss: 40.1605\n",
      "Validation Loss: 66.6640\n",
      "NME: 0.3040\n",
      "Epoch [198/300], Loss: 37.7875\n",
      "Validation Loss: 64.1999\n",
      "NME: 0.2891\n",
      "Best model saved at epoch 198 with val_loss 64.1999\n",
      "Epoch [199/300], Loss: 41.5742\n",
      "Validation Loss: 66.0738\n",
      "NME: 0.2969\n",
      "Epoch [200/300], Loss: 40.5679\n",
      "Validation Loss: 63.9248\n",
      "NME: 0.2995\n",
      "Best model saved at epoch 200 with val_loss 63.9248\n",
      "Epoch [201/300], Loss: 41.1673\n",
      "Validation Loss: 67.3387\n",
      "NME: 0.3027\n",
      "Epoch [202/300], Loss: 40.6565\n",
      "Validation Loss: 73.2662\n",
      "NME: 0.3172\n",
      "Epoch [203/300], Loss: 40.8139\n",
      "Validation Loss: 63.7063\n",
      "NME: 0.3031\n",
      "Best model saved at epoch 203 with val_loss 63.7063\n",
      "Epoch [204/300], Loss: 39.4856\n",
      "Validation Loss: 64.0479\n",
      "NME: 0.2945\n",
      "Epoch [205/300], Loss: 41.1636\n",
      "Validation Loss: 66.8142\n",
      "NME: 0.3028\n",
      "Epoch [206/300], Loss: 38.2727\n",
      "Validation Loss: 65.3554\n",
      "NME: 0.3054\n",
      "Epoch [207/300], Loss: 37.4162\n",
      "Validation Loss: 62.2201\n",
      "NME: 0.2937\n",
      "Best model saved at epoch 207 with val_loss 62.2201\n",
      "Epoch [208/300], Loss: 42.1412\n",
      "Validation Loss: 63.2936\n",
      "NME: 0.2945\n",
      "Epoch [209/300], Loss: 37.3633\n",
      "Validation Loss: 61.3768\n",
      "NME: 0.2970\n",
      "Best model saved at epoch 209 with val_loss 61.3768\n",
      "Epoch [210/300], Loss: 38.7588\n",
      "Validation Loss: 62.1183\n",
      "NME: 0.3012\n",
      "Epoch [211/300], Loss: 36.7322\n",
      "Validation Loss: 61.0671\n",
      "NME: 0.2903\n",
      "Best model saved at epoch 211 with val_loss 61.0671\n",
      "Epoch [212/300], Loss: 36.9246\n",
      "Validation Loss: 60.9377\n",
      "NME: 0.2959\n",
      "Best model saved at epoch 212 with val_loss 60.9377\n",
      "Epoch [213/300], Loss: 41.8979\n",
      "Validation Loss: 67.8870\n",
      "NME: 0.3169\n",
      "Epoch [214/300], Loss: 37.4161\n",
      "Validation Loss: 62.2100\n",
      "NME: 0.2924\n",
      "Epoch [215/300], Loss: 36.3350\n",
      "Validation Loss: 61.4304\n",
      "NME: 0.2918\n",
      "Epoch [216/300], Loss: 35.2673\n",
      "Validation Loss: 60.5803\n",
      "NME: 0.2929\n",
      "Best model saved at epoch 216 with val_loss 60.5803\n",
      "Epoch [217/300], Loss: 33.4634\n",
      "Validation Loss: 61.3622\n",
      "NME: 0.2902\n",
      "Epoch [218/300], Loss: 35.4640\n",
      "Validation Loss: 61.0264\n",
      "NME: 0.2838\n",
      "Epoch [219/300], Loss: 37.1060\n",
      "Validation Loss: 66.4053\n",
      "NME: 0.2990\n",
      "Epoch [220/300], Loss: 37.9053\n",
      "Validation Loss: 77.6169\n",
      "NME: 0.3223\n",
      "Epoch [221/300], Loss: 36.5174\n",
      "Validation Loss: 80.9314\n",
      "NME: 0.3218\n",
      "Epoch [222/300], Loss: 34.1487\n",
      "Validation Loss: 71.2633\n",
      "NME: 0.3109\n",
      "Epoch [223/300], Loss: 33.1380\n",
      "Validation Loss: 63.7099\n",
      "NME: 0.3041\n",
      "Epoch [224/300], Loss: 33.4608\n",
      "Validation Loss: 63.3665\n",
      "NME: 0.2953\n",
      "Epoch [225/300], Loss: 32.9950\n",
      "Validation Loss: 61.9703\n",
      "NME: 0.2953\n",
      "Epoch [226/300], Loss: 32.0416\n",
      "Validation Loss: 63.0178\n",
      "NME: 0.2998\n",
      "Epoch [227/300], Loss: 32.7784\n",
      "Validation Loss: 66.7653\n",
      "NME: 0.2994\n",
      "Epoch [228/300], Loss: 31.8911\n",
      "Validation Loss: 69.1845\n",
      "NME: 0.3113\n",
      "Epoch [229/300], Loss: 31.4693\n",
      "Validation Loss: 72.7506\n",
      "NME: 0.3086\n",
      "Epoch [230/300], Loss: 33.7091\n",
      "Validation Loss: 64.2239\n",
      "NME: 0.2996\n",
      "Epoch [231/300], Loss: 32.1759\n",
      "Validation Loss: 62.3658\n",
      "NME: 0.2960\n",
      "Epoch [232/300], Loss: 32.6496\n",
      "Validation Loss: 60.8319\n",
      "NME: 0.3020\n",
      "Epoch [233/300], Loss: 34.1084\n",
      "Validation Loss: 60.9131\n",
      "NME: 0.2948\n",
      "Epoch [234/300], Loss: 34.2593\n",
      "Validation Loss: 62.0029\n",
      "NME: 0.2962\n",
      "Epoch [235/300], Loss: 31.4632\n",
      "Validation Loss: 59.2396\n",
      "NME: 0.2883\n",
      "Best model saved at epoch 235 with val_loss 59.2396\n",
      "Epoch [236/300], Loss: 31.0286\n",
      "Validation Loss: 60.2391\n",
      "NME: 0.2925\n",
      "Epoch [237/300], Loss: 31.3018\n",
      "Validation Loss: 59.3512\n",
      "NME: 0.2812\n",
      "Epoch [238/300], Loss: 33.3704\n",
      "Validation Loss: 71.6250\n",
      "NME: 0.3083\n",
      "Epoch [239/300], Loss: 31.8585\n",
      "Validation Loss: 61.6107\n",
      "NME: 0.2985\n",
      "Epoch [240/300], Loss: 31.6624\n",
      "Validation Loss: 71.1209\n",
      "NME: 0.3122\n",
      "Epoch [241/300], Loss: 30.2902\n",
      "Validation Loss: 63.2315\n",
      "NME: 0.2959\n",
      "Epoch [242/300], Loss: 32.5587\n",
      "Validation Loss: 62.7048\n",
      "NME: 0.2899\n",
      "Epoch [243/300], Loss: 33.0974\n",
      "Validation Loss: 59.0619\n",
      "NME: 0.2878\n",
      "Best model saved at epoch 243 with val_loss 59.0619\n",
      "Epoch [244/300], Loss: 30.4528\n",
      "Validation Loss: 60.3933\n",
      "NME: 0.2943\n",
      "Epoch [245/300], Loss: 29.2563\n",
      "Validation Loss: 60.4508\n",
      "NME: 0.2889\n",
      "Epoch [246/300], Loss: 29.3821\n",
      "Validation Loss: 59.9101\n",
      "NME: 0.2857\n",
      "Epoch [247/300], Loss: 29.4914\n",
      "Validation Loss: 58.9827\n",
      "NME: 0.2904\n",
      "Best model saved at epoch 247 with val_loss 58.9827\n",
      "Epoch [248/300], Loss: 30.5441\n",
      "Validation Loss: 66.4206\n",
      "NME: 0.3151\n",
      "Epoch [249/300], Loss: 31.0838\n",
      "Validation Loss: 59.4219\n",
      "NME: 0.2877\n",
      "Epoch [250/300], Loss: 30.7555\n",
      "Validation Loss: 59.7798\n",
      "NME: 0.2893\n",
      "Epoch [251/300], Loss: 31.2241\n",
      "Validation Loss: 58.3341\n",
      "NME: 0.2886\n",
      "Best model saved at epoch 251 with val_loss 58.3341\n",
      "Epoch [252/300], Loss: 29.3672\n",
      "Validation Loss: 65.0755\n",
      "NME: 0.3027\n",
      "Epoch [253/300], Loss: 29.4786\n",
      "Validation Loss: 83.0253\n",
      "NME: 0.3210\n",
      "Epoch [254/300], Loss: 34.2369\n",
      "Validation Loss: 65.2156\n",
      "NME: 0.3076\n",
      "Epoch [255/300], Loss: 31.4584\n",
      "Validation Loss: 62.7333\n",
      "NME: 0.2920\n",
      "Epoch [256/300], Loss: 28.1954\n",
      "Validation Loss: 62.3334\n",
      "NME: 0.2908\n",
      "Epoch [257/300], Loss: 29.6327\n",
      "Validation Loss: 70.9392\n",
      "NME: 0.3243\n",
      "Epoch [258/300], Loss: 32.0536\n",
      "Validation Loss: 60.7397\n",
      "NME: 0.2846\n",
      "Epoch [259/300], Loss: 29.4183\n",
      "Validation Loss: 60.7930\n",
      "NME: 0.2995\n",
      "Epoch [260/300], Loss: 28.2457\n",
      "Validation Loss: 60.3299\n",
      "NME: 0.2901\n",
      "Epoch [261/300], Loss: 27.4787\n",
      "Validation Loss: 59.6161\n",
      "NME: 0.2913\n",
      "Epoch [262/300], Loss: 26.8196\n",
      "Validation Loss: 60.0456\n",
      "NME: 0.2886\n",
      "Epoch [263/300], Loss: 28.2740\n",
      "Validation Loss: 62.2475\n",
      "NME: 0.2895\n",
      "Epoch [264/300], Loss: 36.5168\n",
      "Validation Loss: 61.8073\n",
      "NME: 0.2952\n",
      "Epoch [265/300], Loss: 34.1224\n",
      "Validation Loss: 61.7877\n",
      "NME: 0.2995\n",
      "Epoch [266/300], Loss: 31.3537\n",
      "Validation Loss: 60.9183\n",
      "NME: 0.2927\n",
      "Epoch [267/300], Loss: 26.9968\n",
      "Validation Loss: 58.9248\n",
      "NME: 0.2899\n",
      "Epoch [268/300], Loss: 27.6348\n",
      "Validation Loss: 60.6757\n",
      "NME: 0.2934\n",
      "Epoch [269/300], Loss: 28.5821\n",
      "Validation Loss: 76.2786\n",
      "NME: 0.3210\n",
      "Epoch [270/300], Loss: 30.0970\n",
      "Validation Loss: 65.8874\n",
      "NME: 0.3187\n",
      "Epoch [271/300], Loss: 27.5204\n",
      "Validation Loss: 64.9046\n",
      "NME: 0.2982\n",
      "Epoch [272/300], Loss: 26.8103\n",
      "Validation Loss: 62.0329\n",
      "NME: 0.2996\n",
      "Epoch [273/300], Loss: 28.8073\n",
      "Validation Loss: 62.0564\n",
      "NME: 0.3014\n",
      "Epoch [274/300], Loss: 28.9026\n",
      "Validation Loss: 62.3799\n",
      "NME: 0.2940\n",
      "Epoch [275/300], Loss: 27.4290\n",
      "Validation Loss: 62.0740\n",
      "NME: 0.2950\n",
      "Epoch [276/300], Loss: 25.7868\n",
      "Validation Loss: 60.9133\n",
      "NME: 0.2902\n",
      "Epoch [277/300], Loss: 25.6394\n",
      "Validation Loss: 59.8033\n",
      "NME: 0.2912\n",
      "Epoch [278/300], Loss: 25.4871\n",
      "Validation Loss: 59.9806\n",
      "NME: 0.2796\n",
      "Epoch [279/300], Loss: 24.3545\n",
      "Validation Loss: 59.6992\n",
      "NME: 0.2863\n",
      "Epoch [280/300], Loss: 25.0077\n",
      "Validation Loss: 61.2331\n",
      "NME: 0.2893\n",
      "Epoch [281/300], Loss: 25.1914\n",
      "Validation Loss: 60.7773\n",
      "NME: 0.2854\n",
      "Epoch [282/300], Loss: 24.9073\n",
      "Validation Loss: 59.5175\n",
      "NME: 0.2811\n",
      "Epoch [283/300], Loss: 26.1827\n",
      "Validation Loss: 61.4682\n",
      "NME: 0.2960\n",
      "Epoch [284/300], Loss: 25.3916\n",
      "Validation Loss: 58.3431\n",
      "NME: 0.2863\n",
      "Epoch [285/300], Loss: 25.8775\n",
      "Validation Loss: 59.9670\n",
      "NME: 0.2947\n",
      "Epoch [286/300], Loss: 26.2966\n",
      "Validation Loss: 57.8058\n",
      "NME: 0.2854\n",
      "Best model saved at epoch 286 with val_loss 57.8058\n",
      "Epoch [287/300], Loss: 30.1160\n",
      "Validation Loss: 63.7148\n",
      "NME: 0.3149\n",
      "Epoch [288/300], Loss: 26.5190\n",
      "Validation Loss: 58.1156\n",
      "NME: 0.2873\n",
      "Epoch [289/300], Loss: 26.4864\n",
      "Validation Loss: 57.1907\n",
      "NME: 0.2885\n",
      "Best model saved at epoch 289 with val_loss 57.1907\n",
      "Epoch [290/300], Loss: 27.0806\n",
      "Validation Loss: 60.0339\n",
      "NME: 0.2934\n",
      "Epoch [291/300], Loss: 26.6603\n",
      "Validation Loss: 60.7517\n",
      "NME: 0.2875\n",
      "Epoch [292/300], Loss: 27.8024\n",
      "Validation Loss: 57.7277\n",
      "NME: 0.2831\n",
      "Epoch [293/300], Loss: 26.9357\n",
      "Validation Loss: 59.7145\n",
      "NME: 0.2859\n",
      "Epoch [294/300], Loss: 23.9550\n",
      "Validation Loss: 57.9370\n",
      "NME: 0.2874\n",
      "Epoch [295/300], Loss: 23.9380\n",
      "Validation Loss: 58.7757\n",
      "NME: 0.2877\n",
      "Epoch [296/300], Loss: 23.9548\n",
      "Validation Loss: 57.8326\n",
      "NME: 0.2840\n",
      "Epoch [297/300], Loss: 23.6382\n",
      "Validation Loss: 57.9885\n",
      "NME: 0.2838\n",
      "Epoch [298/300], Loss: 23.0551\n",
      "Validation Loss: 57.7382\n",
      "NME: 0.2890\n",
      "Epoch [299/300], Loss: 23.8357\n",
      "Validation Loss: 57.6837\n",
      "NME: 0.2837\n",
      "Epoch [300/300], Loss: 22.9773\n",
      "Validation Loss: 58.7508\n",
      "NME: 0.2895\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los 칤ndices de las regiones seg칰n los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "\n",
    "# Funci칩n para calcular el punto promedio de una regi칩n\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EyeLeftDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el 치ngulo de rotaci칩n\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotaci칩n\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave del ojo izquierdo\n",
    "        eye_left_points = np.array([landmarks[i] for i in ojo_izq], dtype=np.float32)\n",
    "        eye_left_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotaci칩n\n",
    "        ones = np.ones(shape=(len(eye_left_points), 1))\n",
    "        points_ones = np.hstack([eye_left_points, ones])\n",
    "        eye_left_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado del ojo izquierdo\n",
    "        centro_x, centro_y = calcular_centro_region(eye_left_points_rotated, range(len(ojo_izq)))\n",
    "\n",
    "        # Definir los l칤mites del recorte de 56x56 p칤xeles\n",
    "        half_crop_size = 28\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_eye = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_eye, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales del ojo izquierdo al nuevo recorte\n",
    "        eye_left_points_adjusted = [(p[0] - x1, p[1] - y1) for p in eye_left_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        eye_left_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in eye_left_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=eye_left_points_scaled)\n",
    "            image = augmented['image']\n",
    "            eye_left_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(eye_left_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotaci칩n aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicaci칩n de m치scaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validaci칩n\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validaci칩n\n",
    "train_dataset = EyeLeftDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EyeLeftDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EyeLeft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EyeLeft, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(ojo_izq) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuraci칩n y entrenamiento\n",
    "model = DenseNet121EyeLeft().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la f칩rmula espec칤fica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tama침o (N, M, 2), donde\n",
    "                        N es el n칰mero de im치genes, M el n칰mero de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tama침o que predictions.\n",
    "    :param num_landmarks: N칰mero de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los 칤ndices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para ojo izquierdo)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la f칩rmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, eye_left_points, _, _, _ in train_dataloader:\n",
    "            images, eye_left_points = images.cuda(), eye_left_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, eye_left_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validaci칩n y c치lculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_eye_left_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_eye_left_points = val_images.cuda(), val_eye_left_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_eye_left_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el c치lculo de NME\n",
    "                    all_labels.append(val_eye_left_points.cpu().numpy().reshape(-1, len(ojo_izq), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(ojo_izq), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(ojo_izq))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EyeLeftLandmarks V2.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14212.2814\n",
      "Validation Loss: 12039.6662\n",
      "NME: 6.7084\n",
      "Best model saved at epoch 1 with val_loss 12039.6662\n",
      "Epoch [2/300], Loss: 6811.4053\n",
      "Validation Loss: 2062.4994\n",
      "NME: 2.2246\n",
      "Best model saved at epoch 2 with val_loss 2062.4994\n",
      "Epoch [3/300], Loss: 1115.2185\n",
      "Validation Loss: 680.4316\n",
      "NME: 1.1018\n",
      "Best model saved at epoch 3 with val_loss 680.4316\n",
      "Epoch [4/300], Loss: 675.0620\n",
      "Validation Loss: 579.1433\n",
      "NME: 1.0557\n",
      "Best model saved at epoch 4 with val_loss 579.1433\n",
      "Epoch [5/300], Loss: 648.3628\n",
      "Validation Loss: 579.7174\n",
      "NME: 1.0577\n",
      "Epoch [6/300], Loss: 646.2025\n",
      "Validation Loss: 568.0584\n",
      "NME: 1.0353\n",
      "Best model saved at epoch 6 with val_loss 568.0584\n",
      "Epoch [7/300], Loss: 635.3362\n",
      "Validation Loss: 561.9599\n",
      "NME: 1.0271\n",
      "Best model saved at epoch 7 with val_loss 561.9599\n",
      "Epoch [8/300], Loss: 625.6166\n",
      "Validation Loss: 549.0863\n",
      "NME: 1.0458\n",
      "Best model saved at epoch 8 with val_loss 549.0863\n",
      "Epoch [9/300], Loss: 623.0666\n",
      "Validation Loss: 540.1474\n",
      "NME: 1.0057\n",
      "Best model saved at epoch 9 with val_loss 540.1474\n",
      "Epoch [10/300], Loss: 618.3102\n",
      "Validation Loss: 527.3660\n",
      "NME: 0.9940\n",
      "Best model saved at epoch 10 with val_loss 527.3660\n",
      "Epoch [11/300], Loss: 602.9664\n",
      "Validation Loss: 509.8333\n",
      "NME: 0.9711\n",
      "Best model saved at epoch 11 with val_loss 509.8333\n",
      "Epoch [12/300], Loss: 570.4297\n",
      "Validation Loss: 474.5298\n",
      "NME: 0.9198\n",
      "Best model saved at epoch 12 with val_loss 474.5298\n",
      "Epoch [13/300], Loss: 528.8890\n",
      "Validation Loss: 405.6913\n",
      "NME: 0.8485\n",
      "Best model saved at epoch 13 with val_loss 405.6913\n",
      "Epoch [14/300], Loss: 465.8347\n",
      "Validation Loss: 324.0214\n",
      "NME: 0.7399\n",
      "Best model saved at epoch 14 with val_loss 324.0214\n",
      "Epoch [15/300], Loss: 390.3183\n",
      "Validation Loss: 258.3664\n",
      "NME: 0.6534\n",
      "Best model saved at epoch 15 with val_loss 258.3664\n",
      "Epoch [16/300], Loss: 328.8582\n",
      "Validation Loss: 191.5722\n",
      "NME: 0.5371\n",
      "Best model saved at epoch 16 with val_loss 191.5722\n",
      "Epoch [17/300], Loss: 272.7599\n",
      "Validation Loss: 153.6655\n",
      "NME: 0.4981\n",
      "Best model saved at epoch 17 with val_loss 153.6655\n",
      "Epoch [18/300], Loss: 258.8261\n",
      "Validation Loss: 143.1337\n",
      "NME: 0.4875\n",
      "Best model saved at epoch 18 with val_loss 143.1337\n",
      "Epoch [19/300], Loss: 234.9280\n",
      "Validation Loss: 135.2104\n",
      "NME: 0.4590\n",
      "Best model saved at epoch 19 with val_loss 135.2104\n",
      "Epoch [20/300], Loss: 249.4136\n",
      "Validation Loss: 136.5649\n",
      "NME: 0.4632\n",
      "Epoch [21/300], Loss: 241.3333\n",
      "Validation Loss: 119.8432\n",
      "NME: 0.4369\n",
      "Best model saved at epoch 21 with val_loss 119.8432\n",
      "Epoch [22/300], Loss: 217.2023\n",
      "Validation Loss: 116.8337\n",
      "NME: 0.4296\n",
      "Best model saved at epoch 22 with val_loss 116.8337\n",
      "Epoch [23/300], Loss: 222.3845\n",
      "Validation Loss: 126.1351\n",
      "NME: 0.4569\n",
      "Epoch [24/300], Loss: 209.0039\n",
      "Validation Loss: 121.8744\n",
      "NME: 0.4460\n",
      "Epoch [25/300], Loss: 231.1865\n",
      "Validation Loss: 136.5482\n",
      "NME: 0.4793\n",
      "Epoch [26/300], Loss: 235.7900\n",
      "Validation Loss: 136.7233\n",
      "NME: 0.4594\n",
      "Epoch [27/300], Loss: 201.3012\n",
      "Validation Loss: 122.9833\n",
      "NME: 0.4448\n",
      "Epoch [28/300], Loss: 208.0071\n",
      "Validation Loss: 123.8809\n",
      "NME: 0.4494\n",
      "Epoch [29/300], Loss: 202.8920\n",
      "Validation Loss: 126.9395\n",
      "NME: 0.4744\n",
      "Epoch [30/300], Loss: 192.2218\n",
      "Validation Loss: 122.2245\n",
      "NME: 0.4835\n",
      "Epoch [31/300], Loss: 212.5485\n",
      "Validation Loss: 123.0664\n",
      "NME: 0.4927\n",
      "Epoch [32/300], Loss: 196.3490\n",
      "Validation Loss: 119.5020\n",
      "NME: 0.4625\n",
      "Epoch [33/300], Loss: 205.7208\n",
      "Validation Loss: 121.0558\n",
      "NME: 0.4549\n",
      "Epoch [34/300], Loss: 189.5265\n",
      "Validation Loss: 119.0800\n",
      "NME: 0.4446\n",
      "Epoch [35/300], Loss: 200.6281\n",
      "Validation Loss: 126.7251\n",
      "NME: 0.4945\n",
      "Epoch [36/300], Loss: 182.0089\n",
      "Validation Loss: 127.4552\n",
      "NME: 0.5301\n",
      "Epoch [37/300], Loss: 188.9025\n",
      "Validation Loss: 133.0772\n",
      "NME: 0.5070\n",
      "Epoch [38/300], Loss: 185.4630\n",
      "Validation Loss: 114.4398\n",
      "NME: 0.4495\n",
      "Best model saved at epoch 38 with val_loss 114.4398\n",
      "Epoch [39/300], Loss: 192.0143\n",
      "Validation Loss: 113.5669\n",
      "NME: 0.4395\n",
      "Best model saved at epoch 39 with val_loss 113.5669\n",
      "Epoch [40/300], Loss: 186.2784\n",
      "Validation Loss: 113.5243\n",
      "NME: 0.4424\n",
      "Best model saved at epoch 40 with val_loss 113.5243\n",
      "Epoch [41/300], Loss: 186.8541\n",
      "Validation Loss: 109.0550\n",
      "NME: 0.4324\n",
      "Best model saved at epoch 41 with val_loss 109.0550\n",
      "Epoch [42/300], Loss: 183.3599\n",
      "Validation Loss: 118.1386\n",
      "NME: 0.4549\n",
      "Epoch [43/300], Loss: 195.5060\n",
      "Validation Loss: 105.0552\n",
      "NME: 0.4118\n",
      "Best model saved at epoch 43 with val_loss 105.0552\n",
      "Epoch [44/300], Loss: 186.6240\n",
      "Validation Loss: 145.6457\n",
      "NME: 0.5624\n",
      "Epoch [45/300], Loss: 196.9877\n",
      "Validation Loss: 155.8062\n",
      "NME: 0.4817\n",
      "Epoch [46/300], Loss: 194.2531\n",
      "Validation Loss: 118.5885\n",
      "NME: 0.4672\n",
      "Epoch [47/300], Loss: 189.6588\n",
      "Validation Loss: 118.7582\n",
      "NME: 0.4733\n",
      "Epoch [48/300], Loss: 193.5536\n",
      "Validation Loss: 112.1877\n",
      "NME: 0.4451\n",
      "Epoch [49/300], Loss: 185.0092\n",
      "Validation Loss: 118.4190\n",
      "NME: 0.4590\n",
      "Epoch [50/300], Loss: 195.1658\n",
      "Validation Loss: 120.0555\n",
      "NME: 0.4476\n",
      "Epoch [51/300], Loss: 182.9519\n",
      "Validation Loss: 124.4017\n",
      "NME: 0.4538\n",
      "Epoch [52/300], Loss: 205.4690\n",
      "Validation Loss: 148.0956\n",
      "NME: 0.4652\n",
      "Epoch [53/300], Loss: 213.6983\n",
      "Validation Loss: 119.6534\n",
      "NME: 0.4678\n",
      "Epoch [54/300], Loss: 197.3600\n",
      "Validation Loss: 127.0924\n",
      "NME: 0.4532\n",
      "Epoch [55/300], Loss: 178.8884\n",
      "Validation Loss: 115.5315\n",
      "NME: 0.4442\n",
      "Epoch [56/300], Loss: 188.4137\n",
      "Validation Loss: 116.7667\n",
      "NME: 0.4355\n",
      "Epoch [57/300], Loss: 181.2626\n",
      "Validation Loss: 110.4243\n",
      "NME: 0.4236\n",
      "Epoch [58/300], Loss: 189.2899\n",
      "Validation Loss: 111.9730\n",
      "NME: 0.4355\n",
      "Epoch [59/300], Loss: 189.2703\n",
      "Validation Loss: 113.3727\n",
      "NME: 0.4407\n",
      "Epoch [60/300], Loss: 184.6245\n",
      "Validation Loss: 110.6508\n",
      "NME: 0.4288\n",
      "Epoch [61/300], Loss: 178.8837\n",
      "Validation Loss: 114.4191\n",
      "NME: 0.4408\n",
      "Epoch [62/300], Loss: 191.3455\n",
      "Validation Loss: 106.9729\n",
      "NME: 0.4326\n",
      "Epoch [63/300], Loss: 173.8831\n",
      "Validation Loss: 105.3922\n",
      "NME: 0.4217\n",
      "Epoch [64/300], Loss: 172.7310\n",
      "Validation Loss: 106.3603\n",
      "NME: 0.4187\n",
      "Epoch [65/300], Loss: 173.2772\n",
      "Validation Loss: 112.0112\n",
      "NME: 0.4290\n",
      "Epoch [66/300], Loss: 160.6271\n",
      "Validation Loss: 102.5708\n",
      "NME: 0.4115\n",
      "Best model saved at epoch 66 with val_loss 102.5708\n",
      "Epoch [67/300], Loss: 152.2932\n",
      "Validation Loss: 107.5347\n",
      "NME: 0.4391\n",
      "Epoch [68/300], Loss: 165.3670\n",
      "Validation Loss: 105.9972\n",
      "NME: 0.4043\n",
      "Epoch [69/300], Loss: 141.4345\n",
      "Validation Loss: 104.7821\n",
      "NME: 0.4133\n",
      "Epoch [70/300], Loss: 142.1605\n",
      "Validation Loss: 112.0027\n",
      "NME: 0.4361\n",
      "Epoch [71/300], Loss: 121.3256\n",
      "Validation Loss: 104.1070\n",
      "NME: 0.3934\n",
      "Epoch [72/300], Loss: 122.3802\n",
      "Validation Loss: 100.9948\n",
      "NME: 0.4011\n",
      "Best model saved at epoch 72 with val_loss 100.9948\n",
      "Epoch [73/300], Loss: 115.3904\n",
      "Validation Loss: 113.5962\n",
      "NME: 0.4448\n",
      "Epoch [74/300], Loss: 107.0079\n",
      "Validation Loss: 102.0615\n",
      "NME: 0.3994\n",
      "Epoch [75/300], Loss: 100.2015\n",
      "Validation Loss: 99.3900\n",
      "NME: 0.4046\n",
      "Best model saved at epoch 75 with val_loss 99.3900\n",
      "Epoch [76/300], Loss: 103.1613\n",
      "Validation Loss: 106.6430\n",
      "NME: 0.4017\n",
      "Epoch [77/300], Loss: 90.3682\n",
      "Validation Loss: 92.8927\n",
      "NME: 0.3867\n",
      "Best model saved at epoch 77 with val_loss 92.8927\n",
      "Epoch [78/300], Loss: 101.8311\n",
      "Validation Loss: 105.3980\n",
      "NME: 0.3929\n",
      "Epoch [79/300], Loss: 103.7398\n",
      "Validation Loss: 95.7567\n",
      "NME: 0.3925\n",
      "Epoch [80/300], Loss: 87.0762\n",
      "Validation Loss: 93.1362\n",
      "NME: 0.3781\n",
      "Epoch [81/300], Loss: 87.1777\n",
      "Validation Loss: 93.8781\n",
      "NME: 0.3828\n",
      "Epoch [82/300], Loss: 87.4000\n",
      "Validation Loss: 86.2874\n",
      "NME: 0.3693\n",
      "Best model saved at epoch 82 with val_loss 86.2874\n",
      "Epoch [83/300], Loss: 92.4723\n",
      "Validation Loss: 99.8245\n",
      "NME: 0.3967\n",
      "Epoch [84/300], Loss: 83.8128\n",
      "Validation Loss: 91.4217\n",
      "NME: 0.3766\n",
      "Epoch [85/300], Loss: 83.5534\n",
      "Validation Loss: 86.2280\n",
      "NME: 0.3659\n",
      "Best model saved at epoch 85 with val_loss 86.2280\n",
      "Epoch [86/300], Loss: 82.8791\n",
      "Validation Loss: 91.5082\n",
      "NME: 0.3809\n",
      "Epoch [87/300], Loss: 80.8896\n",
      "Validation Loss: 89.3324\n",
      "NME: 0.3673\n",
      "Epoch [88/300], Loss: 92.4527\n",
      "Validation Loss: 94.1143\n",
      "NME: 0.3797\n",
      "Epoch [89/300], Loss: 85.0325\n",
      "Validation Loss: 98.5549\n",
      "NME: 0.3685\n",
      "Epoch [90/300], Loss: 81.2758\n",
      "Validation Loss: 92.7886\n",
      "NME: 0.3881\n",
      "Epoch [91/300], Loss: 75.0495\n",
      "Validation Loss: 86.4951\n",
      "NME: 0.3559\n",
      "Epoch [92/300], Loss: 74.8150\n",
      "Validation Loss: 91.5974\n",
      "NME: 0.3594\n",
      "Epoch [93/300], Loss: 79.6872\n",
      "Validation Loss: 87.6406\n",
      "NME: 0.3599\n",
      "Epoch [94/300], Loss: 74.3468\n",
      "Validation Loss: 85.0161\n",
      "NME: 0.3469\n",
      "Best model saved at epoch 94 with val_loss 85.0161\n",
      "Epoch [95/300], Loss: 70.7397\n",
      "Validation Loss: 82.8316\n",
      "NME: 0.3508\n",
      "Best model saved at epoch 95 with val_loss 82.8316\n",
      "Epoch [96/300], Loss: 68.8469\n",
      "Validation Loss: 82.6363\n",
      "NME: 0.3434\n",
      "Best model saved at epoch 96 with val_loss 82.6363\n",
      "Epoch [97/300], Loss: 63.8357\n",
      "Validation Loss: 80.9814\n",
      "NME: 0.3415\n",
      "Best model saved at epoch 97 with val_loss 80.9814\n",
      "Epoch [98/300], Loss: 68.8790\n",
      "Validation Loss: 83.6349\n",
      "NME: 0.3484\n",
      "Epoch [99/300], Loss: 61.7845\n",
      "Validation Loss: 83.2917\n",
      "NME: 0.3640\n",
      "Epoch [100/300], Loss: 67.1907\n",
      "Validation Loss: 81.3544\n",
      "NME: 0.3396\n",
      "Epoch [101/300], Loss: 64.0851\n",
      "Validation Loss: 83.4299\n",
      "NME: 0.3481\n",
      "Epoch [102/300], Loss: 62.2554\n",
      "Validation Loss: 85.4539\n",
      "NME: 0.3531\n",
      "Epoch [103/300], Loss: 70.8625\n",
      "Validation Loss: 79.0361\n",
      "NME: 0.3334\n",
      "Best model saved at epoch 103 with val_loss 79.0361\n",
      "Epoch [104/300], Loss: 63.5957\n",
      "Validation Loss: 78.0648\n",
      "NME: 0.3282\n",
      "Best model saved at epoch 104 with val_loss 78.0648\n",
      "Epoch [105/300], Loss: 58.9393\n",
      "Validation Loss: 80.0319\n",
      "NME: 0.3279\n",
      "Epoch [106/300], Loss: 59.3892\n",
      "Validation Loss: 79.2536\n",
      "NME: 0.3295\n",
      "Epoch [107/300], Loss: 58.7639\n",
      "Validation Loss: 78.1019\n",
      "NME: 0.3384\n",
      "Epoch [108/300], Loss: 57.5200\n",
      "Validation Loss: 75.4534\n",
      "NME: 0.3271\n",
      "Best model saved at epoch 108 with val_loss 75.4534\n",
      "Epoch [109/300], Loss: 56.0478\n",
      "Validation Loss: 74.5331\n",
      "NME: 0.3334\n",
      "Best model saved at epoch 109 with val_loss 74.5331\n",
      "Epoch [110/300], Loss: 57.1666\n",
      "Validation Loss: 74.6930\n",
      "NME: 0.3238\n",
      "Epoch [111/300], Loss: 65.7610\n",
      "Validation Loss: 79.4522\n",
      "NME: 0.3342\n",
      "Epoch [112/300], Loss: 58.5659\n",
      "Validation Loss: 77.6265\n",
      "NME: 0.3353\n",
      "Epoch [113/300], Loss: 60.5825\n",
      "Validation Loss: 77.1087\n",
      "NME: 0.3315\n",
      "Epoch [114/300], Loss: 68.2397\n",
      "Validation Loss: 81.5252\n",
      "NME: 0.3439\n",
      "Epoch [115/300], Loss: 63.0237\n",
      "Validation Loss: 79.4555\n",
      "NME: 0.3260\n",
      "Epoch [116/300], Loss: 59.3745\n",
      "Validation Loss: 83.0806\n",
      "NME: 0.3368\n",
      "Epoch [117/300], Loss: 61.6980\n",
      "Validation Loss: 86.3308\n",
      "NME: 0.3410\n",
      "Epoch [118/300], Loss: 61.9214\n",
      "Validation Loss: 76.2161\n",
      "NME: 0.3189\n",
      "Epoch [119/300], Loss: 54.5053\n",
      "Validation Loss: 74.5657\n",
      "NME: 0.3136\n",
      "Epoch [120/300], Loss: 53.9098\n",
      "Validation Loss: 76.0649\n",
      "NME: 0.3116\n",
      "Epoch [121/300], Loss: 52.6737\n",
      "Validation Loss: 74.1320\n",
      "NME: 0.3172\n",
      "Best model saved at epoch 121 with val_loss 74.1320\n",
      "Epoch [122/300], Loss: 57.8363\n",
      "Validation Loss: 79.4491\n",
      "NME: 0.3196\n",
      "Epoch [123/300], Loss: 50.9682\n",
      "Validation Loss: 72.2994\n",
      "NME: 0.3133\n",
      "Best model saved at epoch 123 with val_loss 72.2994\n",
      "Epoch [124/300], Loss: 50.8735\n",
      "Validation Loss: 72.9695\n",
      "NME: 0.3131\n",
      "Epoch [125/300], Loss: 51.6897\n",
      "Validation Loss: 72.8769\n",
      "NME: 0.3083\n",
      "Epoch [126/300], Loss: 50.1066\n",
      "Validation Loss: 74.7784\n",
      "NME: 0.3132\n",
      "Epoch [127/300], Loss: 50.2789\n",
      "Validation Loss: 90.9405\n",
      "NME: 0.3638\n",
      "Epoch [128/300], Loss: 59.3248\n",
      "Validation Loss: 79.2573\n",
      "NME: 0.3221\n",
      "Epoch [129/300], Loss: 56.5830\n",
      "Validation Loss: 85.2415\n",
      "NME: 0.3507\n",
      "Epoch [130/300], Loss: 54.8930\n",
      "Validation Loss: 76.2467\n",
      "NME: 0.3190\n",
      "Epoch [131/300], Loss: 51.3079\n",
      "Validation Loss: 76.5249\n",
      "NME: 0.3235\n",
      "Epoch [132/300], Loss: 54.4780\n",
      "Validation Loss: 71.2888\n",
      "NME: 0.3122\n",
      "Best model saved at epoch 132 with val_loss 71.2888\n",
      "Epoch [133/300], Loss: 51.3884\n",
      "Validation Loss: 85.8715\n",
      "NME: 0.3428\n",
      "Epoch [134/300], Loss: 64.7084\n",
      "Validation Loss: 78.6410\n",
      "NME: 0.3280\n",
      "Epoch [135/300], Loss: 67.7735\n",
      "Validation Loss: 81.8278\n",
      "NME: 0.3219\n",
      "Epoch [136/300], Loss: 54.7093\n",
      "Validation Loss: 79.2738\n",
      "NME: 0.3423\n",
      "Epoch [137/300], Loss: 56.1493\n",
      "Validation Loss: 82.6790\n",
      "NME: 0.3361\n",
      "Epoch [138/300], Loss: 52.5647\n",
      "Validation Loss: 81.4520\n",
      "NME: 0.3269\n",
      "Epoch [139/300], Loss: 50.0376\n",
      "Validation Loss: 76.2962\n",
      "NME: 0.3132\n",
      "Epoch [140/300], Loss: 49.3333\n",
      "Validation Loss: 75.8827\n",
      "NME: 0.3107\n",
      "Epoch [141/300], Loss: 48.1025\n",
      "Validation Loss: 74.5181\n",
      "NME: 0.3148\n",
      "Epoch [142/300], Loss: 48.9545\n",
      "Validation Loss: 75.5791\n",
      "NME: 0.3241\n",
      "Epoch [143/300], Loss: 49.3906\n",
      "Validation Loss: 76.1904\n",
      "NME: 0.3116\n",
      "Epoch [144/300], Loss: 48.6496\n",
      "Validation Loss: 74.8496\n",
      "NME: 0.3130\n",
      "Epoch [145/300], Loss: 48.8901\n",
      "Validation Loss: 78.2934\n",
      "NME: 0.3271\n",
      "Epoch [146/300], Loss: 50.0595\n",
      "Validation Loss: 76.1741\n",
      "NME: 0.3121\n",
      "Epoch [147/300], Loss: 45.9133\n",
      "Validation Loss: 74.1225\n",
      "NME: 0.3173\n",
      "Epoch [148/300], Loss: 46.0861\n",
      "Validation Loss: 71.1242\n",
      "NME: 0.3099\n",
      "Best model saved at epoch 148 with val_loss 71.1242\n",
      "Epoch [149/300], Loss: 44.9777\n",
      "Validation Loss: 71.1015\n",
      "NME: 0.3135\n",
      "Best model saved at epoch 149 with val_loss 71.1015\n",
      "Epoch [150/300], Loss: 44.6040\n",
      "Validation Loss: 73.6655\n",
      "NME: 0.3124\n",
      "Epoch [151/300], Loss: 45.9284\n",
      "Validation Loss: 73.4230\n",
      "NME: 0.3219\n",
      "Epoch [152/300], Loss: 46.1628\n",
      "Validation Loss: 72.3286\n",
      "NME: 0.3197\n",
      "Epoch [153/300], Loss: 46.3153\n",
      "Validation Loss: 76.6262\n",
      "NME: 0.3331\n",
      "Epoch [154/300], Loss: 45.2870\n",
      "Validation Loss: 76.1097\n",
      "NME: 0.3137\n",
      "Epoch [155/300], Loss: 44.3382\n",
      "Validation Loss: 73.2577\n",
      "NME: 0.3139\n",
      "Epoch [156/300], Loss: 48.6670\n",
      "Validation Loss: 72.3477\n",
      "NME: 0.3232\n",
      "Epoch [157/300], Loss: 50.6176\n",
      "Validation Loss: 73.3955\n",
      "NME: 0.3199\n",
      "Epoch [158/300], Loss: 47.8913\n",
      "Validation Loss: 75.2981\n",
      "NME: 0.3307\n",
      "Epoch [159/300], Loss: 47.9056\n",
      "Validation Loss: 73.5432\n",
      "NME: 0.3135\n",
      "Epoch [160/300], Loss: 45.0430\n",
      "Validation Loss: 72.5228\n",
      "NME: 0.3086\n",
      "Epoch [161/300], Loss: 44.0900\n",
      "Validation Loss: 73.2885\n",
      "NME: 0.3177\n",
      "Epoch [162/300], Loss: 47.3483\n",
      "Validation Loss: 75.6437\n",
      "NME: 0.3218\n",
      "Epoch [163/300], Loss: 48.4500\n",
      "Validation Loss: 75.5334\n",
      "NME: 0.3233\n",
      "Epoch [164/300], Loss: 49.0685\n",
      "Validation Loss: 95.4006\n",
      "NME: 0.3803\n",
      "Epoch [165/300], Loss: 49.6277\n",
      "Validation Loss: 71.9747\n",
      "NME: 0.3118\n",
      "Epoch [166/300], Loss: 62.4834\n",
      "Validation Loss: 99.3959\n",
      "NME: 0.3485\n",
      "Epoch [167/300], Loss: 67.5145\n",
      "Validation Loss: 82.4009\n",
      "NME: 0.3184\n",
      "Epoch [168/300], Loss: 48.8481\n",
      "Validation Loss: 77.4446\n",
      "NME: 0.3220\n",
      "Epoch [169/300], Loss: 50.1128\n",
      "Validation Loss: 79.9579\n",
      "NME: 0.3178\n",
      "Epoch [170/300], Loss: 47.2163\n",
      "Validation Loss: 75.9152\n",
      "NME: 0.3266\n",
      "Epoch [171/300], Loss: 48.0393\n",
      "Validation Loss: 74.8580\n",
      "NME: 0.3177\n",
      "Epoch [172/300], Loss: 43.3662\n",
      "Validation Loss: 72.3164\n",
      "NME: 0.3117\n",
      "Epoch [173/300], Loss: 43.6589\n",
      "Validation Loss: 70.8575\n",
      "NME: 0.3052\n",
      "Best model saved at epoch 173 with val_loss 70.8575\n",
      "Epoch [174/300], Loss: 43.7178\n",
      "Validation Loss: 71.6280\n",
      "NME: 0.3130\n",
      "Epoch [175/300], Loss: 45.3744\n",
      "Validation Loss: 75.1584\n",
      "NME: 0.3178\n",
      "Epoch [176/300], Loss: 46.3178\n",
      "Validation Loss: 73.5262\n",
      "NME: 0.3163\n",
      "Epoch [177/300], Loss: 44.2058\n",
      "Validation Loss: 71.5384\n",
      "NME: 0.3060\n",
      "Epoch [178/300], Loss: 42.3649\n",
      "Validation Loss: 70.5883\n",
      "NME: 0.3082\n",
      "Best model saved at epoch 178 with val_loss 70.5883\n",
      "Epoch [179/300], Loss: 40.9651\n",
      "Validation Loss: 70.1614\n",
      "NME: 0.3162\n",
      "Best model saved at epoch 179 with val_loss 70.1614\n",
      "Epoch [180/300], Loss: 40.2232\n",
      "Validation Loss: 66.5424\n",
      "NME: 0.3026\n",
      "Best model saved at epoch 180 with val_loss 66.5424\n",
      "Epoch [181/300], Loss: 41.6918\n",
      "Validation Loss: 70.4329\n",
      "NME: 0.3043\n",
      "Epoch [182/300], Loss: 42.3395\n",
      "Validation Loss: 70.1908\n",
      "NME: 0.3092\n",
      "Epoch [183/300], Loss: 41.1206\n",
      "Validation Loss: 71.7003\n",
      "NME: 0.3216\n",
      "Epoch [184/300], Loss: 41.3117\n",
      "Validation Loss: 69.6876\n",
      "NME: 0.3176\n",
      "Epoch [185/300], Loss: 40.1835\n",
      "Validation Loss: 69.7124\n",
      "NME: 0.3053\n",
      "Epoch [186/300], Loss: 45.1490\n",
      "Validation Loss: 73.9041\n",
      "NME: 0.3057\n",
      "Epoch [187/300], Loss: 40.7815\n",
      "Validation Loss: 71.2484\n",
      "NME: 0.3115\n",
      "Epoch [188/300], Loss: 39.9496\n",
      "Validation Loss: 70.2183\n",
      "NME: 0.3053\n",
      "Epoch [189/300], Loss: 38.5983\n",
      "Validation Loss: 71.6710\n",
      "NME: 0.3143\n",
      "Epoch [190/300], Loss: 38.2094\n",
      "Validation Loss: 67.4844\n",
      "NME: 0.3009\n",
      "Epoch [191/300], Loss: 37.0097\n",
      "Validation Loss: 72.1673\n",
      "NME: 0.2962\n",
      "Epoch [192/300], Loss: 36.8974\n",
      "Validation Loss: 66.3945\n",
      "NME: 0.2984\n",
      "Best model saved at epoch 192 with val_loss 66.3945\n",
      "Epoch [193/300], Loss: 46.8450\n",
      "Validation Loss: 70.3580\n",
      "NME: 0.3190\n",
      "Epoch [194/300], Loss: 41.7992\n",
      "Validation Loss: 67.5384\n",
      "NME: 0.3046\n",
      "Epoch [195/300], Loss: 37.3364\n",
      "Validation Loss: 65.9425\n",
      "NME: 0.3064\n",
      "Best model saved at epoch 195 with val_loss 65.9425\n",
      "Epoch [196/300], Loss: 41.2796\n",
      "Validation Loss: 78.4734\n",
      "NME: 0.3460\n",
      "Epoch [197/300], Loss: 42.7524\n",
      "Validation Loss: 68.2416\n",
      "NME: 0.3040\n",
      "Epoch [198/300], Loss: 38.5372\n",
      "Validation Loss: 67.2911\n",
      "NME: 0.3045\n",
      "Epoch [199/300], Loss: 41.0025\n",
      "Validation Loss: 67.3663\n",
      "NME: 0.3007\n",
      "Epoch [200/300], Loss: 37.2443\n",
      "Validation Loss: 64.7661\n",
      "NME: 0.2961\n",
      "Best model saved at epoch 200 with val_loss 64.7661\n",
      "Epoch [201/300], Loss: 36.2180\n",
      "Validation Loss: 66.5917\n",
      "NME: 0.3081\n",
      "Epoch [202/300], Loss: 36.5683\n",
      "Validation Loss: 64.9169\n",
      "NME: 0.2984\n",
      "Epoch [203/300], Loss: 37.6089\n",
      "Validation Loss: 66.2728\n",
      "NME: 0.2988\n",
      "Epoch [204/300], Loss: 36.0828\n",
      "Validation Loss: 67.1526\n",
      "NME: 0.2952\n",
      "Epoch [205/300], Loss: 34.1387\n",
      "Validation Loss: 66.7900\n",
      "NME: 0.3024\n",
      "Epoch [206/300], Loss: 37.3978\n",
      "Validation Loss: 68.4337\n",
      "NME: 0.3022\n",
      "Epoch [207/300], Loss: 39.5517\n",
      "Validation Loss: 66.5933\n",
      "NME: 0.2983\n",
      "Epoch [208/300], Loss: 36.2129\n",
      "Validation Loss: 66.5608\n",
      "NME: 0.3069\n",
      "Epoch [209/300], Loss: 35.7265\n",
      "Validation Loss: 66.8914\n",
      "NME: 0.2983\n",
      "Epoch [210/300], Loss: 35.2843\n",
      "Validation Loss: 68.6663\n",
      "NME: 0.3101\n",
      "Epoch [211/300], Loss: 34.2642\n",
      "Validation Loss: 66.9879\n",
      "NME: 0.3121\n",
      "Epoch [212/300], Loss: 34.7484\n",
      "Validation Loss: 65.0861\n",
      "NME: 0.3019\n",
      "Epoch [213/300], Loss: 33.4396\n",
      "Validation Loss: 65.6023\n",
      "NME: 0.2981\n",
      "Epoch [214/300], Loss: 34.6937\n",
      "Validation Loss: 66.5911\n",
      "NME: 0.3029\n",
      "Epoch [215/300], Loss: 33.5708\n",
      "Validation Loss: 64.5742\n",
      "NME: 0.3017\n",
      "Best model saved at epoch 215 with val_loss 64.5742\n",
      "Epoch [216/300], Loss: 33.0220\n",
      "Validation Loss: 63.8543\n",
      "NME: 0.3000\n",
      "Best model saved at epoch 216 with val_loss 63.8543\n",
      "Epoch [217/300], Loss: 33.5981\n",
      "Validation Loss: 66.5863\n",
      "NME: 0.3067\n",
      "Epoch [218/300], Loss: 33.0281\n",
      "Validation Loss: 68.0010\n",
      "NME: 0.3034\n",
      "Epoch [219/300], Loss: 33.2246\n",
      "Validation Loss: 64.6870\n",
      "NME: 0.3001\n",
      "Epoch [220/300], Loss: 33.2768\n",
      "Validation Loss: 65.2810\n",
      "NME: 0.3033\n",
      "Epoch [221/300], Loss: 34.7705\n",
      "Validation Loss: 70.3382\n",
      "NME: 0.3166\n",
      "Epoch [222/300], Loss: 34.4276\n",
      "Validation Loss: 65.3436\n",
      "NME: 0.3046\n",
      "Epoch [223/300], Loss: 34.8770\n",
      "Validation Loss: 71.6026\n",
      "NME: 0.3142\n",
      "Epoch [224/300], Loss: 33.1633\n",
      "Validation Loss: 64.7179\n",
      "NME: 0.3032\n",
      "Epoch [225/300], Loss: 32.2480\n",
      "Validation Loss: 67.8496\n",
      "NME: 0.3018\n",
      "Epoch [226/300], Loss: 31.5175\n",
      "Validation Loss: 65.8844\n",
      "NME: 0.3084\n",
      "Epoch [227/300], Loss: 31.1842\n",
      "Validation Loss: 64.5662\n",
      "NME: 0.3088\n",
      "Epoch [228/300], Loss: 33.6973\n",
      "Validation Loss: 71.9671\n",
      "NME: 0.3115\n",
      "Epoch [229/300], Loss: 33.4432\n",
      "Validation Loss: 66.5889\n",
      "NME: 0.2989\n",
      "Epoch [230/300], Loss: 33.1147\n",
      "Validation Loss: 63.4926\n",
      "NME: 0.2994\n",
      "Best model saved at epoch 230 with val_loss 63.4926\n",
      "Epoch [231/300], Loss: 32.2887\n",
      "Validation Loss: 63.4966\n",
      "NME: 0.2968\n",
      "Epoch [232/300], Loss: 32.0010\n",
      "Validation Loss: 62.1038\n",
      "NME: 0.3026\n",
      "Best model saved at epoch 232 with val_loss 62.1038\n",
      "Epoch [233/300], Loss: 31.3924\n",
      "Validation Loss: 67.3019\n",
      "NME: 0.3034\n",
      "Epoch [234/300], Loss: 33.1580\n",
      "Validation Loss: 68.3799\n",
      "NME: 0.3092\n",
      "Epoch [235/300], Loss: 32.1237\n",
      "Validation Loss: 64.0059\n",
      "NME: 0.2970\n",
      "Epoch [236/300], Loss: 29.6262\n",
      "Validation Loss: 66.5434\n",
      "NME: 0.3025\n",
      "Epoch [237/300], Loss: 32.4553\n",
      "Validation Loss: 64.8399\n",
      "NME: 0.2986\n",
      "Epoch [238/300], Loss: 33.4354\n",
      "Validation Loss: 65.1941\n",
      "NME: 0.3090\n",
      "Epoch [239/300], Loss: 30.8830\n",
      "Validation Loss: 63.3746\n",
      "NME: 0.2957\n",
      "Epoch [240/300], Loss: 31.2283\n",
      "Validation Loss: 63.7464\n",
      "NME: 0.3001\n",
      "Epoch [241/300], Loss: 29.8907\n",
      "Validation Loss: 64.3278\n",
      "NME: 0.2972\n",
      "Epoch [242/300], Loss: 30.2865\n",
      "Validation Loss: 63.4126\n",
      "NME: 0.3003\n",
      "Epoch [243/300], Loss: 29.7118\n",
      "Validation Loss: 64.4646\n",
      "NME: 0.3003\n",
      "Epoch [244/300], Loss: 30.8197\n",
      "Validation Loss: 64.5447\n",
      "NME: 0.2969\n",
      "Epoch [245/300], Loss: 29.8263\n",
      "Validation Loss: 65.1544\n",
      "NME: 0.3075\n",
      "Epoch [246/300], Loss: 28.9072\n",
      "Validation Loss: 64.4983\n",
      "NME: 0.3045\n",
      "Epoch [247/300], Loss: 28.7401\n",
      "Validation Loss: 63.4493\n",
      "NME: 0.2961\n",
      "Epoch [248/300], Loss: 33.2961\n",
      "Validation Loss: 69.1476\n",
      "NME: 0.3068\n",
      "Epoch [249/300], Loss: 33.4680\n",
      "Validation Loss: 67.1869\n",
      "NME: 0.3105\n",
      "Epoch [250/300], Loss: 30.2006\n",
      "Validation Loss: 62.3115\n",
      "NME: 0.3022\n",
      "Epoch [251/300], Loss: 29.1476\n",
      "Validation Loss: 63.4996\n",
      "NME: 0.2997\n",
      "Epoch [252/300], Loss: 39.6418\n",
      "Validation Loss: 69.9606\n",
      "NME: 0.3280\n",
      "Epoch [253/300], Loss: 43.8465\n",
      "Validation Loss: 69.3902\n",
      "NME: 0.3051\n",
      "Epoch [254/300], Loss: 42.5083\n",
      "Validation Loss: 66.6861\n",
      "NME: 0.3007\n",
      "Epoch [255/300], Loss: 33.0047\n",
      "Validation Loss: 68.8861\n",
      "NME: 0.3021\n",
      "Epoch [256/300], Loss: 30.4289\n",
      "Validation Loss: 64.4270\n",
      "NME: 0.2911\n",
      "Epoch [257/300], Loss: 28.5535\n",
      "Validation Loss: 65.2044\n",
      "NME: 0.2986\n",
      "Epoch [258/300], Loss: 33.0295\n",
      "Validation Loss: 77.4222\n",
      "NME: 0.3340\n",
      "Epoch [259/300], Loss: 28.7622\n",
      "Validation Loss: 65.6643\n",
      "NME: 0.2930\n",
      "Epoch [260/300], Loss: 27.8606\n",
      "Validation Loss: 65.2730\n",
      "NME: 0.3002\n",
      "Epoch [261/300], Loss: 28.2029\n",
      "Validation Loss: 64.1211\n",
      "NME: 0.2964\n",
      "Epoch [262/300], Loss: 28.0033\n",
      "Validation Loss: 63.3274\n",
      "NME: 0.2988\n",
      "Epoch [263/300], Loss: 26.0350\n",
      "Validation Loss: 62.8391\n",
      "NME: 0.2900\n",
      "Epoch [264/300], Loss: 25.9549\n",
      "Validation Loss: 64.7665\n",
      "NME: 0.2907\n",
      "Epoch [265/300], Loss: 25.3579\n",
      "Validation Loss: 63.3297\n",
      "NME: 0.2903\n",
      "Epoch [266/300], Loss: 25.9066\n",
      "Validation Loss: 64.8104\n",
      "NME: 0.2962\n",
      "Epoch [267/300], Loss: 25.2471\n",
      "Validation Loss: 63.3377\n",
      "NME: 0.2961\n",
      "Epoch [268/300], Loss: 28.1077\n",
      "Validation Loss: 75.4880\n",
      "NME: 0.3333\n",
      "Epoch [269/300], Loss: 31.8656\n",
      "Validation Loss: 62.9199\n",
      "NME: 0.2934\n",
      "Epoch [270/300], Loss: 33.6796\n",
      "Validation Loss: 77.1077\n",
      "NME: 0.3162\n",
      "Epoch [271/300], Loss: 32.7625\n",
      "Validation Loss: 76.0393\n",
      "NME: 0.3227\n",
      "Epoch [272/300], Loss: 39.0357\n",
      "Validation Loss: 66.8403\n",
      "NME: 0.3006\n",
      "Epoch [273/300], Loss: 31.6387\n",
      "Validation Loss: 65.8793\n",
      "NME: 0.2960\n",
      "Epoch [274/300], Loss: 28.5368\n",
      "Validation Loss: 65.6299\n",
      "NME: 0.2953\n",
      "Epoch [275/300], Loss: 25.2724\n",
      "Validation Loss: 64.0631\n",
      "NME: 0.2956\n",
      "Epoch [276/300], Loss: 26.2586\n",
      "Validation Loss: 66.8035\n",
      "NME: 0.3036\n",
      "Epoch [277/300], Loss: 26.4999\n",
      "Validation Loss: 64.9355\n",
      "NME: 0.2921\n",
      "Epoch [278/300], Loss: 26.8176\n",
      "Validation Loss: 67.9678\n",
      "NME: 0.2959\n",
      "Epoch [279/300], Loss: 25.4300\n",
      "Validation Loss: 64.0236\n",
      "NME: 0.2930\n",
      "Epoch [280/300], Loss: 24.4299\n",
      "Validation Loss: 62.6874\n",
      "NME: 0.2958\n",
      "Epoch [281/300], Loss: 24.0843\n",
      "Validation Loss: 63.3250\n",
      "NME: 0.2871\n",
      "Epoch [282/300], Loss: 23.5830\n",
      "Validation Loss: 62.5778\n",
      "NME: 0.2849\n",
      "Epoch [283/300], Loss: 26.8905\n",
      "Validation Loss: 65.4759\n",
      "NME: 0.2984\n",
      "Epoch [284/300], Loss: 25.1535\n",
      "Validation Loss: 63.9294\n",
      "NME: 0.2949\n",
      "Epoch [285/300], Loss: 23.7331\n",
      "Validation Loss: 63.3830\n",
      "NME: 0.2969\n",
      "Epoch [286/300], Loss: 24.7682\n",
      "Validation Loss: 66.6838\n",
      "NME: 0.3165\n",
      "Epoch [287/300], Loss: 30.8057\n",
      "Validation Loss: 64.8484\n",
      "NME: 0.2947\n",
      "Epoch [288/300], Loss: 25.2117\n",
      "Validation Loss: 62.8001\n",
      "NME: 0.2962\n",
      "Epoch [289/300], Loss: 24.8363\n",
      "Validation Loss: 61.9227\n",
      "NME: 0.2924\n",
      "Best model saved at epoch 289 with val_loss 61.9227\n",
      "Epoch [290/300], Loss: 23.9094\n",
      "Validation Loss: 63.5008\n",
      "NME: 0.2983\n",
      "Epoch [291/300], Loss: 23.5220\n",
      "Validation Loss: 67.7349\n",
      "NME: 0.2971\n",
      "Epoch [292/300], Loss: 24.5809\n",
      "Validation Loss: 62.5027\n",
      "NME: 0.2883\n",
      "Epoch [293/300], Loss: 24.4285\n",
      "Validation Loss: 60.1509\n",
      "NME: 0.2868\n",
      "Best model saved at epoch 293 with val_loss 60.1509\n",
      "Epoch [294/300], Loss: 22.9068\n",
      "Validation Loss: 61.6171\n",
      "NME: 0.2903\n",
      "Epoch [295/300], Loss: 23.9545\n",
      "Validation Loss: 60.3940\n",
      "NME: 0.2890\n",
      "Epoch [296/300], Loss: 22.6797\n",
      "Validation Loss: 61.5426\n",
      "NME: 0.2897\n",
      "Epoch [297/300], Loss: 22.4674\n",
      "Validation Loss: 65.2834\n",
      "NME: 0.2857\n",
      "Epoch [298/300], Loss: 24.6298\n",
      "Validation Loss: 64.5860\n",
      "NME: 0.2940\n",
      "Epoch [299/300], Loss: 23.9954\n",
      "Validation Loss: 62.5943\n",
      "NME: 0.2879\n",
      "Epoch [300/300], Loss: 23.1293\n",
      "Validation Loss: 64.2155\n",
      "NME: 0.2919\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los 칤ndices de las regiones seg칰n los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "\n",
    "# Funci칩n para calcular el punto promedio de una regi칩n\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EyeRightDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el 치ngulo de rotaci칩n\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotaci칩n\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave del ojo derecho\n",
    "        eye_right_points = np.array([landmarks[i] for i in ojo_der], dtype=np.float32)\n",
    "        eye_right_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotaci칩n\n",
    "        ones = np.ones(shape=(len(eye_right_points), 1))\n",
    "        points_ones = np.hstack([eye_right_points, ones])\n",
    "        eye_right_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado del ojo derecho\n",
    "        centro_x, centro_y = calcular_centro_region(eye_right_points_rotated, range(len(ojo_der)))\n",
    "\n",
    "        # Definir los l칤mites del recorte de 56x56 p칤xeles\n",
    "        half_crop_size = 28\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_eye = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_eye, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales del ojo derecho al nuevo recorte\n",
    "        eye_right_points_adjusted = [(p[0] - x1, p[1] - y1) for p in eye_right_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        eye_right_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in eye_right_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=eye_right_points_scaled)\n",
    "            image = augmented['image']\n",
    "            eye_right_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(eye_right_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotaci칩n aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicaci칩n de m치scaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validaci칩n\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validaci칩n\n",
    "train_dataset = EyeRightDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EyeRightDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EyeRight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EyeRight, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(ojo_der) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuraci칩n y entrenamiento\n",
    "model = DenseNet121EyeRight().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la f칩rmula espec칤fica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tama침o (N, M, 2), donde\n",
    "                        N es el n칰mero de im치genes, M el n칰mero de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tama침o que predictions.\n",
    "    :param num_landmarks: N칰mero de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los 칤ndices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para ojo derecho)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la f칩rmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, eye_right_points, _, _, _ in train_dataloader:\n",
    "            images, eye_right_points = images.cuda(), eye_right_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, eye_right_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validaci칩n y c치lculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_eye_right_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_eye_right_points = val_images.cuda(), val_eye_right_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_eye_right_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el c치lculo de NME\n",
    "                    all_labels.append(val_eye_right_points.cpu().numpy().reshape(-1, len(ojo_der), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(ojo_der), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(ojo_der))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EyeRightLandmarks.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 16295.4488\n",
      "Validation Loss: 14465.2864\n",
      "NME: 3.2240\n",
      "Best model saved at epoch 1 with val_loss 14465.2864\n",
      "Epoch [2/300], Loss: 9046.4421\n",
      "Validation Loss: 3420.5417\n",
      "NME: 1.1890\n",
      "Best model saved at epoch 2 with val_loss 3420.5417\n",
      "Epoch [3/300], Loss: 1968.8574\n",
      "Validation Loss: 1269.3468\n",
      "NME: 0.6183\n",
      "Best model saved at epoch 3 with val_loss 1269.3468\n",
      "Epoch [4/300], Loss: 1095.9607\n",
      "Validation Loss: 927.7681\n",
      "NME: 0.5398\n",
      "Best model saved at epoch 4 with val_loss 927.7681\n",
      "Epoch [5/300], Loss: 945.4137\n",
      "Validation Loss: 865.4155\n",
      "NME: 0.5401\n",
      "Best model saved at epoch 5 with val_loss 865.4155\n",
      "Epoch [6/300], Loss: 921.8355\n",
      "Validation Loss: 859.3690\n",
      "NME: 0.5429\n",
      "Best model saved at epoch 6 with val_loss 859.3690\n",
      "Epoch [7/300], Loss: 903.0185\n",
      "Validation Loss: 843.0697\n",
      "NME: 0.5533\n",
      "Best model saved at epoch 7 with val_loss 843.0697\n",
      "Epoch [8/300], Loss: 904.0369\n",
      "Validation Loss: 837.3348\n",
      "NME: 0.5458\n",
      "Best model saved at epoch 8 with val_loss 837.3348\n",
      "Epoch [9/300], Loss: 896.6160\n",
      "Validation Loss: 828.7184\n",
      "NME: 0.5322\n",
      "Best model saved at epoch 9 with val_loss 828.7184\n",
      "Epoch [10/300], Loss: 883.7400\n",
      "Validation Loss: 811.4221\n",
      "NME: 0.5214\n",
      "Best model saved at epoch 10 with val_loss 811.4221\n",
      "Epoch [11/300], Loss: 868.0256\n",
      "Validation Loss: 778.3706\n",
      "NME: 0.5123\n",
      "Best model saved at epoch 11 with val_loss 778.3706\n",
      "Epoch [12/300], Loss: 817.6987\n",
      "Validation Loss: 721.6694\n",
      "NME: 0.5028\n",
      "Best model saved at epoch 12 with val_loss 721.6694\n",
      "Epoch [13/300], Loss: 760.9903\n",
      "Validation Loss: 636.1013\n",
      "NME: 0.4533\n",
      "Best model saved at epoch 13 with val_loss 636.1013\n",
      "Epoch [14/300], Loss: 652.9926\n",
      "Validation Loss: 493.5226\n",
      "NME: 0.4090\n",
      "Best model saved at epoch 14 with val_loss 493.5226\n",
      "Epoch [15/300], Loss: 568.9955\n",
      "Validation Loss: 428.5663\n",
      "NME: 0.3736\n",
      "Best model saved at epoch 15 with val_loss 428.5663\n",
      "Epoch [16/300], Loss: 481.9743\n",
      "Validation Loss: 325.2142\n",
      "NME: 0.3379\n",
      "Best model saved at epoch 16 with val_loss 325.2142\n",
      "Epoch [17/300], Loss: 399.1204\n",
      "Validation Loss: 241.6276\n",
      "NME: 0.2862\n",
      "Best model saved at epoch 17 with val_loss 241.6276\n",
      "Epoch [18/300], Loss: 371.6509\n",
      "Validation Loss: 207.5255\n",
      "NME: 0.2708\n",
      "Best model saved at epoch 18 with val_loss 207.5255\n",
      "Epoch [19/300], Loss: 348.5667\n",
      "Validation Loss: 200.7173\n",
      "NME: 0.2622\n",
      "Best model saved at epoch 19 with val_loss 200.7173\n",
      "Epoch [20/300], Loss: 316.9427\n",
      "Validation Loss: 184.0352\n",
      "NME: 0.2487\n",
      "Best model saved at epoch 20 with val_loss 184.0352\n",
      "Epoch [21/300], Loss: 290.0518\n",
      "Validation Loss: 193.8383\n",
      "NME: 0.2544\n",
      "Epoch [22/300], Loss: 316.7615\n",
      "Validation Loss: 171.2256\n",
      "NME: 0.2454\n",
      "Best model saved at epoch 22 with val_loss 171.2256\n",
      "Epoch [23/300], Loss: 296.9151\n",
      "Validation Loss: 174.5104\n",
      "NME: 0.2472\n",
      "Epoch [24/300], Loss: 279.3622\n",
      "Validation Loss: 176.2925\n",
      "NME: 0.2586\n",
      "Epoch [25/300], Loss: 270.4603\n",
      "Validation Loss: 174.5695\n",
      "NME: 0.2659\n",
      "Epoch [26/300], Loss: 276.0140\n",
      "Validation Loss: 169.0857\n",
      "NME: 0.2477\n",
      "Best model saved at epoch 26 with val_loss 169.0857\n",
      "Epoch [27/300], Loss: 255.7886\n",
      "Validation Loss: 166.1583\n",
      "NME: 0.2266\n",
      "Best model saved at epoch 27 with val_loss 166.1583\n",
      "Epoch [28/300], Loss: 259.0581\n",
      "Validation Loss: 181.7319\n",
      "NME: 0.2657\n",
      "Epoch [29/300], Loss: 277.2996\n",
      "Validation Loss: 179.0579\n",
      "NME: 0.2461\n",
      "Epoch [30/300], Loss: 257.0099\n",
      "Validation Loss: 164.8255\n",
      "NME: 0.2330\n",
      "Best model saved at epoch 30 with val_loss 164.8255\n",
      "Epoch [31/300], Loss: 242.1890\n",
      "Validation Loss: 159.3005\n",
      "NME: 0.2427\n",
      "Best model saved at epoch 31 with val_loss 159.3005\n",
      "Epoch [32/300], Loss: 262.2677\n",
      "Validation Loss: 154.4456\n",
      "NME: 0.2320\n",
      "Best model saved at epoch 32 with val_loss 154.4456\n",
      "Epoch [33/300], Loss: 245.9876\n",
      "Validation Loss: 179.3290\n",
      "NME: 0.2528\n",
      "Epoch [34/300], Loss: 249.4909\n",
      "Validation Loss: 168.1448\n",
      "NME: 0.2329\n",
      "Epoch [35/300], Loss: 250.5245\n",
      "Validation Loss: 168.2842\n",
      "NME: 0.2155\n",
      "Epoch [36/300], Loss: 244.6944\n",
      "Validation Loss: 148.9397\n",
      "NME: 0.2176\n",
      "Best model saved at epoch 36 with val_loss 148.9397\n",
      "Epoch [37/300], Loss: 246.5136\n",
      "Validation Loss: 181.9683\n",
      "NME: 0.2638\n",
      "Epoch [38/300], Loss: 232.1892\n",
      "Validation Loss: 158.3506\n",
      "NME: 0.2290\n",
      "Epoch [39/300], Loss: 239.5902\n",
      "Validation Loss: 143.8863\n",
      "NME: 0.2110\n",
      "Best model saved at epoch 39 with val_loss 143.8863\n",
      "Epoch [40/300], Loss: 233.2105\n",
      "Validation Loss: 142.8759\n",
      "NME: 0.2017\n",
      "Best model saved at epoch 40 with val_loss 142.8759\n",
      "Epoch [41/300], Loss: 236.7896\n",
      "Validation Loss: 147.3357\n",
      "NME: 0.2066\n",
      "Epoch [42/300], Loss: 237.2176\n",
      "Validation Loss: 140.7056\n",
      "NME: 0.2135\n",
      "Best model saved at epoch 42 with val_loss 140.7056\n",
      "Epoch [43/300], Loss: 224.0190\n",
      "Validation Loss: 146.1941\n",
      "NME: 0.2066\n",
      "Epoch [44/300], Loss: 240.1445\n",
      "Validation Loss: 147.1138\n",
      "NME: 0.2093\n",
      "Epoch [45/300], Loss: 233.3176\n",
      "Validation Loss: 139.4977\n",
      "NME: 0.2015\n",
      "Best model saved at epoch 45 with val_loss 139.4977\n",
      "Epoch [46/300], Loss: 217.3032\n",
      "Validation Loss: 150.6726\n",
      "NME: 0.2059\n",
      "Epoch [47/300], Loss: 226.6021\n",
      "Validation Loss: 154.9703\n",
      "NME: 0.2175\n",
      "Epoch [48/300], Loss: 224.4939\n",
      "Validation Loss: 140.6233\n",
      "NME: 0.1878\n",
      "Epoch [49/300], Loss: 220.0184\n",
      "Validation Loss: 136.0692\n",
      "NME: 0.1916\n",
      "Best model saved at epoch 49 with val_loss 136.0692\n",
      "Epoch [50/300], Loss: 207.0183\n",
      "Validation Loss: 147.0479\n",
      "NME: 0.2174\n",
      "Epoch [51/300], Loss: 220.0881\n",
      "Validation Loss: 154.3869\n",
      "NME: 0.2080\n",
      "Epoch [52/300], Loss: 239.7214\n",
      "Validation Loss: 152.6627\n",
      "NME: 0.2011\n",
      "Epoch [53/300], Loss: 230.1735\n",
      "Validation Loss: 133.8092\n",
      "NME: 0.1873\n",
      "Best model saved at epoch 53 with val_loss 133.8092\n",
      "Epoch [54/300], Loss: 205.8436\n",
      "Validation Loss: 142.5613\n",
      "NME: 0.2148\n",
      "Epoch [55/300], Loss: 215.1007\n",
      "Validation Loss: 145.9766\n",
      "NME: 0.2099\n",
      "Epoch [56/300], Loss: 230.6306\n",
      "Validation Loss: 166.9683\n",
      "NME: 0.2135\n",
      "Epoch [57/300], Loss: 202.8183\n",
      "Validation Loss: 142.9086\n",
      "NME: 0.2038\n",
      "Epoch [58/300], Loss: 209.0969\n",
      "Validation Loss: 139.6379\n",
      "NME: 0.1929\n",
      "Epoch [59/300], Loss: 197.3178\n",
      "Validation Loss: 146.0866\n",
      "NME: 0.1937\n",
      "Epoch [60/300], Loss: 207.7360\n",
      "Validation Loss: 155.4631\n",
      "NME: 0.2271\n",
      "Epoch [61/300], Loss: 186.7952\n",
      "Validation Loss: 140.1933\n",
      "NME: 0.1904\n",
      "Epoch [62/300], Loss: 181.8027\n",
      "Validation Loss: 146.7065\n",
      "NME: 0.2035\n",
      "Epoch [63/300], Loss: 178.6328\n",
      "Validation Loss: 146.5952\n",
      "NME: 0.2020\n",
      "Epoch [64/300], Loss: 167.9867\n",
      "Validation Loss: 158.6724\n",
      "NME: 0.2104\n",
      "Epoch [65/300], Loss: 147.5068\n",
      "Validation Loss: 136.1297\n",
      "NME: 0.1948\n",
      "Epoch [66/300], Loss: 160.7070\n",
      "Validation Loss: 146.5695\n",
      "NME: 0.2088\n",
      "Epoch [67/300], Loss: 152.9334\n",
      "Validation Loss: 148.0867\n",
      "NME: 0.2094\n",
      "Epoch [68/300], Loss: 152.8339\n",
      "Validation Loss: 148.2952\n",
      "NME: 0.1921\n",
      "Epoch [69/300], Loss: 143.8452\n",
      "Validation Loss: 146.4669\n",
      "NME: 0.2059\n",
      "Epoch [70/300], Loss: 138.0104\n",
      "Validation Loss: 141.3062\n",
      "NME: 0.1929\n",
      "Epoch [71/300], Loss: 135.1216\n",
      "Validation Loss: 143.0803\n",
      "NME: 0.1952\n",
      "Epoch [72/300], Loss: 136.8995\n",
      "Validation Loss: 147.9219\n",
      "NME: 0.2107\n",
      "Epoch [73/300], Loss: 131.7566\n",
      "Validation Loss: 139.9486\n",
      "NME: 0.1925\n",
      "Epoch [74/300], Loss: 127.5522\n",
      "Validation Loss: 132.8588\n",
      "NME: 0.1854\n",
      "Best model saved at epoch 74 with val_loss 132.8588\n",
      "Epoch [75/300], Loss: 129.0626\n",
      "Validation Loss: 145.3839\n",
      "NME: 0.1847\n",
      "Epoch [76/300], Loss: 127.6977\n",
      "Validation Loss: 142.4663\n",
      "NME: 0.1862\n",
      "Epoch [77/300], Loss: 126.6619\n",
      "Validation Loss: 137.7323\n",
      "NME: 0.1875\n",
      "Epoch [78/300], Loss: 140.2297\n",
      "Validation Loss: 149.3793\n",
      "NME: 0.1915\n",
      "Epoch [79/300], Loss: 132.5085\n",
      "Validation Loss: 139.7828\n",
      "NME: 0.1920\n",
      "Epoch [80/300], Loss: 126.1053\n",
      "Validation Loss: 143.7414\n",
      "NME: 0.1934\n",
      "Epoch [81/300], Loss: 120.6270\n",
      "Validation Loss: 139.4522\n",
      "NME: 0.1871\n",
      "Epoch [82/300], Loss: 118.7184\n",
      "Validation Loss: 137.2707\n",
      "NME: 0.1866\n",
      "Epoch [83/300], Loss: 117.3253\n",
      "Validation Loss: 135.2998\n",
      "NME: 0.1819\n",
      "Epoch [84/300], Loss: 125.8742\n",
      "Validation Loss: 150.2869\n",
      "NME: 0.2002\n",
      "Epoch [85/300], Loss: 119.3388\n",
      "Validation Loss: 134.1671\n",
      "NME: 0.1838\n",
      "Epoch [86/300], Loss: 117.7567\n",
      "Validation Loss: 146.4595\n",
      "NME: 0.1829\n",
      "Epoch [87/300], Loss: 119.5923\n",
      "Validation Loss: 144.4740\n",
      "NME: 0.1912\n",
      "Epoch [88/300], Loss: 115.7223\n",
      "Validation Loss: 139.7474\n",
      "NME: 0.1953\n",
      "Epoch [89/300], Loss: 114.2662\n",
      "Validation Loss: 128.6945\n",
      "NME: 0.1761\n",
      "Best model saved at epoch 89 with val_loss 128.6945\n",
      "Epoch [90/300], Loss: 113.5339\n",
      "Validation Loss: 139.2686\n",
      "NME: 0.1941\n",
      "Epoch [91/300], Loss: 115.1976\n",
      "Validation Loss: 135.7601\n",
      "NME: 0.1817\n",
      "Epoch [92/300], Loss: 114.0329\n",
      "Validation Loss: 136.3286\n",
      "NME: 0.1747\n",
      "Epoch [93/300], Loss: 111.1085\n",
      "Validation Loss: 126.6858\n",
      "NME: 0.1754\n",
      "Best model saved at epoch 93 with val_loss 126.6858\n",
      "Epoch [94/300], Loss: 115.4064\n",
      "Validation Loss: 136.4198\n",
      "NME: 0.1887\n",
      "Epoch [95/300], Loss: 112.4975\n",
      "Validation Loss: 141.6262\n",
      "NME: 0.1946\n",
      "Epoch [96/300], Loss: 116.0784\n",
      "Validation Loss: 139.6646\n",
      "NME: 0.1816\n",
      "Epoch [97/300], Loss: 112.1841\n",
      "Validation Loss: 135.3581\n",
      "NME: 0.1896\n",
      "Epoch [98/300], Loss: 122.8433\n",
      "Validation Loss: 133.8525\n",
      "NME: 0.1741\n",
      "Epoch [99/300], Loss: 114.0349\n",
      "Validation Loss: 124.9565\n",
      "NME: 0.1732\n",
      "Best model saved at epoch 99 with val_loss 124.9565\n",
      "Epoch [100/300], Loss: 106.8578\n",
      "Validation Loss: 129.6942\n",
      "NME: 0.1756\n",
      "Epoch [101/300], Loss: 109.1080\n",
      "Validation Loss: 129.4494\n",
      "NME: 0.1700\n",
      "Epoch [102/300], Loss: 108.5077\n",
      "Validation Loss: 126.2214\n",
      "NME: 0.1741\n",
      "Epoch [103/300], Loss: 130.3658\n",
      "Validation Loss: 137.1322\n",
      "NME: 0.1785\n",
      "Epoch [104/300], Loss: 108.9936\n",
      "Validation Loss: 132.6188\n",
      "NME: 0.1904\n",
      "Epoch [105/300], Loss: 108.1686\n",
      "Validation Loss: 128.3124\n",
      "NME: 0.1756\n",
      "Epoch [106/300], Loss: 106.0647\n",
      "Validation Loss: 124.2394\n",
      "NME: 0.1704\n",
      "Best model saved at epoch 106 with val_loss 124.2394\n",
      "Epoch [107/300], Loss: 104.1979\n",
      "Validation Loss: 124.6536\n",
      "NME: 0.1696\n",
      "Epoch [108/300], Loss: 104.1809\n",
      "Validation Loss: 121.4403\n",
      "NME: 0.1657\n",
      "Best model saved at epoch 108 with val_loss 121.4403\n",
      "Epoch [109/300], Loss: 104.4335\n",
      "Validation Loss: 125.0403\n",
      "NME: 0.1700\n",
      "Epoch [110/300], Loss: 103.5977\n",
      "Validation Loss: 122.0192\n",
      "NME: 0.1710\n",
      "Epoch [111/300], Loss: 101.0629\n",
      "Validation Loss: 122.4228\n",
      "NME: 0.1696\n",
      "Epoch [112/300], Loss: 102.1215\n",
      "Validation Loss: 118.3808\n",
      "NME: 0.1706\n",
      "Best model saved at epoch 112 with val_loss 118.3808\n",
      "Epoch [113/300], Loss: 100.9073\n",
      "Validation Loss: 119.6169\n",
      "NME: 0.1767\n",
      "Epoch [114/300], Loss: 101.3930\n",
      "Validation Loss: 122.9485\n",
      "NME: 0.1697\n",
      "Epoch [115/300], Loss: 96.3251\n",
      "Validation Loss: 113.7328\n",
      "NME: 0.1628\n",
      "Best model saved at epoch 115 with val_loss 113.7328\n",
      "Epoch [116/300], Loss: 94.9733\n",
      "Validation Loss: 115.6020\n",
      "NME: 0.1598\n",
      "Epoch [117/300], Loss: 99.1168\n",
      "Validation Loss: 124.0766\n",
      "NME: 0.1776\n",
      "Epoch [118/300], Loss: 100.3626\n",
      "Validation Loss: 116.2570\n",
      "NME: 0.1619\n",
      "Epoch [119/300], Loss: 92.0960\n",
      "Validation Loss: 112.9733\n",
      "NME: 0.1679\n",
      "Best model saved at epoch 119 with val_loss 112.9733\n",
      "Epoch [120/300], Loss: 92.3267\n",
      "Validation Loss: 111.0902\n",
      "NME: 0.1641\n",
      "Best model saved at epoch 120 with val_loss 111.0902\n",
      "Epoch [121/300], Loss: 90.4596\n",
      "Validation Loss: 110.8163\n",
      "NME: 0.1594\n",
      "Best model saved at epoch 121 with val_loss 110.8163\n",
      "Epoch [122/300], Loss: 91.5981\n",
      "Validation Loss: 115.2838\n",
      "NME: 0.1668\n",
      "Epoch [123/300], Loss: 89.7632\n",
      "Validation Loss: 108.8242\n",
      "NME: 0.1634\n",
      "Best model saved at epoch 123 with val_loss 108.8242\n",
      "Epoch [124/300], Loss: 88.2770\n",
      "Validation Loss: 107.6159\n",
      "NME: 0.1615\n",
      "Best model saved at epoch 124 with val_loss 107.6159\n",
      "Epoch [125/300], Loss: 89.0272\n",
      "Validation Loss: 105.0741\n",
      "NME: 0.1609\n",
      "Best model saved at epoch 125 with val_loss 105.0741\n",
      "Epoch [126/300], Loss: 87.9099\n",
      "Validation Loss: 108.0356\n",
      "NME: 0.1623\n",
      "Epoch [127/300], Loss: 95.4687\n",
      "Validation Loss: 113.2152\n",
      "NME: 0.1784\n",
      "Epoch [128/300], Loss: 102.6346\n",
      "Validation Loss: 108.5320\n",
      "NME: 0.1638\n",
      "Epoch [129/300], Loss: 88.2877\n",
      "Validation Loss: 112.2658\n",
      "NME: 0.1662\n",
      "Epoch [130/300], Loss: 87.1223\n",
      "Validation Loss: 107.1874\n",
      "NME: 0.1587\n",
      "Epoch [131/300], Loss: 83.1543\n",
      "Validation Loss: 106.7942\n",
      "NME: 0.1599\n",
      "Epoch [132/300], Loss: 86.1365\n",
      "Validation Loss: 106.9223\n",
      "NME: 0.1672\n",
      "Epoch [133/300], Loss: 97.9237\n",
      "Validation Loss: 116.9132\n",
      "NME: 0.1811\n",
      "Epoch [134/300], Loss: 90.9297\n",
      "Validation Loss: 106.0494\n",
      "NME: 0.1554\n",
      "Epoch [135/300], Loss: 87.6934\n",
      "Validation Loss: 103.1058\n",
      "NME: 0.1569\n",
      "Best model saved at epoch 135 with val_loss 103.1058\n",
      "Epoch [136/300], Loss: 86.8658\n",
      "Validation Loss: 105.7242\n",
      "NME: 0.1645\n",
      "Epoch [137/300], Loss: 82.8169\n",
      "Validation Loss: 104.4063\n",
      "NME: 0.1591\n",
      "Epoch [138/300], Loss: 82.3812\n",
      "Validation Loss: 103.4943\n",
      "NME: 0.1557\n",
      "Epoch [139/300], Loss: 80.5338\n",
      "Validation Loss: 107.1364\n",
      "NME: 0.1596\n",
      "Epoch [140/300], Loss: 82.4696\n",
      "Validation Loss: 102.5274\n",
      "NME: 0.1551\n",
      "Best model saved at epoch 140 with val_loss 102.5274\n",
      "Epoch [141/300], Loss: 78.5935\n",
      "Validation Loss: 100.6380\n",
      "NME: 0.1537\n",
      "Best model saved at epoch 141 with val_loss 100.6380\n",
      "Epoch [142/300], Loss: 79.0530\n",
      "Validation Loss: 104.0409\n",
      "NME: 0.1675\n",
      "Epoch [143/300], Loss: 76.4272\n",
      "Validation Loss: 98.5490\n",
      "NME: 0.1532\n",
      "Best model saved at epoch 143 with val_loss 98.5490\n",
      "Epoch [144/300], Loss: 75.3797\n",
      "Validation Loss: 96.8354\n",
      "NME: 0.1562\n",
      "Best model saved at epoch 144 with val_loss 96.8354\n",
      "Epoch [145/300], Loss: 74.8985\n",
      "Validation Loss: 98.9187\n",
      "NME: 0.1556\n",
      "Epoch [146/300], Loss: 73.3331\n",
      "Validation Loss: 93.0767\n",
      "NME: 0.1473\n",
      "Best model saved at epoch 146 with val_loss 93.0767\n",
      "Epoch [147/300], Loss: 71.3452\n",
      "Validation Loss: 91.1330\n",
      "NME: 0.1470\n",
      "Best model saved at epoch 147 with val_loss 91.1330\n",
      "Epoch [148/300], Loss: 73.3295\n",
      "Validation Loss: 95.3296\n",
      "NME: 0.1501\n",
      "Epoch [149/300], Loss: 70.6867\n",
      "Validation Loss: 88.9954\n",
      "NME: 0.1465\n",
      "Best model saved at epoch 149 with val_loss 88.9954\n",
      "Epoch [150/300], Loss: 68.5739\n",
      "Validation Loss: 88.1098\n",
      "NME: 0.1416\n",
      "Best model saved at epoch 150 with val_loss 88.1098\n",
      "Epoch [151/300], Loss: 66.2267\n",
      "Validation Loss: 89.2593\n",
      "NME: 0.1459\n",
      "Epoch [152/300], Loss: 64.9344\n",
      "Validation Loss: 85.6798\n",
      "NME: 0.1350\n",
      "Best model saved at epoch 152 with val_loss 85.6798\n",
      "Epoch [153/300], Loss: 62.4756\n",
      "Validation Loss: 81.6331\n",
      "NME: 0.1378\n",
      "Best model saved at epoch 153 with val_loss 81.6331\n",
      "Epoch [154/300], Loss: 61.9690\n",
      "Validation Loss: 83.7758\n",
      "NME: 0.1421\n",
      "Epoch [155/300], Loss: 59.7715\n",
      "Validation Loss: 79.8968\n",
      "NME: 0.1358\n",
      "Best model saved at epoch 155 with val_loss 79.8968\n",
      "Epoch [156/300], Loss: 63.2632\n",
      "Validation Loss: 79.4778\n",
      "NME: 0.1373\n",
      "Best model saved at epoch 156 with val_loss 79.4778\n",
      "Epoch [157/300], Loss: 60.9106\n",
      "Validation Loss: 88.0453\n",
      "NME: 0.1453\n",
      "Epoch [158/300], Loss: 73.0242\n",
      "Validation Loss: 82.4026\n",
      "NME: 0.1410\n",
      "Epoch [159/300], Loss: 65.5840\n",
      "Validation Loss: 78.9493\n",
      "NME: 0.1376\n",
      "Best model saved at epoch 159 with val_loss 78.9493\n",
      "Epoch [160/300], Loss: 58.5227\n",
      "Validation Loss: 77.0889\n",
      "NME: 0.1361\n",
      "Best model saved at epoch 160 with val_loss 77.0889\n",
      "Epoch [161/300], Loss: 57.5918\n",
      "Validation Loss: 77.4418\n",
      "NME: 0.1391\n",
      "Epoch [162/300], Loss: 55.8357\n",
      "Validation Loss: 76.7281\n",
      "NME: 0.1312\n",
      "Best model saved at epoch 162 with val_loss 76.7281\n",
      "Epoch [163/300], Loss: 54.7824\n",
      "Validation Loss: 78.4723\n",
      "NME: 0.1390\n",
      "Epoch [164/300], Loss: 56.7893\n",
      "Validation Loss: 82.8992\n",
      "NME: 0.1456\n",
      "Epoch [165/300], Loss: 55.1231\n",
      "Validation Loss: 77.4573\n",
      "NME: 0.1361\n",
      "Epoch [166/300], Loss: 55.8411\n",
      "Validation Loss: 75.3318\n",
      "NME: 0.1287\n",
      "Best model saved at epoch 166 with val_loss 75.3318\n",
      "Epoch [167/300], Loss: 53.6849\n",
      "Validation Loss: 73.9271\n",
      "NME: 0.1327\n",
      "Best model saved at epoch 167 with val_loss 73.9271\n",
      "Epoch [168/300], Loss: 53.8324\n",
      "Validation Loss: 77.6376\n",
      "NME: 0.1389\n",
      "Epoch [169/300], Loss: 54.5425\n",
      "Validation Loss: 72.3305\n",
      "NME: 0.1311\n",
      "Best model saved at epoch 169 with val_loss 72.3305\n",
      "Epoch [170/300], Loss: 54.7766\n",
      "Validation Loss: 73.4475\n",
      "NME: 0.1306\n",
      "Epoch [171/300], Loss: 56.3735\n",
      "Validation Loss: 76.1538\n",
      "NME: 0.1349\n",
      "Epoch [172/300], Loss: 54.7791\n",
      "Validation Loss: 76.1189\n",
      "NME: 0.1355\n",
      "Epoch [173/300], Loss: 54.3165\n",
      "Validation Loss: 74.0736\n",
      "NME: 0.1291\n",
      "Epoch [174/300], Loss: 53.6146\n",
      "Validation Loss: 75.4326\n",
      "NME: 0.1315\n",
      "Epoch [175/300], Loss: 54.3331\n",
      "Validation Loss: 72.7809\n",
      "NME: 0.1321\n",
      "Epoch [176/300], Loss: 53.0453\n",
      "Validation Loss: 71.5877\n",
      "NME: 0.1273\n",
      "Best model saved at epoch 176 with val_loss 71.5877\n",
      "Epoch [177/300], Loss: 53.4074\n",
      "Validation Loss: 72.5453\n",
      "NME: 0.1276\n",
      "Epoch [178/300], Loss: 54.1406\n",
      "Validation Loss: 71.4222\n",
      "NME: 0.1270\n",
      "Best model saved at epoch 178 with val_loss 71.4222\n",
      "Epoch [179/300], Loss: 52.5489\n",
      "Validation Loss: 75.3857\n",
      "NME: 0.1313\n",
      "Epoch [180/300], Loss: 52.8248\n",
      "Validation Loss: 75.4480\n",
      "NME: 0.1335\n",
      "Epoch [181/300], Loss: 51.5723\n",
      "Validation Loss: 72.9508\n",
      "NME: 0.1322\n",
      "Epoch [182/300], Loss: 61.2471\n",
      "Validation Loss: 92.7013\n",
      "NME: 0.1715\n",
      "Epoch [183/300], Loss: 64.9968\n",
      "Validation Loss: 84.0729\n",
      "NME: 0.1363\n",
      "Epoch [184/300], Loss: 55.2118\n",
      "Validation Loss: 74.8834\n",
      "NME: 0.1330\n",
      "Epoch [185/300], Loss: 52.4955\n",
      "Validation Loss: 74.2790\n",
      "NME: 0.1309\n",
      "Epoch [186/300], Loss: 51.5102\n",
      "Validation Loss: 74.1666\n",
      "NME: 0.1294\n",
      "Epoch [187/300], Loss: 53.0940\n",
      "Validation Loss: 75.4085\n",
      "NME: 0.1284\n",
      "Epoch [188/300], Loss: 53.4385\n",
      "Validation Loss: 73.5198\n",
      "NME: 0.1322\n",
      "Epoch [189/300], Loss: 51.2751\n",
      "Validation Loss: 72.0774\n",
      "NME: 0.1258\n",
      "Epoch [190/300], Loss: 51.5956\n",
      "Validation Loss: 85.4596\n",
      "NME: 0.1334\n",
      "Epoch [191/300], Loss: 51.3941\n",
      "Validation Loss: 75.4187\n",
      "NME: 0.1272\n",
      "Epoch [192/300], Loss: 50.4442\n",
      "Validation Loss: 76.1842\n",
      "NME: 0.1304\n",
      "Epoch [193/300], Loss: 49.4627\n",
      "Validation Loss: 76.1866\n",
      "NME: 0.1312\n",
      "Epoch [194/300], Loss: 49.6016\n",
      "Validation Loss: 76.3267\n",
      "NME: 0.1271\n",
      "Epoch [195/300], Loss: 53.9456\n",
      "Validation Loss: 85.3486\n",
      "NME: 0.1270\n",
      "Epoch [196/300], Loss: 53.7311\n",
      "Validation Loss: 78.9240\n",
      "NME: 0.1322\n",
      "Epoch [197/300], Loss: 52.5064\n",
      "Validation Loss: 86.8412\n",
      "NME: 0.1316\n",
      "Epoch [198/300], Loss: 52.8340\n",
      "Validation Loss: 78.3903\n",
      "NME: 0.1303\n",
      "Epoch [199/300], Loss: 51.0986\n",
      "Validation Loss: 75.0198\n",
      "NME: 0.1293\n",
      "Epoch [200/300], Loss: 51.0593\n",
      "Validation Loss: 75.3891\n",
      "NME: 0.1274\n",
      "Epoch [201/300], Loss: 49.8850\n",
      "Validation Loss: 74.5310\n",
      "NME: 0.1308\n",
      "Epoch [202/300], Loss: 49.9119\n",
      "Validation Loss: 78.1124\n",
      "NME: 0.1364\n",
      "Epoch [203/300], Loss: 51.2858\n",
      "Validation Loss: 77.9405\n",
      "NME: 0.1365\n",
      "Epoch [204/300], Loss: 48.9522\n",
      "Validation Loss: 73.5665\n",
      "NME: 0.1274\n",
      "Epoch [205/300], Loss: 49.0356\n",
      "Validation Loss: 72.6304\n",
      "NME: 0.1275\n",
      "Epoch [206/300], Loss: 49.2094\n",
      "Validation Loss: 73.9319\n",
      "NME: 0.1260\n",
      "Epoch [207/300], Loss: 49.6236\n",
      "Validation Loss: 74.3685\n",
      "NME: 0.1311\n",
      "Epoch [208/300], Loss: 49.0259\n",
      "Validation Loss: 73.6534\n",
      "NME: 0.1305\n",
      "Epoch [209/300], Loss: 48.0080\n",
      "Validation Loss: 71.8867\n",
      "NME: 0.1262\n",
      "Epoch [210/300], Loss: 48.2479\n",
      "Validation Loss: 71.2912\n",
      "NME: 0.1274\n",
      "Best model saved at epoch 210 with val_loss 71.2912\n",
      "Epoch [211/300], Loss: 48.9753\n",
      "Validation Loss: 74.0399\n",
      "NME: 0.1276\n",
      "Epoch [212/300], Loss: 49.4466\n",
      "Validation Loss: 71.7924\n",
      "NME: 0.1256\n",
      "Epoch [213/300], Loss: 48.8267\n",
      "Validation Loss: 77.4283\n",
      "NME: 0.1362\n",
      "Epoch [214/300], Loss: 50.2491\n",
      "Validation Loss: 76.2127\n",
      "NME: 0.1311\n",
      "Epoch [215/300], Loss: 51.6555\n",
      "Validation Loss: 73.6294\n",
      "NME: 0.1300\n",
      "Epoch [216/300], Loss: 53.5474\n",
      "Validation Loss: 74.9558\n",
      "NME: 0.1289\n",
      "Epoch [217/300], Loss: 50.3209\n",
      "Validation Loss: 76.6352\n",
      "NME: 0.1255\n",
      "Epoch [218/300], Loss: 49.7959\n",
      "Validation Loss: 73.2748\n",
      "NME: 0.1315\n",
      "Epoch [219/300], Loss: 49.4597\n",
      "Validation Loss: 76.9709\n",
      "NME: 0.1324\n",
      "Epoch [220/300], Loss: 49.0162\n",
      "Validation Loss: 74.3990\n",
      "NME: 0.1386\n",
      "Epoch [221/300], Loss: 49.2636\n",
      "Validation Loss: 72.9763\n",
      "NME: 0.1283\n",
      "Epoch [222/300], Loss: 47.8455\n",
      "Validation Loss: 70.7796\n",
      "NME: 0.1247\n",
      "Best model saved at epoch 222 with val_loss 70.7796\n",
      "Epoch [223/300], Loss: 48.6102\n",
      "Validation Loss: 76.9770\n",
      "NME: 0.1274\n",
      "Epoch [224/300], Loss: 48.3522\n",
      "Validation Loss: 73.9448\n",
      "NME: 0.1287\n",
      "Epoch [225/300], Loss: 47.8052\n",
      "Validation Loss: 72.6283\n",
      "NME: 0.1291\n",
      "Epoch [226/300], Loss: 48.0846\n",
      "Validation Loss: 73.4959\n",
      "NME: 0.1285\n",
      "Epoch [227/300], Loss: 48.9341\n",
      "Validation Loss: 76.4674\n",
      "NME: 0.1275\n",
      "Epoch [228/300], Loss: 49.4971\n",
      "Validation Loss: 73.5839\n",
      "NME: 0.1231\n",
      "Epoch [229/300], Loss: 48.2638\n",
      "Validation Loss: 70.8784\n",
      "NME: 0.1280\n",
      "Epoch [230/300], Loss: 48.0505\n",
      "Validation Loss: 70.5162\n",
      "NME: 0.1244\n",
      "Best model saved at epoch 230 with val_loss 70.5162\n",
      "Epoch [231/300], Loss: 49.0880\n",
      "Validation Loss: 70.3175\n",
      "NME: 0.1278\n",
      "Best model saved at epoch 231 with val_loss 70.3175\n",
      "Epoch [232/300], Loss: 48.2924\n",
      "Validation Loss: 71.6612\n",
      "NME: 0.1261\n",
      "Epoch [233/300], Loss: 47.8525\n",
      "Validation Loss: 71.9516\n",
      "NME: 0.1284\n",
      "Epoch [234/300], Loss: 49.6545\n",
      "Validation Loss: 74.4998\n",
      "NME: 0.1314\n",
      "Epoch [235/300], Loss: 48.7885\n",
      "Validation Loss: 77.3165\n",
      "NME: 0.1305\n",
      "Epoch [236/300], Loss: 48.5462\n",
      "Validation Loss: 74.1836\n",
      "NME: 0.1306\n",
      "Epoch [237/300], Loss: 48.6990\n",
      "Validation Loss: 76.4706\n",
      "NME: 0.1290\n",
      "Epoch [238/300], Loss: 48.8280\n",
      "Validation Loss: 73.0729\n",
      "NME: 0.1259\n",
      "Epoch [239/300], Loss: 48.2892\n",
      "Validation Loss: 72.5167\n",
      "NME: 0.1267\n",
      "Epoch [240/300], Loss: 46.8593\n",
      "Validation Loss: 70.2264\n",
      "NME: 0.1248\n",
      "Best model saved at epoch 240 with val_loss 70.2264\n",
      "Epoch [241/300], Loss: 47.0670\n",
      "Validation Loss: 71.8391\n",
      "NME: 0.1260\n",
      "Epoch [242/300], Loss: 47.9531\n",
      "Validation Loss: 68.8439\n",
      "NME: 0.1240\n",
      "Best model saved at epoch 242 with val_loss 68.8439\n",
      "Epoch [243/300], Loss: 47.6975\n",
      "Validation Loss: 73.0845\n",
      "NME: 0.1274\n",
      "Epoch [244/300], Loss: 46.9846\n",
      "Validation Loss: 70.9582\n",
      "NME: 0.1260\n",
      "Epoch [245/300], Loss: 46.4264\n",
      "Validation Loss: 69.1928\n",
      "NME: 0.1248\n",
      "Epoch [246/300], Loss: 47.5096\n",
      "Validation Loss: 67.7608\n",
      "NME: 0.1231\n",
      "Best model saved at epoch 246 with val_loss 67.7608\n",
      "Epoch [247/300], Loss: 46.0644\n",
      "Validation Loss: 67.8024\n",
      "NME: 0.1234\n",
      "Epoch [248/300], Loss: 45.9848\n",
      "Validation Loss: 68.7102\n",
      "NME: 0.1242\n",
      "Epoch [249/300], Loss: 46.0086\n",
      "Validation Loss: 69.1232\n",
      "NME: 0.1242\n",
      "Epoch [250/300], Loss: 46.2373\n",
      "Validation Loss: 70.1495\n",
      "NME: 0.1257\n",
      "Epoch [251/300], Loss: 45.6006\n",
      "Validation Loss: 69.6149\n",
      "NME: 0.1252\n",
      "Epoch [252/300], Loss: 45.7286\n",
      "Validation Loss: 70.6178\n",
      "NME: 0.1292\n",
      "Epoch [253/300], Loss: 45.1219\n",
      "Validation Loss: 73.4841\n",
      "NME: 0.1283\n",
      "Epoch [254/300], Loss: 45.2578\n",
      "Validation Loss: 70.8868\n",
      "NME: 0.1275\n",
      "Epoch [255/300], Loss: 45.6463\n",
      "Validation Loss: 72.2974\n",
      "NME: 0.1327\n",
      "Epoch [256/300], Loss: 46.0942\n",
      "Validation Loss: 73.2095\n",
      "NME: 0.1289\n",
      "Epoch [257/300], Loss: 46.4398\n",
      "Validation Loss: 71.8946\n",
      "NME: 0.1295\n",
      "Epoch [258/300], Loss: 45.1740\n",
      "Validation Loss: 72.8026\n",
      "NME: 0.1228\n",
      "Epoch [259/300], Loss: 45.5354\n",
      "Validation Loss: 69.8314\n",
      "NME: 0.1295\n",
      "Epoch [260/300], Loss: 45.5149\n",
      "Validation Loss: 71.0359\n",
      "NME: 0.1275\n",
      "Epoch [261/300], Loss: 44.1206\n",
      "Validation Loss: 70.2962\n",
      "NME: 0.1261\n",
      "Epoch [262/300], Loss: 44.5797\n",
      "Validation Loss: 71.0947\n",
      "NME: 0.1296\n",
      "Epoch [263/300], Loss: 43.9811\n",
      "Validation Loss: 73.9390\n",
      "NME: 0.1304\n",
      "Epoch [264/300], Loss: 44.9585\n",
      "Validation Loss: 69.9991\n",
      "NME: 0.1238\n",
      "Epoch [265/300], Loss: 43.8461\n",
      "Validation Loss: 69.6730\n",
      "NME: 0.1281\n",
      "Epoch [266/300], Loss: 43.6584\n",
      "Validation Loss: 70.4981\n",
      "NME: 0.1237\n",
      "Epoch [267/300], Loss: 44.2599\n",
      "Validation Loss: 71.0069\n",
      "NME: 0.1300\n",
      "Epoch [268/300], Loss: 44.5370\n",
      "Validation Loss: 72.7322\n",
      "NME: 0.1283\n",
      "Epoch [269/300], Loss: 44.6236\n",
      "Validation Loss: 74.0603\n",
      "NME: 0.1396\n",
      "Epoch [270/300], Loss: 44.3685\n",
      "Validation Loss: 71.5797\n",
      "NME: 0.1273\n",
      "Epoch [271/300], Loss: 44.1875\n",
      "Validation Loss: 72.8618\n",
      "NME: 0.1293\n",
      "Epoch [272/300], Loss: 43.6400\n",
      "Validation Loss: 72.7859\n",
      "NME: 0.1309\n",
      "Epoch [273/300], Loss: 43.1442\n",
      "Validation Loss: 72.7721\n",
      "NME: 0.1287\n",
      "Epoch [274/300], Loss: 43.0252\n",
      "Validation Loss: 72.7183\n",
      "NME: 0.1317\n",
      "Epoch [275/300], Loss: 43.3191\n",
      "Validation Loss: 78.1273\n",
      "NME: 0.1325\n",
      "Epoch [276/300], Loss: 56.9182\n",
      "Validation Loss: 75.6743\n",
      "NME: 0.1295\n",
      "Epoch [277/300], Loss: 49.1481\n",
      "Validation Loss: 74.0786\n",
      "NME: 0.1265\n",
      "Epoch [278/300], Loss: 43.6431\n",
      "Validation Loss: 70.7039\n",
      "NME: 0.1278\n",
      "Epoch [279/300], Loss: 42.7788\n",
      "Validation Loss: 69.5231\n",
      "NME: 0.1261\n",
      "Epoch [280/300], Loss: 41.4510\n",
      "Validation Loss: 71.9584\n",
      "NME: 0.1254\n",
      "Epoch [281/300], Loss: 41.7033\n",
      "Validation Loss: 73.3137\n",
      "NME: 0.1311\n",
      "Epoch [282/300], Loss: 42.7343\n",
      "Validation Loss: 69.0161\n",
      "NME: 0.1286\n",
      "Epoch [283/300], Loss: 41.3533\n",
      "Validation Loss: 69.9255\n",
      "NME: 0.1267\n",
      "Epoch [284/300], Loss: 41.0178\n",
      "Validation Loss: 68.3624\n",
      "NME: 0.1252\n",
      "Epoch [285/300], Loss: 39.8959\n",
      "Validation Loss: 67.6112\n",
      "NME: 0.1214\n",
      "Best model saved at epoch 285 with val_loss 67.6112\n",
      "Epoch [286/300], Loss: 40.3813\n",
      "Validation Loss: 69.0842\n",
      "NME: 0.1250\n",
      "Epoch [287/300], Loss: 39.5119\n",
      "Validation Loss: 69.9952\n",
      "NME: 0.1247\n",
      "Epoch [288/300], Loss: 40.0663\n",
      "Validation Loss: 72.5454\n",
      "NME: 0.1335\n",
      "Epoch [289/300], Loss: 39.8181\n",
      "Validation Loss: 70.1810\n",
      "NME: 0.1251\n",
      "Epoch [290/300], Loss: 39.0126\n",
      "Validation Loss: 68.6344\n",
      "NME: 0.1239\n",
      "Epoch [291/300], Loss: 39.6120\n",
      "Validation Loss: 68.3543\n",
      "NME: 0.1237\n",
      "Epoch [292/300], Loss: 38.5607\n",
      "Validation Loss: 69.1071\n",
      "NME: 0.1238\n",
      "Epoch [293/300], Loss: 38.7867\n",
      "Validation Loss: 69.6507\n",
      "NME: 0.1299\n",
      "Epoch [294/300], Loss: 38.6378\n",
      "Validation Loss: 69.7070\n",
      "NME: 0.1282\n",
      "Epoch [295/300], Loss: 37.6137\n",
      "Validation Loss: 68.6126\n",
      "NME: 0.1279\n",
      "Epoch [296/300], Loss: 37.8794\n",
      "Validation Loss: 70.2382\n",
      "NME: 0.1258\n",
      "Epoch [297/300], Loss: 39.3981\n",
      "Validation Loss: 85.6430\n",
      "NME: 0.1371\n",
      "Epoch [298/300], Loss: 44.7207\n",
      "Validation Loss: 73.0344\n",
      "NME: 0.1300\n",
      "Epoch [299/300], Loss: 40.9180\n",
      "Validation Loss: 72.8658\n",
      "NME: 0.1271\n",
      "Epoch [300/300], Loss: 41.9035\n",
      "Validation Loss: 84.6681\n",
      "NME: 0.1421\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los 칤ndices de las regiones seg칰n los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "nariz = [0, 2, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 32, 33, 34, 35, 42, 43, 44, 45, 46, 47]\n",
    "\n",
    "# Funci칩n para calcular el punto promedio de una regi칩n\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class NoseDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos y la nariz\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_nariz = calcular_centro_region(landmarks, nariz)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_nariz -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el 치ngulo de rotaci칩n\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotaci칩n\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la nariz\n",
    "        nose_points = np.array([landmarks[i] for i in nariz], dtype=np.float32)\n",
    "        nose_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotaci칩n\n",
    "        ones = np.ones(shape=(len(nose_points), 1))\n",
    "        points_ones = np.hstack([nose_points, ones])\n",
    "        nose_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la nariz\n",
    "        centro_x, centro_y = calcular_centro_region(nose_points_rotated, range(len(nariz)))\n",
    "\n",
    "        # Definir los l칤mites del recorte de 112x112 p칤xeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_nose = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_nose, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la nariz al nuevo recorte\n",
    "        nose_points_adjusted = [(p[0] - x1, p[1] - y1) for p in nose_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        nose_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in nose_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=nose_points_scaled)\n",
    "            image = augmented['image']\n",
    "            nose_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(nose_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotaci칩n aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicaci칩n de m치scaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validaci칩n\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validaci칩n\n",
    "train_dataset = NoseDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = NoseDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121Nose(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121Nose, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(nariz) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuraci칩n y entrenamiento\n",
    "model = DenseNet121Nose().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la f칩rmula espec칤fica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tama침o (N, M, 2), donde\n",
    "                        N es el n칰mero de im치genes, M el n칰mero de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tama침o que predictions.\n",
    "    :param num_landmarks: N칰mero de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los 칤ndices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para nariz)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la f칩rmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, nose_points, _, _, _ in train_dataloader:\n",
    "            images, nose_points = images.cuda(), nose_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, nose_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validaci칩n y c치lculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_nose_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_nose_points = val_images.cuda(), val_nose_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_nose_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el c치lculo de NME\n",
    "                    all_labels.append(val_nose_points.cpu().numpy().reshape(-1, len(nariz), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(nariz), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(nariz))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'NoseAreaLandmarks V2.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
