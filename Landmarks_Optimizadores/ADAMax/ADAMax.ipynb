{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 18580.1025\n",
      "Validation Loss: 18264.7334\n",
      "NME: 1.5296\n",
      "Best model saved at epoch 1 with val_loss 18264.7334\n",
      "Epoch [2/300], Loss: 17232.5448\n",
      "Validation Loss: 15836.9244\n",
      "NME: 1.4316\n",
      "Best model saved at epoch 2 with val_loss 15836.9244\n",
      "Epoch [3/300], Loss: 13689.1608\n",
      "Validation Loss: 10910.0747\n",
      "NME: 1.1746\n",
      "Best model saved at epoch 3 with val_loss 10910.0747\n",
      "Epoch [4/300], Loss: 8154.5957\n",
      "Validation Loss: 5186.2174\n",
      "NME: 0.7490\n",
      "Best model saved at epoch 4 with val_loss 5186.2174\n",
      "Epoch [5/300], Loss: 3727.8263\n",
      "Validation Loss: 2360.8130\n",
      "NME: 0.4283\n",
      "Best model saved at epoch 5 with val_loss 2360.8130\n",
      "Epoch [6/300], Loss: 2174.2569\n",
      "Validation Loss: 1699.5994\n",
      "NME: 0.3509\n",
      "Best model saved at epoch 6 with val_loss 1699.5994\n",
      "Epoch [7/300], Loss: 1760.5794\n",
      "Validation Loss: 1491.0681\n",
      "NME: 0.3393\n",
      "Best model saved at epoch 7 with val_loss 1491.0681\n",
      "Epoch [8/300], Loss: 1629.6486\n",
      "Validation Loss: 1407.7641\n",
      "NME: 0.3398\n",
      "Best model saved at epoch 8 with val_loss 1407.7641\n",
      "Epoch [9/300], Loss: 1615.9691\n",
      "Validation Loss: 1381.1855\n",
      "NME: 0.3399\n",
      "Best model saved at epoch 9 with val_loss 1381.1855\n",
      "Epoch [10/300], Loss: 1573.8466\n",
      "Validation Loss: 1367.0651\n",
      "NME: 0.3409\n",
      "Best model saved at epoch 10 with val_loss 1367.0651\n",
      "Epoch [11/300], Loss: 1556.4425\n",
      "Validation Loss: 1349.1994\n",
      "NME: 0.3403\n",
      "Best model saved at epoch 11 with val_loss 1349.1994\n",
      "Epoch [12/300], Loss: 1549.6600\n",
      "Validation Loss: 1329.7523\n",
      "NME: 0.3367\n",
      "Best model saved at epoch 12 with val_loss 1329.7523\n",
      "Epoch [13/300], Loss: 1547.1913\n",
      "Validation Loss: 1305.6582\n",
      "NME: 0.3308\n",
      "Best model saved at epoch 13 with val_loss 1305.6582\n",
      "Epoch [14/300], Loss: 1519.5863\n",
      "Validation Loss: 1264.5820\n",
      "NME: 0.3221\n",
      "Best model saved at epoch 14 with val_loss 1264.5820\n",
      "Epoch [15/300], Loss: 1433.3021\n",
      "Validation Loss: 1207.0727\n",
      "NME: 0.3155\n",
      "Best model saved at epoch 15 with val_loss 1207.0727\n",
      "Epoch [16/300], Loss: 1380.9826\n",
      "Validation Loss: 1135.8746\n",
      "NME: 0.3024\n",
      "Best model saved at epoch 16 with val_loss 1135.8746\n",
      "Epoch [17/300], Loss: 1305.2531\n",
      "Validation Loss: 1041.1263\n",
      "NME: 0.2888\n",
      "Best model saved at epoch 17 with val_loss 1041.1263\n",
      "Epoch [18/300], Loss: 1233.3070\n",
      "Validation Loss: 946.0723\n",
      "NME: 0.2725\n",
      "Best model saved at epoch 18 with val_loss 946.0723\n",
      "Epoch [19/300], Loss: 1131.1349\n",
      "Validation Loss: 835.1069\n",
      "NME: 0.2525\n",
      "Best model saved at epoch 19 with val_loss 835.1069\n",
      "Epoch [20/300], Loss: 1040.1231\n",
      "Validation Loss: 753.6327\n",
      "NME: 0.2393\n",
      "Best model saved at epoch 20 with val_loss 753.6327\n",
      "Epoch [21/300], Loss: 968.8033\n",
      "Validation Loss: 670.8817\n",
      "NME: 0.2285\n",
      "Best model saved at epoch 21 with val_loss 670.8817\n",
      "Epoch [22/300], Loss: 901.2035\n",
      "Validation Loss: 623.5114\n",
      "NME: 0.2207\n",
      "Best model saved at epoch 22 with val_loss 623.5114\n",
      "Epoch [23/300], Loss: 849.3639\n",
      "Validation Loss: 574.7967\n",
      "NME: 0.2144\n",
      "Best model saved at epoch 23 with val_loss 574.7967\n",
      "Epoch [24/300], Loss: 807.9865\n",
      "Validation Loss: 527.3968\n",
      "NME: 0.2078\n",
      "Best model saved at epoch 24 with val_loss 527.3968\n",
      "Epoch [25/300], Loss: 796.8503\n",
      "Validation Loss: 510.9218\n",
      "NME: 0.2022\n",
      "Best model saved at epoch 25 with val_loss 510.9218\n",
      "Epoch [26/300], Loss: 776.6459\n",
      "Validation Loss: 486.1795\n",
      "NME: 0.2003\n",
      "Best model saved at epoch 26 with val_loss 486.1795\n",
      "Epoch [27/300], Loss: 729.6722\n",
      "Validation Loss: 452.5022\n",
      "NME: 0.1943\n",
      "Best model saved at epoch 27 with val_loss 452.5022\n",
      "Epoch [28/300], Loss: 718.7683\n",
      "Validation Loss: 435.7972\n",
      "NME: 0.1922\n",
      "Best model saved at epoch 28 with val_loss 435.7972\n",
      "Epoch [29/300], Loss: 674.7186\n",
      "Validation Loss: 431.0864\n",
      "NME: 0.1908\n",
      "Best model saved at epoch 29 with val_loss 431.0864\n",
      "Epoch [30/300], Loss: 705.0877\n",
      "Validation Loss: 416.2886\n",
      "NME: 0.1885\n",
      "Best model saved at epoch 30 with val_loss 416.2886\n",
      "Epoch [31/300], Loss: 693.0700\n",
      "Validation Loss: 425.0096\n",
      "NME: 0.1893\n",
      "Epoch [32/300], Loss: 676.0359\n",
      "Validation Loss: 403.2183\n",
      "NME: 0.1875\n",
      "Best model saved at epoch 32 with val_loss 403.2183\n",
      "Epoch [33/300], Loss: 648.1697\n",
      "Validation Loss: 402.2953\n",
      "NME: 0.1877\n",
      "Best model saved at epoch 33 with val_loss 402.2953\n",
      "Epoch [34/300], Loss: 679.0983\n",
      "Validation Loss: 401.2812\n",
      "NME: 0.1864\n",
      "Best model saved at epoch 34 with val_loss 401.2812\n",
      "Epoch [35/300], Loss: 654.8277\n",
      "Validation Loss: 385.3227\n",
      "NME: 0.1813\n",
      "Best model saved at epoch 35 with val_loss 385.3227\n",
      "Epoch [36/300], Loss: 654.1905\n",
      "Validation Loss: 390.2815\n",
      "NME: 0.1837\n",
      "Epoch [37/300], Loss: 633.7291\n",
      "Validation Loss: 378.6707\n",
      "NME: 0.1835\n",
      "Best model saved at epoch 37 with val_loss 378.6707\n",
      "Epoch [38/300], Loss: 662.2414\n",
      "Validation Loss: 382.5373\n",
      "NME: 0.1798\n",
      "Epoch [39/300], Loss: 588.9061\n",
      "Validation Loss: 367.1486\n",
      "NME: 0.1783\n",
      "Best model saved at epoch 39 with val_loss 367.1486\n",
      "Epoch [40/300], Loss: 623.4507\n",
      "Validation Loss: 386.0129\n",
      "NME: 0.1866\n",
      "Epoch [41/300], Loss: 611.4285\n",
      "Validation Loss: 367.7465\n",
      "NME: 0.1774\n",
      "Epoch [42/300], Loss: 596.7393\n",
      "Validation Loss: 372.2236\n",
      "NME: 0.1772\n",
      "Epoch [43/300], Loss: 578.3124\n",
      "Validation Loss: 367.1844\n",
      "NME: 0.1762\n",
      "Epoch [44/300], Loss: 578.9951\n",
      "Validation Loss: 359.5226\n",
      "NME: 0.1746\n",
      "Best model saved at epoch 44 with val_loss 359.5226\n",
      "Epoch [45/300], Loss: 604.9755\n",
      "Validation Loss: 360.7395\n",
      "NME: 0.1743\n",
      "Epoch [46/300], Loss: 584.2122\n",
      "Validation Loss: 362.1947\n",
      "NME: 0.1752\n",
      "Epoch [47/300], Loss: 592.7143\n",
      "Validation Loss: 366.4841\n",
      "NME: 0.1753\n",
      "Epoch [48/300], Loss: 549.1220\n",
      "Validation Loss: 354.0134\n",
      "NME: 0.1678\n",
      "Best model saved at epoch 48 with val_loss 354.0134\n",
      "Epoch [49/300], Loss: 558.5356\n",
      "Validation Loss: 360.6086\n",
      "NME: 0.1709\n",
      "Epoch [50/300], Loss: 565.9894\n",
      "Validation Loss: 366.0752\n",
      "NME: 0.1738\n",
      "Epoch [51/300], Loss: 564.0498\n",
      "Validation Loss: 375.6197\n",
      "NME: 0.1690\n",
      "Epoch [52/300], Loss: 521.6668\n",
      "Validation Loss: 350.7864\n",
      "NME: 0.1656\n",
      "Best model saved at epoch 52 with val_loss 350.7864\n",
      "Epoch [53/300], Loss: 561.8524\n",
      "Validation Loss: 373.9593\n",
      "NME: 0.1766\n",
      "Epoch [54/300], Loss: 542.1223\n",
      "Validation Loss: 356.6489\n",
      "NME: 0.1695\n",
      "Epoch [55/300], Loss: 554.6827\n",
      "Validation Loss: 350.7526\n",
      "NME: 0.1670\n",
      "Best model saved at epoch 55 with val_loss 350.7526\n",
      "Epoch [56/300], Loss: 511.7112\n",
      "Validation Loss: 337.7853\n",
      "NME: 0.1611\n",
      "Best model saved at epoch 56 with val_loss 337.7853\n",
      "Epoch [57/300], Loss: 584.1092\n",
      "Validation Loss: 347.8283\n",
      "NME: 0.1651\n",
      "Epoch [58/300], Loss: 540.6064\n",
      "Validation Loss: 338.2592\n",
      "NME: 0.1613\n",
      "Epoch [59/300], Loss: 498.9090\n",
      "Validation Loss: 332.9705\n",
      "NME: 0.1564\n",
      "Best model saved at epoch 59 with val_loss 332.9705\n",
      "Epoch [60/300], Loss: 518.9250\n",
      "Validation Loss: 336.5370\n",
      "NME: 0.1558\n",
      "Epoch [61/300], Loss: 519.0180\n",
      "Validation Loss: 340.0382\n",
      "NME: 0.1570\n",
      "Epoch [62/300], Loss: 507.1830\n",
      "Validation Loss: 316.3975\n",
      "NME: 0.1491\n",
      "Best model saved at epoch 62 with val_loss 316.3975\n",
      "Epoch [63/300], Loss: 526.0745\n",
      "Validation Loss: 342.3864\n",
      "NME: 0.1561\n",
      "Epoch [64/300], Loss: 502.8697\n",
      "Validation Loss: 328.6301\n",
      "NME: 0.1527\n",
      "Epoch [65/300], Loss: 510.3848\n",
      "Validation Loss: 337.7688\n",
      "NME: 0.1585\n",
      "Epoch [66/300], Loss: 466.8260\n",
      "Validation Loss: 316.1506\n",
      "NME: 0.1488\n",
      "Best model saved at epoch 66 with val_loss 316.1506\n",
      "Epoch [67/300], Loss: 464.4090\n",
      "Validation Loss: 315.4386\n",
      "NME: 0.1473\n",
      "Best model saved at epoch 67 with val_loss 315.4386\n",
      "Epoch [68/300], Loss: 503.6676\n",
      "Validation Loss: 316.0961\n",
      "NME: 0.1488\n",
      "Epoch [69/300], Loss: 462.9764\n",
      "Validation Loss: 333.6103\n",
      "NME: 0.1533\n",
      "Epoch [70/300], Loss: 466.3972\n",
      "Validation Loss: 293.9771\n",
      "NME: 0.1403\n",
      "Best model saved at epoch 70 with val_loss 293.9771\n",
      "Epoch [71/300], Loss: 440.2310\n",
      "Validation Loss: 301.3450\n",
      "NME: 0.1459\n",
      "Epoch [72/300], Loss: 445.4100\n",
      "Validation Loss: 295.8953\n",
      "NME: 0.1389\n",
      "Epoch [73/300], Loss: 435.8858\n",
      "Validation Loss: 329.2647\n",
      "NME: 0.1525\n",
      "Epoch [74/300], Loss: 416.9256\n",
      "Validation Loss: 293.5578\n",
      "NME: 0.1403\n",
      "Best model saved at epoch 74 with val_loss 293.5578\n",
      "Epoch [75/300], Loss: 419.6946\n",
      "Validation Loss: 269.5370\n",
      "NME: 0.1324\n",
      "Best model saved at epoch 75 with val_loss 269.5370\n",
      "Epoch [76/300], Loss: 409.0819\n",
      "Validation Loss: 274.4653\n",
      "NME: 0.1385\n",
      "Epoch [77/300], Loss: 373.2370\n",
      "Validation Loss: 274.0662\n",
      "NME: 0.1329\n",
      "Epoch [78/300], Loss: 384.5152\n",
      "Validation Loss: 273.8385\n",
      "NME: 0.1375\n",
      "Epoch [79/300], Loss: 353.0971\n",
      "Validation Loss: 267.8132\n",
      "NME: 0.1323\n",
      "Best model saved at epoch 79 with val_loss 267.8132\n",
      "Epoch [80/300], Loss: 355.2447\n",
      "Validation Loss: 281.4724\n",
      "NME: 0.1335\n",
      "Epoch [81/300], Loss: 339.2624\n",
      "Validation Loss: 281.2970\n",
      "NME: 0.1392\n",
      "Epoch [82/300], Loss: 309.1793\n",
      "Validation Loss: 277.5919\n",
      "NME: 0.1343\n",
      "Epoch [83/300], Loss: 310.7850\n",
      "Validation Loss: 261.6301\n",
      "NME: 0.1304\n",
      "Best model saved at epoch 83 with val_loss 261.6301\n",
      "Epoch [84/300], Loss: 320.0594\n",
      "Validation Loss: 252.3636\n",
      "NME: 0.1281\n",
      "Best model saved at epoch 84 with val_loss 252.3636\n",
      "Epoch [85/300], Loss: 317.0995\n",
      "Validation Loss: 262.3161\n",
      "NME: 0.1302\n",
      "Epoch [86/300], Loss: 296.3938\n",
      "Validation Loss: 262.0966\n",
      "NME: 0.1268\n",
      "Epoch [87/300], Loss: 301.0505\n",
      "Validation Loss: 278.8458\n",
      "NME: 0.1317\n",
      "Epoch [88/300], Loss: 285.5308\n",
      "Validation Loss: 272.3129\n",
      "NME: 0.1288\n",
      "Epoch [89/300], Loss: 277.4804\n",
      "Validation Loss: 268.1868\n",
      "NME: 0.1274\n",
      "Epoch [90/300], Loss: 286.3155\n",
      "Validation Loss: 277.8947\n",
      "NME: 0.1275\n",
      "Epoch [91/300], Loss: 269.1112\n",
      "Validation Loss: 266.6027\n",
      "NME: 0.1295\n",
      "Epoch [92/300], Loss: 249.7366\n",
      "Validation Loss: 255.6114\n",
      "NME: 0.1226\n",
      "Epoch [93/300], Loss: 266.7195\n",
      "Validation Loss: 271.9878\n",
      "NME: 0.1286\n",
      "Epoch [94/300], Loss: 263.0433\n",
      "Validation Loss: 271.6041\n",
      "NME: 0.1303\n",
      "Epoch [95/300], Loss: 252.8127\n",
      "Validation Loss: 267.9984\n",
      "NME: 0.1302\n",
      "Epoch [96/300], Loss: 275.3996\n",
      "Validation Loss: 261.4370\n",
      "NME: 0.1271\n",
      "Epoch [97/300], Loss: 247.2291\n",
      "Validation Loss: 264.6637\n",
      "NME: 0.1273\n",
      "Epoch [98/300], Loss: 263.8803\n",
      "Validation Loss: 288.6414\n",
      "NME: 0.1360\n",
      "Epoch [99/300], Loss: 261.4802\n",
      "Validation Loss: 266.3794\n",
      "NME: 0.1248\n",
      "Epoch [100/300], Loss: 242.7016\n",
      "Validation Loss: 272.1297\n",
      "NME: 0.1282\n",
      "Epoch [101/300], Loss: 239.6510\n",
      "Validation Loss: 271.1260\n",
      "NME: 0.1249\n",
      "Epoch [102/300], Loss: 226.1421\n",
      "Validation Loss: 267.5277\n",
      "NME: 0.1249\n",
      "Epoch [103/300], Loss: 242.1084\n",
      "Validation Loss: 266.3271\n",
      "NME: 0.1233\n",
      "Epoch [104/300], Loss: 233.5000\n",
      "Validation Loss: 270.4638\n",
      "NME: 0.1266\n",
      "Epoch [105/300], Loss: 245.2378\n",
      "Validation Loss: 270.5174\n",
      "NME: 0.1237\n",
      "Epoch [106/300], Loss: 240.0249\n",
      "Validation Loss: 273.6978\n",
      "NME: 0.1264\n",
      "Epoch [107/300], Loss: 234.2205\n",
      "Validation Loss: 268.6146\n",
      "NME: 0.1288\n",
      "Epoch [108/300], Loss: 225.6399\n",
      "Validation Loss: 265.7619\n",
      "NME: 0.1250\n",
      "Epoch [109/300], Loss: 255.6421\n",
      "Validation Loss: 273.3341\n",
      "NME: 0.1239\n",
      "Epoch [110/300], Loss: 230.5268\n",
      "Validation Loss: 263.4090\n",
      "NME: 0.1213\n",
      "Epoch [111/300], Loss: 235.8064\n",
      "Validation Loss: 279.8209\n",
      "NME: 0.1330\n",
      "Epoch [112/300], Loss: 218.3236\n",
      "Validation Loss: 267.8245\n",
      "NME: 0.1243\n",
      "Epoch [113/300], Loss: 229.4616\n",
      "Validation Loss: 276.5601\n",
      "NME: 0.1276\n",
      "Epoch [114/300], Loss: 222.5198\n",
      "Validation Loss: 280.2866\n",
      "NME: 0.1264\n",
      "Epoch [115/300], Loss: 202.1183\n",
      "Validation Loss: 264.9752\n",
      "NME: 0.1218\n",
      "Epoch [116/300], Loss: 220.4734\n",
      "Validation Loss: 278.9112\n",
      "NME: 0.1317\n",
      "Epoch [117/300], Loss: 234.3276\n",
      "Validation Loss: 266.7565\n",
      "NME: 0.1227\n",
      "Epoch [118/300], Loss: 228.9874\n",
      "Validation Loss: 265.2728\n",
      "NME: 0.1233\n",
      "Epoch [119/300], Loss: 207.0679\n",
      "Validation Loss: 259.1687\n",
      "NME: 0.1223\n",
      "Epoch [120/300], Loss: 236.3930\n",
      "Validation Loss: 251.8792\n",
      "NME: 0.1192\n",
      "Best model saved at epoch 120 with val_loss 251.8792\n",
      "Epoch [121/300], Loss: 209.4335\n",
      "Validation Loss: 255.6773\n",
      "NME: 0.1193\n",
      "Epoch [122/300], Loss: 211.5213\n",
      "Validation Loss: 255.3787\n",
      "NME: 0.1216\n",
      "Epoch [123/300], Loss: 206.2778\n",
      "Validation Loss: 266.8454\n",
      "NME: 0.1205\n",
      "Epoch [124/300], Loss: 201.1002\n",
      "Validation Loss: 255.9418\n",
      "NME: 0.1225\n",
      "Epoch [125/300], Loss: 199.4588\n",
      "Validation Loss: 260.3772\n",
      "NME: 0.1205\n",
      "Epoch [126/300], Loss: 207.3041\n",
      "Validation Loss: 256.2201\n",
      "NME: 0.1194\n",
      "Epoch [127/300], Loss: 201.6118\n",
      "Validation Loss: 248.9943\n",
      "NME: 0.1200\n",
      "Best model saved at epoch 127 with val_loss 248.9943\n",
      "Epoch [128/300], Loss: 211.4581\n",
      "Validation Loss: 269.0113\n",
      "NME: 0.1237\n",
      "Epoch [129/300], Loss: 219.9082\n",
      "Validation Loss: 261.4740\n",
      "NME: 0.1225\n",
      "Epoch [130/300], Loss: 206.3312\n",
      "Validation Loss: 266.8847\n",
      "NME: 0.1221\n",
      "Epoch [131/300], Loss: 197.1859\n",
      "Validation Loss: 263.4945\n",
      "NME: 0.1222\n",
      "Epoch [132/300], Loss: 206.0747\n",
      "Validation Loss: 269.3398\n",
      "NME: 0.1210\n",
      "Epoch [133/300], Loss: 196.6000\n",
      "Validation Loss: 257.0908\n",
      "NME: 0.1205\n",
      "Epoch [134/300], Loss: 196.7168\n",
      "Validation Loss: 257.4083\n",
      "NME: 0.1203\n",
      "Epoch [135/300], Loss: 197.8804\n",
      "Validation Loss: 259.1334\n",
      "NME: 0.1200\n",
      "Epoch [136/300], Loss: 199.0364\n",
      "Validation Loss: 249.9108\n",
      "NME: 0.1182\n",
      "Epoch [137/300], Loss: 199.2519\n",
      "Validation Loss: 254.8822\n",
      "NME: 0.1187\n",
      "Epoch [138/300], Loss: 191.0729\n",
      "Validation Loss: 260.9844\n",
      "NME: 0.1207\n",
      "Epoch [139/300], Loss: 189.5893\n",
      "Validation Loss: 255.6661\n",
      "NME: 0.1186\n",
      "Epoch [140/300], Loss: 198.6240\n",
      "Validation Loss: 253.7624\n",
      "NME: 0.1211\n",
      "Epoch [141/300], Loss: 197.1346\n",
      "Validation Loss: 251.8893\n",
      "NME: 0.1193\n",
      "Epoch [142/300], Loss: 193.2162\n",
      "Validation Loss: 266.7226\n",
      "NME: 0.1244\n",
      "Epoch [143/300], Loss: 197.0159\n",
      "Validation Loss: 253.9742\n",
      "NME: 0.1227\n",
      "Epoch [144/300], Loss: 201.4680\n",
      "Validation Loss: 246.6910\n",
      "NME: 0.1171\n",
      "Best model saved at epoch 144 with val_loss 246.6910\n",
      "Epoch [145/300], Loss: 193.0129\n",
      "Validation Loss: 251.8870\n",
      "NME: 0.1233\n",
      "Epoch [146/300], Loss: 189.4679\n",
      "Validation Loss: 250.3363\n",
      "NME: 0.1221\n",
      "Epoch [147/300], Loss: 197.4297\n",
      "Validation Loss: 243.5231\n",
      "NME: 0.1207\n",
      "Best model saved at epoch 147 with val_loss 243.5231\n",
      "Epoch [148/300], Loss: 188.9166\n",
      "Validation Loss: 245.8043\n",
      "NME: 0.1199\n",
      "Epoch [149/300], Loss: 186.5975\n",
      "Validation Loss: 235.9704\n",
      "NME: 0.1156\n",
      "Best model saved at epoch 149 with val_loss 235.9704\n",
      "Epoch [150/300], Loss: 191.0756\n",
      "Validation Loss: 246.4558\n",
      "NME: 0.1181\n",
      "Epoch [151/300], Loss: 188.2783\n",
      "Validation Loss: 260.0060\n",
      "NME: 0.1174\n",
      "Epoch [152/300], Loss: 183.6771\n",
      "Validation Loss: 267.3580\n",
      "NME: 0.1195\n",
      "Epoch [153/300], Loss: 190.8008\n",
      "Validation Loss: 254.8062\n",
      "NME: 0.1179\n",
      "Epoch [154/300], Loss: 200.0717\n",
      "Validation Loss: 237.6527\n",
      "NME: 0.1178\n",
      "Epoch [155/300], Loss: 178.0718\n",
      "Validation Loss: 238.4094\n",
      "NME: 0.1161\n",
      "Epoch [156/300], Loss: 184.6036\n",
      "Validation Loss: 242.7503\n",
      "NME: 0.1160\n",
      "Epoch [157/300], Loss: 177.6168\n",
      "Validation Loss: 228.7660\n",
      "NME: 0.1154\n",
      "Best model saved at epoch 157 with val_loss 228.7660\n",
      "Epoch [158/300], Loss: 180.7559\n",
      "Validation Loss: 242.1636\n",
      "NME: 0.1193\n",
      "Epoch [159/300], Loss: 171.1272\n",
      "Validation Loss: 234.4512\n",
      "NME: 0.1142\n",
      "Epoch [160/300], Loss: 180.0598\n",
      "Validation Loss: 242.2461\n",
      "NME: 0.1139\n",
      "Epoch [161/300], Loss: 181.6315\n",
      "Validation Loss: 241.8889\n",
      "NME: 0.1156\n",
      "Epoch [162/300], Loss: 181.9941\n",
      "Validation Loss: 252.5659\n",
      "NME: 0.1161\n",
      "Epoch [163/300], Loss: 173.6168\n",
      "Validation Loss: 244.4748\n",
      "NME: 0.1132\n",
      "Epoch [164/300], Loss: 171.2280\n",
      "Validation Loss: 241.2783\n",
      "NME: 0.1153\n",
      "Epoch [165/300], Loss: 170.3510\n",
      "Validation Loss: 235.5627\n",
      "NME: 0.1125\n",
      "Epoch [166/300], Loss: 169.6617\n",
      "Validation Loss: 241.5092\n",
      "NME: 0.1167\n",
      "Epoch [167/300], Loss: 173.1261\n",
      "Validation Loss: 239.9134\n",
      "NME: 0.1138\n",
      "Epoch [168/300], Loss: 167.7168\n",
      "Validation Loss: 232.1921\n",
      "NME: 0.1124\n",
      "Epoch [169/300], Loss: 175.3295\n",
      "Validation Loss: 240.3822\n",
      "NME: 0.1172\n",
      "Epoch [170/300], Loss: 176.0883\n",
      "Validation Loss: 242.5901\n",
      "NME: 0.1154\n",
      "Epoch [171/300], Loss: 166.8239\n",
      "Validation Loss: 228.9369\n",
      "NME: 0.1114\n",
      "Epoch [172/300], Loss: 160.5708\n",
      "Validation Loss: 219.9978\n",
      "NME: 0.1125\n",
      "Best model saved at epoch 172 with val_loss 219.9978\n",
      "Epoch [173/300], Loss: 168.8470\n",
      "Validation Loss: 224.3604\n",
      "NME: 0.1145\n",
      "Epoch [174/300], Loss: 172.3321\n",
      "Validation Loss: 219.7379\n",
      "NME: 0.1097\n",
      "Best model saved at epoch 174 with val_loss 219.7379\n",
      "Epoch [175/300], Loss: 167.6400\n",
      "Validation Loss: 232.7741\n",
      "NME: 0.1115\n",
      "Epoch [176/300], Loss: 161.9346\n",
      "Validation Loss: 225.8149\n",
      "NME: 0.1167\n",
      "Epoch [177/300], Loss: 161.4747\n",
      "Validation Loss: 229.3982\n",
      "NME: 0.1099\n",
      "Epoch [178/300], Loss: 161.3784\n",
      "Validation Loss: 210.9042\n",
      "NME: 0.1088\n",
      "Best model saved at epoch 178 with val_loss 210.9042\n",
      "Epoch [179/300], Loss: 165.7657\n",
      "Validation Loss: 218.6662\n",
      "NME: 0.1091\n",
      "Epoch [180/300], Loss: 156.9233\n",
      "Validation Loss: 213.6683\n",
      "NME: 0.1092\n",
      "Epoch [181/300], Loss: 155.9843\n",
      "Validation Loss: 210.2966\n",
      "NME: 0.1085\n",
      "Best model saved at epoch 181 with val_loss 210.2966\n",
      "Epoch [182/300], Loss: 158.5944\n",
      "Validation Loss: 209.5521\n",
      "NME: 0.1079\n",
      "Best model saved at epoch 182 with val_loss 209.5521\n",
      "Epoch [183/300], Loss: 164.2408\n",
      "Validation Loss: 215.8970\n",
      "NME: 0.1105\n",
      "Epoch [184/300], Loss: 151.4583\n",
      "Validation Loss: 210.8600\n",
      "NME: 0.1067\n",
      "Epoch [185/300], Loss: 156.8790\n",
      "Validation Loss: 208.3605\n",
      "NME: 0.1061\n",
      "Best model saved at epoch 185 with val_loss 208.3605\n",
      "Epoch [186/300], Loss: 151.0549\n",
      "Validation Loss: 211.5533\n",
      "NME: 0.1080\n",
      "Epoch [187/300], Loss: 143.5180\n",
      "Validation Loss: 210.0878\n",
      "NME: 0.1085\n",
      "Epoch [188/300], Loss: 150.2116\n",
      "Validation Loss: 217.4509\n",
      "NME: 0.1124\n",
      "Epoch [189/300], Loss: 152.0954\n",
      "Validation Loss: 204.4020\n",
      "NME: 0.1055\n",
      "Best model saved at epoch 189 with val_loss 204.4020\n",
      "Epoch [190/300], Loss: 152.6812\n",
      "Validation Loss: 201.3034\n",
      "NME: 0.1051\n",
      "Best model saved at epoch 190 with val_loss 201.3034\n",
      "Epoch [191/300], Loss: 145.2603\n",
      "Validation Loss: 204.4921\n",
      "NME: 0.1043\n",
      "Epoch [192/300], Loss: 153.5950\n",
      "Validation Loss: 208.4243\n",
      "NME: 0.1078\n",
      "Epoch [193/300], Loss: 144.7007\n",
      "Validation Loss: 196.6432\n",
      "NME: 0.1031\n",
      "Best model saved at epoch 193 with val_loss 196.6432\n",
      "Epoch [194/300], Loss: 148.5287\n",
      "Validation Loss: 205.3703\n",
      "NME: 0.1053\n",
      "Epoch [195/300], Loss: 147.6807\n",
      "Validation Loss: 216.1543\n",
      "NME: 0.1111\n",
      "Epoch [196/300], Loss: 150.4415\n",
      "Validation Loss: 207.8854\n",
      "NME: 0.1039\n",
      "Epoch [197/300], Loss: 151.4304\n",
      "Validation Loss: 204.5389\n",
      "NME: 0.1066\n",
      "Epoch [198/300], Loss: 149.5340\n",
      "Validation Loss: 208.7581\n",
      "NME: 0.1056\n",
      "Epoch [199/300], Loss: 144.2660\n",
      "Validation Loss: 206.0084\n",
      "NME: 0.1031\n",
      "Epoch [200/300], Loss: 135.6194\n",
      "Validation Loss: 196.2058\n",
      "NME: 0.1008\n",
      "Best model saved at epoch 200 with val_loss 196.2058\n",
      "Epoch [201/300], Loss: 141.9240\n",
      "Validation Loss: 198.0644\n",
      "NME: 0.1025\n",
      "Epoch [202/300], Loss: 143.1065\n",
      "Validation Loss: 195.3167\n",
      "NME: 0.1023\n",
      "Best model saved at epoch 202 with val_loss 195.3167\n",
      "Epoch [203/300], Loss: 140.3883\n",
      "Validation Loss: 194.6460\n",
      "NME: 0.1031\n",
      "Best model saved at epoch 203 with val_loss 194.6460\n",
      "Epoch [204/300], Loss: 140.0686\n",
      "Validation Loss: 212.6889\n",
      "NME: 0.1014\n",
      "Epoch [205/300], Loss: 136.8418\n",
      "Validation Loss: 194.5101\n",
      "NME: 0.1041\n",
      "Best model saved at epoch 205 with val_loss 194.5101\n",
      "Epoch [206/300], Loss: 135.8827\n",
      "Validation Loss: 191.0282\n",
      "NME: 0.0998\n",
      "Best model saved at epoch 206 with val_loss 191.0282\n",
      "Epoch [207/300], Loss: 140.0213\n",
      "Validation Loss: 192.5373\n",
      "NME: 0.1001\n",
      "Epoch [208/300], Loss: 139.5720\n",
      "Validation Loss: 193.0835\n",
      "NME: 0.1008\n",
      "Epoch [209/300], Loss: 137.1259\n",
      "Validation Loss: 199.4245\n",
      "NME: 0.1032\n",
      "Epoch [210/300], Loss: 144.9691\n",
      "Validation Loss: 207.5394\n",
      "NME: 0.1030\n",
      "Epoch [211/300], Loss: 141.9907\n",
      "Validation Loss: 194.1055\n",
      "NME: 0.1001\n",
      "Epoch [212/300], Loss: 140.0746\n",
      "Validation Loss: 204.5354\n",
      "NME: 0.1017\n",
      "Epoch [213/300], Loss: 135.7973\n",
      "Validation Loss: 200.5058\n",
      "NME: 0.1001\n",
      "Epoch [214/300], Loss: 134.4805\n",
      "Validation Loss: 194.6421\n",
      "NME: 0.0991\n",
      "Epoch [215/300], Loss: 132.2975\n",
      "Validation Loss: 192.5863\n",
      "NME: 0.1010\n",
      "Epoch [216/300], Loss: 127.7557\n",
      "Validation Loss: 184.7233\n",
      "NME: 0.0998\n",
      "Best model saved at epoch 216 with val_loss 184.7233\n",
      "Epoch [217/300], Loss: 134.0746\n",
      "Validation Loss: 199.4886\n",
      "NME: 0.1023\n",
      "Epoch [218/300], Loss: 129.0246\n",
      "Validation Loss: 186.5785\n",
      "NME: 0.0992\n",
      "Epoch [219/300], Loss: 125.3108\n",
      "Validation Loss: 191.2480\n",
      "NME: 0.0977\n",
      "Epoch [220/300], Loss: 132.0967\n",
      "Validation Loss: 202.1603\n",
      "NME: 0.1005\n",
      "Epoch [221/300], Loss: 124.7463\n",
      "Validation Loss: 185.6839\n",
      "NME: 0.0984\n",
      "Epoch [222/300], Loss: 128.4099\n",
      "Validation Loss: 184.2620\n",
      "NME: 0.0974\n",
      "Best model saved at epoch 222 with val_loss 184.2620\n",
      "Epoch [223/300], Loss: 134.9938\n",
      "Validation Loss: 190.5293\n",
      "NME: 0.1021\n",
      "Epoch [224/300], Loss: 131.7752\n",
      "Validation Loss: 192.3909\n",
      "NME: 0.1001\n",
      "Epoch [225/300], Loss: 131.4021\n",
      "Validation Loss: 194.3169\n",
      "NME: 0.0990\n",
      "Epoch [226/300], Loss: 128.0633\n",
      "Validation Loss: 188.8195\n",
      "NME: 0.0989\n",
      "Epoch [227/300], Loss: 129.3495\n",
      "Validation Loss: 191.3974\n",
      "NME: 0.0964\n",
      "Epoch [228/300], Loss: 124.5607\n",
      "Validation Loss: 183.5360\n",
      "NME: 0.0992\n",
      "Best model saved at epoch 228 with val_loss 183.5360\n",
      "Epoch [229/300], Loss: 123.3632\n",
      "Validation Loss: 183.0542\n",
      "NME: 0.0991\n",
      "Best model saved at epoch 229 with val_loss 183.0542\n",
      "Epoch [230/300], Loss: 125.5387\n",
      "Validation Loss: 182.4286\n",
      "NME: 0.0960\n",
      "Best model saved at epoch 230 with val_loss 182.4286\n",
      "Epoch [231/300], Loss: 122.1983\n",
      "Validation Loss: 189.8788\n",
      "NME: 0.1018\n",
      "Epoch [232/300], Loss: 120.8149\n",
      "Validation Loss: 182.0027\n",
      "NME: 0.0960\n",
      "Best model saved at epoch 232 with val_loss 182.0027\n",
      "Epoch [233/300], Loss: 115.8809\n",
      "Validation Loss: 188.4742\n",
      "NME: 0.0979\n",
      "Epoch [234/300], Loss: 126.6512\n",
      "Validation Loss: 195.8979\n",
      "NME: 0.1086\n",
      "Epoch [235/300], Loss: 121.8859\n",
      "Validation Loss: 189.0777\n",
      "NME: 0.0973\n",
      "Epoch [236/300], Loss: 117.1234\n",
      "Validation Loss: 185.9402\n",
      "NME: 0.0975\n",
      "Epoch [237/300], Loss: 121.6399\n",
      "Validation Loss: 190.3305\n",
      "NME: 0.0967\n",
      "Epoch [238/300], Loss: 114.2919\n",
      "Validation Loss: 196.3527\n",
      "NME: 0.0991\n",
      "Epoch [239/300], Loss: 121.7440\n",
      "Validation Loss: 180.2496\n",
      "NME: 0.0962\n",
      "Best model saved at epoch 239 with val_loss 180.2496\n",
      "Epoch [240/300], Loss: 116.7018\n",
      "Validation Loss: 192.1610\n",
      "NME: 0.0983\n",
      "Epoch [241/300], Loss: 118.2323\n",
      "Validation Loss: 190.7377\n",
      "NME: 0.0971\n",
      "Epoch [242/300], Loss: 115.6295\n",
      "Validation Loss: 198.7590\n",
      "NME: 0.1015\n",
      "Epoch [243/300], Loss: 120.7922\n",
      "Validation Loss: 193.0542\n",
      "NME: 0.0999\n",
      "Epoch [244/300], Loss: 117.3751\n",
      "Validation Loss: 179.2630\n",
      "NME: 0.0956\n",
      "Best model saved at epoch 244 with val_loss 179.2630\n",
      "Epoch [245/300], Loss: 116.7842\n",
      "Validation Loss: 193.5544\n",
      "NME: 0.0979\n",
      "Epoch [246/300], Loss: 112.2692\n",
      "Validation Loss: 178.6240\n",
      "NME: 0.0946\n",
      "Best model saved at epoch 246 with val_loss 178.6240\n",
      "Epoch [247/300], Loss: 109.4568\n",
      "Validation Loss: 181.5819\n",
      "NME: 0.0955\n",
      "Epoch [248/300], Loss: 112.3465\n",
      "Validation Loss: 187.1226\n",
      "NME: 0.0959\n",
      "Epoch [249/300], Loss: 110.9312\n",
      "Validation Loss: 181.6026\n",
      "NME: 0.0939\n",
      "Epoch [250/300], Loss: 111.2752\n",
      "Validation Loss: 176.4368\n",
      "NME: 0.0946\n",
      "Best model saved at epoch 250 with val_loss 176.4368\n",
      "Epoch [251/300], Loss: 118.1152\n",
      "Validation Loss: 183.4394\n",
      "NME: 0.0968\n",
      "Epoch [252/300], Loss: 114.3048\n",
      "Validation Loss: 181.7678\n",
      "NME: 0.0948\n",
      "Epoch [253/300], Loss: 114.3693\n",
      "Validation Loss: 176.1678\n",
      "NME: 0.0987\n",
      "Best model saved at epoch 253 with val_loss 176.1678\n",
      "Epoch [254/300], Loss: 112.5904\n",
      "Validation Loss: 181.9933\n",
      "NME: 0.0995\n",
      "Epoch [255/300], Loss: 116.4580\n",
      "Validation Loss: 175.6747\n",
      "NME: 0.0956\n",
      "Best model saved at epoch 255 with val_loss 175.6747\n",
      "Epoch [256/300], Loss: 109.8408\n",
      "Validation Loss: 179.9096\n",
      "NME: 0.0969\n",
      "Epoch [257/300], Loss: 111.7627\n",
      "Validation Loss: 179.2649\n",
      "NME: 0.0964\n",
      "Epoch [258/300], Loss: 109.8898\n",
      "Validation Loss: 180.3658\n",
      "NME: 0.0957\n",
      "Epoch [259/300], Loss: 114.3161\n",
      "Validation Loss: 181.9754\n",
      "NME: 0.0954\n",
      "Epoch [260/300], Loss: 121.0442\n",
      "Validation Loss: 175.5846\n",
      "NME: 0.0953\n",
      "Best model saved at epoch 260 with val_loss 175.5846\n",
      "Epoch [261/300], Loss: 110.2245\n",
      "Validation Loss: 177.6291\n",
      "NME: 0.0960\n",
      "Epoch [262/300], Loss: 106.6657\n",
      "Validation Loss: 175.1231\n",
      "NME: 0.0946\n",
      "Best model saved at epoch 262 with val_loss 175.1231\n",
      "Epoch [263/300], Loss: 112.0366\n",
      "Validation Loss: 178.6529\n",
      "NME: 0.0947\n",
      "Epoch [264/300], Loss: 106.5549\n",
      "Validation Loss: 179.1727\n",
      "NME: 0.0947\n",
      "Epoch [265/300], Loss: 108.9534\n",
      "Validation Loss: 187.5020\n",
      "NME: 0.0967\n",
      "Epoch [266/300], Loss: 109.0409\n",
      "Validation Loss: 180.2267\n",
      "NME: 0.0944\n",
      "Epoch [267/300], Loss: 105.7896\n",
      "Validation Loss: 180.5394\n",
      "NME: 0.0945\n",
      "Epoch [268/300], Loss: 102.8241\n",
      "Validation Loss: 182.2388\n",
      "NME: 0.0954\n",
      "Epoch [269/300], Loss: 106.6501\n",
      "Validation Loss: 182.5552\n",
      "NME: 0.0963\n",
      "Epoch [270/300], Loss: 105.3665\n",
      "Validation Loss: 181.4505\n",
      "NME: 0.0947\n",
      "Epoch [271/300], Loss: 104.5239\n",
      "Validation Loss: 183.3534\n",
      "NME: 0.0962\n",
      "Epoch [272/300], Loss: 108.4945\n",
      "Validation Loss: 186.0081\n",
      "NME: 0.0951\n",
      "Epoch [273/300], Loss: 108.7296\n",
      "Validation Loss: 180.5343\n",
      "NME: 0.0959\n",
      "Epoch [274/300], Loss: 105.2616\n",
      "Validation Loss: 190.2611\n",
      "NME: 0.0952\n",
      "Epoch [275/300], Loss: 101.6994\n",
      "Validation Loss: 180.4696\n",
      "NME: 0.0957\n",
      "Epoch [276/300], Loss: 108.6453\n",
      "Validation Loss: 183.3376\n",
      "NME: 0.0935\n",
      "Epoch [277/300], Loss: 103.7884\n",
      "Validation Loss: 206.8658\n",
      "NME: 0.0977\n",
      "Epoch [278/300], Loss: 102.1825\n",
      "Validation Loss: 189.3671\n",
      "NME: 0.0952\n",
      "Epoch [279/300], Loss: 105.3162\n",
      "Validation Loss: 179.2681\n",
      "NME: 0.0941\n",
      "Epoch [280/300], Loss: 102.7215\n",
      "Validation Loss: 175.5559\n",
      "NME: 0.0960\n",
      "Epoch [281/300], Loss: 103.6216\n",
      "Validation Loss: 176.9561\n",
      "NME: 0.0965\n",
      "Epoch [282/300], Loss: 100.7407\n",
      "Validation Loss: 181.8555\n",
      "NME: 0.0954\n",
      "Epoch [283/300], Loss: 102.6448\n",
      "Validation Loss: 184.1497\n",
      "NME: 0.0950\n",
      "Epoch [284/300], Loss: 99.8879\n",
      "Validation Loss: 179.3844\n",
      "NME: 0.0938\n",
      "Epoch [285/300], Loss: 96.2461\n",
      "Validation Loss: 180.5619\n",
      "NME: 0.0964\n",
      "Epoch [286/300], Loss: 113.4211\n",
      "Validation Loss: 179.5271\n",
      "NME: 0.0954\n",
      "Epoch [287/300], Loss: 100.5006\n",
      "Validation Loss: 176.5362\n",
      "NME: 0.0948\n",
      "Epoch [288/300], Loss: 101.6462\n",
      "Validation Loss: 172.4909\n",
      "NME: 0.0945\n",
      "Best model saved at epoch 288 with val_loss 172.4909\n",
      "Epoch [289/300], Loss: 101.9866\n",
      "Validation Loss: 179.5896\n",
      "NME: 0.0965\n",
      "Epoch [290/300], Loss: 104.5300\n",
      "Validation Loss: 176.6414\n",
      "NME: 0.0952\n",
      "Epoch [291/300], Loss: 104.1975\n",
      "Validation Loss: 187.4523\n",
      "NME: 0.0966\n",
      "Epoch [292/300], Loss: 112.4568\n",
      "Validation Loss: 184.8581\n",
      "NME: 0.0994\n",
      "Epoch [293/300], Loss: 98.5749\n",
      "Validation Loss: 166.0534\n",
      "NME: 0.0920\n",
      "Best model saved at epoch 293 with val_loss 166.0534\n",
      "Epoch [294/300], Loss: 97.0124\n",
      "Validation Loss: 174.1125\n",
      "NME: 0.0947\n",
      "Epoch [295/300], Loss: 98.9435\n",
      "Validation Loss: 172.9730\n",
      "NME: 0.0933\n",
      "Epoch [296/300], Loss: 98.8004\n",
      "Validation Loss: 174.7155\n",
      "NME: 0.0962\n",
      "Epoch [297/300], Loss: 105.0674\n",
      "Validation Loss: 182.9651\n",
      "NME: 0.0944\n",
      "Epoch [298/300], Loss: 97.0537\n",
      "Validation Loss: 180.5595\n",
      "NME: 0.0952\n",
      "Epoch [299/300], Loss: 97.2703\n",
      "Validation Loss: 182.0793\n",
      "NME: 0.0941\n",
      "Epoch [300/300], Loss: 95.3500\n",
      "Validation Loss: 183.5618\n",
      "NME: 0.0946\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "oreja_izq = [27, 28, 29, 30, 31]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EarLeftDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_oreja_izq = calcular_centro_region(landmarks, oreja_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_oreja_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la oreja izquierda\n",
    "        ear_left_points = np.array([landmarks[i] for i in oreja_izq], dtype=np.float32)\n",
    "        ear_left_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(ear_left_points), 1))\n",
    "        points_ones = np.hstack([ear_left_points, ones])\n",
    "        ear_left_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la oreja izquierda\n",
    "        centro_x, centro_y = calcular_centro_region(ear_left_points_rotated, range(len(oreja_izq)))\n",
    "\n",
    "        # Definir los límites del recorte de 112x112 píxeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_ear = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_ear, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la oreja izquierda al nuevo recorte\n",
    "        ear_left_points_adjusted = [(p[0] - x1, p[1] - y1) for p in ear_left_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        ear_left_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in ear_left_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=ear_left_points_scaled)\n",
    "            image = augmented['image']\n",
    "            ear_left_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(ear_left_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EarLeftDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EarLeftDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EarLeft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EarLeft, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(oreja_izq) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EarLeft().cuda()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para oreja izquierda)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, ear_left_points, _, _, _ in train_dataloader:\n",
    "            images, ear_left_points = images.cuda(), ear_left_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ear_left_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_ear_left_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_ear_left_points = val_images.cuda(), val_ear_left_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_ear_left_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_ear_left_points.cpu().numpy().reshape(-1, len(oreja_izq), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(oreja_izq), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(oreja_izq))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EarLeftLandmarks V3.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 16192.0011\n",
      "Validation Loss: 15823.5184\n",
      "NME: 1.2604\n",
      "Best model saved at epoch 1 with val_loss 15823.5184\n",
      "Epoch [2/300], Loss: 14375.6213\n",
      "Validation Loss: 13012.2011\n",
      "NME: 1.1824\n",
      "Best model saved at epoch 2 with val_loss 13012.2011\n",
      "Epoch [3/300], Loss: 10416.5522\n",
      "Validation Loss: 8376.8387\n",
      "NME: 0.9797\n",
      "Best model saved at epoch 3 with val_loss 8376.8387\n",
      "Epoch [4/300], Loss: 5671.8928\n",
      "Validation Loss: 3423.1829\n",
      "NME: 0.5915\n",
      "Best model saved at epoch 4 with val_loss 3423.1829\n",
      "Epoch [5/300], Loss: 2348.4614\n",
      "Validation Loss: 1499.0376\n",
      "NME: 0.2963\n",
      "Best model saved at epoch 5 with val_loss 1499.0376\n",
      "Epoch [6/300], Loss: 1502.2516\n",
      "Validation Loss: 1237.2129\n",
      "NME: 0.2688\n",
      "Best model saved at epoch 6 with val_loss 1237.2129\n",
      "Epoch [7/300], Loss: 1337.1945\n",
      "Validation Loss: 1152.7776\n",
      "NME: 0.2622\n",
      "Best model saved at epoch 7 with val_loss 1152.7776\n",
      "Epoch [8/300], Loss: 1317.7789\n",
      "Validation Loss: 1124.7537\n",
      "NME: 0.2647\n",
      "Best model saved at epoch 8 with val_loss 1124.7537\n",
      "Epoch [9/300], Loss: 1275.1480\n",
      "Validation Loss: 1116.8022\n",
      "NME: 0.2679\n",
      "Best model saved at epoch 9 with val_loss 1116.8022\n",
      "Epoch [10/300], Loss: 1259.2422\n",
      "Validation Loss: 1114.8580\n",
      "NME: 0.2681\n",
      "Best model saved at epoch 10 with val_loss 1114.8580\n",
      "Epoch [11/300], Loss: 1284.9276\n",
      "Validation Loss: 1105.8700\n",
      "NME: 0.2679\n",
      "Best model saved at epoch 11 with val_loss 1105.8700\n",
      "Epoch [12/300], Loss: 1293.3895\n",
      "Validation Loss: 1100.9506\n",
      "NME: 0.2671\n",
      "Best model saved at epoch 12 with val_loss 1100.9506\n",
      "Epoch [13/300], Loss: 1256.0074\n",
      "Validation Loss: 1094.7204\n",
      "NME: 0.2674\n",
      "Best model saved at epoch 13 with val_loss 1094.7204\n",
      "Epoch [14/300], Loss: 1276.0353\n",
      "Validation Loss: 1101.0641\n",
      "NME: 0.2641\n",
      "Epoch [15/300], Loss: 1250.6650\n",
      "Validation Loss: 1101.0707\n",
      "NME: 0.2642\n",
      "Epoch [16/300], Loss: 1249.4400\n",
      "Validation Loss: 1093.2611\n",
      "NME: 0.2638\n",
      "Best model saved at epoch 16 with val_loss 1093.2611\n",
      "Epoch [17/300], Loss: 1253.1593\n",
      "Validation Loss: 1083.6333\n",
      "NME: 0.2625\n",
      "Best model saved at epoch 17 with val_loss 1083.6333\n",
      "Epoch [18/300], Loss: 1218.4200\n",
      "Validation Loss: 1078.4145\n",
      "NME: 0.2624\n",
      "Best model saved at epoch 18 with val_loss 1078.4145\n",
      "Epoch [19/300], Loss: 1223.7247\n",
      "Validation Loss: 1081.9056\n",
      "NME: 0.2631\n",
      "Epoch [20/300], Loss: 1208.7434\n",
      "Validation Loss: 1073.4725\n",
      "NME: 0.2625\n",
      "Best model saved at epoch 20 with val_loss 1073.4725\n",
      "Epoch [21/300], Loss: 1201.5278\n",
      "Validation Loss: 1046.7615\n",
      "NME: 0.2593\n",
      "Best model saved at epoch 21 with val_loss 1046.7615\n",
      "Epoch [22/300], Loss: 1188.7796\n",
      "Validation Loss: 1026.2652\n",
      "NME: 0.2526\n",
      "Best model saved at epoch 22 with val_loss 1026.2652\n",
      "Epoch [23/300], Loss: 1144.7219\n",
      "Validation Loss: 1008.5265\n",
      "NME: 0.2506\n",
      "Best model saved at epoch 23 with val_loss 1008.5265\n",
      "Epoch [24/300], Loss: 1125.4575\n",
      "Validation Loss: 971.1873\n",
      "NME: 0.2452\n",
      "Best model saved at epoch 24 with val_loss 971.1873\n",
      "Epoch [25/300], Loss: 1132.5535\n",
      "Validation Loss: 938.5308\n",
      "NME: 0.2398\n",
      "Best model saved at epoch 25 with val_loss 938.5308\n",
      "Epoch [26/300], Loss: 1069.1354\n",
      "Validation Loss: 907.4194\n",
      "NME: 0.2322\n",
      "Best model saved at epoch 26 with val_loss 907.4194\n",
      "Epoch [27/300], Loss: 1018.1332\n",
      "Validation Loss: 839.6606\n",
      "NME: 0.2202\n",
      "Best model saved at epoch 27 with val_loss 839.6606\n",
      "Epoch [28/300], Loss: 956.1544\n",
      "Validation Loss: 803.8447\n",
      "NME: 0.2128\n",
      "Best model saved at epoch 28 with val_loss 803.8447\n",
      "Epoch [29/300], Loss: 925.4075\n",
      "Validation Loss: 747.2183\n",
      "NME: 0.2006\n",
      "Best model saved at epoch 29 with val_loss 747.2183\n",
      "Epoch [30/300], Loss: 891.9761\n",
      "Validation Loss: 692.1131\n",
      "NME: 0.1891\n",
      "Best model saved at epoch 30 with val_loss 692.1131\n",
      "Epoch [31/300], Loss: 862.5194\n",
      "Validation Loss: 645.5361\n",
      "NME: 0.1844\n",
      "Best model saved at epoch 31 with val_loss 645.5361\n",
      "Epoch [32/300], Loss: 812.2309\n",
      "Validation Loss: 608.5703\n",
      "NME: 0.1803\n",
      "Best model saved at epoch 32 with val_loss 608.5703\n",
      "Epoch [33/300], Loss: 719.2444\n",
      "Validation Loss: 570.3379\n",
      "NME: 0.1732\n",
      "Best model saved at epoch 33 with val_loss 570.3379\n",
      "Epoch [34/300], Loss: 721.2001\n",
      "Validation Loss: 550.5490\n",
      "NME: 0.1690\n",
      "Best model saved at epoch 34 with val_loss 550.5490\n",
      "Epoch [35/300], Loss: 668.2824\n",
      "Validation Loss: 537.4765\n",
      "NME: 0.1661\n",
      "Best model saved at epoch 35 with val_loss 537.4765\n",
      "Epoch [36/300], Loss: 673.0614\n",
      "Validation Loss: 545.6794\n",
      "NME: 0.1660\n",
      "Epoch [37/300], Loss: 669.6284\n",
      "Validation Loss: 499.3228\n",
      "NME: 0.1618\n",
      "Best model saved at epoch 37 with val_loss 499.3228\n",
      "Epoch [38/300], Loss: 614.7802\n",
      "Validation Loss: 488.1862\n",
      "NME: 0.1579\n",
      "Best model saved at epoch 38 with val_loss 488.1862\n",
      "Epoch [39/300], Loss: 616.4692\n",
      "Validation Loss: 475.0482\n",
      "NME: 0.1590\n",
      "Best model saved at epoch 39 with val_loss 475.0482\n",
      "Epoch [40/300], Loss: 593.7418\n",
      "Validation Loss: 488.1423\n",
      "NME: 0.1601\n",
      "Epoch [41/300], Loss: 611.6393\n",
      "Validation Loss: 484.2455\n",
      "NME: 0.1599\n",
      "Epoch [42/300], Loss: 597.5568\n",
      "Validation Loss: 453.0284\n",
      "NME: 0.1564\n",
      "Best model saved at epoch 42 with val_loss 453.0284\n",
      "Epoch [43/300], Loss: 564.8587\n",
      "Validation Loss: 447.7499\n",
      "NME: 0.1535\n",
      "Best model saved at epoch 43 with val_loss 447.7499\n",
      "Epoch [44/300], Loss: 598.2680\n",
      "Validation Loss: 425.9142\n",
      "NME: 0.1500\n",
      "Best model saved at epoch 44 with val_loss 425.9142\n",
      "Epoch [45/300], Loss: 526.6238\n",
      "Validation Loss: 444.2215\n",
      "NME: 0.1588\n",
      "Epoch [46/300], Loss: 570.3230\n",
      "Validation Loss: 432.4575\n",
      "NME: 0.1546\n",
      "Epoch [47/300], Loss: 556.2010\n",
      "Validation Loss: 430.9824\n",
      "NME: 0.1540\n",
      "Epoch [48/300], Loss: 541.9296\n",
      "Validation Loss: 431.5753\n",
      "NME: 0.1487\n",
      "Epoch [49/300], Loss: 576.9652\n",
      "Validation Loss: 430.2785\n",
      "NME: 0.1507\n",
      "Epoch [50/300], Loss: 558.4250\n",
      "Validation Loss: 403.0832\n",
      "NME: 0.1500\n",
      "Best model saved at epoch 50 with val_loss 403.0832\n",
      "Epoch [51/300], Loss: 570.4426\n",
      "Validation Loss: 416.7124\n",
      "NME: 0.1522\n",
      "Epoch [52/300], Loss: 534.3272\n",
      "Validation Loss: 409.8838\n",
      "NME: 0.1524\n",
      "Epoch [53/300], Loss: 583.1932\n",
      "Validation Loss: 435.9778\n",
      "NME: 0.1524\n",
      "Epoch [54/300], Loss: 569.8811\n",
      "Validation Loss: 447.8483\n",
      "NME: 0.1572\n",
      "Epoch [55/300], Loss: 545.6977\n",
      "Validation Loss: 411.5119\n",
      "NME: 0.1515\n",
      "Epoch [56/300], Loss: 506.9027\n",
      "Validation Loss: 432.9334\n",
      "NME: 0.1531\n",
      "Epoch [57/300], Loss: 548.7317\n",
      "Validation Loss: 433.0256\n",
      "NME: 0.1506\n",
      "Epoch [58/300], Loss: 508.7439\n",
      "Validation Loss: 410.6203\n",
      "NME: 0.1493\n",
      "Epoch [59/300], Loss: 540.1074\n",
      "Validation Loss: 406.4683\n",
      "NME: 0.1468\n",
      "Epoch [60/300], Loss: 516.9771\n",
      "Validation Loss: 422.9592\n",
      "NME: 0.1496\n",
      "Epoch [61/300], Loss: 519.3571\n",
      "Validation Loss: 421.7538\n",
      "NME: 0.1489\n",
      "Epoch [62/300], Loss: 496.1661\n",
      "Validation Loss: 443.6072\n",
      "NME: 0.1592\n",
      "Epoch [63/300], Loss: 548.7065\n",
      "Validation Loss: 404.4759\n",
      "NME: 0.1476\n",
      "Epoch [64/300], Loss: 536.2083\n",
      "Validation Loss: 413.4244\n",
      "NME: 0.1479\n",
      "Epoch [65/300], Loss: 538.5828\n",
      "Validation Loss: 429.0446\n",
      "NME: 0.1547\n",
      "Epoch [66/300], Loss: 519.4122\n",
      "Validation Loss: 417.3974\n",
      "NME: 0.1470\n",
      "Epoch [67/300], Loss: 506.0080\n",
      "Validation Loss: 446.7461\n",
      "NME: 0.1613\n",
      "Epoch [68/300], Loss: 517.1462\n",
      "Validation Loss: 408.1132\n",
      "NME: 0.1500\n",
      "Epoch [69/300], Loss: 520.0340\n",
      "Validation Loss: 446.1004\n",
      "NME: 0.1573\n",
      "Epoch [70/300], Loss: 523.0481\n",
      "Validation Loss: 395.3516\n",
      "NME: 0.1476\n",
      "Best model saved at epoch 70 with val_loss 395.3516\n",
      "Epoch [71/300], Loss: 507.6007\n",
      "Validation Loss: 437.4242\n",
      "NME: 0.1536\n",
      "Epoch [72/300], Loss: 480.0095\n",
      "Validation Loss: 414.2169\n",
      "NME: 0.1525\n",
      "Epoch [73/300], Loss: 503.0368\n",
      "Validation Loss: 424.7476\n",
      "NME: 0.1505\n",
      "Epoch [74/300], Loss: 483.5469\n",
      "Validation Loss: 411.0535\n",
      "NME: 0.1497\n",
      "Epoch [75/300], Loss: 505.3015\n",
      "Validation Loss: 432.6708\n",
      "NME: 0.1552\n",
      "Epoch [76/300], Loss: 473.4197\n",
      "Validation Loss: 438.3135\n",
      "NME: 0.1589\n",
      "Epoch [77/300], Loss: 480.7958\n",
      "Validation Loss: 392.1052\n",
      "NME: 0.1448\n",
      "Best model saved at epoch 77 with val_loss 392.1052\n",
      "Epoch [78/300], Loss: 476.6871\n",
      "Validation Loss: 413.7816\n",
      "NME: 0.1471\n",
      "Epoch [79/300], Loss: 456.7586\n",
      "Validation Loss: 393.3787\n",
      "NME: 0.1437\n",
      "Epoch [80/300], Loss: 446.7037\n",
      "Validation Loss: 384.2464\n",
      "NME: 0.1460\n",
      "Best model saved at epoch 80 with val_loss 384.2464\n",
      "Epoch [81/300], Loss: 438.3232\n",
      "Validation Loss: 391.1153\n",
      "NME: 0.1470\n",
      "Epoch [82/300], Loss: 472.3454\n",
      "Validation Loss: 408.5555\n",
      "NME: 0.1522\n",
      "Epoch [83/300], Loss: 430.9290\n",
      "Validation Loss: 373.3326\n",
      "NME: 0.1442\n",
      "Best model saved at epoch 83 with val_loss 373.3326\n",
      "Epoch [84/300], Loss: 424.2396\n",
      "Validation Loss: 365.3651\n",
      "NME: 0.1419\n",
      "Best model saved at epoch 84 with val_loss 365.3651\n",
      "Epoch [85/300], Loss: 414.6147\n",
      "Validation Loss: 369.0113\n",
      "NME: 0.1395\n",
      "Epoch [86/300], Loss: 378.2288\n",
      "Validation Loss: 396.6111\n",
      "NME: 0.1518\n",
      "Epoch [87/300], Loss: 396.9389\n",
      "Validation Loss: 386.4803\n",
      "NME: 0.1453\n",
      "Epoch [88/300], Loss: 386.1412\n",
      "Validation Loss: 360.4870\n",
      "NME: 0.1388\n",
      "Best model saved at epoch 88 with val_loss 360.4870\n",
      "Epoch [89/300], Loss: 362.1024\n",
      "Validation Loss: 352.8126\n",
      "NME: 0.1393\n",
      "Best model saved at epoch 89 with val_loss 352.8126\n",
      "Epoch [90/300], Loss: 353.2744\n",
      "Validation Loss: 375.5776\n",
      "NME: 0.1392\n",
      "Epoch [91/300], Loss: 357.7052\n",
      "Validation Loss: 427.7102\n",
      "NME: 0.1586\n",
      "Epoch [92/300], Loss: 357.5561\n",
      "Validation Loss: 374.4592\n",
      "NME: 0.1406\n",
      "Epoch [93/300], Loss: 338.5784\n",
      "Validation Loss: 403.9255\n",
      "NME: 0.1534\n",
      "Epoch [94/300], Loss: 319.8809\n",
      "Validation Loss: 357.4080\n",
      "NME: 0.1395\n",
      "Epoch [95/300], Loss: 339.7340\n",
      "Validation Loss: 351.1517\n",
      "NME: 0.1413\n",
      "Best model saved at epoch 95 with val_loss 351.1517\n",
      "Epoch [96/300], Loss: 306.4352\n",
      "Validation Loss: 352.7906\n",
      "NME: 0.1402\n",
      "Epoch [97/300], Loss: 318.1840\n",
      "Validation Loss: 361.7783\n",
      "NME: 0.1396\n",
      "Epoch [98/300], Loss: 303.9672\n",
      "Validation Loss: 345.2104\n",
      "NME: 0.1398\n",
      "Best model saved at epoch 98 with val_loss 345.2104\n",
      "Epoch [99/300], Loss: 311.1802\n",
      "Validation Loss: 336.4026\n",
      "NME: 0.1360\n",
      "Best model saved at epoch 99 with val_loss 336.4026\n",
      "Epoch [100/300], Loss: 285.8697\n",
      "Validation Loss: 334.7692\n",
      "NME: 0.1376\n",
      "Best model saved at epoch 100 with val_loss 334.7692\n",
      "Epoch [101/300], Loss: 305.9182\n",
      "Validation Loss: 385.1077\n",
      "NME: 0.1474\n",
      "Epoch [102/300], Loss: 297.3370\n",
      "Validation Loss: 349.1757\n",
      "NME: 0.1384\n",
      "Epoch [103/300], Loss: 281.4517\n",
      "Validation Loss: 354.3781\n",
      "NME: 0.1390\n",
      "Epoch [104/300], Loss: 276.5638\n",
      "Validation Loss: 345.5273\n",
      "NME: 0.1366\n",
      "Epoch [105/300], Loss: 269.3108\n",
      "Validation Loss: 341.3809\n",
      "NME: 0.1354\n",
      "Epoch [106/300], Loss: 275.5733\n",
      "Validation Loss: 337.8259\n",
      "NME: 0.1381\n",
      "Epoch [107/300], Loss: 271.9261\n",
      "Validation Loss: 349.0410\n",
      "NME: 0.1403\n",
      "Epoch [108/300], Loss: 257.8867\n",
      "Validation Loss: 384.4284\n",
      "NME: 0.1465\n",
      "Epoch [109/300], Loss: 279.9246\n",
      "Validation Loss: 337.3235\n",
      "NME: 0.1386\n",
      "Epoch [110/300], Loss: 266.0366\n",
      "Validation Loss: 337.6276\n",
      "NME: 0.1368\n",
      "Epoch [111/300], Loss: 262.4528\n",
      "Validation Loss: 361.0769\n",
      "NME: 0.1449\n",
      "Epoch [112/300], Loss: 260.6060\n",
      "Validation Loss: 348.9808\n",
      "NME: 0.1408\n",
      "Epoch [113/300], Loss: 271.8223\n",
      "Validation Loss: 332.4865\n",
      "NME: 0.1372\n",
      "Best model saved at epoch 113 with val_loss 332.4865\n",
      "Epoch [114/300], Loss: 255.1056\n",
      "Validation Loss: 325.1971\n",
      "NME: 0.1350\n",
      "Best model saved at epoch 114 with val_loss 325.1971\n",
      "Epoch [115/300], Loss: 246.2099\n",
      "Validation Loss: 336.9139\n",
      "NME: 0.1362\n",
      "Epoch [116/300], Loss: 264.1472\n",
      "Validation Loss: 331.7736\n",
      "NME: 0.1356\n",
      "Epoch [117/300], Loss: 242.8753\n",
      "Validation Loss: 353.4078\n",
      "NME: 0.1443\n",
      "Epoch [118/300], Loss: 241.3818\n",
      "Validation Loss: 326.1999\n",
      "NME: 0.1344\n",
      "Epoch [119/300], Loss: 248.7421\n",
      "Validation Loss: 321.3310\n",
      "NME: 0.1345\n",
      "Best model saved at epoch 119 with val_loss 321.3310\n",
      "Epoch [120/300], Loss: 240.8132\n",
      "Validation Loss: 339.9039\n",
      "NME: 0.1398\n",
      "Epoch [121/300], Loss: 244.4497\n",
      "Validation Loss: 340.0624\n",
      "NME: 0.1361\n",
      "Epoch [122/300], Loss: 240.2515\n",
      "Validation Loss: 338.5667\n",
      "NME: 0.1358\n",
      "Epoch [123/300], Loss: 241.4202\n",
      "Validation Loss: 327.4641\n",
      "NME: 0.1349\n",
      "Epoch [124/300], Loss: 245.2043\n",
      "Validation Loss: 326.0980\n",
      "NME: 0.1350\n",
      "Epoch [125/300], Loss: 238.7574\n",
      "Validation Loss: 337.2878\n",
      "NME: 0.1393\n",
      "Epoch [126/300], Loss: 241.3528\n",
      "Validation Loss: 334.9799\n",
      "NME: 0.1387\n",
      "Epoch [127/300], Loss: 241.8699\n",
      "Validation Loss: 335.4552\n",
      "NME: 0.1381\n",
      "Epoch [128/300], Loss: 241.9176\n",
      "Validation Loss: 328.6385\n",
      "NME: 0.1359\n",
      "Epoch [129/300], Loss: 231.5628\n",
      "Validation Loss: 346.8595\n",
      "NME: 0.1373\n",
      "Epoch [130/300], Loss: 233.5970\n",
      "Validation Loss: 332.2133\n",
      "NME: 0.1341\n",
      "Epoch [131/300], Loss: 238.5205\n",
      "Validation Loss: 331.2993\n",
      "NME: 0.1355\n",
      "Epoch [132/300], Loss: 234.2441\n",
      "Validation Loss: 333.7276\n",
      "NME: 0.1367\n",
      "Epoch [133/300], Loss: 238.0607\n",
      "Validation Loss: 339.6263\n",
      "NME: 0.1368\n",
      "Epoch [134/300], Loss: 231.5007\n",
      "Validation Loss: 328.1018\n",
      "NME: 0.1347\n",
      "Epoch [135/300], Loss: 233.3572\n",
      "Validation Loss: 324.0634\n",
      "NME: 0.1357\n",
      "Epoch [136/300], Loss: 234.5599\n",
      "Validation Loss: 348.7852\n",
      "NME: 0.1351\n",
      "Epoch [137/300], Loss: 226.7884\n",
      "Validation Loss: 327.1460\n",
      "NME: 0.1335\n",
      "Epoch [138/300], Loss: 225.8380\n",
      "Validation Loss: 329.6774\n",
      "NME: 0.1374\n",
      "Epoch [139/300], Loss: 222.5337\n",
      "Validation Loss: 338.0938\n",
      "NME: 0.1362\n",
      "Epoch [140/300], Loss: 221.3237\n",
      "Validation Loss: 346.8078\n",
      "NME: 0.1387\n",
      "Epoch [141/300], Loss: 231.4923\n",
      "Validation Loss: 324.9361\n",
      "NME: 0.1360\n",
      "Epoch [142/300], Loss: 225.2407\n",
      "Validation Loss: 349.2173\n",
      "NME: 0.1385\n",
      "Epoch [143/300], Loss: 216.8685\n",
      "Validation Loss: 319.7847\n",
      "NME: 0.1338\n",
      "Best model saved at epoch 143 with val_loss 319.7847\n",
      "Epoch [144/300], Loss: 233.8558\n",
      "Validation Loss: 332.4389\n",
      "NME: 0.1368\n",
      "Epoch [145/300], Loss: 218.5926\n",
      "Validation Loss: 332.7634\n",
      "NME: 0.1340\n",
      "Epoch [146/300], Loss: 220.0524\n",
      "Validation Loss: 329.2811\n",
      "NME: 0.1335\n",
      "Epoch [147/300], Loss: 224.0721\n",
      "Validation Loss: 318.8910\n",
      "NME: 0.1329\n",
      "Best model saved at epoch 147 with val_loss 318.8910\n",
      "Epoch [148/300], Loss: 230.7733\n",
      "Validation Loss: 358.1809\n",
      "NME: 0.1410\n",
      "Epoch [149/300], Loss: 222.8217\n",
      "Validation Loss: 328.1464\n",
      "NME: 0.1353\n",
      "Epoch [150/300], Loss: 225.8299\n",
      "Validation Loss: 322.1781\n",
      "NME: 0.1335\n",
      "Epoch [151/300], Loss: 224.0116\n",
      "Validation Loss: 327.5478\n",
      "NME: 0.1336\n",
      "Epoch [152/300], Loss: 225.5221\n",
      "Validation Loss: 331.9167\n",
      "NME: 0.1357\n",
      "Epoch [153/300], Loss: 214.6326\n",
      "Validation Loss: 340.3183\n",
      "NME: 0.1395\n",
      "Epoch [154/300], Loss: 225.5596\n",
      "Validation Loss: 310.9263\n",
      "NME: 0.1323\n",
      "Best model saved at epoch 154 with val_loss 310.9263\n",
      "Epoch [155/300], Loss: 217.0242\n",
      "Validation Loss: 323.6372\n",
      "NME: 0.1325\n",
      "Epoch [156/300], Loss: 220.5776\n",
      "Validation Loss: 319.1501\n",
      "NME: 0.1356\n",
      "Epoch [157/300], Loss: 217.1046\n",
      "Validation Loss: 325.6593\n",
      "NME: 0.1329\n",
      "Epoch [158/300], Loss: 216.6162\n",
      "Validation Loss: 323.5222\n",
      "NME: 0.1357\n",
      "Epoch [159/300], Loss: 224.7031\n",
      "Validation Loss: 311.1081\n",
      "NME: 0.1320\n",
      "Epoch [160/300], Loss: 213.4475\n",
      "Validation Loss: 316.8967\n",
      "NME: 0.1319\n",
      "Epoch [161/300], Loss: 207.5101\n",
      "Validation Loss: 331.7670\n",
      "NME: 0.1350\n",
      "Epoch [162/300], Loss: 212.2948\n",
      "Validation Loss: 334.2587\n",
      "NME: 0.1333\n",
      "Epoch [163/300], Loss: 207.8420\n",
      "Validation Loss: 312.5962\n",
      "NME: 0.1316\n",
      "Epoch [164/300], Loss: 209.9653\n",
      "Validation Loss: 308.4475\n",
      "NME: 0.1310\n",
      "Best model saved at epoch 164 with val_loss 308.4475\n",
      "Epoch [165/300], Loss: 221.4672\n",
      "Validation Loss: 311.2301\n",
      "NME: 0.1304\n",
      "Epoch [166/300], Loss: 211.5133\n",
      "Validation Loss: 315.7511\n",
      "NME: 0.1314\n",
      "Epoch [167/300], Loss: 207.5180\n",
      "Validation Loss: 325.5763\n",
      "NME: 0.1317\n",
      "Epoch [168/300], Loss: 216.6066\n",
      "Validation Loss: 334.8601\n",
      "NME: 0.1366\n",
      "Epoch [169/300], Loss: 209.9315\n",
      "Validation Loss: 319.3042\n",
      "NME: 0.1327\n",
      "Epoch [170/300], Loss: 209.9197\n",
      "Validation Loss: 314.0119\n",
      "NME: 0.1329\n",
      "Epoch [171/300], Loss: 211.7976\n",
      "Validation Loss: 308.5717\n",
      "NME: 0.1304\n",
      "Epoch [172/300], Loss: 201.5388\n",
      "Validation Loss: 312.0486\n",
      "NME: 0.1313\n",
      "Epoch [173/300], Loss: 207.9453\n",
      "Validation Loss: 319.9459\n",
      "NME: 0.1307\n",
      "Epoch [174/300], Loss: 205.6902\n",
      "Validation Loss: 323.1721\n",
      "NME: 0.1322\n",
      "Epoch [175/300], Loss: 206.8049\n",
      "Validation Loss: 327.4504\n",
      "NME: 0.1358\n",
      "Epoch [176/300], Loss: 203.4580\n",
      "Validation Loss: 312.7004\n",
      "NME: 0.1310\n",
      "Epoch [177/300], Loss: 211.1842\n",
      "Validation Loss: 311.6809\n",
      "NME: 0.1290\n",
      "Epoch [178/300], Loss: 202.1863\n",
      "Validation Loss: 318.1448\n",
      "NME: 0.1301\n",
      "Epoch [179/300], Loss: 214.0660\n",
      "Validation Loss: 302.9559\n",
      "NME: 0.1287\n",
      "Best model saved at epoch 179 with val_loss 302.9559\n",
      "Epoch [180/300], Loss: 200.1545\n",
      "Validation Loss: 300.9406\n",
      "NME: 0.1269\n",
      "Best model saved at epoch 180 with val_loss 300.9406\n",
      "Epoch [181/300], Loss: 196.4382\n",
      "Validation Loss: 307.3311\n",
      "NME: 0.1293\n",
      "Epoch [182/300], Loss: 195.9731\n",
      "Validation Loss: 310.3570\n",
      "NME: 0.1285\n",
      "Epoch [183/300], Loss: 196.0788\n",
      "Validation Loss: 305.9826\n",
      "NME: 0.1281\n",
      "Epoch [184/300], Loss: 195.8045\n",
      "Validation Loss: 307.7414\n",
      "NME: 0.1295\n",
      "Epoch [185/300], Loss: 192.3987\n",
      "Validation Loss: 308.7654\n",
      "NME: 0.1281\n",
      "Epoch [186/300], Loss: 200.9152\n",
      "Validation Loss: 310.1825\n",
      "NME: 0.1281\n",
      "Epoch [187/300], Loss: 187.4520\n",
      "Validation Loss: 305.6699\n",
      "NME: 0.1273\n",
      "Epoch [188/300], Loss: 198.8171\n",
      "Validation Loss: 316.9620\n",
      "NME: 0.1298\n",
      "Epoch [189/300], Loss: 188.7256\n",
      "Validation Loss: 303.0640\n",
      "NME: 0.1263\n",
      "Epoch [190/300], Loss: 190.0506\n",
      "Validation Loss: 299.8847\n",
      "NME: 0.1242\n",
      "Best model saved at epoch 190 with val_loss 299.8847\n",
      "Epoch [191/300], Loss: 193.5757\n",
      "Validation Loss: 305.2404\n",
      "NME: 0.1259\n",
      "Epoch [192/300], Loss: 199.6720\n",
      "Validation Loss: 307.8293\n",
      "NME: 0.1275\n",
      "Epoch [193/300], Loss: 187.9341\n",
      "Validation Loss: 289.2995\n",
      "NME: 0.1229\n",
      "Best model saved at epoch 193 with val_loss 289.2995\n",
      "Epoch [194/300], Loss: 184.8436\n",
      "Validation Loss: 288.5414\n",
      "NME: 0.1226\n",
      "Best model saved at epoch 194 with val_loss 288.5414\n",
      "Epoch [195/300], Loss: 183.2157\n",
      "Validation Loss: 288.2281\n",
      "NME: 0.1219\n",
      "Best model saved at epoch 195 with val_loss 288.2281\n",
      "Epoch [196/300], Loss: 178.3805\n",
      "Validation Loss: 292.7329\n",
      "NME: 0.1217\n",
      "Epoch [197/300], Loss: 191.8781\n",
      "Validation Loss: 290.7889\n",
      "NME: 0.1198\n",
      "Epoch [198/300], Loss: 182.3175\n",
      "Validation Loss: 285.7217\n",
      "NME: 0.1192\n",
      "Best model saved at epoch 198 with val_loss 285.7217\n",
      "Epoch [199/300], Loss: 178.3889\n",
      "Validation Loss: 279.8965\n",
      "NME: 0.1171\n",
      "Best model saved at epoch 199 with val_loss 279.8965\n",
      "Epoch [200/300], Loss: 171.4228\n",
      "Validation Loss: 283.1614\n",
      "NME: 0.1184\n",
      "Epoch [201/300], Loss: 177.1505\n",
      "Validation Loss: 281.8019\n",
      "NME: 0.1188\n",
      "Epoch [202/300], Loss: 180.0127\n",
      "Validation Loss: 280.9511\n",
      "NME: 0.1177\n",
      "Epoch [203/300], Loss: 174.3598\n",
      "Validation Loss: 290.1446\n",
      "NME: 0.1170\n",
      "Epoch [204/300], Loss: 169.9385\n",
      "Validation Loss: 276.3170\n",
      "NME: 0.1145\n",
      "Best model saved at epoch 204 with val_loss 276.3170\n",
      "Epoch [205/300], Loss: 177.0626\n",
      "Validation Loss: 276.3458\n",
      "NME: 0.1157\n",
      "Epoch [206/300], Loss: 160.2960\n",
      "Validation Loss: 264.5102\n",
      "NME: 0.1134\n",
      "Best model saved at epoch 206 with val_loss 264.5102\n",
      "Epoch [207/300], Loss: 165.6555\n",
      "Validation Loss: 271.1285\n",
      "NME: 0.1143\n",
      "Epoch [208/300], Loss: 157.5972\n",
      "Validation Loss: 255.9695\n",
      "NME: 0.1118\n",
      "Best model saved at epoch 208 with val_loss 255.9695\n",
      "Epoch [209/300], Loss: 169.0275\n",
      "Validation Loss: 260.0485\n",
      "NME: 0.1138\n",
      "Epoch [210/300], Loss: 162.3924\n",
      "Validation Loss: 256.1296\n",
      "NME: 0.1104\n",
      "Epoch [211/300], Loss: 157.0971\n",
      "Validation Loss: 263.2639\n",
      "NME: 0.1114\n",
      "Epoch [212/300], Loss: 156.2602\n",
      "Validation Loss: 269.4497\n",
      "NME: 0.1124\n",
      "Epoch [213/300], Loss: 154.4477\n",
      "Validation Loss: 268.6573\n",
      "NME: 0.1116\n",
      "Epoch [214/300], Loss: 157.6941\n",
      "Validation Loss: 251.3486\n",
      "NME: 0.1085\n",
      "Best model saved at epoch 214 with val_loss 251.3486\n",
      "Epoch [215/300], Loss: 150.9812\n",
      "Validation Loss: 251.4553\n",
      "NME: 0.1074\n",
      "Epoch [216/300], Loss: 153.0457\n",
      "Validation Loss: 250.2577\n",
      "NME: 0.1064\n",
      "Best model saved at epoch 216 with val_loss 250.2577\n",
      "Epoch [217/300], Loss: 152.8359\n",
      "Validation Loss: 244.4826\n",
      "NME: 0.1070\n",
      "Best model saved at epoch 217 with val_loss 244.4826\n",
      "Epoch [218/300], Loss: 144.6134\n",
      "Validation Loss: 244.4099\n",
      "NME: 0.1065\n",
      "Best model saved at epoch 218 with val_loss 244.4099\n",
      "Epoch [219/300], Loss: 140.3727\n",
      "Validation Loss: 246.5859\n",
      "NME: 0.1065\n",
      "Epoch [220/300], Loss: 146.2969\n",
      "Validation Loss: 240.2018\n",
      "NME: 0.1045\n",
      "Best model saved at epoch 220 with val_loss 240.2018\n",
      "Epoch [221/300], Loss: 141.6637\n",
      "Validation Loss: 243.5811\n",
      "NME: 0.1053\n",
      "Epoch [222/300], Loss: 146.3427\n",
      "Validation Loss: 241.9118\n",
      "NME: 0.1047\n",
      "Epoch [223/300], Loss: 140.8486\n",
      "Validation Loss: 238.3322\n",
      "NME: 0.1055\n",
      "Best model saved at epoch 223 with val_loss 238.3322\n",
      "Epoch [224/300], Loss: 140.5396\n",
      "Validation Loss: 249.9398\n",
      "NME: 0.1061\n",
      "Epoch [225/300], Loss: 135.0250\n",
      "Validation Loss: 237.4892\n",
      "NME: 0.1024\n",
      "Best model saved at epoch 225 with val_loss 237.4892\n",
      "Epoch [226/300], Loss: 140.8046\n",
      "Validation Loss: 237.6008\n",
      "NME: 0.1022\n",
      "Epoch [227/300], Loss: 135.6016\n",
      "Validation Loss: 237.7536\n",
      "NME: 0.1029\n",
      "Epoch [228/300], Loss: 135.6645\n",
      "Validation Loss: 247.9511\n",
      "NME: 0.1058\n",
      "Epoch [229/300], Loss: 137.0411\n",
      "Validation Loss: 236.0256\n",
      "NME: 0.1027\n",
      "Best model saved at epoch 229 with val_loss 236.0256\n",
      "Epoch [230/300], Loss: 130.8090\n",
      "Validation Loss: 242.5481\n",
      "NME: 0.1049\n",
      "Epoch [231/300], Loss: 139.7027\n",
      "Validation Loss: 245.8762\n",
      "NME: 0.1024\n",
      "Epoch [232/300], Loss: 137.0905\n",
      "Validation Loss: 246.2931\n",
      "NME: 0.1043\n",
      "Epoch [233/300], Loss: 127.8992\n",
      "Validation Loss: 246.9810\n",
      "NME: 0.1017\n",
      "Epoch [234/300], Loss: 128.5946\n",
      "Validation Loss: 236.0055\n",
      "NME: 0.1007\n",
      "Best model saved at epoch 234 with val_loss 236.0055\n",
      "Epoch [235/300], Loss: 127.3082\n",
      "Validation Loss: 230.4415\n",
      "NME: 0.0995\n",
      "Best model saved at epoch 235 with val_loss 230.4415\n",
      "Epoch [236/300], Loss: 125.2476\n",
      "Validation Loss: 234.7670\n",
      "NME: 0.0995\n",
      "Epoch [237/300], Loss: 133.7856\n",
      "Validation Loss: 239.9971\n",
      "NME: 0.1021\n",
      "Epoch [238/300], Loss: 122.8329\n",
      "Validation Loss: 234.0001\n",
      "NME: 0.1018\n",
      "Epoch [239/300], Loss: 126.4092\n",
      "Validation Loss: 217.5229\n",
      "NME: 0.0986\n",
      "Best model saved at epoch 239 with val_loss 217.5229\n",
      "Epoch [240/300], Loss: 122.4422\n",
      "Validation Loss: 225.1884\n",
      "NME: 0.0987\n",
      "Epoch [241/300], Loss: 120.9720\n",
      "Validation Loss: 233.3570\n",
      "NME: 0.1015\n",
      "Epoch [242/300], Loss: 122.6639\n",
      "Validation Loss: 231.8000\n",
      "NME: 0.0994\n",
      "Epoch [243/300], Loss: 119.4185\n",
      "Validation Loss: 236.1120\n",
      "NME: 0.1005\n",
      "Epoch [244/300], Loss: 123.1590\n",
      "Validation Loss: 227.0494\n",
      "NME: 0.1007\n",
      "Epoch [245/300], Loss: 121.0076\n",
      "Validation Loss: 227.4699\n",
      "NME: 0.0989\n",
      "Epoch [246/300], Loss: 117.4480\n",
      "Validation Loss: 224.0402\n",
      "NME: 0.0967\n",
      "Epoch [247/300], Loss: 120.3999\n",
      "Validation Loss: 226.6532\n",
      "NME: 0.0963\n",
      "Epoch [248/300], Loss: 123.5262\n",
      "Validation Loss: 231.7195\n",
      "NME: 0.0971\n",
      "Epoch [249/300], Loss: 120.6082\n",
      "Validation Loss: 227.3540\n",
      "NME: 0.0984\n",
      "Epoch [250/300], Loss: 118.9971\n",
      "Validation Loss: 228.4150\n",
      "NME: 0.0972\n",
      "Epoch [251/300], Loss: 116.7292\n",
      "Validation Loss: 237.5279\n",
      "NME: 0.0986\n",
      "Epoch [252/300], Loss: 115.6836\n",
      "Validation Loss: 226.4750\n",
      "NME: 0.0991\n",
      "Epoch [253/300], Loss: 119.0106\n",
      "Validation Loss: 231.8407\n",
      "NME: 0.0984\n",
      "Epoch [254/300], Loss: 112.6969\n",
      "Validation Loss: 237.1791\n",
      "NME: 0.0985\n",
      "Epoch [255/300], Loss: 112.7477\n",
      "Validation Loss: 228.3807\n",
      "NME: 0.0974\n",
      "Epoch [256/300], Loss: 115.2988\n",
      "Validation Loss: 238.8355\n",
      "NME: 0.1015\n",
      "Epoch [257/300], Loss: 110.1245\n",
      "Validation Loss: 223.3995\n",
      "NME: 0.0958\n",
      "Epoch [258/300], Loss: 111.6456\n",
      "Validation Loss: 222.7089\n",
      "NME: 0.0956\n",
      "Epoch [259/300], Loss: 113.0859\n",
      "Validation Loss: 219.0157\n",
      "NME: 0.0960\n",
      "Epoch [260/300], Loss: 112.3997\n",
      "Validation Loss: 225.4211\n",
      "NME: 0.0968\n",
      "Epoch [261/300], Loss: 110.5037\n",
      "Validation Loss: 218.3168\n",
      "NME: 0.0960\n",
      "Epoch [262/300], Loss: 108.3005\n",
      "Validation Loss: 220.3970\n",
      "NME: 0.0951\n",
      "Epoch [263/300], Loss: 104.1170\n",
      "Validation Loss: 227.0364\n",
      "NME: 0.0960\n",
      "Epoch [264/300], Loss: 108.7611\n",
      "Validation Loss: 225.2869\n",
      "NME: 0.0969\n",
      "Epoch [265/300], Loss: 107.8761\n",
      "Validation Loss: 222.4380\n",
      "NME: 0.0965\n",
      "Epoch [266/300], Loss: 105.4692\n",
      "Validation Loss: 220.5042\n",
      "NME: 0.0957\n",
      "Epoch [267/300], Loss: 105.8351\n",
      "Validation Loss: 219.1487\n",
      "NME: 0.0972\n",
      "Epoch [268/300], Loss: 101.3045\n",
      "Validation Loss: 226.1570\n",
      "NME: 0.0953\n",
      "Epoch [269/300], Loss: 108.7981\n",
      "Validation Loss: 218.6240\n",
      "NME: 0.0945\n",
      "Epoch [270/300], Loss: 105.7830\n",
      "Validation Loss: 224.8270\n",
      "NME: 0.0969\n",
      "Epoch [271/300], Loss: 107.2112\n",
      "Validation Loss: 224.1904\n",
      "NME: 0.0954\n",
      "Epoch [272/300], Loss: 104.3661\n",
      "Validation Loss: 226.1088\n",
      "NME: 0.0965\n",
      "Epoch [273/300], Loss: 100.9685\n",
      "Validation Loss: 221.2405\n",
      "NME: 0.0937\n",
      "Epoch [274/300], Loss: 102.4006\n",
      "Validation Loss: 232.5830\n",
      "NME: 0.0975\n",
      "Epoch [275/300], Loss: 101.8548\n",
      "Validation Loss: 208.9180\n",
      "NME: 0.0950\n",
      "Best model saved at epoch 275 with val_loss 208.9180\n",
      "Epoch [276/300], Loss: 98.6092\n",
      "Validation Loss: 217.3078\n",
      "NME: 0.0944\n",
      "Epoch [277/300], Loss: 102.1216\n",
      "Validation Loss: 219.8831\n",
      "NME: 0.0939\n",
      "Epoch [278/300], Loss: 114.6174\n",
      "Validation Loss: 220.6880\n",
      "NME: 0.0935\n",
      "Epoch [279/300], Loss: 98.0891\n",
      "Validation Loss: 222.5916\n",
      "NME: 0.0959\n",
      "Epoch [280/300], Loss: 103.6917\n",
      "Validation Loss: 227.4477\n",
      "NME: 0.0961\n",
      "Epoch [281/300], Loss: 99.1737\n",
      "Validation Loss: 237.9697\n",
      "NME: 0.0983\n",
      "Epoch [282/300], Loss: 102.0640\n",
      "Validation Loss: 224.5155\n",
      "NME: 0.0966\n",
      "Epoch [283/300], Loss: 98.8862\n",
      "Validation Loss: 219.5203\n",
      "NME: 0.0947\n",
      "Epoch [284/300], Loss: 98.1904\n",
      "Validation Loss: 221.7396\n",
      "NME: 0.0951\n",
      "Epoch [285/300], Loss: 99.2234\n",
      "Validation Loss: 218.9046\n",
      "NME: 0.0954\n",
      "Epoch [286/300], Loss: 102.2853\n",
      "Validation Loss: 224.0342\n",
      "NME: 0.0962\n",
      "Epoch [287/300], Loss: 99.5091\n",
      "Validation Loss: 224.4291\n",
      "NME: 0.0942\n",
      "Epoch [288/300], Loss: 100.5275\n",
      "Validation Loss: 218.0769\n",
      "NME: 0.0941\n",
      "Epoch [289/300], Loss: 99.0369\n",
      "Validation Loss: 221.0385\n",
      "NME: 0.0966\n",
      "Epoch [290/300], Loss: 99.2935\n",
      "Validation Loss: 220.9127\n",
      "NME: 0.0960\n",
      "Epoch [291/300], Loss: 93.3171\n",
      "Validation Loss: 221.1196\n",
      "NME: 0.0953\n",
      "Epoch [292/300], Loss: 93.7940\n",
      "Validation Loss: 223.1414\n",
      "NME: 0.0952\n",
      "Epoch [293/300], Loss: 97.2576\n",
      "Validation Loss: 223.9005\n",
      "NME: 0.0968\n",
      "Epoch [294/300], Loss: 98.3386\n",
      "Validation Loss: 217.6261\n",
      "NME: 0.0947\n",
      "Epoch [295/300], Loss: 97.3394\n",
      "Validation Loss: 224.9127\n",
      "NME: 0.0958\n",
      "Epoch [296/300], Loss: 96.8694\n",
      "Validation Loss: 222.4393\n",
      "NME: 0.0940\n",
      "Epoch [297/300], Loss: 97.7418\n",
      "Validation Loss: 219.9288\n",
      "NME: 0.0939\n",
      "Epoch [298/300], Loss: 95.2012\n",
      "Validation Loss: 222.8021\n",
      "NME: 0.0939\n",
      "Epoch [299/300], Loss: 93.9730\n",
      "Validation Loss: 222.7996\n",
      "NME: 0.0948\n",
      "Epoch [300/300], Loss: 95.3749\n",
      "Validation Loss: 226.0814\n",
      "NME: 0.0942\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "oreja_der = [22, 23, 24, 25, 26]  # Cambiado a oreja derecha\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EarRightDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_oreja_der = calcular_centro_region(landmarks, oreja_der)  # Cambiado a oreja derecha\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_oreja_der -= np.array([x_min, y_min])  # Cambiado a oreja derecha\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la oreja derecha\n",
    "        ear_right_points = np.array([landmarks[i] for i in oreja_der], dtype=np.float32)  # Cambiado a oreja derecha\n",
    "        ear_right_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(ear_right_points), 1))\n",
    "        points_ones = np.hstack([ear_right_points, ones])\n",
    "        ear_right_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la oreja derecha\n",
    "        centro_x, centro_y = calcular_centro_region(ear_right_points_rotated, range(len(oreja_der)))  # Cambiado a oreja derecha\n",
    "\n",
    "        # Definir los límites del recorte de 112x112 píxeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_ear = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_ear, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la oreja derecha al nuevo recorte\n",
    "        ear_right_points_adjusted = [(p[0] - x1, p[1] - y1) for p in ear_right_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        ear_right_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in ear_right_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=ear_right_points_scaled)\n",
    "            image = augmented['image']\n",
    "            ear_right_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(ear_right_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EarRightDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EarRightDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EarRight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EarRight, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(oreja_der) * 2)  # Cambiado a oreja derecha\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EarRight().cuda()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para oreja derecha)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, ear_right_points, _, _, _ in train_dataloader:  # Cambiado a oreja derecha\n",
    "            images, ear_right_points = images.cuda(), ear_right_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, ear_right_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_ear_right_points, _, _, _ in val_dataloader:  # Cambiado a oreja derecha\n",
    "                    val_images, val_ear_right_points = val_images.cuda(), val_ear_right_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_ear_right_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_ear_right_points.cpu().numpy().reshape(-1, len(oreja_der), 2))  # Cambiado a oreja derecha\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(oreja_der), 2))  # Cambiado a oreja derecha\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(oreja_der))  # Cambiado a oreja derecha\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EarRightLandmarks V3.pth')  # Cambiado a oreja derecha\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14645.3623\n",
      "Validation Loss: 14082.6291\n",
      "NME: 7.3234\n",
      "Best model saved at epoch 1 with val_loss 14082.6291\n",
      "Epoch [2/300], Loss: 12694.1615\n",
      "Validation Loss: 10678.9164\n",
      "NME: 6.4475\n",
      "Best model saved at epoch 2 with val_loss 10678.9164\n",
      "Epoch [3/300], Loss: 7792.6973\n",
      "Validation Loss: 4449.0203\n",
      "NME: 3.8791\n",
      "Best model saved at epoch 3 with val_loss 4449.0203\n",
      "Epoch [4/300], Loss: 2352.0898\n",
      "Validation Loss: 1133.5370\n",
      "NME: 1.4848\n",
      "Best model saved at epoch 4 with val_loss 1133.5370\n",
      "Epoch [5/300], Loss: 881.2938\n",
      "Validation Loss: 681.7194\n",
      "NME: 0.9981\n",
      "Best model saved at epoch 5 with val_loss 681.7194\n",
      "Epoch [6/300], Loss: 669.4985\n",
      "Validation Loss: 586.9979\n",
      "NME: 0.9569\n",
      "Best model saved at epoch 6 with val_loss 586.9979\n",
      "Epoch [7/300], Loss: 626.2771\n",
      "Validation Loss: 565.0573\n",
      "NME: 0.9966\n",
      "Best model saved at epoch 7 with val_loss 565.0573\n",
      "Epoch [8/300], Loss: 615.2845\n",
      "Validation Loss: 561.0078\n",
      "NME: 1.0191\n",
      "Best model saved at epoch 8 with val_loss 561.0078\n",
      "Epoch [9/300], Loss: 613.3866\n",
      "Validation Loss: 562.1663\n",
      "NME: 1.0361\n",
      "Epoch [10/300], Loss: 620.7905\n",
      "Validation Loss: 558.9637\n",
      "NME: 1.0427\n",
      "Best model saved at epoch 10 with val_loss 558.9637\n",
      "Epoch [11/300], Loss: 617.0549\n",
      "Validation Loss: 558.2398\n",
      "NME: 1.0234\n",
      "Best model saved at epoch 11 with val_loss 558.2398\n",
      "Epoch [12/300], Loss: 612.1220\n",
      "Validation Loss: 557.6509\n",
      "NME: 1.0310\n",
      "Best model saved at epoch 12 with val_loss 557.6509\n",
      "Epoch [13/300], Loss: 609.8235\n",
      "Validation Loss: 556.3954\n",
      "NME: 1.0296\n",
      "Best model saved at epoch 13 with val_loss 556.3954\n",
      "Epoch [14/300], Loss: 610.3497\n",
      "Validation Loss: 556.4918\n",
      "NME: 1.0320\n",
      "Epoch [15/300], Loss: 607.1325\n",
      "Validation Loss: 555.0318\n",
      "NME: 1.0241\n",
      "Best model saved at epoch 15 with val_loss 555.0318\n",
      "Epoch [16/300], Loss: 609.9921\n",
      "Validation Loss: 554.2573\n",
      "NME: 1.0403\n",
      "Best model saved at epoch 16 with val_loss 554.2573\n",
      "Epoch [17/300], Loss: 613.0026\n",
      "Validation Loss: 548.7002\n",
      "NME: 1.0136\n",
      "Best model saved at epoch 17 with val_loss 548.7002\n",
      "Epoch [18/300], Loss: 607.3469\n",
      "Validation Loss: 545.6487\n",
      "NME: 1.0040\n",
      "Best model saved at epoch 18 with val_loss 545.6487\n",
      "Epoch [19/300], Loss: 604.1010\n",
      "Validation Loss: 534.6362\n",
      "NME: 1.0192\n",
      "Best model saved at epoch 19 with val_loss 534.6362\n",
      "Epoch [20/300], Loss: 591.4963\n",
      "Validation Loss: 521.9390\n",
      "NME: 1.0010\n",
      "Best model saved at epoch 20 with val_loss 521.9390\n",
      "Epoch [21/300], Loss: 569.4069\n",
      "Validation Loss: 501.4914\n",
      "NME: 0.9803\n",
      "Best model saved at epoch 21 with val_loss 501.4914\n",
      "Epoch [22/300], Loss: 555.0602\n",
      "Validation Loss: 479.5730\n",
      "NME: 0.9532\n",
      "Best model saved at epoch 22 with val_loss 479.5730\n",
      "Epoch [23/300], Loss: 526.0734\n",
      "Validation Loss: 447.7458\n",
      "NME: 0.9048\n",
      "Best model saved at epoch 23 with val_loss 447.7458\n",
      "Epoch [24/300], Loss: 497.8867\n",
      "Validation Loss: 408.3032\n",
      "NME: 0.8580\n",
      "Best model saved at epoch 24 with val_loss 408.3032\n",
      "Epoch [25/300], Loss: 455.8850\n",
      "Validation Loss: 360.3791\n",
      "NME: 0.7829\n",
      "Best model saved at epoch 25 with val_loss 360.3791\n",
      "Epoch [26/300], Loss: 420.2945\n",
      "Validation Loss: 312.5950\n",
      "NME: 0.7186\n",
      "Best model saved at epoch 26 with val_loss 312.5950\n",
      "Epoch [27/300], Loss: 371.4570\n",
      "Validation Loss: 278.5064\n",
      "NME: 0.6606\n",
      "Best model saved at epoch 27 with val_loss 278.5064\n",
      "Epoch [28/300], Loss: 339.1397\n",
      "Validation Loss: 236.9711\n",
      "NME: 0.6060\n",
      "Best model saved at epoch 28 with val_loss 236.9711\n",
      "Epoch [29/300], Loss: 314.2819\n",
      "Validation Loss: 209.7823\n",
      "NME: 0.5580\n",
      "Best model saved at epoch 29 with val_loss 209.7823\n",
      "Epoch [30/300], Loss: 285.2843\n",
      "Validation Loss: 185.7110\n",
      "NME: 0.5266\n",
      "Best model saved at epoch 30 with val_loss 185.7110\n",
      "Epoch [31/300], Loss: 269.8951\n",
      "Validation Loss: 168.8180\n",
      "NME: 0.4868\n",
      "Best model saved at epoch 31 with val_loss 168.8180\n",
      "Epoch [32/300], Loss: 261.6898\n",
      "Validation Loss: 156.9109\n",
      "NME: 0.4695\n",
      "Best model saved at epoch 32 with val_loss 156.9109\n",
      "Epoch [33/300], Loss: 244.0746\n",
      "Validation Loss: 147.5386\n",
      "NME: 0.4596\n",
      "Best model saved at epoch 33 with val_loss 147.5386\n",
      "Epoch [34/300], Loss: 234.1583\n",
      "Validation Loss: 146.6775\n",
      "NME: 0.4547\n",
      "Best model saved at epoch 34 with val_loss 146.6775\n",
      "Epoch [35/300], Loss: 236.7241\n",
      "Validation Loss: 140.0941\n",
      "NME: 0.4495\n",
      "Best model saved at epoch 35 with val_loss 140.0941\n",
      "Epoch [36/300], Loss: 222.8616\n",
      "Validation Loss: 139.7575\n",
      "NME: 0.4548\n",
      "Best model saved at epoch 36 with val_loss 139.7575\n",
      "Epoch [37/300], Loss: 214.7882\n",
      "Validation Loss: 133.7316\n",
      "NME: 0.4344\n",
      "Best model saved at epoch 37 with val_loss 133.7316\n",
      "Epoch [38/300], Loss: 215.4788\n",
      "Validation Loss: 129.0771\n",
      "NME: 0.4246\n",
      "Best model saved at epoch 38 with val_loss 129.0771\n",
      "Epoch [39/300], Loss: 206.6991\n",
      "Validation Loss: 128.7483\n",
      "NME: 0.4327\n",
      "Best model saved at epoch 39 with val_loss 128.7483\n",
      "Epoch [40/300], Loss: 211.7660\n",
      "Validation Loss: 126.1024\n",
      "NME: 0.4373\n",
      "Best model saved at epoch 40 with val_loss 126.1024\n",
      "Epoch [41/300], Loss: 212.9272\n",
      "Validation Loss: 127.9361\n",
      "NME: 0.4307\n",
      "Epoch [42/300], Loss: 211.6071\n",
      "Validation Loss: 129.4555\n",
      "NME: 0.4406\n",
      "Epoch [43/300], Loss: 197.0179\n",
      "Validation Loss: 128.0902\n",
      "NME: 0.4199\n",
      "Epoch [44/300], Loss: 206.4342\n",
      "Validation Loss: 136.6904\n",
      "NME: 0.4787\n",
      "Epoch [45/300], Loss: 193.0890\n",
      "Validation Loss: 122.1532\n",
      "NME: 0.4259\n",
      "Best model saved at epoch 45 with val_loss 122.1532\n",
      "Epoch [46/300], Loss: 208.7305\n",
      "Validation Loss: 144.1235\n",
      "NME: 0.5014\n",
      "Epoch [47/300], Loss: 197.8582\n",
      "Validation Loss: 137.3312\n",
      "NME: 0.4450\n",
      "Epoch [48/300], Loss: 198.8414\n",
      "Validation Loss: 123.7315\n",
      "NME: 0.4232\n",
      "Epoch [49/300], Loss: 196.5681\n",
      "Validation Loss: 129.7984\n",
      "NME: 0.4555\n",
      "Epoch [50/300], Loss: 192.3957\n",
      "Validation Loss: 127.0828\n",
      "NME: 0.4273\n",
      "Epoch [51/300], Loss: 192.4029\n",
      "Validation Loss: 125.6820\n",
      "NME: 0.4432\n",
      "Epoch [52/300], Loss: 190.8468\n",
      "Validation Loss: 135.7948\n",
      "NME: 0.4810\n",
      "Epoch [53/300], Loss: 194.6801\n",
      "Validation Loss: 155.5149\n",
      "NME: 0.5352\n",
      "Epoch [54/300], Loss: 181.6326\n",
      "Validation Loss: 145.5008\n",
      "NME: 0.5017\n",
      "Epoch [55/300], Loss: 189.2592\n",
      "Validation Loss: 128.2192\n",
      "NME: 0.4360\n",
      "Epoch [56/300], Loss: 199.2493\n",
      "Validation Loss: 139.5939\n",
      "NME: 0.4468\n",
      "Epoch [57/300], Loss: 198.1506\n",
      "Validation Loss: 127.7264\n",
      "NME: 0.4466\n",
      "Epoch [58/300], Loss: 185.1122\n",
      "Validation Loss: 128.4170\n",
      "NME: 0.4474\n",
      "Epoch [59/300], Loss: 190.2147\n",
      "Validation Loss: 137.5159\n",
      "NME: 0.4591\n",
      "Epoch [60/300], Loss: 197.8749\n",
      "Validation Loss: 140.5177\n",
      "NME: 0.4916\n",
      "Epoch [61/300], Loss: 185.8121\n",
      "Validation Loss: 129.8320\n",
      "NME: 0.4569\n",
      "Epoch [62/300], Loss: 186.2851\n",
      "Validation Loss: 129.7958\n",
      "NME: 0.4769\n",
      "Epoch [63/300], Loss: 201.8660\n",
      "Validation Loss: 133.7466\n",
      "NME: 0.4939\n",
      "Epoch [64/300], Loss: 188.1669\n",
      "Validation Loss: 130.1938\n",
      "NME: 0.4710\n",
      "Epoch [65/300], Loss: 189.8884\n",
      "Validation Loss: 140.0918\n",
      "NME: 0.4942\n",
      "Epoch [66/300], Loss: 172.1900\n",
      "Validation Loss: 137.7450\n",
      "NME: 0.4971\n",
      "Epoch [67/300], Loss: 185.8041\n",
      "Validation Loss: 126.1734\n",
      "NME: 0.4456\n",
      "Epoch [68/300], Loss: 183.4019\n",
      "Validation Loss: 127.6461\n",
      "NME: 0.4435\n",
      "Epoch [69/300], Loss: 193.7830\n",
      "Validation Loss: 138.8055\n",
      "NME: 0.5028\n",
      "Epoch [70/300], Loss: 194.6566\n",
      "Validation Loss: 137.5877\n",
      "NME: 0.4619\n",
      "Epoch [71/300], Loss: 190.5325\n",
      "Validation Loss: 124.8490\n",
      "NME: 0.4550\n",
      "Epoch [72/300], Loss: 185.7091\n",
      "Validation Loss: 143.1317\n",
      "NME: 0.5166\n",
      "Epoch [73/300], Loss: 187.1523\n",
      "Validation Loss: 125.2987\n",
      "NME: 0.4303\n",
      "Epoch [74/300], Loss: 189.5922\n",
      "Validation Loss: 131.3552\n",
      "NME: 0.4713\n",
      "Epoch [75/300], Loss: 195.2710\n",
      "Validation Loss: 137.9770\n",
      "NME: 0.4997\n",
      "Epoch [76/300], Loss: 193.5146\n",
      "Validation Loss: 136.0539\n",
      "NME: 0.4976\n",
      "Epoch [77/300], Loss: 176.6252\n",
      "Validation Loss: 137.4497\n",
      "NME: 0.4816\n",
      "Epoch [78/300], Loss: 175.5332\n",
      "Validation Loss: 120.9982\n",
      "NME: 0.4293\n",
      "Best model saved at epoch 78 with val_loss 120.9982\n",
      "Epoch [79/300], Loss: 190.8654\n",
      "Validation Loss: 117.8911\n",
      "NME: 0.4328\n",
      "Best model saved at epoch 79 with val_loss 117.8911\n",
      "Epoch [80/300], Loss: 186.9552\n",
      "Validation Loss: 135.0499\n",
      "NME: 0.4832\n",
      "Epoch [81/300], Loss: 187.0820\n",
      "Validation Loss: 130.1034\n",
      "NME: 0.4605\n",
      "Epoch [82/300], Loss: 190.4123\n",
      "Validation Loss: 122.9121\n",
      "NME: 0.4359\n",
      "Epoch [83/300], Loss: 187.2900\n",
      "Validation Loss: 144.4911\n",
      "NME: 0.5161\n",
      "Epoch [84/300], Loss: 189.4062\n",
      "Validation Loss: 128.1464\n",
      "NME: 0.4323\n",
      "Epoch [85/300], Loss: 188.8388\n",
      "Validation Loss: 132.4303\n",
      "NME: 0.4585\n",
      "Epoch [86/300], Loss: 178.8734\n",
      "Validation Loss: 134.2243\n",
      "NME: 0.4863\n",
      "Epoch [87/300], Loss: 179.1941\n",
      "Validation Loss: 148.3369\n",
      "NME: 0.4989\n",
      "Epoch [88/300], Loss: 182.0520\n",
      "Validation Loss: 132.4921\n",
      "NME: 0.4614\n",
      "Epoch [89/300], Loss: 175.6912\n",
      "Validation Loss: 128.8098\n",
      "NME: 0.4745\n",
      "Epoch [90/300], Loss: 178.4749\n",
      "Validation Loss: 133.7793\n",
      "NME: 0.4681\n",
      "Epoch [91/300], Loss: 172.0901\n",
      "Validation Loss: 125.1506\n",
      "NME: 0.4338\n",
      "Epoch [92/300], Loss: 185.6670\n",
      "Validation Loss: 133.4862\n",
      "NME: 0.4844\n",
      "Epoch [93/300], Loss: 182.0954\n",
      "Validation Loss: 129.2986\n",
      "NME: 0.4696\n",
      "Epoch [94/300], Loss: 186.8411\n",
      "Validation Loss: 143.0874\n",
      "NME: 0.5074\n",
      "Epoch [95/300], Loss: 183.8628\n",
      "Validation Loss: 130.5987\n",
      "NME: 0.4562\n",
      "Epoch [96/300], Loss: 178.3222\n",
      "Validation Loss: 135.2925\n",
      "NME: 0.4903\n",
      "Epoch [97/300], Loss: 178.1246\n",
      "Validation Loss: 121.4808\n",
      "NME: 0.4301\n",
      "Epoch [98/300], Loss: 182.1430\n",
      "Validation Loss: 136.0928\n",
      "NME: 0.4843\n",
      "Epoch [99/300], Loss: 176.4274\n",
      "Validation Loss: 124.9890\n",
      "NME: 0.4595\n",
      "Epoch [100/300], Loss: 170.5597\n",
      "Validation Loss: 130.4158\n",
      "NME: 0.4686\n",
      "Epoch [101/300], Loss: 170.3986\n",
      "Validation Loss: 128.1537\n",
      "NME: 0.4559\n",
      "Epoch [102/300], Loss: 156.2768\n",
      "Validation Loss: 123.0339\n",
      "NME: 0.4343\n",
      "Epoch [103/300], Loss: 167.3538\n",
      "Validation Loss: 137.3033\n",
      "NME: 0.4851\n",
      "Epoch [104/300], Loss: 155.9881\n",
      "Validation Loss: 127.2949\n",
      "NME: 0.4434\n",
      "Epoch [105/300], Loss: 152.7954\n",
      "Validation Loss: 130.4924\n",
      "NME: 0.4566\n",
      "Epoch [106/300], Loss: 154.1060\n",
      "Validation Loss: 131.5954\n",
      "NME: 0.4770\n",
      "Epoch [107/300], Loss: 158.0153\n",
      "Validation Loss: 137.0343\n",
      "NME: 0.4887\n",
      "Epoch [108/300], Loss: 148.7104\n",
      "Validation Loss: 123.6783\n",
      "NME: 0.4245\n",
      "Epoch [109/300], Loss: 144.2477\n",
      "Validation Loss: 132.1108\n",
      "NME: 0.4640\n",
      "Epoch [110/300], Loss: 144.0913\n",
      "Validation Loss: 124.1713\n",
      "NME: 0.4344\n",
      "Epoch [111/300], Loss: 134.7238\n",
      "Validation Loss: 135.4434\n",
      "NME: 0.4842\n",
      "Epoch [112/300], Loss: 138.6351\n",
      "Validation Loss: 149.2842\n",
      "NME: 0.5400\n",
      "Epoch [113/300], Loss: 135.5047\n",
      "Validation Loss: 140.9221\n",
      "NME: 0.5200\n",
      "Epoch [114/300], Loss: 128.7928\n",
      "Validation Loss: 125.0992\n",
      "NME: 0.4379\n",
      "Epoch [115/300], Loss: 123.6815\n",
      "Validation Loss: 127.0540\n",
      "NME: 0.4501\n",
      "Epoch [116/300], Loss: 122.6947\n",
      "Validation Loss: 129.3980\n",
      "NME: 0.4559\n",
      "Epoch [117/300], Loss: 131.4221\n",
      "Validation Loss: 129.7868\n",
      "NME: 0.4704\n",
      "Epoch [118/300], Loss: 122.6774\n",
      "Validation Loss: 127.2660\n",
      "NME: 0.4539\n",
      "Epoch [119/300], Loss: 121.2886\n",
      "Validation Loss: 129.8923\n",
      "NME: 0.4557\n",
      "Epoch [120/300], Loss: 120.2157\n",
      "Validation Loss: 123.2007\n",
      "NME: 0.4385\n",
      "Epoch [121/300], Loss: 117.1323\n",
      "Validation Loss: 124.6539\n",
      "NME: 0.4431\n",
      "Epoch [122/300], Loss: 118.0980\n",
      "Validation Loss: 121.4925\n",
      "NME: 0.4369\n",
      "Epoch [123/300], Loss: 120.2865\n",
      "Validation Loss: 123.0786\n",
      "NME: 0.4503\n",
      "Epoch [124/300], Loss: 115.9005\n",
      "Validation Loss: 121.1024\n",
      "NME: 0.4345\n",
      "Epoch [125/300], Loss: 112.4090\n",
      "Validation Loss: 130.2124\n",
      "NME: 0.4673\n",
      "Epoch [126/300], Loss: 107.6969\n",
      "Validation Loss: 122.1655\n",
      "NME: 0.4408\n",
      "Epoch [127/300], Loss: 108.8485\n",
      "Validation Loss: 122.7962\n",
      "NME: 0.4437\n",
      "Epoch [128/300], Loss: 109.1557\n",
      "Validation Loss: 127.5393\n",
      "NME: 0.4542\n",
      "Epoch [129/300], Loss: 107.9993\n",
      "Validation Loss: 130.0391\n",
      "NME: 0.4641\n",
      "Epoch [130/300], Loss: 115.2817\n",
      "Validation Loss: 121.6088\n",
      "NME: 0.4381\n",
      "Epoch [131/300], Loss: 115.4644\n",
      "Validation Loss: 123.2498\n",
      "NME: 0.4403\n",
      "Epoch [132/300], Loss: 107.5659\n",
      "Validation Loss: 121.9881\n",
      "NME: 0.4262\n",
      "Epoch [133/300], Loss: 108.5293\n",
      "Validation Loss: 122.7931\n",
      "NME: 0.4460\n",
      "Epoch [134/300], Loss: 107.1822\n",
      "Validation Loss: 126.9348\n",
      "NME: 0.4630\n",
      "Epoch [135/300], Loss: 105.0904\n",
      "Validation Loss: 128.4071\n",
      "NME: 0.4559\n",
      "Epoch [136/300], Loss: 108.7495\n",
      "Validation Loss: 119.3670\n",
      "NME: 0.4260\n",
      "Epoch [137/300], Loss: 103.8673\n",
      "Validation Loss: 121.3602\n",
      "NME: 0.4354\n",
      "Epoch [138/300], Loss: 109.9566\n",
      "Validation Loss: 131.4754\n",
      "NME: 0.4699\n",
      "Epoch [139/300], Loss: 104.4060\n",
      "Validation Loss: 123.3144\n",
      "NME: 0.4269\n",
      "Epoch [140/300], Loss: 105.2400\n",
      "Validation Loss: 121.0301\n",
      "NME: 0.4415\n",
      "Epoch [141/300], Loss: 107.0818\n",
      "Validation Loss: 122.3435\n",
      "NME: 0.4415\n",
      "Epoch [142/300], Loss: 104.1309\n",
      "Validation Loss: 125.2069\n",
      "NME: 0.4482\n",
      "Epoch [143/300], Loss: 104.3465\n",
      "Validation Loss: 127.5894\n",
      "NME: 0.4508\n",
      "Epoch [144/300], Loss: 104.1311\n",
      "Validation Loss: 127.5208\n",
      "NME: 0.4575\n",
      "Epoch [145/300], Loss: 103.1173\n",
      "Validation Loss: 125.1048\n",
      "NME: 0.4394\n",
      "Epoch [146/300], Loss: 100.2953\n",
      "Validation Loss: 120.5273\n",
      "NME: 0.4322\n",
      "Epoch [147/300], Loss: 99.3745\n",
      "Validation Loss: 127.7616\n",
      "NME: 0.4595\n",
      "Epoch [148/300], Loss: 103.5527\n",
      "Validation Loss: 122.9042\n",
      "NME: 0.4412\n",
      "Epoch [149/300], Loss: 100.7690\n",
      "Validation Loss: 121.6359\n",
      "NME: 0.4383\n",
      "Epoch [150/300], Loss: 98.8521\n",
      "Validation Loss: 117.7866\n",
      "NME: 0.4253\n",
      "Best model saved at epoch 150 with val_loss 117.7866\n",
      "Epoch [151/300], Loss: 101.6109\n",
      "Validation Loss: 114.6907\n",
      "NME: 0.4217\n",
      "Best model saved at epoch 151 with val_loss 114.6907\n",
      "Epoch [152/300], Loss: 104.0434\n",
      "Validation Loss: 120.7946\n",
      "NME: 0.4380\n",
      "Epoch [153/300], Loss: 100.5437\n",
      "Validation Loss: 121.6924\n",
      "NME: 0.4298\n",
      "Epoch [154/300], Loss: 102.4718\n",
      "Validation Loss: 122.8763\n",
      "NME: 0.4313\n",
      "Epoch [155/300], Loss: 99.7882\n",
      "Validation Loss: 124.8621\n",
      "NME: 0.4389\n",
      "Epoch [156/300], Loss: 98.9909\n",
      "Validation Loss: 123.2993\n",
      "NME: 0.4406\n",
      "Epoch [157/300], Loss: 97.0615\n",
      "Validation Loss: 118.2026\n",
      "NME: 0.4216\n",
      "Epoch [158/300], Loss: 98.7506\n",
      "Validation Loss: 126.4068\n",
      "NME: 0.4590\n",
      "Epoch [159/300], Loss: 97.8760\n",
      "Validation Loss: 121.1198\n",
      "NME: 0.4315\n",
      "Epoch [160/300], Loss: 99.8221\n",
      "Validation Loss: 124.3938\n",
      "NME: 0.4406\n",
      "Epoch [161/300], Loss: 101.6671\n",
      "Validation Loss: 122.6603\n",
      "NME: 0.4345\n",
      "Epoch [162/300], Loss: 97.1233\n",
      "Validation Loss: 121.7462\n",
      "NME: 0.4378\n",
      "Epoch [163/300], Loss: 97.6817\n",
      "Validation Loss: 121.1510\n",
      "NME: 0.4362\n",
      "Epoch [164/300], Loss: 98.2292\n",
      "Validation Loss: 126.1235\n",
      "NME: 0.4570\n",
      "Epoch [165/300], Loss: 99.0222\n",
      "Validation Loss: 127.2714\n",
      "NME: 0.4474\n",
      "Epoch [166/300], Loss: 97.9912\n",
      "Validation Loss: 121.1337\n",
      "NME: 0.4315\n",
      "Epoch [167/300], Loss: 99.2413\n",
      "Validation Loss: 118.5028\n",
      "NME: 0.4326\n",
      "Epoch [168/300], Loss: 94.6587\n",
      "Validation Loss: 118.7300\n",
      "NME: 0.4356\n",
      "Epoch [169/300], Loss: 95.1938\n",
      "Validation Loss: 121.6470\n",
      "NME: 0.4310\n",
      "Epoch [170/300], Loss: 96.3822\n",
      "Validation Loss: 117.0224\n",
      "NME: 0.4231\n",
      "Epoch [171/300], Loss: 94.8749\n",
      "Validation Loss: 116.4849\n",
      "NME: 0.4307\n",
      "Epoch [172/300], Loss: 94.0261\n",
      "Validation Loss: 116.7550\n",
      "NME: 0.4228\n",
      "Epoch [173/300], Loss: 96.5745\n",
      "Validation Loss: 111.2734\n",
      "NME: 0.4199\n",
      "Best model saved at epoch 173 with val_loss 111.2734\n",
      "Epoch [174/300], Loss: 93.1277\n",
      "Validation Loss: 120.1085\n",
      "NME: 0.4377\n",
      "Epoch [175/300], Loss: 96.4971\n",
      "Validation Loss: 113.2029\n",
      "NME: 0.4275\n",
      "Epoch [176/300], Loss: 90.8375\n",
      "Validation Loss: 113.9240\n",
      "NME: 0.4219\n",
      "Epoch [177/300], Loss: 93.8272\n",
      "Validation Loss: 114.7872\n",
      "NME: 0.4213\n",
      "Epoch [178/300], Loss: 93.5421\n",
      "Validation Loss: 115.1969\n",
      "NME: 0.4261\n",
      "Epoch [179/300], Loss: 95.5803\n",
      "Validation Loss: 119.0230\n",
      "NME: 0.4324\n",
      "Epoch [180/300], Loss: 94.5925\n",
      "Validation Loss: 117.0796\n",
      "NME: 0.4161\n",
      "Epoch [181/300], Loss: 95.9173\n",
      "Validation Loss: 116.7449\n",
      "NME: 0.4232\n",
      "Epoch [182/300], Loss: 93.0330\n",
      "Validation Loss: 113.3499\n",
      "NME: 0.4109\n",
      "Epoch [183/300], Loss: 93.6159\n",
      "Validation Loss: 116.9144\n",
      "NME: 0.4211\n",
      "Epoch [184/300], Loss: 89.2655\n",
      "Validation Loss: 117.4229\n",
      "NME: 0.4208\n",
      "Epoch [185/300], Loss: 91.7745\n",
      "Validation Loss: 114.1166\n",
      "NME: 0.4166\n",
      "Epoch [186/300], Loss: 89.1812\n",
      "Validation Loss: 116.0099\n",
      "NME: 0.4171\n",
      "Epoch [187/300], Loss: 90.2415\n",
      "Validation Loss: 114.5165\n",
      "NME: 0.4107\n",
      "Epoch [188/300], Loss: 94.7264\n",
      "Validation Loss: 114.7743\n",
      "NME: 0.4162\n",
      "Epoch [189/300], Loss: 88.4808\n",
      "Validation Loss: 115.8960\n",
      "NME: 0.4141\n",
      "Epoch [190/300], Loss: 87.7214\n",
      "Validation Loss: 109.0216\n",
      "NME: 0.4030\n",
      "Best model saved at epoch 190 with val_loss 109.0216\n",
      "Epoch [191/300], Loss: 86.1257\n",
      "Validation Loss: 111.1387\n",
      "NME: 0.4110\n",
      "Epoch [192/300], Loss: 90.5810\n",
      "Validation Loss: 112.0110\n",
      "NME: 0.4215\n",
      "Epoch [193/300], Loss: 87.2047\n",
      "Validation Loss: 110.4076\n",
      "NME: 0.4211\n",
      "Epoch [194/300], Loss: 85.9306\n",
      "Validation Loss: 104.6459\n",
      "NME: 0.4041\n",
      "Best model saved at epoch 194 with val_loss 104.6459\n",
      "Epoch [195/300], Loss: 89.0338\n",
      "Validation Loss: 106.3666\n",
      "NME: 0.4031\n",
      "Epoch [196/300], Loss: 85.0508\n",
      "Validation Loss: 105.6074\n",
      "NME: 0.3994\n",
      "Epoch [197/300], Loss: 84.4111\n",
      "Validation Loss: 103.0365\n",
      "NME: 0.4016\n",
      "Best model saved at epoch 197 with val_loss 103.0365\n",
      "Epoch [198/300], Loss: 83.2592\n",
      "Validation Loss: 101.1275\n",
      "NME: 0.3956\n",
      "Best model saved at epoch 198 with val_loss 101.1275\n",
      "Epoch [199/300], Loss: 80.8345\n",
      "Validation Loss: 100.4764\n",
      "NME: 0.3905\n",
      "Best model saved at epoch 199 with val_loss 100.4764\n",
      "Epoch [200/300], Loss: 84.2171\n",
      "Validation Loss: 98.9962\n",
      "NME: 0.3993\n",
      "Best model saved at epoch 200 with val_loss 98.9962\n",
      "Epoch [201/300], Loss: 81.7569\n",
      "Validation Loss: 99.8792\n",
      "NME: 0.3960\n",
      "Epoch [202/300], Loss: 80.1044\n",
      "Validation Loss: 98.8599\n",
      "NME: 0.3841\n",
      "Best model saved at epoch 202 with val_loss 98.8599\n",
      "Epoch [203/300], Loss: 79.4932\n",
      "Validation Loss: 99.0499\n",
      "NME: 0.3939\n",
      "Epoch [204/300], Loss: 78.9332\n",
      "Validation Loss: 103.6440\n",
      "NME: 0.3989\n",
      "Epoch [205/300], Loss: 79.6657\n",
      "Validation Loss: 98.4600\n",
      "NME: 0.3850\n",
      "Best model saved at epoch 205 with val_loss 98.4600\n",
      "Epoch [206/300], Loss: 78.0689\n",
      "Validation Loss: 105.5722\n",
      "NME: 0.3955\n",
      "Epoch [207/300], Loss: 79.8152\n",
      "Validation Loss: 111.2695\n",
      "NME: 0.4525\n",
      "Epoch [208/300], Loss: 77.8168\n",
      "Validation Loss: 102.0293\n",
      "NME: 0.3831\n",
      "Epoch [209/300], Loss: 77.0028\n",
      "Validation Loss: 93.4402\n",
      "NME: 0.3694\n",
      "Best model saved at epoch 209 with val_loss 93.4402\n",
      "Epoch [210/300], Loss: 76.7485\n",
      "Validation Loss: 102.6263\n",
      "NME: 0.3926\n",
      "Epoch [211/300], Loss: 75.7043\n",
      "Validation Loss: 94.3872\n",
      "NME: 0.3679\n",
      "Epoch [212/300], Loss: 74.2565\n",
      "Validation Loss: 93.0809\n",
      "NME: 0.3743\n",
      "Best model saved at epoch 212 with val_loss 93.0809\n",
      "Epoch [213/300], Loss: 71.1824\n",
      "Validation Loss: 93.3223\n",
      "NME: 0.3820\n",
      "Epoch [214/300], Loss: 72.7027\n",
      "Validation Loss: 97.7284\n",
      "NME: 0.3825\n",
      "Epoch [215/300], Loss: 70.8007\n",
      "Validation Loss: 99.4414\n",
      "NME: 0.3886\n",
      "Epoch [216/300], Loss: 71.8361\n",
      "Validation Loss: 96.8055\n",
      "NME: 0.3813\n",
      "Epoch [217/300], Loss: 71.4201\n",
      "Validation Loss: 97.0351\n",
      "NME: 0.3688\n",
      "Epoch [218/300], Loss: 69.5037\n",
      "Validation Loss: 93.5587\n",
      "NME: 0.3698\n",
      "Epoch [219/300], Loss: 67.5092\n",
      "Validation Loss: 93.5953\n",
      "NME: 0.3806\n",
      "Epoch [220/300], Loss: 65.4971\n",
      "Validation Loss: 89.1388\n",
      "NME: 0.3613\n",
      "Best model saved at epoch 220 with val_loss 89.1388\n",
      "Epoch [221/300], Loss: 69.0798\n",
      "Validation Loss: 93.1665\n",
      "NME: 0.3753\n",
      "Epoch [222/300], Loss: 66.8410\n",
      "Validation Loss: 86.7962\n",
      "NME: 0.3563\n",
      "Best model saved at epoch 222 with val_loss 86.7962\n",
      "Epoch [223/300], Loss: 65.2652\n",
      "Validation Loss: 94.6127\n",
      "NME: 0.3623\n",
      "Epoch [224/300], Loss: 65.0653\n",
      "Validation Loss: 88.9531\n",
      "NME: 0.3455\n",
      "Epoch [225/300], Loss: 64.9636\n",
      "Validation Loss: 89.4799\n",
      "NME: 0.3609\n",
      "Epoch [226/300], Loss: 66.3410\n",
      "Validation Loss: 85.0573\n",
      "NME: 0.3520\n",
      "Best model saved at epoch 226 with val_loss 85.0573\n",
      "Epoch [227/300], Loss: 64.6824\n",
      "Validation Loss: 86.9715\n",
      "NME: 0.3597\n",
      "Epoch [228/300], Loss: 61.8166\n",
      "Validation Loss: 87.7816\n",
      "NME: 0.3633\n",
      "Epoch [229/300], Loss: 65.4919\n",
      "Validation Loss: 91.8791\n",
      "NME: 0.3823\n",
      "Epoch [230/300], Loss: 63.9914\n",
      "Validation Loss: 87.4127\n",
      "NME: 0.3599\n",
      "Epoch [231/300], Loss: 62.9458\n",
      "Validation Loss: 87.5438\n",
      "NME: 0.3454\n",
      "Epoch [232/300], Loss: 61.5862\n",
      "Validation Loss: 88.4435\n",
      "NME: 0.3496\n",
      "Epoch [233/300], Loss: 63.3837\n",
      "Validation Loss: 92.3918\n",
      "NME: 0.3499\n",
      "Epoch [234/300], Loss: 60.7766\n",
      "Validation Loss: 91.7817\n",
      "NME: 0.3677\n",
      "Epoch [235/300], Loss: 58.5943\n",
      "Validation Loss: 87.1367\n",
      "NME: 0.3478\n",
      "Epoch [236/300], Loss: 60.5651\n",
      "Validation Loss: 90.0980\n",
      "NME: 0.3631\n",
      "Epoch [237/300], Loss: 60.2075\n",
      "Validation Loss: 89.8415\n",
      "NME: 0.3543\n",
      "Epoch [238/300], Loss: 60.0830\n",
      "Validation Loss: 87.2473\n",
      "NME: 0.3500\n",
      "Epoch [239/300], Loss: 60.3543\n",
      "Validation Loss: 90.0558\n",
      "NME: 0.3578\n",
      "Epoch [240/300], Loss: 59.3938\n",
      "Validation Loss: 90.0436\n",
      "NME: 0.3490\n",
      "Epoch [241/300], Loss: 57.8578\n",
      "Validation Loss: 90.0568\n",
      "NME: 0.3472\n",
      "Epoch [242/300], Loss: 59.3406\n",
      "Validation Loss: 88.1542\n",
      "NME: 0.3442\n",
      "Epoch [243/300], Loss: 55.8663\n",
      "Validation Loss: 86.2864\n",
      "NME: 0.3379\n",
      "Epoch [244/300], Loss: 60.8550\n",
      "Validation Loss: 89.7673\n",
      "NME: 0.3661\n",
      "Epoch [245/300], Loss: 60.3984\n",
      "Validation Loss: 88.2466\n",
      "NME: 0.3585\n",
      "Epoch [246/300], Loss: 57.7575\n",
      "Validation Loss: 85.8297\n",
      "NME: 0.3451\n",
      "Epoch [247/300], Loss: 57.5458\n",
      "Validation Loss: 80.9281\n",
      "NME: 0.3356\n",
      "Best model saved at epoch 247 with val_loss 80.9281\n",
      "Epoch [248/300], Loss: 55.2916\n",
      "Validation Loss: 83.0147\n",
      "NME: 0.3467\n",
      "Epoch [249/300], Loss: 59.9824\n",
      "Validation Loss: 84.1965\n",
      "NME: 0.3414\n",
      "Epoch [250/300], Loss: 56.0227\n",
      "Validation Loss: 84.5688\n",
      "NME: 0.3483\n",
      "Epoch [251/300], Loss: 57.9816\n",
      "Validation Loss: 85.1985\n",
      "NME: 0.3396\n",
      "Epoch [252/300], Loss: 56.8091\n",
      "Validation Loss: 82.3354\n",
      "NME: 0.3372\n",
      "Epoch [253/300], Loss: 55.3582\n",
      "Validation Loss: 84.8997\n",
      "NME: 0.3431\n",
      "Epoch [254/300], Loss: 56.8081\n",
      "Validation Loss: 85.7253\n",
      "NME: 0.3508\n",
      "Epoch [255/300], Loss: 55.7284\n",
      "Validation Loss: 82.7307\n",
      "NME: 0.3356\n",
      "Epoch [256/300], Loss: 54.4924\n",
      "Validation Loss: 84.7842\n",
      "NME: 0.3505\n",
      "Epoch [257/300], Loss: 55.5815\n",
      "Validation Loss: 86.0542\n",
      "NME: 0.3374\n",
      "Epoch [258/300], Loss: 54.2367\n",
      "Validation Loss: 84.2945\n",
      "NME: 0.3316\n",
      "Epoch [259/300], Loss: 56.3150\n",
      "Validation Loss: 88.2492\n",
      "NME: 0.3452\n",
      "Epoch [260/300], Loss: 55.2822\n",
      "Validation Loss: 84.3784\n",
      "NME: 0.3414\n",
      "Epoch [261/300], Loss: 53.2967\n",
      "Validation Loss: 83.3195\n",
      "NME: 0.3414\n",
      "Epoch [262/300], Loss: 53.3456\n",
      "Validation Loss: 83.1059\n",
      "NME: 0.3379\n",
      "Epoch [263/300], Loss: 53.2312\n",
      "Validation Loss: 87.4912\n",
      "NME: 0.3423\n",
      "Epoch [264/300], Loss: 53.2165\n",
      "Validation Loss: 84.6046\n",
      "NME: 0.3344\n",
      "Epoch [265/300], Loss: 51.8688\n",
      "Validation Loss: 84.0425\n",
      "NME: 0.3349\n",
      "Epoch [266/300], Loss: 52.2483\n",
      "Validation Loss: 82.2664\n",
      "NME: 0.3346\n",
      "Epoch [267/300], Loss: 52.7417\n",
      "Validation Loss: 86.6166\n",
      "NME: 0.3508\n",
      "Epoch [268/300], Loss: 53.5540\n",
      "Validation Loss: 83.7079\n",
      "NME: 0.3372\n",
      "Epoch [269/300], Loss: 53.2322\n",
      "Validation Loss: 85.9171\n",
      "NME: 0.3395\n",
      "Epoch [270/300], Loss: 51.4499\n",
      "Validation Loss: 83.5892\n",
      "NME: 0.3371\n",
      "Epoch [271/300], Loss: 51.4548\n",
      "Validation Loss: 83.0898\n",
      "NME: 0.3329\n",
      "Epoch [272/300], Loss: 52.0298\n",
      "Validation Loss: 82.9864\n",
      "NME: 0.3392\n",
      "Epoch [273/300], Loss: 53.1232\n",
      "Validation Loss: 85.4860\n",
      "NME: 0.3455\n",
      "Epoch [274/300], Loss: 52.2883\n",
      "Validation Loss: 84.2245\n",
      "NME: 0.3379\n",
      "Epoch [275/300], Loss: 50.2988\n",
      "Validation Loss: 82.5008\n",
      "NME: 0.3360\n",
      "Epoch [276/300], Loss: 50.7629\n",
      "Validation Loss: 84.0078\n",
      "NME: 0.3450\n",
      "Epoch [277/300], Loss: 51.5094\n",
      "Validation Loss: 85.5361\n",
      "NME: 0.3396\n",
      "Epoch [278/300], Loss: 54.5468\n",
      "Validation Loss: 87.7052\n",
      "NME: 0.3407\n",
      "Epoch [279/300], Loss: 49.5283\n",
      "Validation Loss: 85.8995\n",
      "NME: 0.3386\n",
      "Epoch [280/300], Loss: 51.8518\n",
      "Validation Loss: 86.3603\n",
      "NME: 0.3318\n",
      "Epoch [281/300], Loss: 50.5200\n",
      "Validation Loss: 88.4327\n",
      "NME: 0.3464\n",
      "Epoch [282/300], Loss: 49.8041\n",
      "Validation Loss: 73.8951\n",
      "NME: 0.3189\n",
      "Best model saved at epoch 282 with val_loss 73.8951\n",
      "Epoch [283/300], Loss: 49.3650\n",
      "Validation Loss: 86.0188\n",
      "NME: 0.3378\n",
      "Epoch [284/300], Loss: 54.0723\n",
      "Validation Loss: 88.3876\n",
      "NME: 0.3427\n",
      "Epoch [285/300], Loss: 50.5736\n",
      "Validation Loss: 88.4654\n",
      "NME: 0.3479\n",
      "Epoch [286/300], Loss: 49.4390\n",
      "Validation Loss: 84.1250\n",
      "NME: 0.3367\n",
      "Epoch [287/300], Loss: 49.6076\n",
      "Validation Loss: 81.8510\n",
      "NME: 0.3266\n",
      "Epoch [288/300], Loss: 48.7055\n",
      "Validation Loss: 84.8065\n",
      "NME: 0.3327\n",
      "Epoch [289/300], Loss: 49.2018\n",
      "Validation Loss: 83.0949\n",
      "NME: 0.3330\n",
      "Epoch [290/300], Loss: 49.3513\n",
      "Validation Loss: 87.1244\n",
      "NME: 0.3444\n",
      "Epoch [291/300], Loss: 48.3140\n",
      "Validation Loss: 82.8102\n",
      "NME: 0.3291\n",
      "Epoch [292/300], Loss: 48.6042\n",
      "Validation Loss: 84.3500\n",
      "NME: 0.3301\n",
      "Epoch [293/300], Loss: 49.1150\n",
      "Validation Loss: 80.7474\n",
      "NME: 0.3397\n",
      "Epoch [294/300], Loss: 49.5360\n",
      "Validation Loss: 81.3465\n",
      "NME: 0.3347\n",
      "Epoch [295/300], Loss: 48.0046\n",
      "Validation Loss: 81.7677\n",
      "NME: 0.3285\n",
      "Epoch [296/300], Loss: 49.7503\n",
      "Validation Loss: 80.5832\n",
      "NME: 0.3285\n",
      "Epoch [297/300], Loss: 49.9041\n",
      "Validation Loss: 85.3338\n",
      "NME: 0.3410\n",
      "Epoch [298/300], Loss: 48.0488\n",
      "Validation Loss: 86.4344\n",
      "NME: 0.3395\n",
      "Epoch [299/300], Loss: 48.2924\n",
      "Validation Loss: 80.9648\n",
      "NME: 0.3317\n",
      "Epoch [300/300], Loss: 48.2471\n",
      "Validation Loss: 80.0020\n",
      "NME: 0.3298\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EyeLeftDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave del ojo izquierdo\n",
    "        eye_left_points = np.array([landmarks[i] for i in ojo_izq], dtype=np.float32)\n",
    "        eye_left_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(eye_left_points), 1))\n",
    "        points_ones = np.hstack([eye_left_points, ones])\n",
    "        eye_left_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado del ojo izquierdo\n",
    "        centro_x, centro_y = calcular_centro_region(eye_left_points_rotated, range(len(ojo_izq)))\n",
    "\n",
    "        # Definir los límites del recorte de 56x56 píxeles\n",
    "        half_crop_size = 28\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_eye = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_eye, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales del ojo izquierdo al nuevo recorte\n",
    "        eye_left_points_adjusted = [(p[0] - x1, p[1] - y1) for p in eye_left_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        eye_left_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in eye_left_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=eye_left_points_scaled)\n",
    "            image = augmented['image']\n",
    "            eye_left_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(eye_left_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EyeLeftDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EyeLeftDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EyeLeft(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EyeLeft, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(ojo_izq) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EyeLeft().cuda()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para ojo izquierdo)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, eye_left_points, _, _, _ in train_dataloader:\n",
    "            images, eye_left_points = images.cuda(), eye_left_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, eye_left_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_eye_left_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_eye_left_points = val_images.cuda(), val_eye_left_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_eye_left_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_eye_left_points.cpu().numpy().reshape(-1, len(ojo_izq), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(ojo_izq), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(ojo_izq))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EyeLeftLandmarks V3.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14734.0587\n",
      "Validation Loss: 14261.8735\n",
      "NME: 7.3281\n",
      "Best model saved at epoch 1 with val_loss 14261.8735\n",
      "Epoch [2/300], Loss: 13062.6246\n",
      "Validation Loss: 11191.3888\n",
      "NME: 6.4099\n",
      "Best model saved at epoch 2 with val_loss 11191.3888\n",
      "Epoch [3/300], Loss: 8761.4587\n",
      "Validation Loss: 5664.5527\n",
      "NME: 4.2109\n",
      "Best model saved at epoch 3 with val_loss 5664.5527\n",
      "Epoch [4/300], Loss: 3565.9724\n",
      "Validation Loss: 2106.3515\n",
      "NME: 2.0268\n",
      "Best model saved at epoch 4 with val_loss 2106.3515\n",
      "Epoch [5/300], Loss: 1603.0103\n",
      "Validation Loss: 1178.1881\n",
      "NME: 1.3132\n",
      "Best model saved at epoch 5 with val_loss 1178.1881\n",
      "Epoch [6/300], Loss: 1011.1178\n",
      "Validation Loss: 800.8623\n",
      "NME: 1.0178\n",
      "Best model saved at epoch 6 with val_loss 800.8623\n",
      "Epoch [7/300], Loss: 761.8532\n",
      "Validation Loss: 638.9376\n",
      "NME: 0.9486\n",
      "Best model saved at epoch 7 with val_loss 638.9376\n",
      "Epoch [8/300], Loss: 678.5910\n",
      "Validation Loss: 588.5069\n",
      "NME: 0.9748\n",
      "Best model saved at epoch 8 with val_loss 588.5069\n",
      "Epoch [9/300], Loss: 648.2744\n",
      "Validation Loss: 570.2049\n",
      "NME: 0.9999\n",
      "Best model saved at epoch 9 with val_loss 570.2049\n",
      "Epoch [10/300], Loss: 642.6902\n",
      "Validation Loss: 567.1500\n",
      "NME: 1.0202\n",
      "Best model saved at epoch 10 with val_loss 567.1500\n",
      "Epoch [11/300], Loss: 634.3954\n",
      "Validation Loss: 566.4194\n",
      "NME: 1.0331\n",
      "Best model saved at epoch 11 with val_loss 566.4194\n",
      "Epoch [12/300], Loss: 639.8132\n",
      "Validation Loss: 562.8222\n",
      "NME: 1.0387\n",
      "Best model saved at epoch 12 with val_loss 562.8222\n",
      "Epoch [13/300], Loss: 640.1305\n",
      "Validation Loss: 562.5678\n",
      "NME: 1.0349\n",
      "Best model saved at epoch 13 with val_loss 562.5678\n",
      "Epoch [14/300], Loss: 631.4282\n",
      "Validation Loss: 561.1919\n",
      "NME: 1.0325\n",
      "Best model saved at epoch 14 with val_loss 561.1919\n",
      "Epoch [15/300], Loss: 629.7919\n",
      "Validation Loss: 558.2036\n",
      "NME: 1.0332\n",
      "Best model saved at epoch 15 with val_loss 558.2036\n",
      "Epoch [16/300], Loss: 631.9773\n",
      "Validation Loss: 553.7115\n",
      "NME: 1.0310\n",
      "Best model saved at epoch 16 with val_loss 553.7115\n",
      "Epoch [17/300], Loss: 625.6510\n",
      "Validation Loss: 548.2330\n",
      "NME: 1.0063\n",
      "Best model saved at epoch 17 with val_loss 548.2330\n",
      "Epoch [18/300], Loss: 606.4373\n",
      "Validation Loss: 536.9661\n",
      "NME: 1.0108\n",
      "Best model saved at epoch 18 with val_loss 536.9661\n",
      "Epoch [19/300], Loss: 615.7884\n",
      "Validation Loss: 524.8957\n",
      "NME: 0.9891\n",
      "Best model saved at epoch 19 with val_loss 524.8957\n",
      "Epoch [20/300], Loss: 587.9916\n",
      "Validation Loss: 502.9874\n",
      "NME: 0.9679\n",
      "Best model saved at epoch 20 with val_loss 502.9874\n",
      "Epoch [21/300], Loss: 564.8760\n",
      "Validation Loss: 467.7368\n",
      "NME: 0.9419\n",
      "Best model saved at epoch 21 with val_loss 467.7368\n",
      "Epoch [22/300], Loss: 526.6643\n",
      "Validation Loss: 430.5013\n",
      "NME: 0.8629\n",
      "Best model saved at epoch 22 with val_loss 430.5013\n",
      "Epoch [23/300], Loss: 489.2448\n",
      "Validation Loss: 380.3744\n",
      "NME: 0.7849\n",
      "Best model saved at epoch 23 with val_loss 380.3744\n",
      "Epoch [24/300], Loss: 439.9007\n",
      "Validation Loss: 328.2145\n",
      "NME: 0.7298\n",
      "Best model saved at epoch 24 with val_loss 328.2145\n",
      "Epoch [25/300], Loss: 384.9769\n",
      "Validation Loss: 267.7581\n",
      "NME: 0.6425\n",
      "Best model saved at epoch 25 with val_loss 267.7581\n",
      "Epoch [26/300], Loss: 351.5788\n",
      "Validation Loss: 225.7325\n",
      "NME: 0.5859\n",
      "Best model saved at epoch 26 with val_loss 225.7325\n",
      "Epoch [27/300], Loss: 310.8673\n",
      "Validation Loss: 190.3837\n",
      "NME: 0.5280\n",
      "Best model saved at epoch 27 with val_loss 190.3837\n",
      "Epoch [28/300], Loss: 279.8489\n",
      "Validation Loss: 165.4613\n",
      "NME: 0.4949\n",
      "Best model saved at epoch 28 with val_loss 165.4613\n",
      "Epoch [29/300], Loss: 269.0965\n",
      "Validation Loss: 151.6002\n",
      "NME: 0.4883\n",
      "Best model saved at epoch 29 with val_loss 151.6002\n",
      "Epoch [30/300], Loss: 254.0862\n",
      "Validation Loss: 140.3548\n",
      "NME: 0.4675\n",
      "Best model saved at epoch 30 with val_loss 140.3548\n",
      "Epoch [31/300], Loss: 246.2842\n",
      "Validation Loss: 134.7401\n",
      "NME: 0.4460\n",
      "Best model saved at epoch 31 with val_loss 134.7401\n",
      "Epoch [32/300], Loss: 228.8652\n",
      "Validation Loss: 132.6275\n",
      "NME: 0.4512\n",
      "Best model saved at epoch 32 with val_loss 132.6275\n",
      "Epoch [33/300], Loss: 228.1940\n",
      "Validation Loss: 127.8641\n",
      "NME: 0.4321\n",
      "Best model saved at epoch 33 with val_loss 127.8641\n",
      "Epoch [34/300], Loss: 235.0550\n",
      "Validation Loss: 120.6312\n",
      "NME: 0.4220\n",
      "Best model saved at epoch 34 with val_loss 120.6312\n",
      "Epoch [35/300], Loss: 220.6077\n",
      "Validation Loss: 121.1017\n",
      "NME: 0.4245\n",
      "Epoch [36/300], Loss: 209.3782\n",
      "Validation Loss: 119.7537\n",
      "NME: 0.4200\n",
      "Best model saved at epoch 36 with val_loss 119.7537\n",
      "Epoch [37/300], Loss: 214.4334\n",
      "Validation Loss: 118.1964\n",
      "NME: 0.4260\n",
      "Best model saved at epoch 37 with val_loss 118.1964\n",
      "Epoch [38/300], Loss: 202.2187\n",
      "Validation Loss: 120.6830\n",
      "NME: 0.4191\n",
      "Epoch [39/300], Loss: 211.0649\n",
      "Validation Loss: 122.4226\n",
      "NME: 0.4371\n",
      "Epoch [40/300], Loss: 203.6034\n",
      "Validation Loss: 121.7227\n",
      "NME: 0.4243\n",
      "Epoch [41/300], Loss: 210.8631\n",
      "Validation Loss: 114.9817\n",
      "NME: 0.4135\n",
      "Best model saved at epoch 41 with val_loss 114.9817\n",
      "Epoch [42/300], Loss: 198.8184\n",
      "Validation Loss: 118.0622\n",
      "NME: 0.4176\n",
      "Epoch [43/300], Loss: 208.5946\n",
      "Validation Loss: 112.4124\n",
      "NME: 0.4135\n",
      "Best model saved at epoch 43 with val_loss 112.4124\n",
      "Epoch [44/300], Loss: 205.0371\n",
      "Validation Loss: 114.7032\n",
      "NME: 0.4147\n",
      "Epoch [45/300], Loss: 206.5524\n",
      "Validation Loss: 115.2534\n",
      "NME: 0.4392\n",
      "Epoch [46/300], Loss: 195.6876\n",
      "Validation Loss: 117.9356\n",
      "NME: 0.4372\n",
      "Epoch [47/300], Loss: 198.5880\n",
      "Validation Loss: 126.8776\n",
      "NME: 0.4797\n",
      "Epoch [48/300], Loss: 198.7189\n",
      "Validation Loss: 115.3485\n",
      "NME: 0.4308\n",
      "Epoch [49/300], Loss: 190.3768\n",
      "Validation Loss: 115.2733\n",
      "NME: 0.4235\n",
      "Epoch [50/300], Loss: 196.0409\n",
      "Validation Loss: 118.2218\n",
      "NME: 0.4367\n",
      "Epoch [51/300], Loss: 186.9719\n",
      "Validation Loss: 114.1327\n",
      "NME: 0.4141\n",
      "Epoch [52/300], Loss: 184.9592\n",
      "Validation Loss: 118.1956\n",
      "NME: 0.4379\n",
      "Epoch [53/300], Loss: 183.6220\n",
      "Validation Loss: 124.8671\n",
      "NME: 0.4630\n",
      "Epoch [54/300], Loss: 208.9138\n",
      "Validation Loss: 120.0880\n",
      "NME: 0.4310\n",
      "Epoch [55/300], Loss: 191.3782\n",
      "Validation Loss: 114.0656\n",
      "NME: 0.4213\n",
      "Epoch [56/300], Loss: 187.5117\n",
      "Validation Loss: 125.7933\n",
      "NME: 0.4870\n",
      "Epoch [57/300], Loss: 198.0266\n",
      "Validation Loss: 123.1191\n",
      "NME: 0.4711\n",
      "Epoch [58/300], Loss: 188.8777\n",
      "Validation Loss: 117.4327\n",
      "NME: 0.4344\n",
      "Epoch [59/300], Loss: 189.2407\n",
      "Validation Loss: 123.8795\n",
      "NME: 0.4568\n",
      "Epoch [60/300], Loss: 183.0326\n",
      "Validation Loss: 125.8801\n",
      "NME: 0.4742\n",
      "Epoch [61/300], Loss: 173.8412\n",
      "Validation Loss: 116.7072\n",
      "NME: 0.4424\n",
      "Epoch [62/300], Loss: 195.9147\n",
      "Validation Loss: 117.0641\n",
      "NME: 0.4450\n",
      "Epoch [63/300], Loss: 186.4194\n",
      "Validation Loss: 123.4116\n",
      "NME: 0.4779\n",
      "Epoch [64/300], Loss: 190.6934\n",
      "Validation Loss: 128.2918\n",
      "NME: 0.5206\n",
      "Epoch [65/300], Loss: 189.4972\n",
      "Validation Loss: 115.8823\n",
      "NME: 0.4229\n",
      "Epoch [66/300], Loss: 193.7032\n",
      "Validation Loss: 113.6872\n",
      "NME: 0.4361\n",
      "Epoch [67/300], Loss: 176.6658\n",
      "Validation Loss: 113.0366\n",
      "NME: 0.4303\n",
      "Epoch [68/300], Loss: 195.8932\n",
      "Validation Loss: 123.6604\n",
      "NME: 0.4811\n",
      "Epoch [69/300], Loss: 181.8385\n",
      "Validation Loss: 121.9665\n",
      "NME: 0.4818\n",
      "Epoch [70/300], Loss: 195.5303\n",
      "Validation Loss: 123.3319\n",
      "NME: 0.4786\n",
      "Epoch [71/300], Loss: 181.5256\n",
      "Validation Loss: 120.4852\n",
      "NME: 0.4561\n",
      "Epoch [72/300], Loss: 181.9479\n",
      "Validation Loss: 114.5055\n",
      "NME: 0.4417\n",
      "Epoch [73/300], Loss: 184.4913\n",
      "Validation Loss: 122.9038\n",
      "NME: 0.4651\n",
      "Epoch [74/300], Loss: 193.0780\n",
      "Validation Loss: 123.7637\n",
      "NME: 0.4916\n",
      "Epoch [75/300], Loss: 169.6234\n",
      "Validation Loss: 121.7472\n",
      "NME: 0.4669\n",
      "Epoch [76/300], Loss: 186.7196\n",
      "Validation Loss: 123.6487\n",
      "NME: 0.4821\n",
      "Epoch [77/300], Loss: 184.4478\n",
      "Validation Loss: 117.7074\n",
      "NME: 0.4706\n",
      "Epoch [78/300], Loss: 172.0687\n",
      "Validation Loss: 114.3186\n",
      "NME: 0.4426\n",
      "Epoch [79/300], Loss: 188.4679\n",
      "Validation Loss: 115.0717\n",
      "NME: 0.4557\n",
      "Epoch [80/300], Loss: 189.9265\n",
      "Validation Loss: 112.2083\n",
      "NME: 0.4365\n",
      "Best model saved at epoch 80 with val_loss 112.2083\n",
      "Epoch [81/300], Loss: 190.1662\n",
      "Validation Loss: 117.4219\n",
      "NME: 0.4606\n",
      "Epoch [82/300], Loss: 182.3932\n",
      "Validation Loss: 122.4147\n",
      "NME: 0.4866\n",
      "Epoch [83/300], Loss: 189.5131\n",
      "Validation Loss: 116.1751\n",
      "NME: 0.4524\n",
      "Epoch [84/300], Loss: 174.2820\n",
      "Validation Loss: 116.5462\n",
      "NME: 0.4540\n",
      "Epoch [85/300], Loss: 182.9177\n",
      "Validation Loss: 113.5075\n",
      "NME: 0.4378\n",
      "Epoch [86/300], Loss: 182.8682\n",
      "Validation Loss: 110.1631\n",
      "NME: 0.4298\n",
      "Best model saved at epoch 86 with val_loss 110.1631\n",
      "Epoch [87/300], Loss: 194.7990\n",
      "Validation Loss: 124.1005\n",
      "NME: 0.4832\n",
      "Epoch [88/300], Loss: 178.7455\n",
      "Validation Loss: 113.4052\n",
      "NME: 0.4426\n",
      "Epoch [89/300], Loss: 189.2179\n",
      "Validation Loss: 109.8210\n",
      "NME: 0.4136\n",
      "Best model saved at epoch 89 with val_loss 109.8210\n",
      "Epoch [90/300], Loss: 168.5878\n",
      "Validation Loss: 123.7365\n",
      "NME: 0.4674\n",
      "Epoch [91/300], Loss: 183.7752\n",
      "Validation Loss: 120.3495\n",
      "NME: 0.4451\n",
      "Epoch [92/300], Loss: 186.7349\n",
      "Validation Loss: 112.2022\n",
      "NME: 0.4220\n",
      "Epoch [93/300], Loss: 179.3569\n",
      "Validation Loss: 119.4862\n",
      "NME: 0.4719\n",
      "Epoch [94/300], Loss: 189.3253\n",
      "Validation Loss: 108.3893\n",
      "NME: 0.4264\n",
      "Best model saved at epoch 94 with val_loss 108.3893\n",
      "Epoch [95/300], Loss: 178.6740\n",
      "Validation Loss: 115.0534\n",
      "NME: 0.4464\n",
      "Epoch [96/300], Loss: 185.0863\n",
      "Validation Loss: 117.7424\n",
      "NME: 0.4504\n",
      "Epoch [97/300], Loss: 175.4511\n",
      "Validation Loss: 121.4322\n",
      "NME: 0.4561\n",
      "Epoch [98/300], Loss: 181.5061\n",
      "Validation Loss: 113.0883\n",
      "NME: 0.4245\n",
      "Epoch [99/300], Loss: 192.1342\n",
      "Validation Loss: 109.8371\n",
      "NME: 0.4287\n",
      "Epoch [100/300], Loss: 170.3905\n",
      "Validation Loss: 111.3078\n",
      "NME: 0.4351\n",
      "Epoch [101/300], Loss: 169.0648\n",
      "Validation Loss: 112.8435\n",
      "NME: 0.4604\n",
      "Epoch [102/300], Loss: 174.3848\n",
      "Validation Loss: 118.0163\n",
      "NME: 0.4710\n",
      "Epoch [103/300], Loss: 170.0741\n",
      "Validation Loss: 115.8775\n",
      "NME: 0.4398\n",
      "Epoch [104/300], Loss: 165.8323\n",
      "Validation Loss: 108.6132\n",
      "NME: 0.4333\n",
      "Epoch [105/300], Loss: 164.4049\n",
      "Validation Loss: 108.4236\n",
      "NME: 0.4219\n",
      "Epoch [106/300], Loss: 174.1334\n",
      "Validation Loss: 108.5226\n",
      "NME: 0.4331\n",
      "Epoch [107/300], Loss: 164.5467\n",
      "Validation Loss: 108.1901\n",
      "NME: 0.4460\n",
      "Best model saved at epoch 107 with val_loss 108.1901\n",
      "Epoch [108/300], Loss: 155.7320\n",
      "Validation Loss: 109.5808\n",
      "NME: 0.4292\n",
      "Epoch [109/300], Loss: 155.1988\n",
      "Validation Loss: 112.6770\n",
      "NME: 0.4235\n",
      "Epoch [110/300], Loss: 150.4838\n",
      "Validation Loss: 119.9865\n",
      "NME: 0.4999\n",
      "Epoch [111/300], Loss: 150.0183\n",
      "Validation Loss: 110.5690\n",
      "NME: 0.4537\n",
      "Epoch [112/300], Loss: 141.8503\n",
      "Validation Loss: 107.0397\n",
      "NME: 0.4357\n",
      "Best model saved at epoch 112 with val_loss 107.0397\n",
      "Epoch [113/300], Loss: 139.7804\n",
      "Validation Loss: 109.2191\n",
      "NME: 0.4344\n",
      "Epoch [114/300], Loss: 141.2006\n",
      "Validation Loss: 107.9172\n",
      "NME: 0.4322\n",
      "Epoch [115/300], Loss: 130.9862\n",
      "Validation Loss: 120.9236\n",
      "NME: 0.4976\n",
      "Epoch [116/300], Loss: 136.1703\n",
      "Validation Loss: 114.1630\n",
      "NME: 0.4425\n",
      "Epoch [117/300], Loss: 123.8903\n",
      "Validation Loss: 120.9790\n",
      "NME: 0.4917\n",
      "Epoch [118/300], Loss: 123.6583\n",
      "Validation Loss: 112.0832\n",
      "NME: 0.4423\n",
      "Epoch [119/300], Loss: 122.7212\n",
      "Validation Loss: 111.6168\n",
      "NME: 0.4381\n",
      "Epoch [120/300], Loss: 121.9634\n",
      "Validation Loss: 112.5155\n",
      "NME: 0.4372\n",
      "Epoch [121/300], Loss: 118.0069\n",
      "Validation Loss: 107.4962\n",
      "NME: 0.4238\n",
      "Epoch [122/300], Loss: 119.9265\n",
      "Validation Loss: 112.4027\n",
      "NME: 0.4285\n",
      "Epoch [123/300], Loss: 123.3798\n",
      "Validation Loss: 108.3941\n",
      "NME: 0.4485\n",
      "Epoch [124/300], Loss: 110.7325\n",
      "Validation Loss: 107.8747\n",
      "NME: 0.4321\n",
      "Epoch [125/300], Loss: 109.2335\n",
      "Validation Loss: 107.9306\n",
      "NME: 0.4293\n",
      "Epoch [126/300], Loss: 107.5094\n",
      "Validation Loss: 107.1247\n",
      "NME: 0.4292\n",
      "Epoch [127/300], Loss: 109.8046\n",
      "Validation Loss: 110.7598\n",
      "NME: 0.4209\n",
      "Epoch [128/300], Loss: 112.5044\n",
      "Validation Loss: 112.1762\n",
      "NME: 0.4458\n",
      "Epoch [129/300], Loss: 107.9269\n",
      "Validation Loss: 109.6147\n",
      "NME: 0.4245\n",
      "Epoch [130/300], Loss: 102.2659\n",
      "Validation Loss: 112.6839\n",
      "NME: 0.4555\n",
      "Epoch [131/300], Loss: 106.2851\n",
      "Validation Loss: 109.8852\n",
      "NME: 0.4220\n",
      "Epoch [132/300], Loss: 105.2879\n",
      "Validation Loss: 106.3300\n",
      "NME: 0.4243\n",
      "Best model saved at epoch 132 with val_loss 106.3300\n",
      "Epoch [133/300], Loss: 105.7065\n",
      "Validation Loss: 106.8283\n",
      "NME: 0.4153\n",
      "Epoch [134/300], Loss: 100.8701\n",
      "Validation Loss: 106.5829\n",
      "NME: 0.4161\n",
      "Epoch [135/300], Loss: 102.8361\n",
      "Validation Loss: 118.6117\n",
      "NME: 0.4567\n",
      "Epoch [136/300], Loss: 102.8888\n",
      "Validation Loss: 110.1595\n",
      "NME: 0.4385\n",
      "Epoch [137/300], Loss: 100.1791\n",
      "Validation Loss: 108.8971\n",
      "NME: 0.4290\n",
      "Epoch [138/300], Loss: 100.5594\n",
      "Validation Loss: 106.8099\n",
      "NME: 0.4165\n",
      "Epoch [139/300], Loss: 103.7697\n",
      "Validation Loss: 102.6762\n",
      "NME: 0.4176\n",
      "Best model saved at epoch 139 with val_loss 102.6762\n",
      "Epoch [140/300], Loss: 99.8025\n",
      "Validation Loss: 103.8091\n",
      "NME: 0.4053\n",
      "Epoch [141/300], Loss: 97.5625\n",
      "Validation Loss: 107.9348\n",
      "NME: 0.4220\n",
      "Epoch [142/300], Loss: 98.0438\n",
      "Validation Loss: 106.1831\n",
      "NME: 0.4195\n",
      "Epoch [143/300], Loss: 96.0853\n",
      "Validation Loss: 105.9060\n",
      "NME: 0.4179\n",
      "Epoch [144/300], Loss: 91.9801\n",
      "Validation Loss: 103.0985\n",
      "NME: 0.3974\n",
      "Epoch [145/300], Loss: 95.4922\n",
      "Validation Loss: 107.0170\n",
      "NME: 0.4279\n",
      "Epoch [146/300], Loss: 92.8084\n",
      "Validation Loss: 106.8066\n",
      "NME: 0.4187\n",
      "Epoch [147/300], Loss: 93.1050\n",
      "Validation Loss: 103.9281\n",
      "NME: 0.4163\n",
      "Epoch [148/300], Loss: 89.9452\n",
      "Validation Loss: 102.8908\n",
      "NME: 0.4049\n",
      "Epoch [149/300], Loss: 92.4384\n",
      "Validation Loss: 105.6906\n",
      "NME: 0.4142\n",
      "Epoch [150/300], Loss: 95.0486\n",
      "Validation Loss: 106.7078\n",
      "NME: 0.4033\n",
      "Epoch [151/300], Loss: 94.5783\n",
      "Validation Loss: 101.2368\n",
      "NME: 0.4065\n",
      "Best model saved at epoch 151 with val_loss 101.2368\n",
      "Epoch [152/300], Loss: 92.2940\n",
      "Validation Loss: 104.0425\n",
      "NME: 0.4025\n",
      "Epoch [153/300], Loss: 90.4502\n",
      "Validation Loss: 104.1606\n",
      "NME: 0.4063\n",
      "Epoch [154/300], Loss: 91.3105\n",
      "Validation Loss: 102.2508\n",
      "NME: 0.3954\n",
      "Epoch [155/300], Loss: 89.5446\n",
      "Validation Loss: 100.5022\n",
      "NME: 0.3964\n",
      "Best model saved at epoch 155 with val_loss 100.5022\n",
      "Epoch [156/300], Loss: 88.6816\n",
      "Validation Loss: 101.3232\n",
      "NME: 0.3960\n",
      "Epoch [157/300], Loss: 89.2365\n",
      "Validation Loss: 104.6839\n",
      "NME: 0.4146\n",
      "Epoch [158/300], Loss: 90.5340\n",
      "Validation Loss: 100.7952\n",
      "NME: 0.4018\n",
      "Epoch [159/300], Loss: 86.5599\n",
      "Validation Loss: 103.5411\n",
      "NME: 0.4216\n",
      "Epoch [160/300], Loss: 86.2170\n",
      "Validation Loss: 100.8518\n",
      "NME: 0.3965\n",
      "Epoch [161/300], Loss: 89.0889\n",
      "Validation Loss: 99.6020\n",
      "NME: 0.4005\n",
      "Best model saved at epoch 161 with val_loss 99.6020\n",
      "Epoch [162/300], Loss: 83.5466\n",
      "Validation Loss: 102.7456\n",
      "NME: 0.4167\n",
      "Epoch [163/300], Loss: 88.0103\n",
      "Validation Loss: 108.6998\n",
      "NME: 0.4158\n",
      "Epoch [164/300], Loss: 84.6483\n",
      "Validation Loss: 100.1707\n",
      "NME: 0.3978\n",
      "Epoch [165/300], Loss: 88.1137\n",
      "Validation Loss: 103.4833\n",
      "NME: 0.4065\n",
      "Epoch [166/300], Loss: 85.0664\n",
      "Validation Loss: 98.7414\n",
      "NME: 0.3834\n",
      "Best model saved at epoch 166 with val_loss 98.7414\n",
      "Epoch [167/300], Loss: 85.7038\n",
      "Validation Loss: 94.2870\n",
      "NME: 0.3748\n",
      "Best model saved at epoch 167 with val_loss 94.2870\n",
      "Epoch [168/300], Loss: 83.1235\n",
      "Validation Loss: 97.9524\n",
      "NME: 0.3934\n",
      "Epoch [169/300], Loss: 83.7700\n",
      "Validation Loss: 96.5051\n",
      "NME: 0.3909\n",
      "Epoch [170/300], Loss: 82.5132\n",
      "Validation Loss: 97.4023\n",
      "NME: 0.3885\n",
      "Epoch [171/300], Loss: 83.0835\n",
      "Validation Loss: 101.9583\n",
      "NME: 0.4081\n",
      "Epoch [172/300], Loss: 82.8464\n",
      "Validation Loss: 95.8293\n",
      "NME: 0.3879\n",
      "Epoch [173/300], Loss: 83.5684\n",
      "Validation Loss: 102.5395\n",
      "NME: 0.4028\n",
      "Epoch [174/300], Loss: 83.0604\n",
      "Validation Loss: 95.2010\n",
      "NME: 0.3843\n",
      "Epoch [175/300], Loss: 81.7937\n",
      "Validation Loss: 97.8625\n",
      "NME: 0.3992\n",
      "Epoch [176/300], Loss: 79.8010\n",
      "Validation Loss: 96.7274\n",
      "NME: 0.3808\n",
      "Epoch [177/300], Loss: 80.0732\n",
      "Validation Loss: 100.8257\n",
      "NME: 0.4013\n",
      "Epoch [178/300], Loss: 80.3052\n",
      "Validation Loss: 94.1745\n",
      "NME: 0.3776\n",
      "Best model saved at epoch 178 with val_loss 94.1745\n",
      "Epoch [179/300], Loss: 78.0125\n",
      "Validation Loss: 93.8280\n",
      "NME: 0.3792\n",
      "Best model saved at epoch 179 with val_loss 93.8280\n",
      "Epoch [180/300], Loss: 80.1954\n",
      "Validation Loss: 96.9818\n",
      "NME: 0.3907\n",
      "Epoch [181/300], Loss: 77.7190\n",
      "Validation Loss: 96.3470\n",
      "NME: 0.4025\n",
      "Epoch [182/300], Loss: 76.7789\n",
      "Validation Loss: 93.6335\n",
      "NME: 0.3826\n",
      "Best model saved at epoch 182 with val_loss 93.6335\n",
      "Epoch [183/300], Loss: 76.1744\n",
      "Validation Loss: 93.1967\n",
      "NME: 0.3785\n",
      "Best model saved at epoch 183 with val_loss 93.1967\n",
      "Epoch [184/300], Loss: 74.8532\n",
      "Validation Loss: 92.4147\n",
      "NME: 0.3705\n",
      "Best model saved at epoch 184 with val_loss 92.4147\n",
      "Epoch [185/300], Loss: 78.0558\n",
      "Validation Loss: 92.0669\n",
      "NME: 0.3787\n",
      "Best model saved at epoch 185 with val_loss 92.0669\n",
      "Epoch [186/300], Loss: 74.8476\n",
      "Validation Loss: 88.1510\n",
      "NME: 0.3701\n",
      "Best model saved at epoch 186 with val_loss 88.1510\n",
      "Epoch [187/300], Loss: 75.9190\n",
      "Validation Loss: 89.7076\n",
      "NME: 0.3730\n",
      "Epoch [188/300], Loss: 74.1805\n",
      "Validation Loss: 90.1250\n",
      "NME: 0.3680\n",
      "Epoch [189/300], Loss: 75.3645\n",
      "Validation Loss: 90.0991\n",
      "NME: 0.3726\n",
      "Epoch [190/300], Loss: 72.9530\n",
      "Validation Loss: 90.9928\n",
      "NME: 0.3780\n",
      "Epoch [191/300], Loss: 70.4731\n",
      "Validation Loss: 89.0325\n",
      "NME: 0.3688\n",
      "Epoch [192/300], Loss: 73.0160\n",
      "Validation Loss: 90.5527\n",
      "NME: 0.3917\n",
      "Epoch [193/300], Loss: 71.9728\n",
      "Validation Loss: 87.1266\n",
      "NME: 0.3674\n",
      "Best model saved at epoch 193 with val_loss 87.1266\n",
      "Epoch [194/300], Loss: 72.4571\n",
      "Validation Loss: 86.3203\n",
      "NME: 0.3657\n",
      "Best model saved at epoch 194 with val_loss 86.3203\n",
      "Epoch [195/300], Loss: 73.7012\n",
      "Validation Loss: 85.9450\n",
      "NME: 0.3568\n",
      "Best model saved at epoch 195 with val_loss 85.9450\n",
      "Epoch [196/300], Loss: 69.5296\n",
      "Validation Loss: 86.6306\n",
      "NME: 0.3692\n",
      "Epoch [197/300], Loss: 67.3317\n",
      "Validation Loss: 84.0045\n",
      "NME: 0.3563\n",
      "Best model saved at epoch 197 with val_loss 84.0045\n",
      "Epoch [198/300], Loss: 66.3842\n",
      "Validation Loss: 81.5179\n",
      "NME: 0.3488\n",
      "Best model saved at epoch 198 with val_loss 81.5179\n",
      "Epoch [199/300], Loss: 67.1465\n",
      "Validation Loss: 86.5713\n",
      "NME: 0.3762\n",
      "Epoch [200/300], Loss: 68.7057\n",
      "Validation Loss: 83.1605\n",
      "NME: 0.3442\n",
      "Epoch [201/300], Loss: 65.9358\n",
      "Validation Loss: 81.1339\n",
      "NME: 0.3468\n",
      "Best model saved at epoch 201 with val_loss 81.1339\n",
      "Epoch [202/300], Loss: 63.3716\n",
      "Validation Loss: 80.8236\n",
      "NME: 0.3542\n",
      "Best model saved at epoch 202 with val_loss 80.8236\n",
      "Epoch [203/300], Loss: 65.3044\n",
      "Validation Loss: 77.5122\n",
      "NME: 0.3394\n",
      "Best model saved at epoch 203 with val_loss 77.5122\n",
      "Epoch [204/300], Loss: 62.6711\n",
      "Validation Loss: 78.4512\n",
      "NME: 0.3414\n",
      "Epoch [205/300], Loss: 64.0494\n",
      "Validation Loss: 83.0955\n",
      "NME: 0.3542\n",
      "Epoch [206/300], Loss: 63.8440\n",
      "Validation Loss: 78.3420\n",
      "NME: 0.3330\n",
      "Epoch [207/300], Loss: 64.5903\n",
      "Validation Loss: 78.8392\n",
      "NME: 0.3386\n",
      "Epoch [208/300], Loss: 58.1266\n",
      "Validation Loss: 78.5467\n",
      "NME: 0.3420\n",
      "Epoch [209/300], Loss: 60.9556\n",
      "Validation Loss: 77.5109\n",
      "NME: 0.3391\n",
      "Best model saved at epoch 209 with val_loss 77.5109\n",
      "Epoch [210/300], Loss: 59.7844\n",
      "Validation Loss: 81.6459\n",
      "NME: 0.3451\n",
      "Epoch [211/300], Loss: 62.7123\n",
      "Validation Loss: 80.7798\n",
      "NME: 0.3523\n",
      "Epoch [212/300], Loss: 63.7052\n",
      "Validation Loss: 81.2850\n",
      "NME: 0.3491\n",
      "Epoch [213/300], Loss: 58.2205\n",
      "Validation Loss: 76.0509\n",
      "NME: 0.3298\n",
      "Best model saved at epoch 213 with val_loss 76.0509\n",
      "Epoch [214/300], Loss: 63.2666\n",
      "Validation Loss: 74.8434\n",
      "NME: 0.3264\n",
      "Best model saved at epoch 214 with val_loss 74.8434\n",
      "Epoch [215/300], Loss: 59.7455\n",
      "Validation Loss: 77.6095\n",
      "NME: 0.3346\n",
      "Epoch [216/300], Loss: 59.0724\n",
      "Validation Loss: 75.9350\n",
      "NME: 0.3340\n",
      "Epoch [217/300], Loss: 56.4349\n",
      "Validation Loss: 76.6897\n",
      "NME: 0.3347\n",
      "Epoch [218/300], Loss: 55.4523\n",
      "Validation Loss: 75.7066\n",
      "NME: 0.3283\n",
      "Epoch [219/300], Loss: 58.1647\n",
      "Validation Loss: 74.9032\n",
      "NME: 0.3283\n",
      "Epoch [220/300], Loss: 58.3778\n",
      "Validation Loss: 73.6230\n",
      "NME: 0.3248\n",
      "Best model saved at epoch 220 with val_loss 73.6230\n",
      "Epoch [221/300], Loss: 56.0475\n",
      "Validation Loss: 76.5081\n",
      "NME: 0.3304\n",
      "Epoch [222/300], Loss: 55.9710\n",
      "Validation Loss: 74.6073\n",
      "NME: 0.3306\n",
      "Epoch [223/300], Loss: 58.8011\n",
      "Validation Loss: 75.9109\n",
      "NME: 0.3360\n",
      "Epoch [224/300], Loss: 58.9678\n",
      "Validation Loss: 74.2078\n",
      "NME: 0.3267\n",
      "Epoch [225/300], Loss: 57.4625\n",
      "Validation Loss: 78.6176\n",
      "NME: 0.3410\n",
      "Epoch [226/300], Loss: 59.8018\n",
      "Validation Loss: 78.2758\n",
      "NME: 0.3303\n",
      "Epoch [227/300], Loss: 52.3861\n",
      "Validation Loss: 73.6434\n",
      "NME: 0.3284\n",
      "Epoch [228/300], Loss: 52.1153\n",
      "Validation Loss: 73.0758\n",
      "NME: 0.3255\n",
      "Best model saved at epoch 228 with val_loss 73.0758\n",
      "Epoch [229/300], Loss: 54.5297\n",
      "Validation Loss: 72.8578\n",
      "NME: 0.3230\n",
      "Best model saved at epoch 229 with val_loss 72.8578\n",
      "Epoch [230/300], Loss: 55.1067\n",
      "Validation Loss: 75.2695\n",
      "NME: 0.3367\n",
      "Epoch [231/300], Loss: 53.3000\n",
      "Validation Loss: 72.7924\n",
      "NME: 0.3192\n",
      "Best model saved at epoch 231 with val_loss 72.7924\n",
      "Epoch [232/300], Loss: 53.4323\n",
      "Validation Loss: 75.8430\n",
      "NME: 0.3285\n",
      "Epoch [233/300], Loss: 53.4352\n",
      "Validation Loss: 74.6148\n",
      "NME: 0.3229\n",
      "Epoch [234/300], Loss: 54.2214\n",
      "Validation Loss: 72.0452\n",
      "NME: 0.3191\n",
      "Best model saved at epoch 234 with val_loss 72.0452\n",
      "Epoch [235/300], Loss: 54.3428\n",
      "Validation Loss: 76.5681\n",
      "NME: 0.3303\n",
      "Epoch [236/300], Loss: 51.7770\n",
      "Validation Loss: 73.5499\n",
      "NME: 0.3260\n",
      "Epoch [237/300], Loss: 52.7333\n",
      "Validation Loss: 74.2706\n",
      "NME: 0.3212\n",
      "Epoch [238/300], Loss: 51.1114\n",
      "Validation Loss: 72.0911\n",
      "NME: 0.3237\n",
      "Epoch [239/300], Loss: 51.1638\n",
      "Validation Loss: 73.7803\n",
      "NME: 0.3240\n",
      "Epoch [240/300], Loss: 51.4961\n",
      "Validation Loss: 75.1884\n",
      "NME: 0.3402\n",
      "Epoch [241/300], Loss: 49.5797\n",
      "Validation Loss: 72.5718\n",
      "NME: 0.3298\n",
      "Epoch [242/300], Loss: 48.9182\n",
      "Validation Loss: 71.9858\n",
      "NME: 0.3162\n",
      "Best model saved at epoch 242 with val_loss 71.9858\n",
      "Epoch [243/300], Loss: 50.4547\n",
      "Validation Loss: 72.5267\n",
      "NME: 0.3240\n",
      "Epoch [244/300], Loss: 49.7183\n",
      "Validation Loss: 71.8483\n",
      "NME: 0.3178\n",
      "Best model saved at epoch 244 with val_loss 71.8483\n",
      "Epoch [245/300], Loss: 49.9417\n",
      "Validation Loss: 72.4515\n",
      "NME: 0.3171\n",
      "Epoch [246/300], Loss: 48.5693\n",
      "Validation Loss: 71.0041\n",
      "NME: 0.3129\n",
      "Best model saved at epoch 246 with val_loss 71.0041\n",
      "Epoch [247/300], Loss: 48.9231\n",
      "Validation Loss: 70.7555\n",
      "NME: 0.3097\n",
      "Best model saved at epoch 247 with val_loss 70.7555\n",
      "Epoch [248/300], Loss: 48.5737\n",
      "Validation Loss: 71.8647\n",
      "NME: 0.3130\n",
      "Epoch [249/300], Loss: 51.3784\n",
      "Validation Loss: 73.7524\n",
      "NME: 0.3213\n",
      "Epoch [250/300], Loss: 49.3071\n",
      "Validation Loss: 72.8949\n",
      "NME: 0.3154\n",
      "Epoch [251/300], Loss: 47.7447\n",
      "Validation Loss: 72.7300\n",
      "NME: 0.3211\n",
      "Epoch [252/300], Loss: 48.3307\n",
      "Validation Loss: 74.0015\n",
      "NME: 0.3215\n",
      "Epoch [253/300], Loss: 50.7162\n",
      "Validation Loss: 76.8390\n",
      "NME: 0.3314\n",
      "Epoch [254/300], Loss: 51.0773\n",
      "Validation Loss: 71.8921\n",
      "NME: 0.3132\n",
      "Epoch [255/300], Loss: 55.0729\n",
      "Validation Loss: 72.9864\n",
      "NME: 0.3160\n",
      "Epoch [256/300], Loss: 49.0269\n",
      "Validation Loss: 71.0509\n",
      "NME: 0.3119\n",
      "Epoch [257/300], Loss: 56.1407\n",
      "Validation Loss: 71.1271\n",
      "NME: 0.3184\n",
      "Epoch [258/300], Loss: 49.3285\n",
      "Validation Loss: 73.3050\n",
      "NME: 0.3161\n",
      "Epoch [259/300], Loss: 46.6788\n",
      "Validation Loss: 72.8777\n",
      "NME: 0.3175\n",
      "Epoch [260/300], Loss: 47.3144\n",
      "Validation Loss: 72.0559\n",
      "NME: 0.3149\n",
      "Epoch [261/300], Loss: 49.0039\n",
      "Validation Loss: 74.4629\n",
      "NME: 0.3277\n",
      "Epoch [262/300], Loss: 49.4519\n",
      "Validation Loss: 72.4225\n",
      "NME: 0.3189\n",
      "Epoch [263/300], Loss: 46.1921\n",
      "Validation Loss: 71.6863\n",
      "NME: 0.3165\n",
      "Epoch [264/300], Loss: 49.3207\n",
      "Validation Loss: 73.2002\n",
      "NME: 0.3171\n",
      "Epoch [265/300], Loss: 46.8928\n",
      "Validation Loss: 73.1836\n",
      "NME: 0.3196\n",
      "Epoch [266/300], Loss: 46.7280\n",
      "Validation Loss: 71.6517\n",
      "NME: 0.3125\n",
      "Epoch [267/300], Loss: 51.2022\n",
      "Validation Loss: 73.5708\n",
      "NME: 0.3213\n",
      "Epoch [268/300], Loss: 46.6260\n",
      "Validation Loss: 71.4593\n",
      "NME: 0.3162\n",
      "Epoch [269/300], Loss: 47.5715\n",
      "Validation Loss: 73.9491\n",
      "NME: 0.3203\n",
      "Epoch [270/300], Loss: 45.0111\n",
      "Validation Loss: 73.9275\n",
      "NME: 0.3224\n",
      "Epoch [271/300], Loss: 45.7996\n",
      "Validation Loss: 71.2815\n",
      "NME: 0.3144\n",
      "Epoch [272/300], Loss: 48.1680\n",
      "Validation Loss: 72.4618\n",
      "NME: 0.3125\n",
      "Epoch [273/300], Loss: 46.4939\n",
      "Validation Loss: 73.2114\n",
      "NME: 0.3189\n",
      "Epoch [274/300], Loss: 47.3069\n",
      "Validation Loss: 74.1062\n",
      "NME: 0.3118\n",
      "Epoch [275/300], Loss: 47.3248\n",
      "Validation Loss: 74.4910\n",
      "NME: 0.3170\n",
      "Epoch [276/300], Loss: 47.2663\n",
      "Validation Loss: 72.3473\n",
      "NME: 0.3144\n",
      "Epoch [277/300], Loss: 47.5049\n",
      "Validation Loss: 72.3587\n",
      "NME: 0.3196\n",
      "Epoch [278/300], Loss: 46.0264\n",
      "Validation Loss: 73.4300\n",
      "NME: 0.3140\n",
      "Epoch [279/300], Loss: 49.2100\n",
      "Validation Loss: 72.8409\n",
      "NME: 0.3174\n",
      "Epoch [280/300], Loss: 45.6944\n",
      "Validation Loss: 71.6627\n",
      "NME: 0.3095\n",
      "Epoch [281/300], Loss: 46.2225\n",
      "Validation Loss: 72.6678\n",
      "NME: 0.3166\n",
      "Epoch [282/300], Loss: 47.1301\n",
      "Validation Loss: 74.1781\n",
      "NME: 0.3223\n",
      "Epoch [283/300], Loss: 46.3021\n",
      "Validation Loss: 72.0613\n",
      "NME: 0.3111\n",
      "Epoch [284/300], Loss: 47.5356\n",
      "Validation Loss: 74.0785\n",
      "NME: 0.3156\n",
      "Epoch [285/300], Loss: 46.2774\n",
      "Validation Loss: 73.7111\n",
      "NME: 0.3138\n",
      "Epoch [286/300], Loss: 45.8954\n",
      "Validation Loss: 72.8417\n",
      "NME: 0.3089\n",
      "Epoch [287/300], Loss: 46.0245\n",
      "Validation Loss: 74.4169\n",
      "NME: 0.3192\n",
      "Epoch [288/300], Loss: 45.7703\n",
      "Validation Loss: 73.1275\n",
      "NME: 0.3196\n",
      "Epoch [289/300], Loss: 45.0025\n",
      "Validation Loss: 75.3201\n",
      "NME: 0.3307\n",
      "Epoch [290/300], Loss: 47.4570\n",
      "Validation Loss: 73.6201\n",
      "NME: 0.3157\n",
      "Epoch [291/300], Loss: 45.5714\n",
      "Validation Loss: 71.3229\n",
      "NME: 0.3115\n",
      "Epoch [292/300], Loss: 44.5851\n",
      "Validation Loss: 71.4397\n",
      "NME: 0.3125\n",
      "Epoch [293/300], Loss: 45.9005\n",
      "Validation Loss: 73.5581\n",
      "NME: 0.3205\n",
      "Epoch [294/300], Loss: 49.7399\n",
      "Validation Loss: 73.1965\n",
      "NME: 0.3123\n",
      "Epoch [295/300], Loss: 45.8072\n",
      "Validation Loss: 71.9635\n",
      "NME: 0.3156\n",
      "Epoch [296/300], Loss: 44.1217\n",
      "Validation Loss: 72.0029\n",
      "NME: 0.3100\n",
      "Epoch [297/300], Loss: 45.6033\n",
      "Validation Loss: 70.1010\n",
      "NME: 0.3081\n",
      "Best model saved at epoch 297 with val_loss 70.1010\n",
      "Epoch [298/300], Loss: 43.3544\n",
      "Validation Loss: 72.2181\n",
      "NME: 0.3113\n",
      "Epoch [299/300], Loss: 44.8413\n",
      "Validation Loss: 72.5401\n",
      "NME: 0.3115\n",
      "Epoch [300/300], Loss: 46.1808\n",
      "Validation Loss: 72.2865\n",
      "NME: 0.3164\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class EyeRightDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave del ojo derecho\n",
    "        eye_right_points = np.array([landmarks[i] for i in ojo_der], dtype=np.float32)\n",
    "        eye_right_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(eye_right_points), 1))\n",
    "        points_ones = np.hstack([eye_right_points, ones])\n",
    "        eye_right_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado del ojo derecho\n",
    "        centro_x, centro_y = calcular_centro_region(eye_right_points_rotated, range(len(ojo_der)))\n",
    "\n",
    "        # Definir los límites del recorte de 56x56 píxeles\n",
    "        half_crop_size = 28\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_eye = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_eye, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales del ojo derecho al nuevo recorte\n",
    "        eye_right_points_adjusted = [(p[0] - x1, p[1] - y1) for p in eye_right_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        eye_right_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in eye_right_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=eye_right_points_scaled)\n",
    "            image = augmented['image']\n",
    "            eye_right_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(eye_right_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = EyeRightDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = EyeRightDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121EyeRight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121EyeRight, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(ojo_der) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121EyeRight().cuda()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para ojo derecho)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, eye_right_points, _, _, _ in train_dataloader:\n",
    "            images, eye_right_points = images.cuda(), eye_right_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, eye_right_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_eye_right_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_eye_right_points = val_images.cuda(), val_eye_right_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_eye_right_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_eye_right_points.cpu().numpy().reshape(-1, len(ojo_der), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(ojo_der), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(ojo_der))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'EyeRightLandmarks V3.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 16677.3260\n",
      "Validation Loss: 16358.2951\n",
      "NME: 3.4990\n",
      "Best model saved at epoch 1 with val_loss 16358.2951\n",
      "Epoch [2/300], Loss: 15202.6198\n",
      "Validation Loss: 13638.2101\n",
      "NME: 3.1398\n",
      "Best model saved at epoch 2 with val_loss 13638.2101\n",
      "Epoch [3/300], Loss: 11017.5939\n",
      "Validation Loss: 8050.1736\n",
      "NME: 2.2835\n",
      "Best model saved at epoch 3 with val_loss 8050.1736\n",
      "Epoch [4/300], Loss: 5194.3109\n",
      "Validation Loss: 2993.6185\n",
      "NME: 1.1581\n",
      "Best model saved at epoch 4 with val_loss 2993.6185\n",
      "Epoch [5/300], Loss: 2073.6053\n",
      "Validation Loss: 1498.7568\n",
      "NME: 0.6843\n",
      "Best model saved at epoch 5 with val_loss 1498.7568\n",
      "Epoch [6/300], Loss: 1288.4567\n",
      "Validation Loss: 1072.7748\n",
      "NME: 0.5406\n",
      "Best model saved at epoch 6 with val_loss 1072.7748\n",
      "Epoch [7/300], Loss: 1025.6153\n",
      "Validation Loss: 926.0035\n",
      "NME: 0.5155\n",
      "Best model saved at epoch 7 with val_loss 926.0035\n",
      "Epoch [8/300], Loss: 950.1219\n",
      "Validation Loss: 876.0608\n",
      "NME: 0.5259\n",
      "Best model saved at epoch 8 with val_loss 876.0608\n",
      "Epoch [9/300], Loss: 921.8651\n",
      "Validation Loss: 859.4567\n",
      "NME: 0.5337\n",
      "Best model saved at epoch 9 with val_loss 859.4567\n",
      "Epoch [10/300], Loss: 912.3538\n",
      "Validation Loss: 854.7385\n",
      "NME: 0.5376\n",
      "Best model saved at epoch 10 with val_loss 854.7385\n",
      "Epoch [11/300], Loss: 912.7298\n",
      "Validation Loss: 850.8074\n",
      "NME: 0.5448\n",
      "Best model saved at epoch 11 with val_loss 850.8074\n",
      "Epoch [12/300], Loss: 907.2582\n",
      "Validation Loss: 844.7642\n",
      "NME: 0.5412\n",
      "Best model saved at epoch 12 with val_loss 844.7642\n",
      "Epoch [13/300], Loss: 907.3629\n",
      "Validation Loss: 840.4749\n",
      "NME: 0.5390\n",
      "Best model saved at epoch 13 with val_loss 840.4749\n",
      "Epoch [14/300], Loss: 893.1334\n",
      "Validation Loss: 837.3409\n",
      "NME: 0.5360\n",
      "Best model saved at epoch 14 with val_loss 837.3409\n",
      "Epoch [15/300], Loss: 894.2441\n",
      "Validation Loss: 831.4002\n",
      "NME: 0.5365\n",
      "Best model saved at epoch 15 with val_loss 831.4002\n",
      "Epoch [16/300], Loss: 884.0238\n",
      "Validation Loss: 822.0914\n",
      "NME: 0.5311\n",
      "Best model saved at epoch 16 with val_loss 822.0914\n",
      "Epoch [17/300], Loss: 871.8393\n",
      "Validation Loss: 802.9066\n",
      "NME: 0.5281\n",
      "Best model saved at epoch 17 with val_loss 802.9066\n",
      "Epoch [18/300], Loss: 852.4623\n",
      "Validation Loss: 780.9918\n",
      "NME: 0.5223\n",
      "Best model saved at epoch 18 with val_loss 780.9918\n",
      "Epoch [19/300], Loss: 830.2411\n",
      "Validation Loss: 743.6516\n",
      "NME: 0.5044\n",
      "Best model saved at epoch 19 with val_loss 743.6516\n",
      "Epoch [20/300], Loss: 793.9228\n",
      "Validation Loss: 696.9679\n",
      "NME: 0.4836\n",
      "Best model saved at epoch 20 with val_loss 696.9679\n",
      "Epoch [21/300], Loss: 748.1923\n",
      "Validation Loss: 644.6611\n",
      "NME: 0.4665\n",
      "Best model saved at epoch 21 with val_loss 644.6611\n",
      "Epoch [22/300], Loss: 698.1162\n",
      "Validation Loss: 594.7194\n",
      "NME: 0.4436\n",
      "Best model saved at epoch 22 with val_loss 594.7194\n",
      "Epoch [23/300], Loss: 644.9200\n",
      "Validation Loss: 538.7397\n",
      "NME: 0.4179\n",
      "Best model saved at epoch 23 with val_loss 538.7397\n",
      "Epoch [24/300], Loss: 600.0152\n",
      "Validation Loss: 474.0928\n",
      "NME: 0.3931\n",
      "Best model saved at epoch 24 with val_loss 474.0928\n",
      "Epoch [25/300], Loss: 540.6020\n",
      "Validation Loss: 415.2273\n",
      "NME: 0.3669\n",
      "Best model saved at epoch 25 with val_loss 415.2273\n",
      "Epoch [26/300], Loss: 497.9130\n",
      "Validation Loss: 371.9901\n",
      "NME: 0.3463\n",
      "Best model saved at epoch 26 with val_loss 371.9901\n",
      "Epoch [27/300], Loss: 463.4626\n",
      "Validation Loss: 332.9905\n",
      "NME: 0.3253\n",
      "Best model saved at epoch 27 with val_loss 332.9905\n",
      "Epoch [28/300], Loss: 435.7068\n",
      "Validation Loss: 305.1087\n",
      "NME: 0.3077\n",
      "Best model saved at epoch 28 with val_loss 305.1087\n",
      "Epoch [29/300], Loss: 407.1096\n",
      "Validation Loss: 276.4713\n",
      "NME: 0.2960\n",
      "Best model saved at epoch 29 with val_loss 276.4713\n",
      "Epoch [30/300], Loss: 383.8072\n",
      "Validation Loss: 264.0098\n",
      "NME: 0.2866\n",
      "Best model saved at epoch 30 with val_loss 264.0098\n",
      "Epoch [31/300], Loss: 364.7310\n",
      "Validation Loss: 249.4955\n",
      "NME: 0.2774\n",
      "Best model saved at epoch 31 with val_loss 249.4955\n",
      "Epoch [32/300], Loss: 351.4699\n",
      "Validation Loss: 227.4497\n",
      "NME: 0.2690\n",
      "Best model saved at epoch 32 with val_loss 227.4497\n",
      "Epoch [33/300], Loss: 336.0444\n",
      "Validation Loss: 213.8194\n",
      "NME: 0.2652\n",
      "Best model saved at epoch 33 with val_loss 213.8194\n",
      "Epoch [34/300], Loss: 336.4934\n",
      "Validation Loss: 213.5415\n",
      "NME: 0.2621\n",
      "Best model saved at epoch 34 with val_loss 213.5415\n",
      "Epoch [35/300], Loss: 320.4613\n",
      "Validation Loss: 198.0797\n",
      "NME: 0.2564\n",
      "Best model saved at epoch 35 with val_loss 198.0797\n",
      "Epoch [36/300], Loss: 320.2749\n",
      "Validation Loss: 194.1594\n",
      "NME: 0.2510\n",
      "Best model saved at epoch 36 with val_loss 194.1594\n",
      "Epoch [37/300], Loss: 328.6173\n",
      "Validation Loss: 190.9664\n",
      "NME: 0.2623\n",
      "Best model saved at epoch 37 with val_loss 190.9664\n",
      "Epoch [38/300], Loss: 310.0736\n",
      "Validation Loss: 187.8436\n",
      "NME: 0.2486\n",
      "Best model saved at epoch 38 with val_loss 187.8436\n",
      "Epoch [39/300], Loss: 304.5836\n",
      "Validation Loss: 197.2212\n",
      "NME: 0.2573\n",
      "Epoch [40/300], Loss: 313.6787\n",
      "Validation Loss: 189.8941\n",
      "NME: 0.2515\n",
      "Epoch [41/300], Loss: 308.9761\n",
      "Validation Loss: 193.9495\n",
      "NME: 0.2613\n",
      "Epoch [42/300], Loss: 302.0292\n",
      "Validation Loss: 189.2968\n",
      "NME: 0.2607\n",
      "Epoch [43/300], Loss: 295.2163\n",
      "Validation Loss: 194.9280\n",
      "NME: 0.2786\n",
      "Epoch [44/300], Loss: 293.5172\n",
      "Validation Loss: 191.8424\n",
      "NME: 0.2628\n",
      "Epoch [45/300], Loss: 284.3336\n",
      "Validation Loss: 189.0378\n",
      "NME: 0.2656\n",
      "Epoch [46/300], Loss: 292.0972\n",
      "Validation Loss: 195.7341\n",
      "NME: 0.2779\n",
      "Epoch [47/300], Loss: 289.0078\n",
      "Validation Loss: 192.6514\n",
      "NME: 0.2653\n",
      "Epoch [48/300], Loss: 269.2127\n",
      "Validation Loss: 198.2357\n",
      "NME: 0.2939\n",
      "Epoch [49/300], Loss: 275.0075\n",
      "Validation Loss: 174.3739\n",
      "NME: 0.2485\n",
      "Best model saved at epoch 49 with val_loss 174.3739\n",
      "Epoch [50/300], Loss: 279.9280\n",
      "Validation Loss: 177.9348\n",
      "NME: 0.2592\n",
      "Epoch [51/300], Loss: 268.8932\n",
      "Validation Loss: 188.3342\n",
      "NME: 0.2635\n",
      "Epoch [52/300], Loss: 284.5508\n",
      "Validation Loss: 170.3001\n",
      "NME: 0.2493\n",
      "Best model saved at epoch 52 with val_loss 170.3001\n",
      "Epoch [53/300], Loss: 264.7356\n",
      "Validation Loss: 182.2867\n",
      "NME: 0.2709\n",
      "Epoch [54/300], Loss: 259.6700\n",
      "Validation Loss: 186.1602\n",
      "NME: 0.2764\n",
      "Epoch [55/300], Loss: 280.5374\n",
      "Validation Loss: 182.2555\n",
      "NME: 0.2595\n",
      "Epoch [56/300], Loss: 259.9301\n",
      "Validation Loss: 190.3893\n",
      "NME: 0.2781\n",
      "Epoch [57/300], Loss: 262.4131\n",
      "Validation Loss: 182.1357\n",
      "NME: 0.2668\n",
      "Epoch [58/300], Loss: 277.4233\n",
      "Validation Loss: 205.9956\n",
      "NME: 0.2909\n",
      "Epoch [59/300], Loss: 260.8807\n",
      "Validation Loss: 184.4050\n",
      "NME: 0.2525\n",
      "Epoch [60/300], Loss: 279.1820\n",
      "Validation Loss: 202.3565\n",
      "NME: 0.2846\n",
      "Epoch [61/300], Loss: 257.9650\n",
      "Validation Loss: 178.7043\n",
      "NME: 0.2630\n",
      "Epoch [62/300], Loss: 253.2887\n",
      "Validation Loss: 182.9108\n",
      "NME: 0.2651\n",
      "Epoch [63/300], Loss: 255.8868\n",
      "Validation Loss: 191.1292\n",
      "NME: 0.2820\n",
      "Epoch [64/300], Loss: 262.2286\n",
      "Validation Loss: 191.7201\n",
      "NME: 0.2847\n",
      "Epoch [65/300], Loss: 250.6167\n",
      "Validation Loss: 210.2933\n",
      "NME: 0.2932\n",
      "Epoch [66/300], Loss: 261.0913\n",
      "Validation Loss: 204.9271\n",
      "NME: 0.3033\n",
      "Epoch [67/300], Loss: 250.5337\n",
      "Validation Loss: 184.7528\n",
      "NME: 0.2786\n",
      "Epoch [68/300], Loss: 254.7004\n",
      "Validation Loss: 172.1773\n",
      "NME: 0.2636\n",
      "Epoch [69/300], Loss: 253.4542\n",
      "Validation Loss: 190.1063\n",
      "NME: 0.2770\n",
      "Epoch [70/300], Loss: 260.0178\n",
      "Validation Loss: 170.2204\n",
      "NME: 0.2413\n",
      "Best model saved at epoch 70 with val_loss 170.2204\n",
      "Epoch [71/300], Loss: 265.2713\n",
      "Validation Loss: 174.8143\n",
      "NME: 0.2639\n",
      "Epoch [72/300], Loss: 252.2090\n",
      "Validation Loss: 178.8483\n",
      "NME: 0.2622\n",
      "Epoch [73/300], Loss: 246.9183\n",
      "Validation Loss: 172.1880\n",
      "NME: 0.2554\n",
      "Epoch [74/300], Loss: 249.9115\n",
      "Validation Loss: 174.2305\n",
      "NME: 0.2617\n",
      "Epoch [75/300], Loss: 249.9501\n",
      "Validation Loss: 191.6466\n",
      "NME: 0.2875\n",
      "Epoch [76/300], Loss: 251.5065\n",
      "Validation Loss: 166.2133\n",
      "NME: 0.2425\n",
      "Best model saved at epoch 76 with val_loss 166.2133\n",
      "Epoch [77/300], Loss: 244.9890\n",
      "Validation Loss: 166.5431\n",
      "NME: 0.2355\n",
      "Epoch [78/300], Loss: 236.4725\n",
      "Validation Loss: 164.4521\n",
      "NME: 0.2415\n",
      "Best model saved at epoch 78 with val_loss 164.4521\n",
      "Epoch [79/300], Loss: 243.8252\n",
      "Validation Loss: 170.7557\n",
      "NME: 0.2429\n",
      "Epoch [80/300], Loss: 252.4772\n",
      "Validation Loss: 181.8027\n",
      "NME: 0.2751\n",
      "Epoch [81/300], Loss: 248.3229\n",
      "Validation Loss: 176.2396\n",
      "NME: 0.2545\n",
      "Epoch [82/300], Loss: 235.1192\n",
      "Validation Loss: 161.3013\n",
      "NME: 0.2354\n",
      "Best model saved at epoch 82 with val_loss 161.3013\n",
      "Epoch [83/300], Loss: 235.8318\n",
      "Validation Loss: 158.5201\n",
      "NME: 0.2294\n",
      "Best model saved at epoch 83 with val_loss 158.5201\n",
      "Epoch [84/300], Loss: 241.3971\n",
      "Validation Loss: 176.7132\n",
      "NME: 0.2709\n",
      "Epoch [85/300], Loss: 242.9836\n",
      "Validation Loss: 159.0257\n",
      "NME: 0.2296\n",
      "Epoch [86/300], Loss: 238.6160\n",
      "Validation Loss: 167.4769\n",
      "NME: 0.2447\n",
      "Epoch [87/300], Loss: 242.6250\n",
      "Validation Loss: 157.9946\n",
      "NME: 0.2274\n",
      "Best model saved at epoch 87 with val_loss 157.9946\n",
      "Epoch [88/300], Loss: 238.0108\n",
      "Validation Loss: 167.5007\n",
      "NME: 0.2461\n",
      "Epoch [89/300], Loss: 247.7545\n",
      "Validation Loss: 158.0383\n",
      "NME: 0.2371\n",
      "Epoch [90/300], Loss: 228.0453\n",
      "Validation Loss: 179.2087\n",
      "NME: 0.2701\n",
      "Epoch [91/300], Loss: 247.0169\n",
      "Validation Loss: 166.6686\n",
      "NME: 0.2381\n",
      "Epoch [92/300], Loss: 238.9910\n",
      "Validation Loss: 158.7909\n",
      "NME: 0.2417\n",
      "Epoch [93/300], Loss: 251.4070\n",
      "Validation Loss: 156.1408\n",
      "NME: 0.2312\n",
      "Best model saved at epoch 93 with val_loss 156.1408\n",
      "Epoch [94/300], Loss: 235.7039\n",
      "Validation Loss: 169.2415\n",
      "NME: 0.2470\n",
      "Epoch [95/300], Loss: 233.7716\n",
      "Validation Loss: 170.4899\n",
      "NME: 0.2648\n",
      "Epoch [96/300], Loss: 231.3459\n",
      "Validation Loss: 166.7305\n",
      "NME: 0.2442\n",
      "Epoch [97/300], Loss: 232.4185\n",
      "Validation Loss: 156.3043\n",
      "NME: 0.2188\n",
      "Epoch [98/300], Loss: 234.7973\n",
      "Validation Loss: 164.5073\n",
      "NME: 0.2393\n",
      "Epoch [99/300], Loss: 234.8318\n",
      "Validation Loss: 166.1339\n",
      "NME: 0.2497\n",
      "Epoch [100/300], Loss: 236.6682\n",
      "Validation Loss: 153.2833\n",
      "NME: 0.2283\n",
      "Best model saved at epoch 100 with val_loss 153.2833\n",
      "Epoch [101/300], Loss: 228.0264\n",
      "Validation Loss: 157.7657\n",
      "NME: 0.2249\n",
      "Epoch [102/300], Loss: 245.2217\n",
      "Validation Loss: 161.7424\n",
      "NME: 0.2377\n",
      "Epoch [103/300], Loss: 228.4111\n",
      "Validation Loss: 150.3520\n",
      "NME: 0.2111\n",
      "Best model saved at epoch 103 with val_loss 150.3520\n",
      "Epoch [104/300], Loss: 219.6817\n",
      "Validation Loss: 153.2874\n",
      "NME: 0.2242\n",
      "Epoch [105/300], Loss: 224.9542\n",
      "Validation Loss: 166.7615\n",
      "NME: 0.2442\n",
      "Epoch [106/300], Loss: 226.7913\n",
      "Validation Loss: 175.1273\n",
      "NME: 0.2751\n",
      "Epoch [107/300], Loss: 232.2689\n",
      "Validation Loss: 143.9450\n",
      "NME: 0.2117\n",
      "Best model saved at epoch 107 with val_loss 143.9450\n",
      "Epoch [108/300], Loss: 224.2675\n",
      "Validation Loss: 148.2680\n",
      "NME: 0.2164\n",
      "Epoch [109/300], Loss: 233.7942\n",
      "Validation Loss: 158.0203\n",
      "NME: 0.2330\n",
      "Epoch [110/300], Loss: 230.4528\n",
      "Validation Loss: 162.9357\n",
      "NME: 0.2205\n",
      "Epoch [111/300], Loss: 226.5221\n",
      "Validation Loss: 155.1646\n",
      "NME: 0.2109\n",
      "Epoch [112/300], Loss: 219.5728\n",
      "Validation Loss: 157.9448\n",
      "NME: 0.2298\n",
      "Epoch [113/300], Loss: 224.6386\n",
      "Validation Loss: 143.8557\n",
      "NME: 0.1987\n",
      "Best model saved at epoch 113 with val_loss 143.8557\n",
      "Epoch [114/300], Loss: 226.7794\n",
      "Validation Loss: 152.3597\n",
      "NME: 0.2185\n",
      "Epoch [115/300], Loss: 220.4009\n",
      "Validation Loss: 148.0752\n",
      "NME: 0.2048\n",
      "Epoch [116/300], Loss: 239.1025\n",
      "Validation Loss: 152.3432\n",
      "NME: 0.2198\n",
      "Epoch [117/300], Loss: 222.1164\n",
      "Validation Loss: 143.6685\n",
      "NME: 0.1999\n",
      "Best model saved at epoch 117 with val_loss 143.6685\n",
      "Epoch [118/300], Loss: 212.4768\n",
      "Validation Loss: 142.6673\n",
      "NME: 0.2075\n",
      "Best model saved at epoch 118 with val_loss 142.6673\n",
      "Epoch [119/300], Loss: 214.4460\n",
      "Validation Loss: 142.8491\n",
      "NME: 0.1945\n",
      "Epoch [120/300], Loss: 229.5753\n",
      "Validation Loss: 154.7992\n",
      "NME: 0.2156\n",
      "Epoch [121/300], Loss: 218.9761\n",
      "Validation Loss: 150.9591\n",
      "NME: 0.2183\n",
      "Epoch [122/300], Loss: 230.8362\n",
      "Validation Loss: 149.7234\n",
      "NME: 0.2147\n",
      "Epoch [123/300], Loss: 230.1815\n",
      "Validation Loss: 158.9298\n",
      "NME: 0.2339\n",
      "Epoch [124/300], Loss: 219.8975\n",
      "Validation Loss: 144.1502\n",
      "NME: 0.2036\n",
      "Epoch [125/300], Loss: 222.4539\n",
      "Validation Loss: 156.1095\n",
      "NME: 0.2245\n",
      "Epoch [126/300], Loss: 218.5533\n",
      "Validation Loss: 150.9774\n",
      "NME: 0.2256\n",
      "Epoch [127/300], Loss: 220.3781\n",
      "Validation Loss: 143.7844\n",
      "NME: 0.1953\n",
      "Epoch [128/300], Loss: 224.4114\n",
      "Validation Loss: 155.5792\n",
      "NME: 0.2206\n",
      "Epoch [129/300], Loss: 226.1755\n",
      "Validation Loss: 145.6347\n",
      "NME: 0.2153\n",
      "Epoch [130/300], Loss: 200.6789\n",
      "Validation Loss: 153.7560\n",
      "NME: 0.2227\n",
      "Epoch [131/300], Loss: 222.4212\n",
      "Validation Loss: 131.9537\n",
      "NME: 0.1855\n",
      "Best model saved at epoch 131 with val_loss 131.9537\n",
      "Epoch [132/300], Loss: 222.6225\n",
      "Validation Loss: 135.4297\n",
      "NME: 0.1913\n",
      "Epoch [133/300], Loss: 212.6860\n",
      "Validation Loss: 138.0857\n",
      "NME: 0.1953\n",
      "Epoch [134/300], Loss: 215.2923\n",
      "Validation Loss: 157.3430\n",
      "NME: 0.2336\n",
      "Epoch [135/300], Loss: 224.1146\n",
      "Validation Loss: 169.1362\n",
      "NME: 0.2519\n",
      "Epoch [136/300], Loss: 218.4755\n",
      "Validation Loss: 150.0952\n",
      "NME: 0.2151\n",
      "Epoch [137/300], Loss: 231.9327\n",
      "Validation Loss: 135.6620\n",
      "NME: 0.1859\n",
      "Epoch [138/300], Loss: 203.9040\n",
      "Validation Loss: 142.7705\n",
      "NME: 0.1960\n",
      "Epoch [139/300], Loss: 204.5733\n",
      "Validation Loss: 139.8070\n",
      "NME: 0.1880\n",
      "Epoch [140/300], Loss: 220.5847\n",
      "Validation Loss: 144.9709\n",
      "NME: 0.2094\n",
      "Epoch [141/300], Loss: 201.0126\n",
      "Validation Loss: 143.7039\n",
      "NME: 0.2033\n",
      "Epoch [142/300], Loss: 218.7818\n",
      "Validation Loss: 141.1391\n",
      "NME: 0.2086\n",
      "Epoch [143/300], Loss: 193.7250\n",
      "Validation Loss: 150.4231\n",
      "NME: 0.2068\n",
      "Epoch [144/300], Loss: 213.4305\n",
      "Validation Loss: 138.7358\n",
      "NME: 0.1922\n",
      "Epoch [145/300], Loss: 225.7990\n",
      "Validation Loss: 139.5736\n",
      "NME: 0.2008\n",
      "Epoch [146/300], Loss: 222.8122\n",
      "Validation Loss: 139.7157\n",
      "NME: 0.1888\n",
      "Epoch [147/300], Loss: 214.5497\n",
      "Validation Loss: 151.4608\n",
      "NME: 0.2100\n",
      "Epoch [148/300], Loss: 204.7445\n",
      "Validation Loss: 153.9723\n",
      "NME: 0.2245\n",
      "Epoch [149/300], Loss: 212.7433\n",
      "Validation Loss: 136.5292\n",
      "NME: 0.1844\n",
      "Epoch [150/300], Loss: 219.0862\n",
      "Validation Loss: 136.0604\n",
      "NME: 0.1910\n",
      "Epoch [151/300], Loss: 206.9236\n",
      "Validation Loss: 139.0863\n",
      "NME: 0.2055\n",
      "Epoch [152/300], Loss: 205.4453\n",
      "Validation Loss: 154.2654\n",
      "NME: 0.2169\n",
      "Epoch [153/300], Loss: 216.8108\n",
      "Validation Loss: 150.6257\n",
      "NME: 0.2182\n",
      "Epoch [154/300], Loss: 195.2664\n",
      "Validation Loss: 142.6523\n",
      "NME: 0.2046\n",
      "Epoch [155/300], Loss: 205.6404\n",
      "Validation Loss: 138.1948\n",
      "NME: 0.1979\n",
      "Epoch [156/300], Loss: 203.9518\n",
      "Validation Loss: 138.4983\n",
      "NME: 0.1892\n",
      "Epoch [157/300], Loss: 207.0657\n",
      "Validation Loss: 142.1745\n",
      "NME: 0.1939\n",
      "Epoch [158/300], Loss: 206.0466\n",
      "Validation Loss: 144.5338\n",
      "NME: 0.1951\n",
      "Epoch [159/300], Loss: 199.4019\n",
      "Validation Loss: 140.7862\n",
      "NME: 0.1926\n",
      "Epoch [160/300], Loss: 200.6185\n",
      "Validation Loss: 142.0211\n",
      "NME: 0.1864\n",
      "Epoch [161/300], Loss: 197.6021\n",
      "Validation Loss: 149.4308\n",
      "NME: 0.2155\n",
      "Epoch [162/300], Loss: 208.8325\n",
      "Validation Loss: 140.8527\n",
      "NME: 0.1922\n",
      "Epoch [163/300], Loss: 210.7976\n",
      "Validation Loss: 139.3585\n",
      "NME: 0.1929\n",
      "Epoch [164/300], Loss: 194.7050\n",
      "Validation Loss: 154.0572\n",
      "NME: 0.2200\n",
      "Epoch [165/300], Loss: 191.8607\n",
      "Validation Loss: 159.2724\n",
      "NME: 0.2177\n",
      "Epoch [166/300], Loss: 193.4417\n",
      "Validation Loss: 143.3315\n",
      "NME: 0.1901\n",
      "Epoch [167/300], Loss: 200.1286\n",
      "Validation Loss: 160.1218\n",
      "NME: 0.2245\n",
      "Epoch [168/300], Loss: 190.7706\n",
      "Validation Loss: 165.9459\n",
      "NME: 0.2415\n",
      "Epoch [169/300], Loss: 190.1392\n",
      "Validation Loss: 142.5258\n",
      "NME: 0.1938\n",
      "Epoch [170/300], Loss: 182.7297\n",
      "Validation Loss: 148.4387\n",
      "NME: 0.2076\n",
      "Epoch [171/300], Loss: 179.8835\n",
      "Validation Loss: 141.8553\n",
      "NME: 0.1936\n",
      "Epoch [172/300], Loss: 195.2586\n",
      "Validation Loss: 143.3557\n",
      "NME: 0.1944\n",
      "Epoch [173/300], Loss: 188.0399\n",
      "Validation Loss: 148.5962\n",
      "NME: 0.1977\n",
      "Epoch [174/300], Loss: 178.6230\n",
      "Validation Loss: 149.4269\n",
      "NME: 0.1915\n",
      "Epoch [175/300], Loss: 174.6895\n",
      "Validation Loss: 141.2776\n",
      "NME: 0.1913\n",
      "Epoch [176/300], Loss: 172.9139\n",
      "Validation Loss: 148.9734\n",
      "NME: 0.2062\n",
      "Epoch [177/300], Loss: 170.7449\n",
      "Validation Loss: 141.6084\n",
      "NME: 0.1958\n",
      "Epoch [178/300], Loss: 171.2421\n",
      "Validation Loss: 141.6433\n",
      "NME: 0.1937\n",
      "Epoch [179/300], Loss: 158.9732\n",
      "Validation Loss: 147.6927\n",
      "NME: 0.2017\n",
      "Epoch [180/300], Loss: 161.4761\n",
      "Validation Loss: 163.0564\n",
      "NME: 0.2367\n",
      "Epoch [181/300], Loss: 165.3386\n",
      "Validation Loss: 144.5590\n",
      "NME: 0.1973\n",
      "Epoch [182/300], Loss: 154.8285\n",
      "Validation Loss: 148.9239\n",
      "NME: 0.2000\n",
      "Epoch [183/300], Loss: 158.4936\n",
      "Validation Loss: 153.8476\n",
      "NME: 0.2091\n",
      "Epoch [184/300], Loss: 156.9003\n",
      "Validation Loss: 146.3823\n",
      "NME: 0.1967\n",
      "Epoch [185/300], Loss: 152.4770\n",
      "Validation Loss: 150.4099\n",
      "NME: 0.2015\n",
      "Epoch [186/300], Loss: 146.0701\n",
      "Validation Loss: 143.3146\n",
      "NME: 0.1980\n",
      "Epoch [187/300], Loss: 144.2643\n",
      "Validation Loss: 138.8845\n",
      "NME: 0.1888\n",
      "Epoch [188/300], Loss: 150.1837\n",
      "Validation Loss: 145.1576\n",
      "NME: 0.1932\n",
      "Epoch [189/300], Loss: 146.1077\n",
      "Validation Loss: 157.1109\n",
      "NME: 0.2180\n",
      "Epoch [190/300], Loss: 144.0747\n",
      "Validation Loss: 146.5328\n",
      "NME: 0.2008\n",
      "Epoch [191/300], Loss: 139.9093\n",
      "Validation Loss: 146.7291\n",
      "NME: 0.1992\n",
      "Epoch [192/300], Loss: 135.5273\n",
      "Validation Loss: 143.1924\n",
      "NME: 0.2017\n",
      "Epoch [193/300], Loss: 134.6130\n",
      "Validation Loss: 147.7839\n",
      "NME: 0.2001\n",
      "Epoch [194/300], Loss: 140.4475\n",
      "Validation Loss: 141.7873\n",
      "NME: 0.1939\n",
      "Epoch [195/300], Loss: 138.3105\n",
      "Validation Loss: 142.4782\n",
      "NME: 0.1968\n",
      "Epoch [196/300], Loss: 136.5765\n",
      "Validation Loss: 140.0213\n",
      "NME: 0.1912\n",
      "Epoch [197/300], Loss: 136.9832\n",
      "Validation Loss: 143.4693\n",
      "NME: 0.1959\n",
      "Epoch [198/300], Loss: 131.7994\n",
      "Validation Loss: 153.0749\n",
      "NME: 0.2009\n",
      "Epoch [199/300], Loss: 135.1320\n",
      "Validation Loss: 137.7095\n",
      "NME: 0.1882\n",
      "Epoch [200/300], Loss: 132.0459\n",
      "Validation Loss: 142.4159\n",
      "NME: 0.1969\n",
      "Epoch [201/300], Loss: 126.0709\n",
      "Validation Loss: 140.5455\n",
      "NME: 0.1913\n",
      "Epoch [202/300], Loss: 130.1845\n",
      "Validation Loss: 144.6652\n",
      "NME: 0.2052\n",
      "Epoch [203/300], Loss: 132.5732\n",
      "Validation Loss: 146.0799\n",
      "NME: 0.2016\n",
      "Epoch [204/300], Loss: 128.0264\n",
      "Validation Loss: 150.0692\n",
      "NME: 0.1979\n",
      "Epoch [205/300], Loss: 123.1176\n",
      "Validation Loss: 148.5550\n",
      "NME: 0.2032\n",
      "Epoch [206/300], Loss: 126.5329\n",
      "Validation Loss: 144.9903\n",
      "NME: 0.1948\n",
      "Epoch [207/300], Loss: 123.2926\n",
      "Validation Loss: 146.5099\n",
      "NME: 0.2020\n",
      "Epoch [208/300], Loss: 122.8486\n",
      "Validation Loss: 146.0815\n",
      "NME: 0.2008\n",
      "Epoch [209/300], Loss: 123.1073\n",
      "Validation Loss: 140.8529\n",
      "NME: 0.1895\n",
      "Epoch [210/300], Loss: 119.8099\n",
      "Validation Loss: 149.8309\n",
      "NME: 0.2110\n",
      "Epoch [211/300], Loss: 127.2627\n",
      "Validation Loss: 139.9385\n",
      "NME: 0.1872\n",
      "Epoch [212/300], Loss: 119.6153\n",
      "Validation Loss: 142.0947\n",
      "NME: 0.1918\n",
      "Epoch [213/300], Loss: 126.7090\n",
      "Validation Loss: 143.0982\n",
      "NME: 0.1987\n",
      "Epoch [214/300], Loss: 121.4619\n",
      "Validation Loss: 137.6593\n",
      "NME: 0.1855\n",
      "Epoch [215/300], Loss: 126.8262\n",
      "Validation Loss: 141.4907\n",
      "NME: 0.1966\n",
      "Epoch [216/300], Loss: 119.4466\n",
      "Validation Loss: 139.4498\n",
      "NME: 0.1899\n",
      "Epoch [217/300], Loss: 120.1342\n",
      "Validation Loss: 143.3302\n",
      "NME: 0.1968\n",
      "Epoch [218/300], Loss: 126.6547\n",
      "Validation Loss: 145.7188\n",
      "NME: 0.1996\n",
      "Epoch [219/300], Loss: 126.3556\n",
      "Validation Loss: 140.8402\n",
      "NME: 0.1929\n",
      "Epoch [220/300], Loss: 122.1423\n",
      "Validation Loss: 143.5409\n",
      "NME: 0.1978\n",
      "Epoch [221/300], Loss: 119.1735\n",
      "Validation Loss: 138.9662\n",
      "NME: 0.1913\n",
      "Epoch [222/300], Loss: 119.0239\n",
      "Validation Loss: 140.0802\n",
      "NME: 0.1928\n",
      "Epoch [223/300], Loss: 117.7041\n",
      "Validation Loss: 141.1549\n",
      "NME: 0.1929\n",
      "Epoch [224/300], Loss: 122.2912\n",
      "Validation Loss: 138.8012\n",
      "NME: 0.1892\n",
      "Epoch [225/300], Loss: 121.9618\n",
      "Validation Loss: 141.1575\n",
      "NME: 0.1961\n",
      "Epoch [226/300], Loss: 118.2606\n",
      "Validation Loss: 147.4014\n",
      "NME: 0.2043\n",
      "Epoch [227/300], Loss: 117.2554\n",
      "Validation Loss: 138.8869\n",
      "NME: 0.1905\n",
      "Epoch [228/300], Loss: 119.2331\n",
      "Validation Loss: 138.0804\n",
      "NME: 0.1885\n",
      "Epoch [229/300], Loss: 123.3239\n",
      "Validation Loss: 140.0511\n",
      "NME: 0.1939\n",
      "Epoch [230/300], Loss: 121.0264\n",
      "Validation Loss: 147.8734\n",
      "NME: 0.2095\n",
      "Epoch [231/300], Loss: 119.1400\n",
      "Validation Loss: 138.8119\n",
      "NME: 0.1898\n",
      "Epoch [232/300], Loss: 118.8160\n",
      "Validation Loss: 140.4152\n",
      "NME: 0.1947\n",
      "Epoch [233/300], Loss: 117.3130\n",
      "Validation Loss: 141.7655\n",
      "NME: 0.1934\n",
      "Epoch [234/300], Loss: 123.3471\n",
      "Validation Loss: 140.3705\n",
      "NME: 0.1923\n",
      "Epoch [235/300], Loss: 118.1310\n",
      "Validation Loss: 142.6953\n",
      "NME: 0.1933\n",
      "Epoch [236/300], Loss: 116.9542\n",
      "Validation Loss: 137.9954\n",
      "NME: 0.1889\n",
      "Epoch [237/300], Loss: 116.8173\n",
      "Validation Loss: 137.2423\n",
      "NME: 0.1872\n",
      "Epoch [238/300], Loss: 116.8432\n",
      "Validation Loss: 144.5917\n",
      "NME: 0.1991\n",
      "Epoch [239/300], Loss: 117.2802\n",
      "Validation Loss: 138.8606\n",
      "NME: 0.1886\n",
      "Epoch [240/300], Loss: 116.9159\n",
      "Validation Loss: 138.4813\n",
      "NME: 0.1887\n",
      "Epoch [241/300], Loss: 117.4496\n",
      "Validation Loss: 146.2756\n",
      "NME: 0.2034\n",
      "Epoch [242/300], Loss: 121.1274\n",
      "Validation Loss: 147.3269\n",
      "NME: 0.2100\n",
      "Epoch [243/300], Loss: 118.9414\n",
      "Validation Loss: 137.1316\n",
      "NME: 0.1841\n",
      "Epoch [244/300], Loss: 119.9152\n",
      "Validation Loss: 137.5464\n",
      "NME: 0.1897\n",
      "Epoch [245/300], Loss: 120.2982\n",
      "Validation Loss: 138.5885\n",
      "NME: 0.1903\n",
      "Epoch [246/300], Loss: 120.2248\n",
      "Validation Loss: 136.1427\n",
      "NME: 0.1848\n",
      "Epoch [247/300], Loss: 117.9905\n",
      "Validation Loss: 139.8932\n",
      "NME: 0.1900\n",
      "Epoch [248/300], Loss: 116.7981\n",
      "Validation Loss: 140.9200\n",
      "NME: 0.1962\n",
      "Epoch [249/300], Loss: 117.5930\n",
      "Validation Loss: 139.3449\n",
      "NME: 0.1920\n",
      "Epoch [250/300], Loss: 116.0097\n",
      "Validation Loss: 153.9378\n",
      "NME: 0.2160\n",
      "Epoch [251/300], Loss: 117.7904\n",
      "Validation Loss: 139.4784\n",
      "NME: 0.1918\n",
      "Epoch [252/300], Loss: 116.1900\n",
      "Validation Loss: 136.9514\n",
      "NME: 0.1842\n",
      "Epoch [253/300], Loss: 122.9627\n",
      "Validation Loss: 145.1531\n",
      "NME: 0.2017\n",
      "Epoch [254/300], Loss: 119.9878\n",
      "Validation Loss: 137.0720\n",
      "NME: 0.1873\n",
      "Epoch [255/300], Loss: 116.0142\n",
      "Validation Loss: 136.7986\n",
      "NME: 0.1884\n",
      "Epoch [256/300], Loss: 116.7215\n",
      "Validation Loss: 135.6443\n",
      "NME: 0.1872\n",
      "Epoch [257/300], Loss: 121.5670\n",
      "Validation Loss: 138.0768\n",
      "NME: 0.1882\n",
      "Epoch [258/300], Loss: 116.6356\n",
      "Validation Loss: 140.9973\n",
      "NME: 0.1927\n",
      "Epoch [259/300], Loss: 116.1077\n",
      "Validation Loss: 137.5369\n",
      "NME: 0.1896\n",
      "Epoch [260/300], Loss: 116.9723\n",
      "Validation Loss: 140.8867\n",
      "NME: 0.1969\n",
      "Epoch [261/300], Loss: 115.6182\n",
      "Validation Loss: 141.4663\n",
      "NME: 0.1981\n",
      "Epoch [262/300], Loss: 118.8191\n",
      "Validation Loss: 136.9074\n",
      "NME: 0.1852\n",
      "Epoch [263/300], Loss: 116.3132\n",
      "Validation Loss: 136.4956\n",
      "NME: 0.1865\n",
      "Epoch [264/300], Loss: 120.9207\n",
      "Validation Loss: 139.7850\n",
      "NME: 0.1926\n",
      "Epoch [265/300], Loss: 116.6277\n",
      "Validation Loss: 145.0979\n",
      "NME: 0.2038\n",
      "Epoch [266/300], Loss: 116.5347\n",
      "Validation Loss: 138.0951\n",
      "NME: 0.1871\n",
      "Epoch [267/300], Loss: 114.9145\n",
      "Validation Loss: 136.7640\n",
      "NME: 0.1901\n",
      "Epoch [268/300], Loss: 116.0452\n",
      "Validation Loss: 136.9992\n",
      "NME: 0.1865\n",
      "Epoch [269/300], Loss: 118.5737\n",
      "Validation Loss: 138.7936\n",
      "NME: 0.1901\n",
      "Epoch [270/300], Loss: 117.2090\n",
      "Validation Loss: 134.8021\n",
      "NME: 0.1825\n",
      "Epoch [271/300], Loss: 116.3062\n",
      "Validation Loss: 134.2290\n",
      "NME: 0.1828\n",
      "Epoch [272/300], Loss: 120.3386\n",
      "Validation Loss: 137.5345\n",
      "NME: 0.1897\n",
      "Epoch [273/300], Loss: 118.1396\n",
      "Validation Loss: 138.6881\n",
      "NME: 0.1923\n",
      "Epoch [274/300], Loss: 118.1071\n",
      "Validation Loss: 134.9584\n",
      "NME: 0.1858\n",
      "Epoch [275/300], Loss: 114.8720\n",
      "Validation Loss: 143.0892\n",
      "NME: 0.1987\n",
      "Epoch [276/300], Loss: 115.8997\n",
      "Validation Loss: 140.3666\n",
      "NME: 0.1948\n",
      "Epoch [277/300], Loss: 115.0005\n",
      "Validation Loss: 141.8024\n",
      "NME: 0.1967\n",
      "Epoch [278/300], Loss: 115.4888\n",
      "Validation Loss: 144.2682\n",
      "NME: 0.2022\n",
      "Epoch [279/300], Loss: 112.3999\n",
      "Validation Loss: 135.6455\n",
      "NME: 0.1873\n",
      "Epoch [280/300], Loss: 120.1534\n",
      "Validation Loss: 141.4185\n",
      "NME: 0.1975\n",
      "Epoch [281/300], Loss: 117.0114\n",
      "Validation Loss: 136.0033\n",
      "NME: 0.1855\n",
      "Epoch [282/300], Loss: 114.6854\n",
      "Validation Loss: 135.0977\n",
      "NME: 0.1856\n",
      "Epoch [283/300], Loss: 112.7097\n",
      "Validation Loss: 135.2853\n",
      "NME: 0.1863\n",
      "Epoch [284/300], Loss: 115.7228\n",
      "Validation Loss: 135.0110\n",
      "NME: 0.1872\n",
      "Epoch [285/300], Loss: 113.6122\n",
      "Validation Loss: 136.1269\n",
      "NME: 0.1870\n",
      "Epoch [286/300], Loss: 115.8950\n",
      "Validation Loss: 133.5766\n",
      "NME: 0.1841\n",
      "Epoch [287/300], Loss: 115.8185\n",
      "Validation Loss: 138.5033\n",
      "NME: 0.1910\n",
      "Epoch [288/300], Loss: 114.6482\n",
      "Validation Loss: 137.9523\n",
      "NME: 0.1921\n",
      "Epoch [289/300], Loss: 113.8702\n",
      "Validation Loss: 144.1579\n",
      "NME: 0.2040\n",
      "Epoch [290/300], Loss: 113.4200\n",
      "Validation Loss: 139.6238\n",
      "NME: 0.1939\n",
      "Epoch [291/300], Loss: 112.1436\n",
      "Validation Loss: 141.3281\n",
      "NME: 0.2027\n",
      "Epoch [292/300], Loss: 115.3551\n",
      "Validation Loss: 137.7337\n",
      "NME: 0.1909\n",
      "Epoch [293/300], Loss: 114.7834\n",
      "Validation Loss: 142.5202\n",
      "NME: 0.1966\n",
      "Epoch [294/300], Loss: 116.1028\n",
      "Validation Loss: 135.6042\n",
      "NME: 0.1868\n",
      "Epoch [295/300], Loss: 115.7615\n",
      "Validation Loss: 140.0136\n",
      "NME: 0.1943\n",
      "Epoch [296/300], Loss: 114.3432\n",
      "Validation Loss: 135.2758\n",
      "NME: 0.1843\n",
      "Epoch [297/300], Loss: 117.1295\n",
      "Validation Loss: 137.1959\n",
      "NME: 0.1896\n",
      "Epoch [298/300], Loss: 112.9274\n",
      "Validation Loss: 139.5631\n",
      "NME: 0.1978\n",
      "Epoch [299/300], Loss: 112.9097\n",
      "Validation Loss: 135.5063\n",
      "NME: 0.1857\n",
      "Epoch [300/300], Loss: 113.4636\n",
      "Validation Loss: 135.4098\n",
      "NME: 0.1851\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# Rutas\n",
    "train_img_dir = r'C:\\CatFLW dataset\\train\\images'\n",
    "train_labels_dir = r'C:\\CatFLW dataset\\train\\labels'\n",
    "val_img_dir = r'C:\\CatFLW dataset\\val\\images'\n",
    "val_labels_dir = r'C:\\CatFLW dataset\\val\\labels'\n",
    "\n",
    "# Definir los índices de las regiones según los puntos proporcionados\n",
    "ojo_der = [3, 4, 5, 6, 7, 36, 37, 38]\n",
    "ojo_izq = [1, 8, 9, 10, 11, 39, 40, 41]\n",
    "nariz = [0, 2, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 32, 33, 34, 35, 42, 43, 44, 45, 46, 47]\n",
    "\n",
    "# Función para calcular el punto promedio de una región\n",
    "def calcular_centro_region(landmarks, indices):\n",
    "    puntos = [landmarks[i] for i in indices]\n",
    "    centro = np.mean(puntos, axis=0)\n",
    "    return centro\n",
    "\n",
    "# Dataset personalizado\n",
    "class NoseDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas y puntos de referencia\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            landmarks = np.array(labels['labels'])  # Convertir a array de NumPy\n",
    "            bounding_box = labels['bounding_boxes']\n",
    "        \n",
    "        # Recortar la imagen usando el bounding box\n",
    "        x_min, y_min, x_max, y_max = map(int, bounding_box)\n",
    "        image_cropped = image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Calcular dimensiones originales\n",
    "        original_height, original_width = image_cropped.shape[:2]\n",
    "        \n",
    "        # Calcular centros de los ojos y la nariz\n",
    "        centro_ojo_der = calcular_centro_region(landmarks, ojo_der)\n",
    "        centro_ojo_izq = calcular_centro_region(landmarks, ojo_izq)\n",
    "        centro_nariz = calcular_centro_region(landmarks, nariz)\n",
    "        \n",
    "        # Ajustar coordenadas de los centros al recorte\n",
    "        centro_ojo_der -= np.array([x_min, y_min])\n",
    "        centro_ojo_izq -= np.array([x_min, y_min])\n",
    "        centro_nariz -= np.array([x_min, y_min])\n",
    "        \n",
    "        # Calcular el ángulo de rotación\n",
    "        dx = centro_ojo_izq[0] - centro_ojo_der[0]\n",
    "        dy = centro_ojo_izq[1] - centro_ojo_der[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        \n",
    "        # Crear matriz de rotación\n",
    "        eye_center = ((centro_ojo_der[0] + centro_ojo_izq[0]) // 2,\n",
    "                      (centro_ojo_der[1] + centro_ojo_izq[1]) // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(eye_center, angle, 1.0)\n",
    "        \n",
    "        # Rotar la imagen\n",
    "        image_aligned = cv2.warpAffine(\n",
    "            image_cropped, rotation_matrix, (original_width, original_height), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convertir los puntos clave de la nariz\n",
    "        nose_points = np.array([landmarks[i] for i in nariz], dtype=np.float32)\n",
    "        nose_points -= [x_min, y_min]\n",
    "\n",
    "        # Transformar los puntos clave con la misma rotación\n",
    "        ones = np.ones(shape=(len(nose_points), 1))\n",
    "        points_ones = np.hstack([nose_points, ones])\n",
    "        nose_points_rotated = rotation_matrix.dot(points_ones.T).T\n",
    "        \n",
    "        # **Nuevo**: Recorte alrededor del punto centrado de la nariz\n",
    "        centro_x, centro_y = calcular_centro_region(nose_points_rotated, range(len(nariz)))\n",
    "\n",
    "        # Definir los límites del recorte de 112x112 píxeles\n",
    "        half_crop_size = 56\n",
    "        x1 = int(max(0, centro_x - half_crop_size))\n",
    "        y1 = int(max(0, centro_y - half_crop_size))\n",
    "        x2 = int(min(original_width, centro_x + half_crop_size))\n",
    "        y2 = int(min(original_height, centro_y + half_crop_size))\n",
    "        \n",
    "        # Recortar la imagen\n",
    "        image_cropped_nose = image_aligned[y1:y2, x1:x2]\n",
    "        \n",
    "        # Redimensionar a 224x224\n",
    "        image_resized = cv2.resize(image_cropped_nose, (224, 224))\n",
    "\n",
    "        # Ajustar los puntos faciales de la nariz al nuevo recorte\n",
    "        nose_points_adjusted = [(p[0] - x1, p[1] - y1) for p in nose_points_rotated]\n",
    "\n",
    "        # Redimensionar las coordenadas de los puntos a la escala 224x224\n",
    "        scale_x = 224 / (x2 - x1)\n",
    "        scale_y = 224 / (y2 - y1)\n",
    "        nose_points_scaled = [(p[0] * scale_x, p[1] * scale_y) for p in nose_points_adjusted]\n",
    "\n",
    "        # Aplicar transformaciones de imagen y etiquetas\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image_resized, keypoints=nose_points_scaled)\n",
    "            image = augmented['image']\n",
    "            nose_points = np.array(augmented['keypoints'], dtype=np.float32).flatten()\n",
    "        \n",
    "        return image, torch.tensor(nose_points).float(), img_name, original_width, original_height\n",
    "\n",
    "# Transformaciones de aumento de datos para el conjunto de entrenamiento\n",
    "train_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Transformaciones para el conjunto de validación\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "# Crear los datasets de entrenamiento y validación\n",
    "train_dataset = NoseDataset(train_img_dir, train_labels_dir, transform=train_transforms)\n",
    "val_dataset = NoseDataset(val_img_dir, val_labels_dir, transform=val_transforms)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121Nose(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121Nose, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, len(nariz) * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Configuración y entrenamiento\n",
    "model = DenseNet121Nose().cuda()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "def calculate_nme(predictions, ground_truths, num_landmarks):\n",
    "    \"\"\"\n",
    "    Calcula el NME (Normalized Mean Error) utilizando la fórmula específica.\n",
    "    \n",
    "    :param predictions: Array de predicciones, de tamaño (N, M, 2), donde\n",
    "                        N es el número de imágenes, M el número de landmarks, \n",
    "                        y 2 son las coordenadas (x, y) de cada punto.\n",
    "    :param ground_truths: Array de valores reales (ground truths), del mismo tamaño que predictions.\n",
    "    :param num_landmarks: Número de landmarks en cada imagen (M).\n",
    "    :return: NME calculado sobre todo el dataset.\n",
    "    \"\"\"\n",
    "    num_images = predictions.shape[0]\n",
    "    total_error = 0.0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Verificar que los índices utilizados para calcular la distancia interocular sean correctos\n",
    "        if len(ground_truths[i]) < 5:\n",
    "            raise ValueError(f\"Expected at least 5 landmarks, but got {len(ground_truths[i])}\")\n",
    "\n",
    "        # Calcula la distancia interocular usando los puntos 0 y 4 (ajustado para nariz)\n",
    "        iodi = np.linalg.norm(ground_truths[i, 0] - ground_truths[i, 4])\n",
    "        \n",
    "        # Suma de errores normalizados por imagen\n",
    "        for j in range(num_landmarks):\n",
    "            pred_coord = predictions[i, j]\n",
    "            gt_coord = ground_truths[i, j]\n",
    "            error = np.linalg.norm(pred_coord - gt_coord) / iodi\n",
    "            total_error += error\n",
    "    \n",
    "    # Aplicar la fórmula para el NME\n",
    "    nme = total_error / (num_landmarks * num_images)\n",
    "    return nme\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, nose_points, _, _, _ in train_dataloader:\n",
    "            images, nose_points = images.cuda(), nose_points.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, nose_points)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación y cálculo del NME\n",
    "        if val_dataloader:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_nose_points, _, _, _ in val_dataloader:\n",
    "                    val_images, val_nose_points = val_images.cuda(), val_nose_points.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_nose_points).item()\n",
    "                    \n",
    "                    # Guardar las predicciones y etiquetas reales para el cálculo de NME\n",
    "                    all_labels.append(val_nose_points.cpu().numpy().reshape(-1, len(nariz), 2))\n",
    "                    all_predictions.append(val_outputs.cpu().numpy().reshape(-1, len(nariz), 2))\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Concatenar todas las predicciones y *ground truths* para el NME\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            nme = calculate_nme(all_predictions, all_labels, num_landmarks=len(nariz))\n",
    "            print(f'NME: {nme:.4f}')\n",
    "            \n",
    "            # Guardar el mejor modelo\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'NoseAreaLandmarks V3.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "                \n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
