{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_11944\\1223325336.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return image, torch.tensor(bounding_box).float(), img_name\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_11944\\1223325336.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 15767.2092\n",
      "Validation Loss: 13612.3573\n",
      "Best model saved at epoch 1 with val_loss 13612.3573\n",
      "Epoch [2/300], Loss: 8117.9266\n",
      "Validation Loss: 3204.4681\n",
      "Best model saved at epoch 2 with val_loss 3204.4681\n",
      "Epoch [3/300], Loss: 1625.7886\n",
      "Validation Loss: 1439.6110\n",
      "Best model saved at epoch 3 with val_loss 1439.6110\n",
      "Epoch [4/300], Loss: 1177.7088\n",
      "Validation Loss: 1511.0898\n",
      "Epoch [5/300], Loss: 1138.6978\n",
      "Validation Loss: 1311.6569\n",
      "Best model saved at epoch 5 with val_loss 1311.6569\n",
      "Epoch [6/300], Loss: 1080.5947\n",
      "Validation Loss: 1281.9706\n",
      "Best model saved at epoch 6 with val_loss 1281.9706\n",
      "Epoch [7/300], Loss: 1133.0956\n",
      "Validation Loss: 1316.6135\n",
      "Epoch [8/300], Loss: 1085.4139\n",
      "Validation Loss: 1276.0176\n",
      "Best model saved at epoch 8 with val_loss 1276.0176\n",
      "Epoch [9/300], Loss: 1058.9062\n",
      "Validation Loss: 1201.9533\n",
      "Best model saved at epoch 9 with val_loss 1201.9533\n",
      "Epoch [10/300], Loss: 1050.9799\n",
      "Validation Loss: 1281.5070\n",
      "Epoch [11/300], Loss: 1044.7371\n",
      "Validation Loss: 1358.4333\n",
      "Epoch [12/300], Loss: 1074.3089\n",
      "Validation Loss: 1223.0840\n",
      "Epoch [13/300], Loss: 1035.2277\n",
      "Validation Loss: 1203.4177\n",
      "Epoch [14/300], Loss: 1046.6737\n",
      "Validation Loss: 1336.0169\n",
      "Epoch [15/300], Loss: 1047.3694\n",
      "Validation Loss: 1392.2164\n",
      "Epoch [16/300], Loss: 1019.3537\n",
      "Validation Loss: 1350.5337\n",
      "Epoch [17/300], Loss: 1001.8533\n",
      "Validation Loss: 1469.7501\n",
      "Epoch [18/300], Loss: 971.7273\n",
      "Validation Loss: 1297.8458\n",
      "Epoch [19/300], Loss: 964.0550\n",
      "Validation Loss: 1325.1600\n",
      "Epoch [20/300], Loss: 894.6426\n",
      "Validation Loss: 1109.1942\n",
      "Best model saved at epoch 20 with val_loss 1109.1942\n",
      "Epoch [21/300], Loss: 795.1146\n",
      "Validation Loss: 1281.7571\n",
      "Epoch [22/300], Loss: 736.2973\n",
      "Validation Loss: 1290.7157\n",
      "Epoch [23/300], Loss: 687.8752\n",
      "Validation Loss: 1070.3880\n",
      "Best model saved at epoch 23 with val_loss 1070.3880\n",
      "Epoch [24/300], Loss: 642.3227\n",
      "Validation Loss: 1350.3382\n",
      "Epoch [25/300], Loss: 665.5420\n",
      "Validation Loss: 1646.5183\n",
      "Epoch [26/300], Loss: 582.4812\n",
      "Validation Loss: 1170.5947\n",
      "Epoch [27/300], Loss: 591.4041\n",
      "Validation Loss: 945.9463\n",
      "Best model saved at epoch 27 with val_loss 945.9463\n",
      "Epoch [28/300], Loss: 580.3143\n",
      "Validation Loss: 994.3717\n",
      "Epoch [29/300], Loss: 501.9549\n",
      "Validation Loss: 1634.4988\n",
      "Epoch [30/300], Loss: 456.6900\n",
      "Validation Loss: 1169.6152\n",
      "Epoch [31/300], Loss: 408.2674\n",
      "Validation Loss: 1395.0930\n",
      "Epoch [32/300], Loss: 331.6084\n",
      "Validation Loss: 1695.8026\n",
      "Epoch [33/300], Loss: 295.6287\n",
      "Validation Loss: 579.5934\n",
      "Best model saved at epoch 33 with val_loss 579.5934\n",
      "Epoch [34/300], Loss: 298.0335\n",
      "Validation Loss: 531.0990\n",
      "Best model saved at epoch 34 with val_loss 531.0990\n",
      "Epoch [35/300], Loss: 310.0194\n",
      "Validation Loss: 1229.8599\n",
      "Epoch [36/300], Loss: 286.1371\n",
      "Validation Loss: 829.3608\n",
      "Epoch [37/300], Loss: 239.7668\n",
      "Validation Loss: 691.0799\n",
      "Epoch [38/300], Loss: 277.6155\n",
      "Validation Loss: 1114.5154\n",
      "Epoch [39/300], Loss: 251.6230\n",
      "Validation Loss: 2472.1802\n",
      "Epoch [40/300], Loss: 243.6345\n",
      "Validation Loss: 551.7393\n",
      "Epoch [41/300], Loss: 243.7682\n",
      "Validation Loss: 1582.4189\n",
      "Epoch [42/300], Loss: 245.1244\n",
      "Validation Loss: 1333.8837\n",
      "Epoch [43/300], Loss: 223.7678\n",
      "Validation Loss: 391.5617\n",
      "Best model saved at epoch 43 with val_loss 391.5617\n",
      "Epoch [44/300], Loss: 243.5731\n",
      "Validation Loss: 1297.2311\n",
      "Epoch [45/300], Loss: 219.8554\n",
      "Validation Loss: 1965.4775\n",
      "Epoch [46/300], Loss: 224.9894\n",
      "Validation Loss: 657.5668\n",
      "Epoch [47/300], Loss: 210.5044\n",
      "Validation Loss: 1629.2338\n",
      "Epoch [48/300], Loss: 203.4030\n",
      "Validation Loss: 1440.3555\n",
      "Epoch [49/300], Loss: 205.4532\n",
      "Validation Loss: 801.7140\n",
      "Epoch [50/300], Loss: 201.8256\n",
      "Validation Loss: 1069.7514\n",
      "Epoch [51/300], Loss: 195.0812\n",
      "Validation Loss: 821.6368\n",
      "Epoch [52/300], Loss: 179.2158\n",
      "Validation Loss: 410.1944\n",
      "Epoch [53/300], Loss: 196.5887\n",
      "Validation Loss: 1272.8262\n",
      "Epoch [54/300], Loss: 180.4522\n",
      "Validation Loss: 1009.6931\n",
      "Epoch [55/300], Loss: 175.8836\n",
      "Validation Loss: 1189.9615\n",
      "Epoch [56/300], Loss: 157.0243\n",
      "Validation Loss: 920.9553\n",
      "Epoch [57/300], Loss: 202.2281\n",
      "Validation Loss: 931.6576\n",
      "Epoch [58/300], Loss: 184.9860\n",
      "Validation Loss: 806.9968\n",
      "Epoch [59/300], Loss: 183.1862\n",
      "Validation Loss: 626.6758\n",
      "Epoch [60/300], Loss: 183.3372\n",
      "Validation Loss: 1123.7223\n",
      "Epoch [61/300], Loss: 159.6738\n",
      "Validation Loss: 498.2833\n",
      "Epoch [62/300], Loss: 145.5776\n",
      "Validation Loss: 343.2265\n",
      "Best model saved at epoch 62 with val_loss 343.2265\n",
      "Epoch [63/300], Loss: 120.2461\n",
      "Validation Loss: 291.6089\n",
      "Best model saved at epoch 63 with val_loss 291.6089\n",
      "Epoch [64/300], Loss: 146.4988\n",
      "Validation Loss: 434.5747\n",
      "Epoch [65/300], Loss: 139.8026\n",
      "Validation Loss: 991.1315\n",
      "Epoch [66/300], Loss: 134.5655\n",
      "Validation Loss: 427.0894\n",
      "Epoch [67/300], Loss: 145.4876\n",
      "Validation Loss: 850.4667\n",
      "Epoch [68/300], Loss: 132.2611\n",
      "Validation Loss: 448.9025\n",
      "Epoch [69/300], Loss: 115.6444\n",
      "Validation Loss: 484.2874\n",
      "Epoch [70/300], Loss: 158.1579\n",
      "Validation Loss: 460.0682\n",
      "Epoch [71/300], Loss: 143.8400\n",
      "Validation Loss: 749.0906\n",
      "Epoch [72/300], Loss: 150.7682\n",
      "Validation Loss: 1102.6318\n",
      "Epoch [73/300], Loss: 129.6692\n",
      "Validation Loss: 492.6460\n",
      "Epoch [74/300], Loss: 114.9656\n",
      "Validation Loss: 509.6093\n",
      "Epoch [75/300], Loss: 119.1703\n",
      "Validation Loss: 318.6303\n",
      "Epoch [76/300], Loss: 113.2970\n",
      "Validation Loss: 268.4062\n",
      "Best model saved at epoch 76 with val_loss 268.4062\n",
      "Epoch [77/300], Loss: 100.4519\n",
      "Validation Loss: 250.7462\n",
      "Best model saved at epoch 77 with val_loss 250.7462\n",
      "Epoch [78/300], Loss: 94.8011\n",
      "Validation Loss: 2098.7274\n",
      "Epoch [79/300], Loss: 116.0735\n",
      "Validation Loss: 2007.9737\n",
      "Epoch [80/300], Loss: 136.6002\n",
      "Validation Loss: 526.9848\n",
      "Epoch [81/300], Loss: 123.9676\n",
      "Validation Loss: 294.2939\n",
      "Epoch [82/300], Loss: 112.0905\n",
      "Validation Loss: 1452.1438\n",
      "Epoch [83/300], Loss: 111.3695\n",
      "Validation Loss: 675.7062\n",
      "Epoch [84/300], Loss: 116.6596\n",
      "Validation Loss: 403.9716\n",
      "Epoch [85/300], Loss: 102.5484\n",
      "Validation Loss: 1745.3062\n",
      "Epoch [86/300], Loss: 94.4285\n",
      "Validation Loss: 910.7313\n",
      "Epoch [87/300], Loss: 105.2186\n",
      "Validation Loss: 905.7833\n",
      "Epoch [88/300], Loss: 121.3490\n",
      "Validation Loss: 951.2160\n",
      "Epoch [89/300], Loss: 101.8304\n",
      "Validation Loss: 664.4582\n",
      "Epoch [90/300], Loss: 101.6066\n",
      "Validation Loss: 1944.9175\n",
      "Epoch [91/300], Loss: 99.5851\n",
      "Validation Loss: 1193.8916\n",
      "Epoch [92/300], Loss: 106.4374\n",
      "Validation Loss: 570.0341\n",
      "Epoch [93/300], Loss: 107.1644\n",
      "Validation Loss: 750.6450\n",
      "Epoch [94/300], Loss: 100.9002\n",
      "Validation Loss: 1241.8146\n",
      "Epoch [95/300], Loss: 90.2950\n",
      "Validation Loss: 1459.5013\n",
      "Epoch [96/300], Loss: 98.4143\n",
      "Validation Loss: 477.3620\n",
      "Epoch [97/300], Loss: 99.4578\n",
      "Validation Loss: 2060.4986\n",
      "Epoch [98/300], Loss: 102.3793\n",
      "Validation Loss: 1850.2914\n",
      "Epoch [99/300], Loss: 99.1667\n",
      "Validation Loss: 689.3903\n",
      "Epoch [100/300], Loss: 88.4659\n",
      "Validation Loss: 260.4668\n",
      "Epoch [101/300], Loss: 79.8041\n",
      "Validation Loss: 794.1034\n",
      "Epoch [102/300], Loss: 98.7043\n",
      "Validation Loss: 805.9896\n",
      "Epoch [103/300], Loss: 98.5113\n",
      "Validation Loss: 1832.6497\n",
      "Epoch [104/300], Loss: 99.2440\n",
      "Validation Loss: 1147.4397\n",
      "Epoch [105/300], Loss: 97.9388\n",
      "Validation Loss: 610.7003\n",
      "Epoch [106/300], Loss: 100.0858\n",
      "Validation Loss: 624.4768\n",
      "Epoch [107/300], Loss: 95.5790\n",
      "Validation Loss: 706.0865\n",
      "Epoch [108/300], Loss: 97.0504\n",
      "Validation Loss: 1664.9308\n",
      "Epoch [109/300], Loss: 96.0060\n",
      "Validation Loss: 1092.4720\n",
      "Epoch [110/300], Loss: 85.9134\n",
      "Validation Loss: 378.2538\n",
      "Epoch [111/300], Loss: 92.6032\n",
      "Validation Loss: 752.8865\n",
      "Epoch [112/300], Loss: 80.1054\n",
      "Validation Loss: 473.5512\n",
      "Epoch [113/300], Loss: 81.1195\n",
      "Validation Loss: 443.4458\n",
      "Epoch [114/300], Loss: 87.6189\n",
      "Validation Loss: 1118.9638\n",
      "Epoch [115/300], Loss: 84.2093\n",
      "Validation Loss: 1262.1413\n",
      "Epoch [116/300], Loss: 87.7639\n",
      "Validation Loss: 516.3300\n",
      "Epoch [117/300], Loss: 89.8746\n",
      "Validation Loss: 1251.8854\n",
      "Epoch [118/300], Loss: 72.8656\n",
      "Validation Loss: 772.8945\n",
      "Epoch [119/300], Loss: 81.6063\n",
      "Validation Loss: 793.9818\n",
      "Epoch [120/300], Loss: 81.8931\n",
      "Validation Loss: 1026.1110\n",
      "Epoch [121/300], Loss: 92.9504\n",
      "Validation Loss: 1202.9746\n",
      "Epoch [122/300], Loss: 77.4435\n",
      "Validation Loss: 1604.0523\n",
      "Epoch [123/300], Loss: 79.8532\n",
      "Validation Loss: 1134.5112\n",
      "Epoch [124/300], Loss: 74.0087\n",
      "Validation Loss: 953.8036\n",
      "Epoch [125/300], Loss: 76.9529\n",
      "Validation Loss: 288.7326\n",
      "Epoch [126/300], Loss: 81.6780\n",
      "Validation Loss: 874.2065\n",
      "Epoch [127/300], Loss: 102.8973\n",
      "Validation Loss: 1821.4289\n",
      "Epoch [128/300], Loss: 104.6668\n",
      "Validation Loss: 2837.5530\n",
      "Epoch [129/300], Loss: 121.0476\n",
      "Validation Loss: 1307.5960\n",
      "Epoch [130/300], Loss: 81.7956\n",
      "Validation Loss: 296.0804\n",
      "Epoch [131/300], Loss: 78.7113\n",
      "Validation Loss: 552.2587\n",
      "Epoch [132/300], Loss: 84.3836\n",
      "Validation Loss: 1579.5005\n",
      "Epoch [133/300], Loss: 77.6814\n",
      "Validation Loss: 505.7801\n",
      "Epoch [134/300], Loss: 78.0191\n",
      "Validation Loss: 428.9345\n",
      "Epoch [135/300], Loss: 74.9812\n",
      "Validation Loss: 765.4636\n",
      "Epoch [136/300], Loss: 68.4973\n",
      "Validation Loss: 415.1077\n",
      "Epoch [137/300], Loss: 95.8849\n",
      "Validation Loss: 572.8010\n",
      "Epoch [138/300], Loss: 73.7927\n",
      "Validation Loss: 2241.6790\n",
      "Epoch [139/300], Loss: 74.4644\n",
      "Validation Loss: 362.4533\n",
      "Epoch [140/300], Loss: 78.1873\n",
      "Validation Loss: 1135.3636\n",
      "Epoch [141/300], Loss: 80.9698\n",
      "Validation Loss: 535.2908\n",
      "Epoch [142/300], Loss: 73.0266\n",
      "Validation Loss: 728.4312\n",
      "Epoch [143/300], Loss: 72.8524\n",
      "Validation Loss: 726.1950\n",
      "Epoch [144/300], Loss: 62.5563\n",
      "Validation Loss: 655.3802\n",
      "Epoch [145/300], Loss: 61.2720\n",
      "Validation Loss: 2744.9784\n",
      "Epoch [146/300], Loss: 71.8943\n",
      "Validation Loss: 1023.0205\n",
      "Epoch [147/300], Loss: 68.3630\n",
      "Validation Loss: 1122.1965\n",
      "Epoch [148/300], Loss: 67.6748\n",
      "Validation Loss: 1632.5289\n",
      "Epoch [149/300], Loss: 71.7038\n",
      "Validation Loss: 1343.5859\n",
      "Epoch [150/300], Loss: 57.4210\n",
      "Validation Loss: 538.5458\n",
      "Epoch [151/300], Loss: 60.2634\n",
      "Validation Loss: 981.2174\n",
      "Epoch [152/300], Loss: 70.4207\n",
      "Validation Loss: 1438.8138\n",
      "Epoch [153/300], Loss: 88.6021\n",
      "Validation Loss: 2444.1431\n",
      "Epoch [154/300], Loss: 69.8242\n",
      "Validation Loss: 254.5905\n",
      "Epoch [155/300], Loss: 57.9508\n",
      "Validation Loss: 206.9015\n",
      "Best model saved at epoch 155 with val_loss 206.9015\n",
      "Epoch [156/300], Loss: 56.7498\n",
      "Validation Loss: 152.6992\n",
      "Best model saved at epoch 156 with val_loss 152.6992\n",
      "Epoch [157/300], Loss: 51.7013\n",
      "Validation Loss: 147.8507\n",
      "Best model saved at epoch 157 with val_loss 147.8507\n",
      "Epoch [158/300], Loss: 53.0840\n",
      "Validation Loss: 171.8899\n",
      "Epoch [159/300], Loss: 56.7732\n",
      "Validation Loss: 195.9709\n",
      "Epoch [160/300], Loss: 54.8679\n",
      "Validation Loss: 150.6815\n",
      "Epoch [161/300], Loss: 56.7565\n",
      "Validation Loss: 390.1082\n",
      "Epoch [162/300], Loss: 51.1471\n",
      "Validation Loss: 229.6086\n",
      "Epoch [163/300], Loss: 49.3109\n",
      "Validation Loss: 162.8042\n",
      "Epoch [164/300], Loss: 45.6293\n",
      "Validation Loss: 173.1577\n",
      "Epoch [165/300], Loss: 47.8956\n",
      "Validation Loss: 207.9157\n",
      "Epoch [166/300], Loss: 47.7636\n",
      "Validation Loss: 143.4277\n",
      "Best model saved at epoch 166 with val_loss 143.4277\n",
      "Epoch [167/300], Loss: 46.0656\n",
      "Validation Loss: 193.3765\n",
      "Epoch [168/300], Loss: 53.0755\n",
      "Validation Loss: 145.9966\n",
      "Epoch [169/300], Loss: 46.9353\n",
      "Validation Loss: 215.6465\n",
      "Epoch [170/300], Loss: 50.0172\n",
      "Validation Loss: 180.9341\n",
      "Epoch [171/300], Loss: 47.0961\n",
      "Validation Loss: 256.5261\n",
      "Epoch [172/300], Loss: 46.8201\n",
      "Validation Loss: 189.6632\n",
      "Epoch [173/300], Loss: 48.6036\n",
      "Validation Loss: 191.8344\n",
      "Epoch [174/300], Loss: 41.6675\n",
      "Validation Loss: 169.7409\n",
      "Epoch [175/300], Loss: 45.2158\n",
      "Validation Loss: 255.9678\n",
      "Epoch [176/300], Loss: 51.1119\n",
      "Validation Loss: 131.5230\n",
      "Best model saved at epoch 176 with val_loss 131.5230\n",
      "Epoch [177/300], Loss: 50.0518\n",
      "Validation Loss: 151.4862\n",
      "Epoch [178/300], Loss: 44.9744\n",
      "Validation Loss: 157.3768\n",
      "Epoch [179/300], Loss: 50.0952\n",
      "Validation Loss: 171.7664\n",
      "Epoch [180/300], Loss: 42.8246\n",
      "Validation Loss: 181.6843\n",
      "Epoch [181/300], Loss: 43.2199\n",
      "Validation Loss: 161.9946\n",
      "Epoch [182/300], Loss: 48.7384\n",
      "Validation Loss: 159.4934\n",
      "Epoch [183/300], Loss: 46.1410\n",
      "Validation Loss: 172.8859\n",
      "Epoch [184/300], Loss: 44.7801\n",
      "Validation Loss: 177.4978\n",
      "Epoch [185/300], Loss: 41.2776\n",
      "Validation Loss: 152.6408\n",
      "Epoch [186/300], Loss: 38.9894\n",
      "Validation Loss: 149.4859\n",
      "Epoch [187/300], Loss: 44.2538\n",
      "Validation Loss: 172.2942\n",
      "Epoch [188/300], Loss: 40.8171\n",
      "Validation Loss: 163.6102\n",
      "Epoch [189/300], Loss: 39.2375\n",
      "Validation Loss: 128.7249\n",
      "Best model saved at epoch 189 with val_loss 128.7249\n",
      "Epoch [190/300], Loss: 48.1271\n",
      "Validation Loss: 187.2217\n",
      "Epoch [191/300], Loss: 40.6054\n",
      "Validation Loss: 202.0354\n",
      "Epoch [192/300], Loss: 45.7663\n",
      "Validation Loss: 219.2535\n",
      "Epoch [193/300], Loss: 41.3306\n",
      "Validation Loss: 486.9772\n",
      "Epoch [194/300], Loss: 40.2748\n",
      "Validation Loss: 116.1991\n",
      "Best model saved at epoch 194 with val_loss 116.1991\n",
      "Epoch [195/300], Loss: 43.5834\n",
      "Validation Loss: 149.8633\n",
      "Epoch [196/300], Loss: 39.7737\n",
      "Validation Loss: 282.6927\n",
      "Epoch [197/300], Loss: 39.4447\n",
      "Validation Loss: 170.1531\n",
      "Epoch [198/300], Loss: 41.4345\n",
      "Validation Loss: 155.4860\n",
      "Epoch [199/300], Loss: 43.0985\n",
      "Validation Loss: 165.6416\n",
      "Epoch [200/300], Loss: 41.0153\n",
      "Validation Loss: 165.2276\n",
      "Epoch [201/300], Loss: 39.2577\n",
      "Validation Loss: 134.4507\n",
      "Epoch [202/300], Loss: 38.4428\n",
      "Validation Loss: 373.1409\n",
      "Epoch [203/300], Loss: 41.3501\n",
      "Validation Loss: 220.6774\n",
      "Epoch [204/300], Loss: 38.7867\n",
      "Validation Loss: 163.5099\n",
      "Epoch [205/300], Loss: 42.8844\n",
      "Validation Loss: 153.4578\n",
      "Epoch [206/300], Loss: 40.6041\n",
      "Validation Loss: 121.2260\n",
      "Epoch [207/300], Loss: 39.9573\n",
      "Validation Loss: 199.9687\n",
      "Epoch [208/300], Loss: 42.4711\n",
      "Validation Loss: 140.4906\n",
      "Epoch [209/300], Loss: 37.5414\n",
      "Validation Loss: 174.9020\n",
      "Epoch [210/300], Loss: 34.5255\n",
      "Validation Loss: 178.1526\n",
      "Epoch [211/300], Loss: 36.2591\n",
      "Validation Loss: 166.7791\n",
      "Epoch [212/300], Loss: 36.7350\n",
      "Validation Loss: 118.6671\n",
      "Epoch [213/300], Loss: 38.7345\n",
      "Validation Loss: 145.4451\n",
      "Epoch [214/300], Loss: 39.3153\n",
      "Validation Loss: 143.8511\n",
      "Epoch [215/300], Loss: 39.3032\n",
      "Validation Loss: 140.0884\n",
      "Epoch [216/300], Loss: 37.8485\n",
      "Validation Loss: 206.7598\n",
      "Epoch [217/300], Loss: 37.6158\n",
      "Validation Loss: 143.1078\n",
      "Epoch [218/300], Loss: 38.9169\n",
      "Validation Loss: 168.5971\n",
      "Epoch [219/300], Loss: 36.3949\n",
      "Validation Loss: 171.5369\n",
      "Epoch [220/300], Loss: 40.5369\n",
      "Validation Loss: 157.6981\n",
      "Epoch [221/300], Loss: 35.7647\n",
      "Validation Loss: 159.6883\n",
      "Epoch [222/300], Loss: 35.6214\n",
      "Validation Loss: 226.8933\n",
      "Epoch [223/300], Loss: 38.0276\n",
      "Validation Loss: 223.9617\n",
      "Epoch [224/300], Loss: 35.6293\n",
      "Validation Loss: 171.1039\n",
      "Epoch [225/300], Loss: 39.1931\n",
      "Validation Loss: 142.1952\n",
      "Epoch [226/300], Loss: 38.8767\n",
      "Validation Loss: 242.8549\n",
      "Epoch [227/300], Loss: 34.4047\n",
      "Validation Loss: 163.7423\n",
      "Epoch [228/300], Loss: 37.5605\n",
      "Validation Loss: 172.0279\n",
      "Epoch [229/300], Loss: 34.8119\n",
      "Validation Loss: 175.1934\n",
      "Epoch [230/300], Loss: 37.1622\n",
      "Validation Loss: 176.1531\n",
      "Epoch [231/300], Loss: 37.2223\n",
      "Validation Loss: 221.2253\n",
      "Epoch [232/300], Loss: 36.3371\n",
      "Validation Loss: 136.0904\n",
      "Epoch [233/300], Loss: 36.1569\n",
      "Validation Loss: 186.4302\n",
      "Epoch [234/300], Loss: 39.3386\n",
      "Validation Loss: 159.7093\n",
      "Epoch [235/300], Loss: 35.1874\n",
      "Validation Loss: 177.5487\n",
      "Epoch [236/300], Loss: 34.6673\n",
      "Validation Loss: 141.1065\n",
      "Epoch [237/300], Loss: 36.9723\n",
      "Validation Loss: 184.6032\n",
      "Epoch [238/300], Loss: 36.6211\n",
      "Validation Loss: 133.2786\n",
      "Epoch [239/300], Loss: 35.2328\n",
      "Validation Loss: 232.7715\n",
      "Epoch [240/300], Loss: 36.5548\n",
      "Validation Loss: 168.9562\n",
      "Epoch [241/300], Loss: 34.6757\n",
      "Validation Loss: 196.5753\n",
      "Epoch [242/300], Loss: 34.3259\n",
      "Validation Loss: 151.3440\n",
      "Epoch [243/300], Loss: 37.3645\n",
      "Validation Loss: 172.2521\n",
      "Epoch [244/300], Loss: 36.0949\n",
      "Validation Loss: 161.7000\n",
      "Epoch [245/300], Loss: 38.4747\n",
      "Validation Loss: 245.7104\n",
      "Epoch [246/300], Loss: 33.0262\n",
      "Validation Loss: 182.5261\n",
      "Epoch [247/300], Loss: 34.6946\n",
      "Validation Loss: 165.0252\n",
      "Epoch [248/300], Loss: 33.7431\n",
      "Validation Loss: 183.7947\n",
      "Epoch [249/300], Loss: 32.1657\n",
      "Validation Loss: 148.4377\n",
      "Epoch [250/300], Loss: 35.9382\n",
      "Validation Loss: 183.4689\n",
      "Epoch [251/300], Loss: 34.4263\n",
      "Validation Loss: 133.1871\n",
      "Epoch [252/300], Loss: 33.3260\n",
      "Validation Loss: 157.3758\n",
      "Epoch [253/300], Loss: 34.3817\n",
      "Validation Loss: 173.2642\n",
      "Epoch [254/300], Loss: 36.1290\n",
      "Validation Loss: 169.4662\n",
      "Epoch [255/300], Loss: 33.4280\n",
      "Validation Loss: 174.1121\n",
      "Epoch [256/300], Loss: 35.8477\n",
      "Validation Loss: 171.3818\n",
      "Epoch [257/300], Loss: 36.8383\n",
      "Validation Loss: 176.3365\n",
      "Epoch [258/300], Loss: 33.9245\n",
      "Validation Loss: 184.5111\n",
      "Epoch [259/300], Loss: 33.1024\n",
      "Validation Loss: 125.9627\n",
      "Epoch [260/300], Loss: 35.7232\n",
      "Validation Loss: 154.1080\n",
      "Epoch [261/300], Loss: 36.1787\n",
      "Validation Loss: 144.9127\n",
      "Epoch [262/300], Loss: 31.1930\n",
      "Validation Loss: 181.1460\n",
      "Epoch [263/300], Loss: 34.4531\n",
      "Validation Loss: 204.4263\n",
      "Epoch [264/300], Loss: 33.8008\n",
      "Validation Loss: 210.5373\n",
      "Epoch [265/300], Loss: 37.0335\n",
      "Validation Loss: 189.4154\n",
      "Epoch [266/300], Loss: 33.0546\n",
      "Validation Loss: 142.3869\n",
      "Epoch [267/300], Loss: 31.4018\n",
      "Validation Loss: 163.3729\n",
      "Epoch [268/300], Loss: 34.9968\n",
      "Validation Loss: 159.9619\n",
      "Epoch [269/300], Loss: 33.5985\n",
      "Validation Loss: 179.2235\n",
      "Epoch [270/300], Loss: 31.4203\n",
      "Validation Loss: 188.8439\n",
      "Epoch [271/300], Loss: 33.7163\n",
      "Validation Loss: 185.5335\n",
      "Epoch [272/300], Loss: 34.6287\n",
      "Validation Loss: 156.4039\n",
      "Epoch [273/300], Loss: 33.2481\n",
      "Validation Loss: 159.5196\n",
      "Epoch [274/300], Loss: 32.3106\n",
      "Validation Loss: 200.4099\n",
      "Epoch [275/300], Loss: 33.7228\n",
      "Validation Loss: 147.6979\n",
      "Epoch [276/300], Loss: 30.2250\n",
      "Validation Loss: 182.3232\n",
      "Epoch [277/300], Loss: 35.5089\n",
      "Validation Loss: 145.5706\n",
      "Epoch [278/300], Loss: 31.0763\n",
      "Validation Loss: 182.6477\n",
      "Epoch [279/300], Loss: 34.1887\n",
      "Validation Loss: 162.7991\n",
      "Epoch [280/300], Loss: 32.1256\n",
      "Validation Loss: 157.0235\n",
      "Epoch [281/300], Loss: 31.3855\n",
      "Validation Loss: 164.8165\n",
      "Epoch [282/300], Loss: 30.7685\n",
      "Validation Loss: 162.7606\n",
      "Epoch [283/300], Loss: 36.5253\n",
      "Validation Loss: 192.2826\n",
      "Epoch [284/300], Loss: 32.6792\n",
      "Validation Loss: 154.3676\n",
      "Epoch [285/300], Loss: 33.4045\n",
      "Validation Loss: 139.2714\n",
      "Epoch [286/300], Loss: 33.2442\n",
      "Validation Loss: 178.6599\n",
      "Epoch [287/300], Loss: 30.3905\n",
      "Validation Loss: 159.4419\n",
      "Epoch [288/300], Loss: 32.7596\n",
      "Validation Loss: 171.4879\n",
      "Epoch [289/300], Loss: 32.4496\n",
      "Validation Loss: 146.6321\n",
      "Epoch [290/300], Loss: 34.8917\n",
      "Validation Loss: 192.4115\n",
      "Epoch [291/300], Loss: 32.7356\n",
      "Validation Loss: 148.5777\n",
      "Epoch [292/300], Loss: 33.2474\n",
      "Validation Loss: 147.5542\n",
      "Epoch [293/300], Loss: 31.9495\n",
      "Validation Loss: 168.9780\n",
      "Epoch [294/300], Loss: 31.7123\n",
      "Validation Loss: 134.1971\n",
      "Epoch [295/300], Loss: 31.2666\n",
      "Validation Loss: 181.4420\n",
      "Epoch [296/300], Loss: 31.4364\n",
      "Validation Loss: 156.5764\n",
      "Epoch [297/300], Loss: 33.4662\n",
      "Validation Loss: 149.3833\n",
      "Epoch [298/300], Loss: 33.1384\n",
      "Validation Loss: 129.8911\n",
      "Epoch [299/300], Loss: 31.8695\n",
      "Validation Loss: 133.6809\n",
      "Epoch [300/300], Loss: 30.9475\n",
      "Validation Loss: 146.3687\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# Ruta a las imágenes y etiquetas\n",
    "img_dir = r'C:\\CatFLW dataset\\images'\n",
    "labels_dir = r'C:\\CatFLW dataset\\labels'\n",
    "output_dir = r'C:\\CatFLW dataset\\cropped_images'  # Ruta para guardar los recortes\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dataset personalizado para cargar imágenes y etiquetas\n",
    "class CatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            bounding_box = labels['bounding_boxes']  # Coordenadas de la caja delimitadora\n",
    "\n",
    "        # Aplicar las transformaciones de imagen y bounding box\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]  # Actualizar el bounding box\n",
    "        \n",
    "        return image, torch.tensor(bounding_box).float(), img_name  # Devuelve también el nombre del archivo\n",
    "\n",
    "# Aumentaciones para el conjunto de entrenamiento utilizando albumentations\n",
    "augmentation_transforms = A.Compose([\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.9),\n",
    "    A.ColorJitter(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Transformación básica (sin aumento) para validación\n",
    "basic_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Dataset con aumentaciones aplicadas solo en el conjunto de entrenamiento\n",
    "class AugmentedCatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None, augment_transform=None):\n",
    "        self.dataset = CatFaceDataset(img_dir, labels_dir, transform)\n",
    "        self.augment_transform = augment_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, bounding_box, img_name = self.dataset[idx]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato numpy array antes de pasarla a Albumentations\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).cpu().numpy()  # Convertir de tensor a numpy array si es necesario\n",
    "\n",
    "        # Aplicar las transformaciones de aumento\n",
    "        if random.random() < 0.9:\n",
    "            augmented = self.augment_transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato [3, 224, 224] antes de devolverla\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.tensor(image).permute(2, 0, 1)  # Convertir de numpy a tensor y reorganizar dimensiones\n",
    "\n",
    "        return image, torch.tensor(bounding_box).float(), img_name\n",
    "\n",
    "# Función de colación personalizada para asegurarse de que los bounding boxes sean tensors\n",
    "def custom_collate_fn(batch):\n",
    "    images, bounding_boxes, img_names = zip(*batch)\n",
    "    \n",
    "    # Convierte las imágenes a tensores\n",
    "    images = torch.stack([img for img in images])\n",
    "    \n",
    "    # Convierte las bounding boxes a tensores\n",
    "    bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n",
    "    \n",
    "    return images, bounding_boxes, img_names\n",
    "\n",
    "# Crear el dataset con aumento en el conjunto de entrenamiento\n",
    "augmented_dataset = AugmentedCatFaceDataset(img_dir, labels_dir, transform=basic_transform, augment_transform=augmentation_transforms)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación (80%, 20%)\n",
    "train_size = int(0.8 * len(augmented_dataset))\n",
    "val_size = len(augmented_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(augmented_dataset, [train_size, val_size])\n",
    "\n",
    "# Crear los dataloaders con la función de colación personalizada\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121BoundingBox(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121BoundingBox, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)  # Cambiado a False\n",
    "        self.backbone.classifier = nn.Identity()  # Eliminar la capa fully connected original\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)  # 4 coordenadas para las esquinas de la caja\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)  # La salida es un vector con 4 coordenadas\n",
    "        return x\n",
    "\n",
    "# Crear modelo, optimizador y función de pérdida\n",
    "model = DenseNet121BoundingBox().cuda()  # Mover el modelo a la GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Reduce el LR cuando el val_loss no mejora\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    model = model.cuda()  # Asegurarse de que el modelo esté en la GPU\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterar sobre el dataloader de entrenamiento\n",
    "        for images, bounding_boxes, img_names in train_dataloader:\n",
    "            images = images.cuda()  # Mover imágenes a la GPU\n",
    "            bounding_boxes = bounding_boxes.cuda()  # Mover bounding boxes a la GPU\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, bounding_boxes)\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calcular la pérdida promedio por época\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación (si se proporciona un val_dataloader)\n",
    "        if val_dataloader:\n",
    "            model.eval()  # Modo de evaluación\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_bounding_boxes, _ in val_dataloader:\n",
    "                    val_images = val_images.cuda()\n",
    "                    val_bounding_boxes = val_bounding_boxes.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_bounding_boxes).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "            # Guardar el mejor modelo basado en la validación\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_model4.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "        \n",
    "            # Ajustar el LR basado en el val_loss usando el scheduler\n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)  # Reduce el LR si no mejora el val_loss\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_4604\\364926700.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return image, torch.tensor(bounding_box).float(), img_name\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_4604\\364926700.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 15873.5695\n",
      "Validation Loss: 13294.0882\n",
      "Best model saved at epoch 1 with val_loss 13294.0882\n",
      "Epoch [2/300], Loss: 8559.4598\n",
      "Validation Loss: 3573.6031\n",
      "Best model saved at epoch 2 with val_loss 3573.6031\n",
      "Epoch [3/300], Loss: 2284.8450\n",
      "Validation Loss: 1644.6595\n",
      "Best model saved at epoch 3 with val_loss 1644.6595\n",
      "Epoch [4/300], Loss: 1590.1594\n",
      "Validation Loss: 1377.1453\n",
      "Best model saved at epoch 4 with val_loss 1377.1453\n",
      "Epoch [5/300], Loss: 1491.5053\n",
      "Validation Loss: 1746.9670\n",
      "Epoch [6/300], Loss: 1451.6426\n",
      "Validation Loss: 1319.0948\n",
      "Best model saved at epoch 6 with val_loss 1319.0948\n",
      "Epoch [7/300], Loss: 1485.3417\n",
      "Validation Loss: 1497.9911\n",
      "Epoch [8/300], Loss: 1462.5173\n",
      "Validation Loss: 1636.1458\n",
      "Epoch [9/300], Loss: 1426.5317\n",
      "Validation Loss: 1440.0339\n",
      "Epoch [10/300], Loss: 1409.2196\n",
      "Validation Loss: 1229.2065\n",
      "Best model saved at epoch 10 with val_loss 1229.2065\n",
      "Epoch [11/300], Loss: 1385.0196\n",
      "Validation Loss: 1305.5481\n",
      "Epoch [12/300], Loss: 1369.0687\n",
      "Validation Loss: 1277.2865\n",
      "Epoch [13/300], Loss: 1369.0325\n",
      "Validation Loss: 1350.3404\n",
      "Epoch [14/300], Loss: 1330.0278\n",
      "Validation Loss: 1392.7386\n",
      "Epoch [15/300], Loss: 1333.3253\n",
      "Validation Loss: 1444.8232\n",
      "Epoch [16/300], Loss: 1273.5976\n",
      "Validation Loss: 1577.6153\n",
      "Epoch [17/300], Loss: 1332.9013\n",
      "Validation Loss: 1319.3967\n",
      "Epoch [18/300], Loss: 1331.5662\n",
      "Validation Loss: 1186.5311\n",
      "Best model saved at epoch 18 with val_loss 1186.5311\n",
      "Epoch [19/300], Loss: 1283.8983\n",
      "Validation Loss: 1469.1005\n",
      "Epoch [20/300], Loss: 1257.8699\n",
      "Validation Loss: 1197.2001\n",
      "Epoch [21/300], Loss: 1233.2743\n",
      "Validation Loss: 1361.2594\n",
      "Epoch [22/300], Loss: 1194.6553\n",
      "Validation Loss: 1479.5904\n",
      "Epoch [23/300], Loss: 1059.8832\n",
      "Validation Loss: 1237.3193\n",
      "Epoch [24/300], Loss: 1029.6274\n",
      "Validation Loss: 1322.5999\n",
      "Epoch [25/300], Loss: 983.6049\n",
      "Validation Loss: 1045.2380\n",
      "Best model saved at epoch 25 with val_loss 1045.2380\n",
      "Epoch [26/300], Loss: 939.1230\n",
      "Validation Loss: 1395.5292\n",
      "Epoch [27/300], Loss: 940.9838\n",
      "Validation Loss: 703.8407\n",
      "Best model saved at epoch 27 with val_loss 703.8407\n",
      "Epoch [28/300], Loss: 939.0208\n",
      "Validation Loss: 993.5203\n",
      "Epoch [29/300], Loss: 916.6518\n",
      "Validation Loss: 849.6960\n",
      "Epoch [30/300], Loss: 909.2823\n",
      "Validation Loss: 1374.2162\n",
      "Epoch [31/300], Loss: 923.5923\n",
      "Validation Loss: 1040.9962\n",
      "Epoch [32/300], Loss: 885.5982\n",
      "Validation Loss: 970.2332\n",
      "Epoch [33/300], Loss: 888.8058\n",
      "Validation Loss: 1597.3010\n",
      "Epoch [34/300], Loss: 854.1520\n",
      "Validation Loss: 953.1345\n",
      "Epoch [35/300], Loss: 867.2977\n",
      "Validation Loss: 1311.3485\n",
      "Epoch [36/300], Loss: 846.7814\n",
      "Validation Loss: 875.2059\n",
      "Epoch [37/300], Loss: 880.4202\n",
      "Validation Loss: 1077.1263\n",
      "Epoch [38/300], Loss: 845.3981\n",
      "Validation Loss: 1141.6144\n",
      "Epoch [39/300], Loss: 864.7820\n",
      "Validation Loss: 878.3028\n",
      "Epoch [40/300], Loss: 810.7045\n",
      "Validation Loss: 980.8412\n",
      "Epoch [41/300], Loss: 776.7016\n",
      "Validation Loss: 904.4330\n",
      "Epoch [42/300], Loss: 744.2087\n",
      "Validation Loss: 1652.5374\n",
      "Epoch [43/300], Loss: 717.4260\n",
      "Validation Loss: 1186.9870\n",
      "Epoch [44/300], Loss: 653.6012\n",
      "Validation Loss: 1235.3724\n",
      "Epoch [45/300], Loss: 643.7970\n",
      "Validation Loss: 488.2219\n",
      "Best model saved at epoch 45 with val_loss 488.2219\n",
      "Epoch [46/300], Loss: 609.2561\n",
      "Validation Loss: 568.8271\n",
      "Epoch [47/300], Loss: 599.0675\n",
      "Validation Loss: 1627.0407\n",
      "Epoch [48/300], Loss: 576.4750\n",
      "Validation Loss: 1367.9492\n",
      "Epoch [49/300], Loss: 541.7701\n",
      "Validation Loss: 685.4488\n",
      "Epoch [50/300], Loss: 555.9506\n",
      "Validation Loss: 649.8782\n",
      "Epoch [51/300], Loss: 559.8670\n",
      "Validation Loss: 1482.6171\n",
      "Epoch [52/300], Loss: 540.5020\n",
      "Validation Loss: 1412.1575\n",
      "Epoch [53/300], Loss: 542.3711\n",
      "Validation Loss: 692.2872\n",
      "Epoch [54/300], Loss: 512.9374\n",
      "Validation Loss: 1506.0083\n",
      "Epoch [55/300], Loss: 561.6764\n",
      "Validation Loss: 908.7714\n",
      "Epoch [56/300], Loss: 532.5534\n",
      "Validation Loss: 1014.8949\n",
      "Epoch [57/300], Loss: 516.5508\n",
      "Validation Loss: 2235.1171\n",
      "Epoch [58/300], Loss: 492.6784\n",
      "Validation Loss: 1336.4200\n",
      "Epoch [59/300], Loss: 537.0247\n",
      "Validation Loss: 1174.9835\n",
      "Epoch [60/300], Loss: 515.2124\n",
      "Validation Loss: 1430.8446\n",
      "Epoch [61/300], Loss: 513.9737\n",
      "Validation Loss: 2561.3610\n",
      "Epoch [62/300], Loss: 500.8671\n",
      "Validation Loss: 1808.9639\n",
      "Epoch [63/300], Loss: 482.2952\n",
      "Validation Loss: 1449.6110\n",
      "Epoch [64/300], Loss: 491.3112\n",
      "Validation Loss: 721.8525\n",
      "Epoch [65/300], Loss: 505.2296\n",
      "Validation Loss: 1769.3035\n",
      "Epoch [66/300], Loss: 488.8603\n",
      "Validation Loss: 743.8786\n",
      "Epoch [67/300], Loss: 477.0131\n",
      "Validation Loss: 644.5199\n",
      "Epoch [68/300], Loss: 462.2811\n",
      "Validation Loss: 1546.7699\n",
      "Epoch [69/300], Loss: 481.6137\n",
      "Validation Loss: 1657.1973\n",
      "Epoch [70/300], Loss: 475.3720\n",
      "Validation Loss: 1748.7885\n",
      "Epoch [71/300], Loss: 459.1618\n",
      "Validation Loss: 759.4737\n",
      "Epoch [72/300], Loss: 448.0204\n",
      "Validation Loss: 502.7030\n",
      "Epoch [73/300], Loss: 453.9628\n",
      "Validation Loss: 1219.8918\n",
      "Epoch [74/300], Loss: 466.8522\n",
      "Validation Loss: 1375.0575\n",
      "Epoch [75/300], Loss: 474.1166\n",
      "Validation Loss: 1290.1440\n",
      "Epoch [76/300], Loss: 444.6103\n",
      "Validation Loss: 334.7319\n",
      "Best model saved at epoch 76 with val_loss 334.7319\n",
      "Epoch [77/300], Loss: 461.3099\n",
      "Validation Loss: 1149.3207\n",
      "Epoch [78/300], Loss: 442.3510\n",
      "Validation Loss: 938.6439\n",
      "Epoch [79/300], Loss: 459.4780\n",
      "Validation Loss: 1410.5461\n",
      "Epoch [80/300], Loss: 448.4835\n",
      "Validation Loss: 1158.2200\n",
      "Epoch [81/300], Loss: 422.7074\n",
      "Validation Loss: 1143.3199\n",
      "Epoch [82/300], Loss: 451.3761\n",
      "Validation Loss: 1064.5432\n",
      "Epoch [83/300], Loss: 453.7350\n",
      "Validation Loss: 1381.4444\n",
      "Epoch [84/300], Loss: 464.0924\n",
      "Validation Loss: 314.9845\n",
      "Best model saved at epoch 84 with val_loss 314.9845\n",
      "Epoch [85/300], Loss: 427.4704\n",
      "Validation Loss: 604.6558\n",
      "Epoch [86/300], Loss: 438.2593\n",
      "Validation Loss: 1551.0714\n",
      "Epoch [87/300], Loss: 418.3424\n",
      "Validation Loss: 799.4152\n",
      "Epoch [88/300], Loss: 405.0293\n",
      "Validation Loss: 2135.1154\n",
      "Epoch [89/300], Loss: 431.3984\n",
      "Validation Loss: 1493.1373\n",
      "Epoch [90/300], Loss: 409.8585\n",
      "Validation Loss: 378.4218\n",
      "Epoch [91/300], Loss: 432.9644\n",
      "Validation Loss: 775.0413\n",
      "Epoch [92/300], Loss: 405.9010\n",
      "Validation Loss: 1760.7433\n",
      "Epoch [93/300], Loss: 417.7824\n",
      "Validation Loss: 1310.9807\n",
      "Epoch [94/300], Loss: 426.1316\n",
      "Validation Loss: 2087.0279\n",
      "Epoch [95/300], Loss: 423.7651\n",
      "Validation Loss: 1289.7361\n",
      "Epoch [96/300], Loss: 408.5145\n",
      "Validation Loss: 1166.8469\n",
      "Epoch [97/300], Loss: 419.4206\n",
      "Validation Loss: 1100.9271\n",
      "Epoch [98/300], Loss: 416.5853\n",
      "Validation Loss: 1721.6858\n",
      "Epoch [99/300], Loss: 415.2331\n",
      "Validation Loss: 963.9497\n",
      "Epoch [100/300], Loss: 402.3716\n",
      "Validation Loss: 371.0373\n",
      "Epoch [101/300], Loss: 447.6857\n",
      "Validation Loss: 1084.5525\n",
      "Epoch [102/300], Loss: 395.5172\n",
      "Validation Loss: 1448.9431\n",
      "Epoch [103/300], Loss: 400.5488\n",
      "Validation Loss: 432.8547\n",
      "Epoch [104/300], Loss: 404.4353\n",
      "Validation Loss: 1543.4966\n",
      "Epoch [105/300], Loss: 404.1044\n",
      "Validation Loss: 1527.0337\n",
      "Epoch [106/300], Loss: 406.0054\n",
      "Validation Loss: 855.3007\n",
      "Epoch [107/300], Loss: 370.4040\n",
      "Validation Loss: 295.7886\n",
      "Best model saved at epoch 107 with val_loss 295.7886\n",
      "Epoch [108/300], Loss: 391.0588\n",
      "Validation Loss: 847.5732\n",
      "Epoch [109/300], Loss: 386.3281\n",
      "Validation Loss: 1660.3898\n",
      "Epoch [110/300], Loss: 395.6821\n",
      "Validation Loss: 529.0254\n",
      "Epoch [111/300], Loss: 380.2633\n",
      "Validation Loss: 544.5347\n",
      "Epoch [112/300], Loss: 387.7991\n",
      "Validation Loss: 1492.4745\n",
      "Epoch [113/300], Loss: 390.5362\n",
      "Validation Loss: 287.2517\n",
      "Best model saved at epoch 113 with val_loss 287.2517\n",
      "Epoch [114/300], Loss: 380.7275\n",
      "Validation Loss: 460.6042\n",
      "Epoch [115/300], Loss: 390.0893\n",
      "Validation Loss: 286.7169\n",
      "Best model saved at epoch 115 with val_loss 286.7169\n",
      "Epoch [116/300], Loss: 377.7315\n",
      "Validation Loss: 783.9241\n",
      "Epoch [117/300], Loss: 392.2368\n",
      "Validation Loss: 1428.6536\n",
      "Epoch [118/300], Loss: 365.9018\n",
      "Validation Loss: 733.6382\n",
      "Epoch [119/300], Loss: 390.3295\n",
      "Validation Loss: 467.3984\n",
      "Epoch [120/300], Loss: 398.8560\n",
      "Validation Loss: 1883.0206\n",
      "Epoch [121/300], Loss: 393.0837\n",
      "Validation Loss: 1343.5815\n",
      "Epoch [122/300], Loss: 409.3945\n",
      "Validation Loss: 1812.3431\n",
      "Epoch [123/300], Loss: 370.4071\n",
      "Validation Loss: 1303.8975\n",
      "Epoch [124/300], Loss: 388.9233\n",
      "Validation Loss: 242.8650\n",
      "Best model saved at epoch 124 with val_loss 242.8650\n",
      "Epoch [125/300], Loss: 368.8809\n",
      "Validation Loss: 2155.1044\n",
      "Epoch [126/300], Loss: 374.9941\n",
      "Validation Loss: 1332.4579\n",
      "Epoch [127/300], Loss: 377.3700\n",
      "Validation Loss: 1429.9951\n",
      "Epoch [128/300], Loss: 402.3010\n",
      "Validation Loss: 1255.4957\n",
      "Epoch [129/300], Loss: 368.2146\n",
      "Validation Loss: 1350.9616\n",
      "Epoch [130/300], Loss: 379.8745\n",
      "Validation Loss: 1296.5846\n",
      "Epoch [131/300], Loss: 375.7226\n",
      "Validation Loss: 305.3207\n",
      "Epoch [132/300], Loss: 364.6578\n",
      "Validation Loss: 1360.0487\n",
      "Epoch [133/300], Loss: 378.9889\n",
      "Validation Loss: 628.5356\n",
      "Epoch [134/300], Loss: 409.8775\n",
      "Validation Loss: 891.4527\n",
      "Epoch [135/300], Loss: 364.5943\n",
      "Validation Loss: 912.4330\n",
      "Epoch [136/300], Loss: 380.8407\n",
      "Validation Loss: 837.0924\n",
      "Epoch [137/300], Loss: 355.1903\n",
      "Validation Loss: 261.8316\n",
      "Epoch [138/300], Loss: 361.7583\n",
      "Validation Loss: 1234.7886\n",
      "Epoch [139/300], Loss: 366.2408\n",
      "Validation Loss: 470.8867\n",
      "Epoch [140/300], Loss: 333.9762\n",
      "Validation Loss: 608.4239\n",
      "Epoch [141/300], Loss: 376.0498\n",
      "Validation Loss: 1195.6270\n",
      "Epoch [142/300], Loss: 371.0266\n",
      "Validation Loss: 551.4173\n",
      "Epoch [143/300], Loss: 379.5549\n",
      "Validation Loss: 656.1979\n",
      "Epoch [144/300], Loss: 363.9643\n",
      "Validation Loss: 1612.2981\n",
      "Epoch [145/300], Loss: 378.8671\n",
      "Validation Loss: 1950.8284\n",
      "Epoch [146/300], Loss: 361.6052\n",
      "Validation Loss: 521.4088\n",
      "Epoch [147/300], Loss: 373.3352\n",
      "Validation Loss: 1722.2409\n",
      "Epoch [148/300], Loss: 347.9856\n",
      "Validation Loss: 761.1319\n",
      "Epoch [149/300], Loss: 368.2369\n",
      "Validation Loss: 945.6928\n",
      "Epoch [150/300], Loss: 350.1219\n",
      "Validation Loss: 1126.3875\n",
      "Epoch [151/300], Loss: 351.6188\n",
      "Validation Loss: 293.8107\n",
      "Epoch [152/300], Loss: 370.0689\n",
      "Validation Loss: 455.8215\n",
      "Epoch [153/300], Loss: 370.3754\n",
      "Validation Loss: 834.9367\n",
      "Epoch [154/300], Loss: 358.9227\n",
      "Validation Loss: 1550.1458\n",
      "Epoch [155/300], Loss: 374.0975\n",
      "Validation Loss: 922.7234\n",
      "Epoch [156/300], Loss: 357.6337\n",
      "Validation Loss: 858.2745\n",
      "Epoch [157/300], Loss: 354.1701\n",
      "Validation Loss: 833.6768\n",
      "Epoch [158/300], Loss: 375.3597\n",
      "Validation Loss: 1797.4794\n",
      "Epoch [159/300], Loss: 360.2652\n",
      "Validation Loss: 1028.7455\n",
      "Epoch [160/300], Loss: 340.6788\n",
      "Validation Loss: 1043.9089\n",
      "Epoch [161/300], Loss: 346.0128\n",
      "Validation Loss: 1490.0257\n",
      "Epoch [162/300], Loss: 351.9058\n",
      "Validation Loss: 661.8267\n",
      "Epoch [163/300], Loss: 360.4492\n",
      "Validation Loss: 1331.7965\n",
      "Epoch [164/300], Loss: 357.5805\n",
      "Validation Loss: 1771.3328\n",
      "Epoch [165/300], Loss: 359.8456\n",
      "Validation Loss: 733.9435\n",
      "Epoch [166/300], Loss: 350.0662\n",
      "Validation Loss: 1074.5709\n",
      "Epoch [167/300], Loss: 344.1407\n",
      "Validation Loss: 432.3313\n",
      "Epoch [168/300], Loss: 351.3376\n",
      "Validation Loss: 1442.3137\n",
      "Epoch [169/300], Loss: 348.1276\n",
      "Validation Loss: 482.3809\n",
      "Epoch [170/300], Loss: 370.5583\n",
      "Validation Loss: 2294.8890\n",
      "Epoch [171/300], Loss: 350.5909\n",
      "Validation Loss: 343.4002\n",
      "Epoch [172/300], Loss: 344.7656\n",
      "Validation Loss: 594.2104\n",
      "Epoch [173/300], Loss: 341.4586\n",
      "Validation Loss: 525.9333\n",
      "Epoch [174/300], Loss: 355.6784\n",
      "Validation Loss: 517.4197\n",
      "Epoch [175/300], Loss: 331.0935\n",
      "Validation Loss: 1090.6733\n",
      "Epoch [176/300], Loss: 331.1282\n",
      "Validation Loss: 1318.1296\n",
      "Epoch [177/300], Loss: 349.4245\n",
      "Validation Loss: 1288.9401\n",
      "Epoch [178/300], Loss: 328.7569\n",
      "Validation Loss: 1309.5198\n",
      "Epoch [179/300], Loss: 363.1858\n",
      "Validation Loss: 2089.0452\n",
      "Epoch [180/300], Loss: 345.9494\n",
      "Validation Loss: 1703.0526\n",
      "Epoch [181/300], Loss: 345.7302\n",
      "Validation Loss: 3529.4508\n",
      "Epoch [182/300], Loss: 350.5019\n",
      "Validation Loss: 595.6425\n",
      "Epoch [183/300], Loss: 354.8248\n",
      "Validation Loss: 539.8425\n",
      "Epoch [184/300], Loss: 377.5574\n",
      "Validation Loss: 1344.3795\n",
      "Epoch [185/300], Loss: 334.5424\n",
      "Validation Loss: 374.5493\n",
      "Epoch [186/300], Loss: 343.3726\n",
      "Validation Loss: 1122.4179\n",
      "Epoch [187/300], Loss: 330.6209\n",
      "Validation Loss: 858.0588\n",
      "Epoch [188/300], Loss: 344.2418\n",
      "Validation Loss: 1235.2639\n",
      "Epoch [189/300], Loss: 328.2903\n",
      "Validation Loss: 674.0668\n",
      "Epoch [190/300], Loss: 341.6990\n",
      "Validation Loss: 601.8648\n",
      "Epoch [191/300], Loss: 345.3276\n",
      "Validation Loss: 607.3584\n",
      "Epoch [192/300], Loss: 347.5805\n",
      "Validation Loss: 248.8291\n",
      "Epoch [193/300], Loss: 356.9840\n",
      "Validation Loss: 353.3469\n",
      "Epoch [194/300], Loss: 338.1016\n",
      "Validation Loss: 1250.3874\n",
      "Epoch [195/300], Loss: 338.8045\n",
      "Validation Loss: 935.5844\n",
      "Epoch [196/300], Loss: 346.2122\n",
      "Validation Loss: 2365.1542\n",
      "Epoch [197/300], Loss: 349.5968\n",
      "Validation Loss: 2397.6974\n",
      "Epoch [198/300], Loss: 347.4673\n",
      "Validation Loss: 1982.5921\n",
      "Epoch [199/300], Loss: 353.1436\n",
      "Validation Loss: 1597.3554\n",
      "Epoch [200/300], Loss: 336.8070\n",
      "Validation Loss: 1161.0940\n",
      "Epoch [201/300], Loss: 337.2175\n",
      "Validation Loss: 308.5696\n",
      "Epoch [202/300], Loss: 347.4888\n",
      "Validation Loss: 168.9368\n",
      "Best model saved at epoch 202 with val_loss 168.9368\n",
      "Epoch [203/300], Loss: 337.6009\n",
      "Validation Loss: 269.6167\n",
      "Epoch [204/300], Loss: 327.1312\n",
      "Validation Loss: 198.9339\n",
      "Epoch [205/300], Loss: 320.1243\n",
      "Validation Loss: 304.6098\n",
      "Epoch [206/300], Loss: 341.8970\n",
      "Validation Loss: 188.8705\n",
      "Epoch [207/300], Loss: 322.2326\n",
      "Validation Loss: 223.1514\n",
      "Epoch [208/300], Loss: 317.8840\n",
      "Validation Loss: 218.1485\n",
      "Epoch [209/300], Loss: 305.1761\n",
      "Validation Loss: 179.0014\n",
      "Epoch [210/300], Loss: 305.9157\n",
      "Validation Loss: 244.6330\n",
      "Epoch [211/300], Loss: 315.5865\n",
      "Validation Loss: 205.9082\n",
      "Epoch [212/300], Loss: 308.3508\n",
      "Validation Loss: 171.3147\n",
      "Epoch [213/300], Loss: 303.2137\n",
      "Validation Loss: 177.7827\n",
      "Epoch [214/300], Loss: 312.2998\n",
      "Validation Loss: 171.1346\n",
      "Epoch [215/300], Loss: 319.7403\n",
      "Validation Loss: 205.8441\n",
      "Epoch [216/300], Loss: 312.8239\n",
      "Validation Loss: 227.5715\n",
      "Epoch [217/300], Loss: 318.2324\n",
      "Validation Loss: 185.9118\n",
      "Epoch [218/300], Loss: 306.8085\n",
      "Validation Loss: 239.0024\n",
      "Epoch [219/300], Loss: 309.3061\n",
      "Validation Loss: 181.3740\n",
      "Epoch [220/300], Loss: 301.4272\n",
      "Validation Loss: 207.3548\n",
      "Epoch [221/300], Loss: 305.8665\n",
      "Validation Loss: 258.0354\n",
      "Epoch [222/300], Loss: 318.3126\n",
      "Validation Loss: 220.7683\n",
      "Epoch [223/300], Loss: 307.1294\n",
      "Validation Loss: 212.6640\n",
      "Epoch [224/300], Loss: 314.0995\n",
      "Validation Loss: 188.8837\n",
      "Epoch [225/300], Loss: 309.9065\n",
      "Validation Loss: 164.8832\n",
      "Best model saved at epoch 225 with val_loss 164.8832\n",
      "Epoch [226/300], Loss: 314.6122\n",
      "Validation Loss: 192.2059\n",
      "Epoch [227/300], Loss: 307.3381\n",
      "Validation Loss: 213.8675\n",
      "Epoch [228/300], Loss: 312.0978\n",
      "Validation Loss: 165.3357\n",
      "Epoch [229/300], Loss: 300.5433\n",
      "Validation Loss: 177.1843\n",
      "Epoch [230/300], Loss: 312.4753\n",
      "Validation Loss: 187.8177\n",
      "Epoch [231/300], Loss: 319.6726\n",
      "Validation Loss: 195.9230\n",
      "Epoch [232/300], Loss: 311.9039\n",
      "Validation Loss: 161.3679\n",
      "Best model saved at epoch 232 with val_loss 161.3679\n",
      "Epoch [233/300], Loss: 300.0682\n",
      "Validation Loss: 190.2833\n",
      "Epoch [234/300], Loss: 309.0950\n",
      "Validation Loss: 197.8406\n",
      "Epoch [235/300], Loss: 310.6572\n",
      "Validation Loss: 225.7812\n",
      "Epoch [236/300], Loss: 325.0235\n",
      "Validation Loss: 233.7857\n",
      "Epoch [237/300], Loss: 298.0435\n",
      "Validation Loss: 252.3753\n",
      "Epoch [238/300], Loss: 311.7717\n",
      "Validation Loss: 221.0559\n",
      "Epoch [239/300], Loss: 313.0042\n",
      "Validation Loss: 240.9302\n",
      "Epoch [240/300], Loss: 307.9704\n",
      "Validation Loss: 172.4844\n",
      "Epoch [241/300], Loss: 298.1967\n",
      "Validation Loss: 170.6118\n",
      "Epoch [242/300], Loss: 308.9728\n",
      "Validation Loss: 264.1102\n",
      "Epoch [243/300], Loss: 309.0198\n",
      "Validation Loss: 184.4686\n",
      "Epoch [244/300], Loss: 301.3669\n",
      "Validation Loss: 291.2203\n",
      "Epoch [245/300], Loss: 297.0774\n",
      "Validation Loss: 159.3096\n",
      "Best model saved at epoch 245 with val_loss 159.3096\n",
      "Epoch [246/300], Loss: 308.6581\n",
      "Validation Loss: 219.3362\n",
      "Epoch [247/300], Loss: 307.5685\n",
      "Validation Loss: 202.8506\n",
      "Epoch [248/300], Loss: 308.3264\n",
      "Validation Loss: 209.4151\n",
      "Epoch [249/300], Loss: 300.8586\n",
      "Validation Loss: 140.4312\n",
      "Best model saved at epoch 249 with val_loss 140.4312\n",
      "Epoch [250/300], Loss: 303.2247\n",
      "Validation Loss: 363.6794\n",
      "Epoch [251/300], Loss: 308.0065\n",
      "Validation Loss: 201.0122\n",
      "Epoch [252/300], Loss: 304.5281\n",
      "Validation Loss: 197.8234\n",
      "Epoch [253/300], Loss: 315.9100\n",
      "Validation Loss: 234.1192\n",
      "Epoch [254/300], Loss: 296.1734\n",
      "Validation Loss: 286.5234\n",
      "Epoch [255/300], Loss: 298.9265\n",
      "Validation Loss: 206.9677\n",
      "Epoch [256/300], Loss: 304.7106\n",
      "Validation Loss: 150.1480\n",
      "Epoch [257/300], Loss: 298.7223\n",
      "Validation Loss: 162.4646\n",
      "Epoch [258/300], Loss: 299.7656\n",
      "Validation Loss: 166.0801\n",
      "Epoch [259/300], Loss: 305.2545\n",
      "Validation Loss: 259.3719\n",
      "Epoch [260/300], Loss: 308.5423\n",
      "Validation Loss: 183.5457\n",
      "Epoch [261/300], Loss: 309.0273\n",
      "Validation Loss: 209.9962\n",
      "Epoch [262/300], Loss: 286.2982\n",
      "Validation Loss: 204.2415\n",
      "Epoch [263/300], Loss: 306.2152\n",
      "Validation Loss: 166.6516\n",
      "Epoch [264/300], Loss: 308.3572\n",
      "Validation Loss: 149.7847\n",
      "Epoch [265/300], Loss: 302.0582\n",
      "Validation Loss: 175.7090\n",
      "Epoch [266/300], Loss: 296.7630\n",
      "Validation Loss: 191.3775\n",
      "Epoch [267/300], Loss: 309.6967\n",
      "Validation Loss: 265.1007\n",
      "Epoch [268/300], Loss: 306.8146\n",
      "Validation Loss: 198.3811\n",
      "Epoch [269/300], Loss: 303.7340\n",
      "Validation Loss: 208.3745\n",
      "Epoch [270/300], Loss: 295.8097\n",
      "Validation Loss: 262.7142\n",
      "Epoch [271/300], Loss: 308.2060\n",
      "Validation Loss: 145.2902\n",
      "Epoch [272/300], Loss: 324.5037\n",
      "Validation Loss: 185.1662\n",
      "Epoch [273/300], Loss: 305.9819\n",
      "Validation Loss: 245.3149\n",
      "Epoch [274/300], Loss: 311.1117\n",
      "Validation Loss: 173.1301\n",
      "Epoch [275/300], Loss: 302.6347\n",
      "Validation Loss: 187.9057\n",
      "Epoch [276/300], Loss: 286.9112\n",
      "Validation Loss: 198.3090\n",
      "Epoch [277/300], Loss: 293.7340\n",
      "Validation Loss: 166.6196\n",
      "Epoch [278/300], Loss: 309.7472\n",
      "Validation Loss: 212.6835\n",
      "Epoch [279/300], Loss: 303.5874\n",
      "Validation Loss: 163.5606\n",
      "Epoch [280/300], Loss: 297.2301\n",
      "Validation Loss: 224.0779\n",
      "Epoch [281/300], Loss: 282.6217\n",
      "Validation Loss: 150.8393\n",
      "Epoch [282/300], Loss: 300.3036\n",
      "Validation Loss: 218.9725\n",
      "Epoch [283/300], Loss: 298.3522\n",
      "Validation Loss: 161.5935\n",
      "Epoch [284/300], Loss: 306.4364\n",
      "Validation Loss: 198.3348\n",
      "Epoch [285/300], Loss: 287.8400\n",
      "Validation Loss: 148.6705\n",
      "Epoch [286/300], Loss: 297.4720\n",
      "Validation Loss: 201.1925\n",
      "Epoch [287/300], Loss: 304.6827\n",
      "Validation Loss: 206.6652\n",
      "Epoch [288/300], Loss: 294.2779\n",
      "Validation Loss: 237.7994\n",
      "Epoch [289/300], Loss: 306.0401\n",
      "Validation Loss: 240.1991\n",
      "Epoch [290/300], Loss: 321.8406\n",
      "Validation Loss: 294.2990\n",
      "Epoch [291/300], Loss: 301.7532\n",
      "Validation Loss: 161.1751\n",
      "Epoch [292/300], Loss: 286.3888\n",
      "Validation Loss: 266.6526\n",
      "Epoch [293/300], Loss: 301.2620\n",
      "Validation Loss: 164.6614\n",
      "Epoch [294/300], Loss: 296.8481\n",
      "Validation Loss: 234.6668\n",
      "Epoch [295/300], Loss: 301.2562\n",
      "Validation Loss: 205.4684\n",
      "Epoch [296/300], Loss: 295.9026\n",
      "Validation Loss: 196.7175\n",
      "Epoch [297/300], Loss: 299.9842\n",
      "Validation Loss: 286.3328\n",
      "Epoch [298/300], Loss: 302.1213\n",
      "Validation Loss: 209.2566\n",
      "Epoch [299/300], Loss: 304.1490\n",
      "Validation Loss: 162.6013\n",
      "Epoch [300/300], Loss: 301.1593\n",
      "Validation Loss: 159.6706\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# Ruta a las imágenes y etiquetas\n",
    "img_dir = r'C:\\CatFLW dataset\\images'\n",
    "labels_dir = r'C:\\CatFLW dataset\\labels'\n",
    "output_dir = r'C:\\CatFLW dataset\\cropped_images'  # Ruta para guardar los recortes\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dataset personalizado para cargar imágenes y etiquetas\n",
    "class CatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            bounding_box = labels['bounding_boxes']  # Coordenadas de la caja delimitadora\n",
    "\n",
    "        # Aplicar las transformaciones de imagen y bounding box\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]  # Actualizar el bounding box\n",
    "        \n",
    "        return image, torch.tensor(bounding_box).float(), img_name  # Devuelve también el nombre del archivo\n",
    "\n",
    "# Aumentaciones para el conjunto de entrenamiento utilizando albumentations\n",
    "augmentation_transforms = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.9),  # Rotación aleatoria con 90% de probabilidad\n",
    "    A.ColorJitter(p=0.9),  # Cambio en el balance de color, brillo, contraste y nitidez con 90% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.9),  # Cambio en el brillo y contraste con 90% de probabilidad\n",
    "    A.GaussianBlur(p=0.9),  # Aplicación de máscaras de desenfoque con 90% de probabilidad\n",
    "    A.GaussNoise(p=0.9),  # Ruido aleatorio con 90% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Transformación básica (sin aumento) para validación\n",
    "basic_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Dataset con aumentaciones aplicadas solo en el conjunto de entrenamiento\n",
    "class AugmentedCatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None, augment_transform=None):\n",
    "        self.dataset = CatFaceDataset(img_dir, labels_dir, transform)\n",
    "        self.augment_transform = augment_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, bounding_box, img_name = self.dataset[idx]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato numpy array antes de pasarla a Albumentations\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).cpu().numpy()  # Convertir de tensor a numpy array si es necesario\n",
    "\n",
    "        # Aplicar las transformaciones de aumento\n",
    "        if random.random() < 0.9:\n",
    "            augmented = self.augment_transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato [3, 224, 224] antes de devolverla\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.tensor(image).permute(2, 0, 1)  # Convertir de numpy a tensor y reorganizar dimensiones\n",
    "\n",
    "        return image, torch.tensor(bounding_box).float(), img_name\n",
    "\n",
    "# Función de colación personalizada para asegurarse de que los bounding boxes sean tensors\n",
    "def custom_collate_fn(batch):\n",
    "    images, bounding_boxes, img_names = zip(*batch)\n",
    "    \n",
    "    # Convierte las imágenes a tensores\n",
    "    images = torch.stack([img for img in images])\n",
    "    \n",
    "    # Convierte las bounding boxes a tensores\n",
    "    bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n",
    "    \n",
    "    return images, bounding_boxes, img_names\n",
    "\n",
    "# Crear el dataset con aumento en el conjunto de entrenamiento\n",
    "augmented_dataset = AugmentedCatFaceDataset(img_dir, labels_dir, transform=basic_transform, augment_transform=augmentation_transforms)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación (80%, 20%)\n",
    "train_size = int(0.8 * len(augmented_dataset))\n",
    "val_size = len(augmented_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(augmented_dataset, [train_size, val_size])\n",
    "\n",
    "# Crear los dataloaders con la función de colación personalizada\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Modelo basado en DenseNet-121 con Dropout en capas fully connected\n",
    "class DenseNet121BoundingBox(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121BoundingBox, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()  # Eliminar la capa fully connected original\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)  # Dropout después de fc1\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)  # Dropout después de fc2\n",
    "        self.fc3 = nn.Linear(64, 4)  # 4 coordenadas para las esquinas de la caja\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout1(x)  # Aplicar Dropout\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.dropout2(x)  # Aplicar Dropout\n",
    "        x = self.fc3(x)  # La salida es un vector con 4 coordenadas\n",
    "        return x\n",
    "\n",
    "\n",
    "# Crear modelo, optimizador y función de pérdida\n",
    "model = DenseNet121BoundingBox().cuda()  # Mover el modelo a la GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Reduce el LR cuando el val_loss no mejora\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    model = model.cuda()  # Asegurarse de que el modelo esté en la GPU\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterar sobre el dataloader de entrenamiento\n",
    "        for images, bounding_boxes, img_names in train_dataloader:\n",
    "            images = images.cuda()  # Mover imágenes a la GPU\n",
    "            bounding_boxes = bounding_boxes.cuda()  # Mover bounding boxes a la GPU\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, bounding_boxes)\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calcular la pérdida promedio por época\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación (si se proporciona un val_dataloader)\n",
    "        if val_dataloader:\n",
    "            model.eval()  # Modo de evaluación\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_bounding_boxes, _ in val_dataloader:\n",
    "                    val_images = val_images.cuda()\n",
    "                    val_bounding_boxes = val_bounding_boxes.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_bounding_boxes).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "            # Guardar el mejor modelo basado en la validación\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_model5.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "        \n",
    "            # Ajustar el LR basado en el val_loss usando el scheduler\n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)  # Reduce el LR si no mejora el val_loss\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_5252\\1611153854.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return image, torch.tensor(bounding_box).float(), img_name\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_5252\\1611153854.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14268.1407\n",
      "Validation Loss: 12245.7245\n",
      "Best model saved at epoch 1 with val_loss 12245.7245\n",
      "Epoch [2/300], Loss: 7465.4935\n",
      "Validation Loss: 3354.6538\n",
      "Best model saved at epoch 2 with val_loss 3354.6538\n",
      "Epoch [3/300], Loss: 1548.3413\n",
      "Validation Loss: 1153.5049\n",
      "Best model saved at epoch 3 with val_loss 1153.5049\n",
      "Epoch [4/300], Loss: 1040.8630\n",
      "Validation Loss: 1041.8532\n",
      "Best model saved at epoch 4 with val_loss 1041.8532\n",
      "Epoch [5/300], Loss: 956.2962\n",
      "Validation Loss: 1012.6812\n",
      "Best model saved at epoch 5 with val_loss 1012.6812\n",
      "Epoch [6/300], Loss: 913.9164\n",
      "Validation Loss: 1059.3733\n",
      "Epoch [7/300], Loss: 904.2026\n",
      "Validation Loss: 1042.3232\n",
      "Epoch [8/300], Loss: 884.3005\n",
      "Validation Loss: 934.5096\n",
      "Best model saved at epoch 8 with val_loss 934.5096\n",
      "Epoch [9/300], Loss: 889.2442\n",
      "Validation Loss: 948.8270\n",
      "Epoch [10/300], Loss: 870.8088\n",
      "Validation Loss: 922.4625\n",
      "Best model saved at epoch 10 with val_loss 922.4625\n",
      "Epoch [11/300], Loss: 870.0405\n",
      "Validation Loss: 981.0921\n",
      "Epoch [12/300], Loss: 876.0189\n",
      "Validation Loss: 985.0611\n",
      "Epoch [13/300], Loss: 862.2909\n",
      "Validation Loss: 990.7192\n",
      "Epoch [14/300], Loss: 860.9655\n",
      "Validation Loss: 972.1005\n",
      "Epoch [15/300], Loss: 840.1181\n",
      "Validation Loss: 864.9820\n",
      "Best model saved at epoch 15 with val_loss 864.9820\n",
      "Epoch [16/300], Loss: 802.2467\n",
      "Validation Loss: 816.6899\n",
      "Best model saved at epoch 16 with val_loss 816.6899\n",
      "Epoch [17/300], Loss: 740.9747\n",
      "Validation Loss: 858.0915\n",
      "Epoch [18/300], Loss: 648.4265\n",
      "Validation Loss: 864.8337\n",
      "Epoch [19/300], Loss: 559.2339\n",
      "Validation Loss: 586.4620\n",
      "Best model saved at epoch 19 with val_loss 586.4620\n",
      "Epoch [20/300], Loss: 494.2878\n",
      "Validation Loss: 701.1329\n",
      "Epoch [21/300], Loss: 477.3385\n",
      "Validation Loss: 735.8211\n",
      "Epoch [22/300], Loss: 462.6002\n",
      "Validation Loss: 614.7396\n",
      "Epoch [23/300], Loss: 451.7231\n",
      "Validation Loss: 556.7067\n",
      "Best model saved at epoch 23 with val_loss 556.7067\n",
      "Epoch [24/300], Loss: 420.5180\n",
      "Validation Loss: 670.7219\n",
      "Epoch [25/300], Loss: 446.9140\n",
      "Validation Loss: 695.0987\n",
      "Epoch [26/300], Loss: 406.1460\n",
      "Validation Loss: 512.6627\n",
      "Best model saved at epoch 26 with val_loss 512.6627\n",
      "Epoch [27/300], Loss: 356.9022\n",
      "Validation Loss: 418.9187\n",
      "Best model saved at epoch 27 with val_loss 418.9187\n",
      "Epoch [28/300], Loss: 315.9390\n",
      "Validation Loss: 451.8528\n",
      "Epoch [29/300], Loss: 304.9482\n",
      "Validation Loss: 637.7642\n",
      "Epoch [30/300], Loss: 309.6261\n",
      "Validation Loss: 441.3707\n",
      "Epoch [31/300], Loss: 281.5216\n",
      "Validation Loss: 1120.3065\n",
      "Epoch [32/300], Loss: 249.4429\n",
      "Validation Loss: 398.6115\n",
      "Best model saved at epoch 32 with val_loss 398.6115\n",
      "Epoch [33/300], Loss: 236.9672\n",
      "Validation Loss: 643.7218\n",
      "Epoch [34/300], Loss: 225.0780\n",
      "Validation Loss: 313.2891\n",
      "Best model saved at epoch 34 with val_loss 313.2891\n",
      "Epoch [35/300], Loss: 229.3535\n",
      "Validation Loss: 658.7973\n",
      "Epoch [36/300], Loss: 251.2340\n",
      "Validation Loss: 334.8436\n",
      "Epoch [37/300], Loss: 226.8822\n",
      "Validation Loss: 634.1272\n",
      "Epoch [38/300], Loss: 206.6560\n",
      "Validation Loss: 245.5665\n",
      "Best model saved at epoch 38 with val_loss 245.5665\n",
      "Epoch [39/300], Loss: 181.3587\n",
      "Validation Loss: 419.0650\n",
      "Epoch [40/300], Loss: 201.6229\n",
      "Validation Loss: 366.2062\n",
      "Epoch [41/300], Loss: 168.4108\n",
      "Validation Loss: 529.6798\n",
      "Epoch [42/300], Loss: 172.9333\n",
      "Validation Loss: 272.3724\n",
      "Epoch [43/300], Loss: 174.9206\n",
      "Validation Loss: 424.1830\n",
      "Epoch [44/300], Loss: 169.1469\n",
      "Validation Loss: 407.4124\n",
      "Epoch [45/300], Loss: 165.0070\n",
      "Validation Loss: 231.1227\n",
      "Best model saved at epoch 45 with val_loss 231.1227\n",
      "Epoch [46/300], Loss: 167.6280\n",
      "Validation Loss: 764.3413\n",
      "Epoch [47/300], Loss: 160.0456\n",
      "Validation Loss: 244.6014\n",
      "Epoch [48/300], Loss: 171.1778\n",
      "Validation Loss: 284.7807\n",
      "Epoch [49/300], Loss: 160.7806\n",
      "Validation Loss: 227.9294\n",
      "Best model saved at epoch 49 with val_loss 227.9294\n",
      "Epoch [50/300], Loss: 164.1637\n",
      "Validation Loss: 271.9225\n",
      "Epoch [51/300], Loss: 149.6325\n",
      "Validation Loss: 255.6839\n",
      "Epoch [52/300], Loss: 155.3041\n",
      "Validation Loss: 372.7030\n",
      "Epoch [53/300], Loss: 150.6216\n",
      "Validation Loss: 479.0652\n",
      "Epoch [54/300], Loss: 135.0202\n",
      "Validation Loss: 541.9748\n",
      "Epoch [55/300], Loss: 141.7871\n",
      "Validation Loss: 227.6111\n",
      "Best model saved at epoch 55 with val_loss 227.6111\n",
      "Epoch [56/300], Loss: 120.5675\n",
      "Validation Loss: 334.3640\n",
      "Epoch [57/300], Loss: 135.7630\n",
      "Validation Loss: 801.4379\n",
      "Epoch [58/300], Loss: 120.5637\n",
      "Validation Loss: 183.0197\n",
      "Best model saved at epoch 58 with val_loss 183.0197\n",
      "Epoch [59/300], Loss: 140.4268\n",
      "Validation Loss: 206.1472\n",
      "Epoch [60/300], Loss: 118.8256\n",
      "Validation Loss: 199.7111\n",
      "Epoch [61/300], Loss: 123.7689\n",
      "Validation Loss: 374.4429\n",
      "Epoch [62/300], Loss: 124.8883\n",
      "Validation Loss: 254.4166\n",
      "Epoch [63/300], Loss: 121.4805\n",
      "Validation Loss: 162.0789\n",
      "Best model saved at epoch 63 with val_loss 162.0789\n",
      "Epoch [64/300], Loss: 147.7048\n",
      "Validation Loss: 290.7254\n",
      "Epoch [65/300], Loss: 143.2886\n",
      "Validation Loss: 676.2381\n",
      "Epoch [66/300], Loss: 156.4780\n",
      "Validation Loss: 248.4051\n",
      "Epoch [67/300], Loss: 143.2268\n",
      "Validation Loss: 292.9925\n",
      "Epoch [68/300], Loss: 143.0376\n",
      "Validation Loss: 863.1944\n",
      "Epoch [69/300], Loss: 136.1823\n",
      "Validation Loss: 268.8557\n",
      "Epoch [70/300], Loss: 140.5827\n",
      "Validation Loss: 229.2080\n",
      "Epoch [71/300], Loss: 112.2465\n",
      "Validation Loss: 263.2261\n",
      "Epoch [72/300], Loss: 112.8251\n",
      "Validation Loss: 340.8829\n",
      "Epoch [73/300], Loss: 118.3208\n",
      "Validation Loss: 180.1443\n",
      "Epoch [74/300], Loss: 96.8596\n",
      "Validation Loss: 226.0493\n",
      "Epoch [75/300], Loss: 115.9670\n",
      "Validation Loss: 180.1381\n",
      "Epoch [76/300], Loss: 117.1728\n",
      "Validation Loss: 391.8666\n",
      "Epoch [77/300], Loss: 99.2623\n",
      "Validation Loss: 189.5126\n",
      "Epoch [78/300], Loss: 117.6383\n",
      "Validation Loss: 262.2365\n",
      "Epoch [79/300], Loss: 120.1398\n",
      "Validation Loss: 228.9541\n",
      "Epoch [80/300], Loss: 106.6610\n",
      "Validation Loss: 601.9166\n",
      "Epoch [81/300], Loss: 112.9462\n",
      "Validation Loss: 303.6717\n",
      "Epoch [82/300], Loss: 141.8118\n",
      "Validation Loss: 2140.5993\n",
      "Epoch [83/300], Loss: 153.3590\n",
      "Validation Loss: 563.5822\n",
      "Epoch [84/300], Loss: 133.3021\n",
      "Validation Loss: 217.1125\n",
      "Epoch [85/300], Loss: 137.6643\n",
      "Validation Loss: 284.0213\n",
      "Epoch [86/300], Loss: 121.2626\n",
      "Validation Loss: 370.2677\n",
      "Epoch [87/300], Loss: 96.4748\n",
      "Validation Loss: 251.2227\n",
      "Epoch [88/300], Loss: 109.6111\n",
      "Validation Loss: 240.4206\n",
      "Epoch [89/300], Loss: 114.8188\n",
      "Validation Loss: 202.7893\n",
      "Epoch [90/300], Loss: 92.6068\n",
      "Validation Loss: 788.1656\n",
      "Epoch [91/300], Loss: 96.3460\n",
      "Validation Loss: 178.9325\n",
      "Epoch [92/300], Loss: 113.9977\n",
      "Validation Loss: 403.6791\n",
      "Epoch [93/300], Loss: 105.6512\n",
      "Validation Loss: 350.7840\n",
      "Epoch [94/300], Loss: 126.0066\n",
      "Validation Loss: 265.5650\n",
      "Epoch [95/300], Loss: 132.3196\n",
      "Validation Loss: 754.1841\n",
      "Epoch [96/300], Loss: 125.3400\n",
      "Validation Loss: 227.7314\n",
      "Epoch [97/300], Loss: 114.4153\n",
      "Validation Loss: 549.4900\n",
      "Epoch [98/300], Loss: 119.6738\n",
      "Validation Loss: 251.2967\n",
      "Epoch [99/300], Loss: 110.3115\n",
      "Validation Loss: 192.8851\n",
      "Epoch [100/300], Loss: 117.7595\n",
      "Validation Loss: 173.8209\n",
      "Epoch [101/300], Loss: 94.3683\n",
      "Validation Loss: 176.4859\n",
      "Epoch [102/300], Loss: 97.7144\n",
      "Validation Loss: 180.3705\n",
      "Epoch [103/300], Loss: 100.2695\n",
      "Validation Loss: 156.0916\n",
      "Best model saved at epoch 103 with val_loss 156.0916\n",
      "Epoch [104/300], Loss: 100.4757\n",
      "Validation Loss: 229.5774\n",
      "Epoch [105/300], Loss: 116.0062\n",
      "Validation Loss: 251.0574\n",
      "Epoch [106/300], Loss: 96.2690\n",
      "Validation Loss: 296.2118\n",
      "Epoch [107/300], Loss: 116.4195\n",
      "Validation Loss: 219.8147\n",
      "Epoch [108/300], Loss: 101.8038\n",
      "Validation Loss: 226.9683\n",
      "Epoch [109/300], Loss: 136.1925\n",
      "Validation Loss: 374.2189\n",
      "Epoch [110/300], Loss: 103.7365\n",
      "Validation Loss: 218.8359\n",
      "Epoch [111/300], Loss: 109.4903\n",
      "Validation Loss: 173.2930\n",
      "Epoch [112/300], Loss: 97.5616\n",
      "Validation Loss: 498.4700\n",
      "Epoch [113/300], Loss: 116.7599\n",
      "Validation Loss: 208.9680\n",
      "Epoch [114/300], Loss: 90.8109\n",
      "Validation Loss: 396.7804\n",
      "Epoch [115/300], Loss: 109.0232\n",
      "Validation Loss: 220.2967\n",
      "Epoch [116/300], Loss: 107.3040\n",
      "Validation Loss: 317.5823\n",
      "Epoch [117/300], Loss: 154.8649\n",
      "Validation Loss: 702.5665\n",
      "Epoch [118/300], Loss: 138.3490\n",
      "Validation Loss: 199.0284\n",
      "Epoch [119/300], Loss: 120.3285\n",
      "Validation Loss: 200.0844\n",
      "Epoch [120/300], Loss: 108.4165\n",
      "Validation Loss: 321.7182\n",
      "Epoch [121/300], Loss: 107.0423\n",
      "Validation Loss: 213.1420\n",
      "Epoch [122/300], Loss: 105.3716\n",
      "Validation Loss: 710.7901\n",
      "Epoch [123/300], Loss: 101.7626\n",
      "Validation Loss: 558.3864\n",
      "Epoch [124/300], Loss: 117.4852\n",
      "Validation Loss: 256.0325\n",
      "Epoch [125/300], Loss: 110.6458\n",
      "Validation Loss: 351.2628\n",
      "Epoch [126/300], Loss: 85.2095\n",
      "Validation Loss: 342.0097\n",
      "Epoch [127/300], Loss: 98.0334\n",
      "Validation Loss: 152.1599\n",
      "Best model saved at epoch 127 with val_loss 152.1599\n",
      "Epoch [128/300], Loss: 101.1904\n",
      "Validation Loss: 271.7285\n",
      "Epoch [129/300], Loss: 107.3747\n",
      "Validation Loss: 241.6591\n",
      "Epoch [130/300], Loss: 107.1835\n",
      "Validation Loss: 189.8876\n",
      "Epoch [131/300], Loss: 114.5088\n",
      "Validation Loss: 184.0114\n",
      "Epoch [132/300], Loss: 102.6316\n",
      "Validation Loss: 174.2639\n",
      "Epoch [133/300], Loss: 104.2199\n",
      "Validation Loss: 189.0339\n",
      "Epoch [134/300], Loss: 100.8247\n",
      "Validation Loss: 611.2981\n",
      "Epoch [135/300], Loss: 102.8157\n",
      "Validation Loss: 235.1761\n",
      "Epoch [136/300], Loss: 116.5235\n",
      "Validation Loss: 192.3880\n",
      "Epoch [137/300], Loss: 93.1432\n",
      "Validation Loss: 481.5489\n",
      "Epoch [138/300], Loss: 117.8482\n",
      "Validation Loss: 228.5210\n",
      "Epoch [139/300], Loss: 80.8478\n",
      "Validation Loss: 202.1974\n",
      "Epoch [140/300], Loss: 104.7167\n",
      "Validation Loss: 276.7916\n",
      "Epoch [141/300], Loss: 100.0333\n",
      "Validation Loss: 193.2082\n",
      "Epoch [142/300], Loss: 103.9766\n",
      "Validation Loss: 152.3269\n",
      "Epoch [143/300], Loss: 93.0832\n",
      "Validation Loss: 176.5425\n",
      "Epoch [144/300], Loss: 99.7319\n",
      "Validation Loss: 189.3480\n",
      "Epoch [145/300], Loss: 107.3901\n",
      "Validation Loss: 260.7007\n",
      "Epoch [146/300], Loss: 92.7051\n",
      "Validation Loss: 154.0936\n",
      "Epoch [147/300], Loss: 84.2648\n",
      "Validation Loss: 457.9478\n",
      "Epoch [148/300], Loss: 94.9052\n",
      "Validation Loss: 151.6926\n",
      "Best model saved at epoch 148 with val_loss 151.6926\n",
      "Epoch [149/300], Loss: 99.3684\n",
      "Validation Loss: 207.7863\n",
      "Epoch [150/300], Loss: 97.8707\n",
      "Validation Loss: 363.3124\n",
      "Epoch [151/300], Loss: 77.9717\n",
      "Validation Loss: 202.8447\n",
      "Epoch [152/300], Loss: 106.6530\n",
      "Validation Loss: 249.6001\n",
      "Epoch [153/300], Loss: 112.5470\n",
      "Validation Loss: 667.6670\n",
      "Epoch [154/300], Loss: 115.3134\n",
      "Validation Loss: 225.5164\n",
      "Epoch [155/300], Loss: 107.8298\n",
      "Validation Loss: 212.0584\n",
      "Epoch [156/300], Loss: 98.9856\n",
      "Validation Loss: 219.3888\n",
      "Epoch [157/300], Loss: 98.7981\n",
      "Validation Loss: 190.4025\n",
      "Epoch [158/300], Loss: 104.0844\n",
      "Validation Loss: 208.6845\n",
      "Epoch [159/300], Loss: 101.2637\n",
      "Validation Loss: 233.9516\n",
      "Epoch [160/300], Loss: 111.2612\n",
      "Validation Loss: 542.8899\n",
      "Epoch [161/300], Loss: 114.7219\n",
      "Validation Loss: 233.9285\n",
      "Epoch [162/300], Loss: 111.9842\n",
      "Validation Loss: 146.8972\n",
      "Best model saved at epoch 162 with val_loss 146.8972\n",
      "Epoch [163/300], Loss: 100.2357\n",
      "Validation Loss: 234.0599\n",
      "Epoch [164/300], Loss: 101.2251\n",
      "Validation Loss: 149.9127\n",
      "Epoch [165/300], Loss: 89.0885\n",
      "Validation Loss: 172.9926\n",
      "Epoch [166/300], Loss: 89.7031\n",
      "Validation Loss: 226.1330\n",
      "Epoch [167/300], Loss: 82.8051\n",
      "Validation Loss: 226.0208\n",
      "Epoch [168/300], Loss: 94.4177\n",
      "Validation Loss: 253.6893\n",
      "Epoch [169/300], Loss: 104.3952\n",
      "Validation Loss: 318.4242\n",
      "Epoch [170/300], Loss: 99.7360\n",
      "Validation Loss: 393.7103\n",
      "Epoch [171/300], Loss: 89.0171\n",
      "Validation Loss: 164.2825\n",
      "Epoch [172/300], Loss: 80.6133\n",
      "Validation Loss: 164.3942\n",
      "Epoch [173/300], Loss: 89.9658\n",
      "Validation Loss: 157.7173\n",
      "Epoch [174/300], Loss: 89.2405\n",
      "Validation Loss: 167.3258\n",
      "Epoch [175/300], Loss: 102.5783\n",
      "Validation Loss: 212.7294\n",
      "Epoch [176/300], Loss: 96.9459\n",
      "Validation Loss: 198.2887\n",
      "Epoch [177/300], Loss: 73.4149\n",
      "Validation Loss: 173.7280\n",
      "Epoch [178/300], Loss: 92.9447\n",
      "Validation Loss: 1305.1881\n",
      "Epoch [179/300], Loss: 105.0322\n",
      "Validation Loss: 163.1769\n",
      "Epoch [180/300], Loss: 95.3758\n",
      "Validation Loss: 256.1038\n",
      "Epoch [181/300], Loss: 82.6090\n",
      "Validation Loss: 196.1595\n",
      "Epoch [182/300], Loss: 90.2204\n",
      "Validation Loss: 131.9632\n",
      "Best model saved at epoch 182 with val_loss 131.9632\n",
      "Epoch [183/300], Loss: 85.4578\n",
      "Validation Loss: 185.5477\n",
      "Epoch [184/300], Loss: 84.2696\n",
      "Validation Loss: 156.0571\n",
      "Epoch [185/300], Loss: 70.5960\n",
      "Validation Loss: 177.9993\n",
      "Epoch [186/300], Loss: 91.5737\n",
      "Validation Loss: 189.9810\n",
      "Epoch [187/300], Loss: 104.9818\n",
      "Validation Loss: 160.8311\n",
      "Epoch [188/300], Loss: 91.6923\n",
      "Validation Loss: 192.8071\n",
      "Epoch [189/300], Loss: 77.1935\n",
      "Validation Loss: 191.8593\n",
      "Epoch [190/300], Loss: 75.4010\n",
      "Validation Loss: 160.1721\n",
      "Epoch [191/300], Loss: 73.7630\n",
      "Validation Loss: 145.1682\n",
      "Epoch [192/300], Loss: 85.9285\n",
      "Validation Loss: 171.9894\n",
      "Epoch [193/300], Loss: 89.6468\n",
      "Validation Loss: 227.7271\n",
      "Epoch [194/300], Loss: 90.7967\n",
      "Validation Loss: 472.5828\n",
      "Epoch [195/300], Loss: 89.5637\n",
      "Validation Loss: 244.4233\n",
      "Epoch [196/300], Loss: 102.2715\n",
      "Validation Loss: 252.7186\n",
      "Epoch [197/300], Loss: 81.3928\n",
      "Validation Loss: 214.1223\n",
      "Epoch [198/300], Loss: 88.4668\n",
      "Validation Loss: 178.9253\n",
      "Epoch [199/300], Loss: 96.3376\n",
      "Validation Loss: 228.2974\n",
      "Epoch [200/300], Loss: 95.7309\n",
      "Validation Loss: 369.7820\n",
      "Epoch [201/300], Loss: 89.2128\n",
      "Validation Loss: 1076.2862\n",
      "Epoch [202/300], Loss: 82.0234\n",
      "Validation Loss: 148.1550\n",
      "Epoch [203/300], Loss: 94.2109\n",
      "Validation Loss: 206.7675\n",
      "Epoch [204/300], Loss: 117.8766\n",
      "Validation Loss: 2254.5566\n",
      "Epoch [205/300], Loss: 103.4412\n",
      "Validation Loss: 213.6475\n",
      "Epoch [206/300], Loss: 85.9099\n",
      "Validation Loss: 222.6895\n",
      "Epoch [207/300], Loss: 78.6241\n",
      "Validation Loss: 206.4250\n",
      "Epoch [208/300], Loss: 82.9176\n",
      "Validation Loss: 215.0779\n",
      "Epoch [209/300], Loss: 88.0265\n",
      "Validation Loss: 186.4279\n",
      "Epoch [210/300], Loss: 77.3264\n",
      "Validation Loss: 196.3712\n",
      "Epoch [211/300], Loss: 83.8333\n",
      "Validation Loss: 164.3871\n",
      "Epoch [212/300], Loss: 84.7256\n",
      "Validation Loss: 163.1073\n",
      "Epoch [213/300], Loss: 87.9203\n",
      "Validation Loss: 371.5818\n",
      "Epoch [214/300], Loss: 104.2253\n",
      "Validation Loss: 262.6942\n",
      "Epoch [215/300], Loss: 99.6176\n",
      "Validation Loss: 166.3761\n",
      "Epoch [216/300], Loss: 84.0340\n",
      "Validation Loss: 218.9707\n",
      "Epoch [217/300], Loss: 95.3038\n",
      "Validation Loss: 340.6065\n",
      "Epoch [218/300], Loss: 84.9748\n",
      "Validation Loss: 209.6492\n",
      "Epoch [219/300], Loss: 96.6799\n",
      "Validation Loss: 176.6814\n",
      "Epoch [220/300], Loss: 97.6230\n",
      "Validation Loss: 156.7544\n",
      "Epoch [221/300], Loss: 79.4627\n",
      "Validation Loss: 205.6940\n",
      "Epoch [222/300], Loss: 89.0321\n",
      "Validation Loss: 139.5236\n",
      "Epoch [223/300], Loss: 77.1192\n",
      "Validation Loss: 187.2872\n",
      "Epoch [224/300], Loss: 91.1113\n",
      "Validation Loss: 155.9628\n",
      "Epoch [225/300], Loss: 82.7246\n",
      "Validation Loss: 152.1825\n",
      "Epoch [226/300], Loss: 79.7374\n",
      "Validation Loss: 179.9728\n",
      "Epoch [227/300], Loss: 64.0357\n",
      "Validation Loss: 163.5480\n",
      "Epoch [228/300], Loss: 83.6156\n",
      "Validation Loss: 191.6681\n",
      "Epoch [229/300], Loss: 79.9680\n",
      "Validation Loss: 222.8153\n",
      "Epoch [230/300], Loss: 101.9056\n",
      "Validation Loss: 461.4318\n",
      "Epoch [231/300], Loss: 91.8519\n",
      "Validation Loss: 238.1610\n",
      "Epoch [232/300], Loss: 104.2553\n",
      "Validation Loss: 238.0604\n",
      "Epoch [233/300], Loss: 78.1827\n",
      "Validation Loss: 181.2102\n",
      "Epoch [234/300], Loss: 105.1428\n",
      "Validation Loss: 151.6293\n",
      "Epoch [235/300], Loss: 85.6283\n",
      "Validation Loss: 176.7140\n",
      "Epoch [236/300], Loss: 83.9158\n",
      "Validation Loss: 176.4925\n",
      "Epoch [237/300], Loss: 80.1714\n",
      "Validation Loss: 168.2861\n",
      "Epoch [238/300], Loss: 72.2459\n",
      "Validation Loss: 186.4611\n",
      "Epoch [239/300], Loss: 66.3769\n",
      "Validation Loss: 192.7645\n",
      "Epoch [240/300], Loss: 77.7261\n",
      "Validation Loss: 324.6672\n",
      "Epoch [241/300], Loss: 91.3021\n",
      "Validation Loss: 195.4591\n",
      "Epoch [242/300], Loss: 86.3066\n",
      "Validation Loss: 183.5197\n",
      "Epoch [243/300], Loss: 81.7305\n",
      "Validation Loss: 196.8933\n",
      "Epoch [244/300], Loss: 84.1500\n",
      "Validation Loss: 287.9865\n",
      "Epoch [245/300], Loss: 83.5936\n",
      "Validation Loss: 343.6017\n",
      "Epoch [246/300], Loss: 87.5715\n",
      "Validation Loss: 148.3538\n",
      "Epoch [247/300], Loss: 80.5187\n",
      "Validation Loss: 216.6419\n",
      "Epoch [248/300], Loss: 79.4146\n",
      "Validation Loss: 253.6149\n",
      "Epoch [249/300], Loss: 81.3990\n",
      "Validation Loss: 220.1980\n",
      "Epoch [250/300], Loss: 105.5614\n",
      "Validation Loss: 333.5018\n",
      "Epoch [251/300], Loss: 98.8984\n",
      "Validation Loss: 392.3924\n",
      "Epoch [252/300], Loss: 97.3263\n",
      "Validation Loss: 582.3434\n",
      "Epoch [253/300], Loss: 72.5132\n",
      "Validation Loss: 182.5949\n",
      "Epoch [254/300], Loss: 90.6446\n",
      "Validation Loss: 226.9493\n",
      "Epoch [255/300], Loss: 83.9440\n",
      "Validation Loss: 278.2769\n",
      "Epoch [256/300], Loss: 85.3117\n",
      "Validation Loss: 174.3606\n",
      "Epoch [257/300], Loss: 104.5636\n",
      "Validation Loss: 231.7235\n",
      "Epoch [258/300], Loss: 83.1580\n",
      "Validation Loss: 208.8068\n",
      "Epoch [259/300], Loss: 85.3887\n",
      "Validation Loss: 176.9393\n",
      "Epoch [260/300], Loss: 72.4576\n",
      "Validation Loss: 176.1882\n",
      "Epoch [261/300], Loss: 75.4946\n",
      "Validation Loss: 147.7477\n",
      "Epoch [262/300], Loss: 85.8193\n",
      "Validation Loss: 160.6795\n",
      "Epoch [263/300], Loss: 73.9606\n",
      "Validation Loss: 154.9443\n",
      "Epoch [264/300], Loss: 85.7325\n",
      "Validation Loss: 163.9519\n",
      "Epoch [265/300], Loss: 76.9524\n",
      "Validation Loss: 170.8783\n",
      "Epoch [266/300], Loss: 92.5669\n",
      "Validation Loss: 139.5288\n",
      "Epoch [267/300], Loss: 74.0445\n",
      "Validation Loss: 162.2691\n",
      "Epoch [268/300], Loss: 88.2690\n",
      "Validation Loss: 190.1426\n",
      "Epoch [269/300], Loss: 81.6924\n",
      "Validation Loss: 157.0505\n",
      "Epoch [270/300], Loss: 88.1872\n",
      "Validation Loss: 132.7280\n",
      "Epoch [271/300], Loss: 85.1181\n",
      "Validation Loss: 161.6826\n",
      "Epoch [272/300], Loss: 72.1164\n",
      "Validation Loss: 143.4398\n",
      "Epoch [273/300], Loss: 73.3721\n",
      "Validation Loss: 152.6583\n",
      "Epoch [274/300], Loss: 80.6440\n",
      "Validation Loss: 155.7491\n",
      "Epoch [275/300], Loss: 91.2942\n",
      "Validation Loss: 170.2512\n",
      "Epoch [276/300], Loss: 78.1484\n",
      "Validation Loss: 154.3764\n",
      "Epoch [277/300], Loss: 81.0788\n",
      "Validation Loss: 143.3319\n",
      "Epoch [278/300], Loss: 75.1302\n",
      "Validation Loss: 182.6646\n",
      "Epoch [279/300], Loss: 74.2907\n",
      "Validation Loss: 155.7377\n",
      "Epoch [280/300], Loss: 84.6160\n",
      "Validation Loss: 106.2920\n",
      "Best model saved at epoch 280 with val_loss 106.2920\n",
      "Epoch [281/300], Loss: 81.1364\n",
      "Validation Loss: 204.3663\n",
      "Epoch [282/300], Loss: 74.2421\n",
      "Validation Loss: 135.5830\n",
      "Epoch [283/300], Loss: 62.3771\n",
      "Validation Loss: 142.5037\n",
      "Epoch [284/300], Loss: 73.2564\n",
      "Validation Loss: 167.6111\n",
      "Epoch [285/300], Loss: 73.2792\n",
      "Validation Loss: 151.1770\n",
      "Epoch [286/300], Loss: 68.4579\n",
      "Validation Loss: 151.2024\n",
      "Epoch [287/300], Loss: 68.9856\n",
      "Validation Loss: 175.2116\n",
      "Epoch [288/300], Loss: 71.3005\n",
      "Validation Loss: 164.0381\n",
      "Epoch [289/300], Loss: 63.7206\n",
      "Validation Loss: 119.1531\n",
      "Epoch [290/300], Loss: 72.9199\n",
      "Validation Loss: 165.2429\n",
      "Epoch [291/300], Loss: 70.5571\n",
      "Validation Loss: 165.3763\n",
      "Epoch [292/300], Loss: 77.0903\n",
      "Validation Loss: 146.7504\n",
      "Epoch [293/300], Loss: 80.0186\n",
      "Validation Loss: 109.3298\n",
      "Epoch [294/300], Loss: 78.4325\n",
      "Validation Loss: 161.2829\n",
      "Epoch [295/300], Loss: 83.2997\n",
      "Validation Loss: 139.4698\n",
      "Epoch [296/300], Loss: 75.0746\n",
      "Validation Loss: 146.5358\n",
      "Epoch [297/300], Loss: 76.4166\n",
      "Validation Loss: 129.3927\n",
      "Epoch [298/300], Loss: 64.6752\n",
      "Validation Loss: 129.8381\n",
      "Epoch [299/300], Loss: 69.1340\n",
      "Validation Loss: 149.4865\n",
      "Epoch [300/300], Loss: 67.8315\n",
      "Validation Loss: 170.0611\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# Ruta a las imágenes y etiquetas\n",
    "img_dir = r'C:\\CatFLW dataset\\images'\n",
    "labels_dir = r'C:\\CatFLW dataset\\labels'\n",
    "output_dir = r'C:\\CatFLW dataset\\cropped_images'  # Ruta para guardar los recortes\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dataset personalizado para cargar imágenes y etiquetas\n",
    "class CatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            bounding_box = labels['bounding_boxes']  # Coordenadas de la caja delimitadora\n",
    "\n",
    "        # Aplicar las transformaciones de imagen y bounding box\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]  # Actualizar el bounding box\n",
    "        \n",
    "        return image, torch.tensor(bounding_box).float(), img_name  # Devuelve también el nombre del archivo\n",
    "\n",
    "# Aumentaciones para el conjunto de entrenamiento utilizando albumentations\n",
    "augmentation_transforms = A.Compose([\n",
    "    \n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en  el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Transformación básica (sin aumento) para validación\n",
    "basic_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Dataset con aumentaciones aplicadas solo en el conjunto de entrenamiento\n",
    "class AugmentedCatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None, augment_transform=None):\n",
    "        self.dataset = CatFaceDataset(img_dir, labels_dir, transform)\n",
    "        self.augment_transform = augment_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, bounding_box, img_name = self.dataset[idx]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato numpy array antes de pasarla a Albumentations\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).cpu().numpy()  # Convertir de tensor a numpy array si es necesario\n",
    "\n",
    "        # Aplicar las transformaciones de aumento\n",
    "        if random.random() < 0.5:\n",
    "            augmented = self.augment_transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato [3, 224, 224] antes de devolverla\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.tensor(image).permute(2, 0, 1)  # Convertir de numpy a tensor y reorganizar dimensiones\n",
    "\n",
    "        return image, torch.tensor(bounding_box).float(), img_name\n",
    "\n",
    "# Función de colación personalizada para asegurarse de que los bounding boxes sean tensors\n",
    "def custom_collate_fn(batch):\n",
    "    images, bounding_boxes, img_names = zip(*batch)\n",
    "    \n",
    "    # Convierte las imágenes a tensores\n",
    "    images = torch.stack([img for img in images])\n",
    "    \n",
    "    # Convierte las bounding boxes a tensores\n",
    "    bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n",
    "    \n",
    "    return images, bounding_boxes, img_names\n",
    "\n",
    "# Crear el dataset con aumento en el conjunto de entrenamiento\n",
    "augmented_dataset = AugmentedCatFaceDataset(img_dir, labels_dir, transform=basic_transform, augment_transform=augmentation_transforms)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación (80%, 20%)\n",
    "train_size = int(0.8 * len(augmented_dataset))\n",
    "val_size = len(augmented_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(augmented_dataset, [train_size, val_size])\n",
    "\n",
    "# Crear los dataloaders con la función de colación personalizada\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121BoundingBox(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121BoundingBox, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()  # Eliminar la capa fully connected original\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)  # 4 coordenadas para las esquinas de la caja\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)  # La salida es un vector con 4 coordenadas\n",
    "        return x\n",
    "\n",
    "# Crear modelo, optimizador y función de pérdida\n",
    "model = DenseNet121BoundingBox().cuda()  # Mover el modelo a la GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Reduce el LR cuando el val_loss no mejora\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    model = model.cuda()  # Asegurarse de que el modelo esté en la GPU\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterar sobre el dataloader de entrenamiento\n",
    "        for images, bounding_boxes, img_names in train_dataloader:\n",
    "            images = images.cuda()  # Mover imágenes a la GPU\n",
    "            bounding_boxes = bounding_boxes.cuda()  # Mover bounding boxes a la GPU\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, bounding_boxes)\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calcular la pérdida promedio por época\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación (si se proporciona un val_dataloader)\n",
    "        if val_dataloader:\n",
    "            model.eval()  # Modo de evaluación\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_bounding_boxes, _ in val_dataloader:\n",
    "                    val_images = val_images.cuda()\n",
    "                    val_bounding_boxes = val_bounding_boxes.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_bounding_boxes).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "            # Guardar el mejor modelo basado en la validación\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_model6.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "        \n",
    "            # Ajustar el LR basado en el val_loss usando el scheduler\n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)  # Reduce el LR si no mejora el val_loss\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
