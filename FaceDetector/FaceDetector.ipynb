{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\luisb250\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_5252\\1611153854.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return image, torch.tensor(bounding_box).float(), img_name\n",
      "C:\\Users\\luisb250\\AppData\\Local\\Temp\\ipykernel_5252\\1611153854.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 14268.1407\n",
      "Validation Loss: 12245.7245\n",
      "Best model saved at epoch 1 with val_loss 12245.7245\n",
      "Epoch [2/300], Loss: 7465.4935\n",
      "Validation Loss: 3354.6538\n",
      "Best model saved at epoch 2 with val_loss 3354.6538\n",
      "Epoch [3/300], Loss: 1548.3413\n",
      "Validation Loss: 1153.5049\n",
      "Best model saved at epoch 3 with val_loss 1153.5049\n",
      "Epoch [4/300], Loss: 1040.8630\n",
      "Validation Loss: 1041.8532\n",
      "Best model saved at epoch 4 with val_loss 1041.8532\n",
      "Epoch [5/300], Loss: 956.2962\n",
      "Validation Loss: 1012.6812\n",
      "Best model saved at epoch 5 with val_loss 1012.6812\n",
      "Epoch [6/300], Loss: 913.9164\n",
      "Validation Loss: 1059.3733\n",
      "Epoch [7/300], Loss: 904.2026\n",
      "Validation Loss: 1042.3232\n",
      "Epoch [8/300], Loss: 884.3005\n",
      "Validation Loss: 934.5096\n",
      "Best model saved at epoch 8 with val_loss 934.5096\n",
      "Epoch [9/300], Loss: 889.2442\n",
      "Validation Loss: 948.8270\n",
      "Epoch [10/300], Loss: 870.8088\n",
      "Validation Loss: 922.4625\n",
      "Best model saved at epoch 10 with val_loss 922.4625\n",
      "Epoch [11/300], Loss: 870.0405\n",
      "Validation Loss: 981.0921\n",
      "Epoch [12/300], Loss: 876.0189\n",
      "Validation Loss: 985.0611\n",
      "Epoch [13/300], Loss: 862.2909\n",
      "Validation Loss: 990.7192\n",
      "Epoch [14/300], Loss: 860.9655\n",
      "Validation Loss: 972.1005\n",
      "Epoch [15/300], Loss: 840.1181\n",
      "Validation Loss: 864.9820\n",
      "Best model saved at epoch 15 with val_loss 864.9820\n",
      "Epoch [16/300], Loss: 802.2467\n",
      "Validation Loss: 816.6899\n",
      "Best model saved at epoch 16 with val_loss 816.6899\n",
      "Epoch [17/300], Loss: 740.9747\n",
      "Validation Loss: 858.0915\n",
      "Epoch [18/300], Loss: 648.4265\n",
      "Validation Loss: 864.8337\n",
      "Epoch [19/300], Loss: 559.2339\n",
      "Validation Loss: 586.4620\n",
      "Best model saved at epoch 19 with val_loss 586.4620\n",
      "Epoch [20/300], Loss: 494.2878\n",
      "Validation Loss: 701.1329\n",
      "Epoch [21/300], Loss: 477.3385\n",
      "Validation Loss: 735.8211\n",
      "Epoch [22/300], Loss: 462.6002\n",
      "Validation Loss: 614.7396\n",
      "Epoch [23/300], Loss: 451.7231\n",
      "Validation Loss: 556.7067\n",
      "Best model saved at epoch 23 with val_loss 556.7067\n",
      "Epoch [24/300], Loss: 420.5180\n",
      "Validation Loss: 670.7219\n",
      "Epoch [25/300], Loss: 446.9140\n",
      "Validation Loss: 695.0987\n",
      "Epoch [26/300], Loss: 406.1460\n",
      "Validation Loss: 512.6627\n",
      "Best model saved at epoch 26 with val_loss 512.6627\n",
      "Epoch [27/300], Loss: 356.9022\n",
      "Validation Loss: 418.9187\n",
      "Best model saved at epoch 27 with val_loss 418.9187\n",
      "Epoch [28/300], Loss: 315.9390\n",
      "Validation Loss: 451.8528\n",
      "Epoch [29/300], Loss: 304.9482\n",
      "Validation Loss: 637.7642\n",
      "Epoch [30/300], Loss: 309.6261\n",
      "Validation Loss: 441.3707\n",
      "Epoch [31/300], Loss: 281.5216\n",
      "Validation Loss: 1120.3065\n",
      "Epoch [32/300], Loss: 249.4429\n",
      "Validation Loss: 398.6115\n",
      "Best model saved at epoch 32 with val_loss 398.6115\n",
      "Epoch [33/300], Loss: 236.9672\n",
      "Validation Loss: 643.7218\n",
      "Epoch [34/300], Loss: 225.0780\n",
      "Validation Loss: 313.2891\n",
      "Best model saved at epoch 34 with val_loss 313.2891\n",
      "Epoch [35/300], Loss: 229.3535\n",
      "Validation Loss: 658.7973\n",
      "Epoch [36/300], Loss: 251.2340\n",
      "Validation Loss: 334.8436\n",
      "Epoch [37/300], Loss: 226.8822\n",
      "Validation Loss: 634.1272\n",
      "Epoch [38/300], Loss: 206.6560\n",
      "Validation Loss: 245.5665\n",
      "Best model saved at epoch 38 with val_loss 245.5665\n",
      "Epoch [39/300], Loss: 181.3587\n",
      "Validation Loss: 419.0650\n",
      "Epoch [40/300], Loss: 201.6229\n",
      "Validation Loss: 366.2062\n",
      "Epoch [41/300], Loss: 168.4108\n",
      "Validation Loss: 529.6798\n",
      "Epoch [42/300], Loss: 172.9333\n",
      "Validation Loss: 272.3724\n",
      "Epoch [43/300], Loss: 174.9206\n",
      "Validation Loss: 424.1830\n",
      "Epoch [44/300], Loss: 169.1469\n",
      "Validation Loss: 407.4124\n",
      "Epoch [45/300], Loss: 165.0070\n",
      "Validation Loss: 231.1227\n",
      "Best model saved at epoch 45 with val_loss 231.1227\n",
      "Epoch [46/300], Loss: 167.6280\n",
      "Validation Loss: 764.3413\n",
      "Epoch [47/300], Loss: 160.0456\n",
      "Validation Loss: 244.6014\n",
      "Epoch [48/300], Loss: 171.1778\n",
      "Validation Loss: 284.7807\n",
      "Epoch [49/300], Loss: 160.7806\n",
      "Validation Loss: 227.9294\n",
      "Best model saved at epoch 49 with val_loss 227.9294\n",
      "Epoch [50/300], Loss: 164.1637\n",
      "Validation Loss: 271.9225\n",
      "Epoch [51/300], Loss: 149.6325\n",
      "Validation Loss: 255.6839\n",
      "Epoch [52/300], Loss: 155.3041\n",
      "Validation Loss: 372.7030\n",
      "Epoch [53/300], Loss: 150.6216\n",
      "Validation Loss: 479.0652\n",
      "Epoch [54/300], Loss: 135.0202\n",
      "Validation Loss: 541.9748\n",
      "Epoch [55/300], Loss: 141.7871\n",
      "Validation Loss: 227.6111\n",
      "Best model saved at epoch 55 with val_loss 227.6111\n",
      "Epoch [56/300], Loss: 120.5675\n",
      "Validation Loss: 334.3640\n",
      "Epoch [57/300], Loss: 135.7630\n",
      "Validation Loss: 801.4379\n",
      "Epoch [58/300], Loss: 120.5637\n",
      "Validation Loss: 183.0197\n",
      "Best model saved at epoch 58 with val_loss 183.0197\n",
      "Epoch [59/300], Loss: 140.4268\n",
      "Validation Loss: 206.1472\n",
      "Epoch [60/300], Loss: 118.8256\n",
      "Validation Loss: 199.7111\n",
      "Epoch [61/300], Loss: 123.7689\n",
      "Validation Loss: 374.4429\n",
      "Epoch [62/300], Loss: 124.8883\n",
      "Validation Loss: 254.4166\n",
      "Epoch [63/300], Loss: 121.4805\n",
      "Validation Loss: 162.0789\n",
      "Best model saved at epoch 63 with val_loss 162.0789\n",
      "Epoch [64/300], Loss: 147.7048\n",
      "Validation Loss: 290.7254\n",
      "Epoch [65/300], Loss: 143.2886\n",
      "Validation Loss: 676.2381\n",
      "Epoch [66/300], Loss: 156.4780\n",
      "Validation Loss: 248.4051\n",
      "Epoch [67/300], Loss: 143.2268\n",
      "Validation Loss: 292.9925\n",
      "Epoch [68/300], Loss: 143.0376\n",
      "Validation Loss: 863.1944\n",
      "Epoch [69/300], Loss: 136.1823\n",
      "Validation Loss: 268.8557\n",
      "Epoch [70/300], Loss: 140.5827\n",
      "Validation Loss: 229.2080\n",
      "Epoch [71/300], Loss: 112.2465\n",
      "Validation Loss: 263.2261\n",
      "Epoch [72/300], Loss: 112.8251\n",
      "Validation Loss: 340.8829\n",
      "Epoch [73/300], Loss: 118.3208\n",
      "Validation Loss: 180.1443\n",
      "Epoch [74/300], Loss: 96.8596\n",
      "Validation Loss: 226.0493\n",
      "Epoch [75/300], Loss: 115.9670\n",
      "Validation Loss: 180.1381\n",
      "Epoch [76/300], Loss: 117.1728\n",
      "Validation Loss: 391.8666\n",
      "Epoch [77/300], Loss: 99.2623\n",
      "Validation Loss: 189.5126\n",
      "Epoch [78/300], Loss: 117.6383\n",
      "Validation Loss: 262.2365\n",
      "Epoch [79/300], Loss: 120.1398\n",
      "Validation Loss: 228.9541\n",
      "Epoch [80/300], Loss: 106.6610\n",
      "Validation Loss: 601.9166\n",
      "Epoch [81/300], Loss: 112.9462\n",
      "Validation Loss: 303.6717\n",
      "Epoch [82/300], Loss: 141.8118\n",
      "Validation Loss: 2140.5993\n",
      "Epoch [83/300], Loss: 153.3590\n",
      "Validation Loss: 563.5822\n",
      "Epoch [84/300], Loss: 133.3021\n",
      "Validation Loss: 217.1125\n",
      "Epoch [85/300], Loss: 137.6643\n",
      "Validation Loss: 284.0213\n",
      "Epoch [86/300], Loss: 121.2626\n",
      "Validation Loss: 370.2677\n",
      "Epoch [87/300], Loss: 96.4748\n",
      "Validation Loss: 251.2227\n",
      "Epoch [88/300], Loss: 109.6111\n",
      "Validation Loss: 240.4206\n",
      "Epoch [89/300], Loss: 114.8188\n",
      "Validation Loss: 202.7893\n",
      "Epoch [90/300], Loss: 92.6068\n",
      "Validation Loss: 788.1656\n",
      "Epoch [91/300], Loss: 96.3460\n",
      "Validation Loss: 178.9325\n",
      "Epoch [92/300], Loss: 113.9977\n",
      "Validation Loss: 403.6791\n",
      "Epoch [93/300], Loss: 105.6512\n",
      "Validation Loss: 350.7840\n",
      "Epoch [94/300], Loss: 126.0066\n",
      "Validation Loss: 265.5650\n",
      "Epoch [95/300], Loss: 132.3196\n",
      "Validation Loss: 754.1841\n",
      "Epoch [96/300], Loss: 125.3400\n",
      "Validation Loss: 227.7314\n",
      "Epoch [97/300], Loss: 114.4153\n",
      "Validation Loss: 549.4900\n",
      "Epoch [98/300], Loss: 119.6738\n",
      "Validation Loss: 251.2967\n",
      "Epoch [99/300], Loss: 110.3115\n",
      "Validation Loss: 192.8851\n",
      "Epoch [100/300], Loss: 117.7595\n",
      "Validation Loss: 173.8209\n",
      "Epoch [101/300], Loss: 94.3683\n",
      "Validation Loss: 176.4859\n",
      "Epoch [102/300], Loss: 97.7144\n",
      "Validation Loss: 180.3705\n",
      "Epoch [103/300], Loss: 100.2695\n",
      "Validation Loss: 156.0916\n",
      "Best model saved at epoch 103 with val_loss 156.0916\n",
      "Epoch [104/300], Loss: 100.4757\n",
      "Validation Loss: 229.5774\n",
      "Epoch [105/300], Loss: 116.0062\n",
      "Validation Loss: 251.0574\n",
      "Epoch [106/300], Loss: 96.2690\n",
      "Validation Loss: 296.2118\n",
      "Epoch [107/300], Loss: 116.4195\n",
      "Validation Loss: 219.8147\n",
      "Epoch [108/300], Loss: 101.8038\n",
      "Validation Loss: 226.9683\n",
      "Epoch [109/300], Loss: 136.1925\n",
      "Validation Loss: 374.2189\n",
      "Epoch [110/300], Loss: 103.7365\n",
      "Validation Loss: 218.8359\n",
      "Epoch [111/300], Loss: 109.4903\n",
      "Validation Loss: 173.2930\n",
      "Epoch [112/300], Loss: 97.5616\n",
      "Validation Loss: 498.4700\n",
      "Epoch [113/300], Loss: 116.7599\n",
      "Validation Loss: 208.9680\n",
      "Epoch [114/300], Loss: 90.8109\n",
      "Validation Loss: 396.7804\n",
      "Epoch [115/300], Loss: 109.0232\n",
      "Validation Loss: 220.2967\n",
      "Epoch [116/300], Loss: 107.3040\n",
      "Validation Loss: 317.5823\n",
      "Epoch [117/300], Loss: 154.8649\n",
      "Validation Loss: 702.5665\n",
      "Epoch [118/300], Loss: 138.3490\n",
      "Validation Loss: 199.0284\n",
      "Epoch [119/300], Loss: 120.3285\n",
      "Validation Loss: 200.0844\n",
      "Epoch [120/300], Loss: 108.4165\n",
      "Validation Loss: 321.7182\n",
      "Epoch [121/300], Loss: 107.0423\n",
      "Validation Loss: 213.1420\n",
      "Epoch [122/300], Loss: 105.3716\n",
      "Validation Loss: 710.7901\n",
      "Epoch [123/300], Loss: 101.7626\n",
      "Validation Loss: 558.3864\n",
      "Epoch [124/300], Loss: 117.4852\n",
      "Validation Loss: 256.0325\n",
      "Epoch [125/300], Loss: 110.6458\n",
      "Validation Loss: 351.2628\n",
      "Epoch [126/300], Loss: 85.2095\n",
      "Validation Loss: 342.0097\n",
      "Epoch [127/300], Loss: 98.0334\n",
      "Validation Loss: 152.1599\n",
      "Best model saved at epoch 127 with val_loss 152.1599\n",
      "Epoch [128/300], Loss: 101.1904\n",
      "Validation Loss: 271.7285\n",
      "Epoch [129/300], Loss: 107.3747\n",
      "Validation Loss: 241.6591\n",
      "Epoch [130/300], Loss: 107.1835\n",
      "Validation Loss: 189.8876\n",
      "Epoch [131/300], Loss: 114.5088\n",
      "Validation Loss: 184.0114\n",
      "Epoch [132/300], Loss: 102.6316\n",
      "Validation Loss: 174.2639\n",
      "Epoch [133/300], Loss: 104.2199\n",
      "Validation Loss: 189.0339\n",
      "Epoch [134/300], Loss: 100.8247\n",
      "Validation Loss: 611.2981\n",
      "Epoch [135/300], Loss: 102.8157\n",
      "Validation Loss: 235.1761\n",
      "Epoch [136/300], Loss: 116.5235\n",
      "Validation Loss: 192.3880\n",
      "Epoch [137/300], Loss: 93.1432\n",
      "Validation Loss: 481.5489\n",
      "Epoch [138/300], Loss: 117.8482\n",
      "Validation Loss: 228.5210\n",
      "Epoch [139/300], Loss: 80.8478\n",
      "Validation Loss: 202.1974\n",
      "Epoch [140/300], Loss: 104.7167\n",
      "Validation Loss: 276.7916\n",
      "Epoch [141/300], Loss: 100.0333\n",
      "Validation Loss: 193.2082\n",
      "Epoch [142/300], Loss: 103.9766\n",
      "Validation Loss: 152.3269\n",
      "Epoch [143/300], Loss: 93.0832\n",
      "Validation Loss: 176.5425\n",
      "Epoch [144/300], Loss: 99.7319\n",
      "Validation Loss: 189.3480\n",
      "Epoch [145/300], Loss: 107.3901\n",
      "Validation Loss: 260.7007\n",
      "Epoch [146/300], Loss: 92.7051\n",
      "Validation Loss: 154.0936\n",
      "Epoch [147/300], Loss: 84.2648\n",
      "Validation Loss: 457.9478\n",
      "Epoch [148/300], Loss: 94.9052\n",
      "Validation Loss: 151.6926\n",
      "Best model saved at epoch 148 with val_loss 151.6926\n",
      "Epoch [149/300], Loss: 99.3684\n",
      "Validation Loss: 207.7863\n",
      "Epoch [150/300], Loss: 97.8707\n",
      "Validation Loss: 363.3124\n",
      "Epoch [151/300], Loss: 77.9717\n",
      "Validation Loss: 202.8447\n",
      "Epoch [152/300], Loss: 106.6530\n",
      "Validation Loss: 249.6001\n",
      "Epoch [153/300], Loss: 112.5470\n",
      "Validation Loss: 667.6670\n",
      "Epoch [154/300], Loss: 115.3134\n",
      "Validation Loss: 225.5164\n",
      "Epoch [155/300], Loss: 107.8298\n",
      "Validation Loss: 212.0584\n",
      "Epoch [156/300], Loss: 98.9856\n",
      "Validation Loss: 219.3888\n",
      "Epoch [157/300], Loss: 98.7981\n",
      "Validation Loss: 190.4025\n",
      "Epoch [158/300], Loss: 104.0844\n",
      "Validation Loss: 208.6845\n",
      "Epoch [159/300], Loss: 101.2637\n",
      "Validation Loss: 233.9516\n",
      "Epoch [160/300], Loss: 111.2612\n",
      "Validation Loss: 542.8899\n",
      "Epoch [161/300], Loss: 114.7219\n",
      "Validation Loss: 233.9285\n",
      "Epoch [162/300], Loss: 111.9842\n",
      "Validation Loss: 146.8972\n",
      "Best model saved at epoch 162 with val_loss 146.8972\n",
      "Epoch [163/300], Loss: 100.2357\n",
      "Validation Loss: 234.0599\n",
      "Epoch [164/300], Loss: 101.2251\n",
      "Validation Loss: 149.9127\n",
      "Epoch [165/300], Loss: 89.0885\n",
      "Validation Loss: 172.9926\n",
      "Epoch [166/300], Loss: 89.7031\n",
      "Validation Loss: 226.1330\n",
      "Epoch [167/300], Loss: 82.8051\n",
      "Validation Loss: 226.0208\n",
      "Epoch [168/300], Loss: 94.4177\n",
      "Validation Loss: 253.6893\n",
      "Epoch [169/300], Loss: 104.3952\n",
      "Validation Loss: 318.4242\n",
      "Epoch [170/300], Loss: 99.7360\n",
      "Validation Loss: 393.7103\n",
      "Epoch [171/300], Loss: 89.0171\n",
      "Validation Loss: 164.2825\n",
      "Epoch [172/300], Loss: 80.6133\n",
      "Validation Loss: 164.3942\n",
      "Epoch [173/300], Loss: 89.9658\n",
      "Validation Loss: 157.7173\n",
      "Epoch [174/300], Loss: 89.2405\n",
      "Validation Loss: 167.3258\n",
      "Epoch [175/300], Loss: 102.5783\n",
      "Validation Loss: 212.7294\n",
      "Epoch [176/300], Loss: 96.9459\n",
      "Validation Loss: 198.2887\n",
      "Epoch [177/300], Loss: 73.4149\n",
      "Validation Loss: 173.7280\n",
      "Epoch [178/300], Loss: 92.9447\n",
      "Validation Loss: 1305.1881\n",
      "Epoch [179/300], Loss: 105.0322\n",
      "Validation Loss: 163.1769\n",
      "Epoch [180/300], Loss: 95.3758\n",
      "Validation Loss: 256.1038\n",
      "Epoch [181/300], Loss: 82.6090\n",
      "Validation Loss: 196.1595\n",
      "Epoch [182/300], Loss: 90.2204\n",
      "Validation Loss: 131.9632\n",
      "Best model saved at epoch 182 with val_loss 131.9632\n",
      "Epoch [183/300], Loss: 85.4578\n",
      "Validation Loss: 185.5477\n",
      "Epoch [184/300], Loss: 84.2696\n",
      "Validation Loss: 156.0571\n",
      "Epoch [185/300], Loss: 70.5960\n",
      "Validation Loss: 177.9993\n",
      "Epoch [186/300], Loss: 91.5737\n",
      "Validation Loss: 189.9810\n",
      "Epoch [187/300], Loss: 104.9818\n",
      "Validation Loss: 160.8311\n",
      "Epoch [188/300], Loss: 91.6923\n",
      "Validation Loss: 192.8071\n",
      "Epoch [189/300], Loss: 77.1935\n",
      "Validation Loss: 191.8593\n",
      "Epoch [190/300], Loss: 75.4010\n",
      "Validation Loss: 160.1721\n",
      "Epoch [191/300], Loss: 73.7630\n",
      "Validation Loss: 145.1682\n",
      "Epoch [192/300], Loss: 85.9285\n",
      "Validation Loss: 171.9894\n",
      "Epoch [193/300], Loss: 89.6468\n",
      "Validation Loss: 227.7271\n",
      "Epoch [194/300], Loss: 90.7967\n",
      "Validation Loss: 472.5828\n",
      "Epoch [195/300], Loss: 89.5637\n",
      "Validation Loss: 244.4233\n",
      "Epoch [196/300], Loss: 102.2715\n",
      "Validation Loss: 252.7186\n",
      "Epoch [197/300], Loss: 81.3928\n",
      "Validation Loss: 214.1223\n",
      "Epoch [198/300], Loss: 88.4668\n",
      "Validation Loss: 178.9253\n",
      "Epoch [199/300], Loss: 96.3376\n",
      "Validation Loss: 228.2974\n",
      "Epoch [200/300], Loss: 95.7309\n",
      "Validation Loss: 369.7820\n",
      "Epoch [201/300], Loss: 89.2128\n",
      "Validation Loss: 1076.2862\n",
      "Epoch [202/300], Loss: 82.0234\n",
      "Validation Loss: 148.1550\n",
      "Epoch [203/300], Loss: 94.2109\n",
      "Validation Loss: 206.7675\n",
      "Epoch [204/300], Loss: 117.8766\n",
      "Validation Loss: 2254.5566\n",
      "Epoch [205/300], Loss: 103.4412\n",
      "Validation Loss: 213.6475\n",
      "Epoch [206/300], Loss: 85.9099\n",
      "Validation Loss: 222.6895\n",
      "Epoch [207/300], Loss: 78.6241\n",
      "Validation Loss: 206.4250\n",
      "Epoch [208/300], Loss: 82.9176\n",
      "Validation Loss: 215.0779\n",
      "Epoch [209/300], Loss: 88.0265\n",
      "Validation Loss: 186.4279\n",
      "Epoch [210/300], Loss: 77.3264\n",
      "Validation Loss: 196.3712\n",
      "Epoch [211/300], Loss: 83.8333\n",
      "Validation Loss: 164.3871\n",
      "Epoch [212/300], Loss: 84.7256\n",
      "Validation Loss: 163.1073\n",
      "Epoch [213/300], Loss: 87.9203\n",
      "Validation Loss: 371.5818\n",
      "Epoch [214/300], Loss: 104.2253\n",
      "Validation Loss: 262.6942\n",
      "Epoch [215/300], Loss: 99.6176\n",
      "Validation Loss: 166.3761\n",
      "Epoch [216/300], Loss: 84.0340\n",
      "Validation Loss: 218.9707\n",
      "Epoch [217/300], Loss: 95.3038\n",
      "Validation Loss: 340.6065\n",
      "Epoch [218/300], Loss: 84.9748\n",
      "Validation Loss: 209.6492\n",
      "Epoch [219/300], Loss: 96.6799\n",
      "Validation Loss: 176.6814\n",
      "Epoch [220/300], Loss: 97.6230\n",
      "Validation Loss: 156.7544\n",
      "Epoch [221/300], Loss: 79.4627\n",
      "Validation Loss: 205.6940\n",
      "Epoch [222/300], Loss: 89.0321\n",
      "Validation Loss: 139.5236\n",
      "Epoch [223/300], Loss: 77.1192\n",
      "Validation Loss: 187.2872\n",
      "Epoch [224/300], Loss: 91.1113\n",
      "Validation Loss: 155.9628\n",
      "Epoch [225/300], Loss: 82.7246\n",
      "Validation Loss: 152.1825\n",
      "Epoch [226/300], Loss: 79.7374\n",
      "Validation Loss: 179.9728\n",
      "Epoch [227/300], Loss: 64.0357\n",
      "Validation Loss: 163.5480\n",
      "Epoch [228/300], Loss: 83.6156\n",
      "Validation Loss: 191.6681\n",
      "Epoch [229/300], Loss: 79.9680\n",
      "Validation Loss: 222.8153\n",
      "Epoch [230/300], Loss: 101.9056\n",
      "Validation Loss: 461.4318\n",
      "Epoch [231/300], Loss: 91.8519\n",
      "Validation Loss: 238.1610\n",
      "Epoch [232/300], Loss: 104.2553\n",
      "Validation Loss: 238.0604\n",
      "Epoch [233/300], Loss: 78.1827\n",
      "Validation Loss: 181.2102\n",
      "Epoch [234/300], Loss: 105.1428\n",
      "Validation Loss: 151.6293\n",
      "Epoch [235/300], Loss: 85.6283\n",
      "Validation Loss: 176.7140\n",
      "Epoch [236/300], Loss: 83.9158\n",
      "Validation Loss: 176.4925\n",
      "Epoch [237/300], Loss: 80.1714\n",
      "Validation Loss: 168.2861\n",
      "Epoch [238/300], Loss: 72.2459\n",
      "Validation Loss: 186.4611\n",
      "Epoch [239/300], Loss: 66.3769\n",
      "Validation Loss: 192.7645\n",
      "Epoch [240/300], Loss: 77.7261\n",
      "Validation Loss: 324.6672\n",
      "Epoch [241/300], Loss: 91.3021\n",
      "Validation Loss: 195.4591\n",
      "Epoch [242/300], Loss: 86.3066\n",
      "Validation Loss: 183.5197\n",
      "Epoch [243/300], Loss: 81.7305\n",
      "Validation Loss: 196.8933\n",
      "Epoch [244/300], Loss: 84.1500\n",
      "Validation Loss: 287.9865\n",
      "Epoch [245/300], Loss: 83.5936\n",
      "Validation Loss: 343.6017\n",
      "Epoch [246/300], Loss: 87.5715\n",
      "Validation Loss: 148.3538\n",
      "Epoch [247/300], Loss: 80.5187\n",
      "Validation Loss: 216.6419\n",
      "Epoch [248/300], Loss: 79.4146\n",
      "Validation Loss: 253.6149\n",
      "Epoch [249/300], Loss: 81.3990\n",
      "Validation Loss: 220.1980\n",
      "Epoch [250/300], Loss: 105.5614\n",
      "Validation Loss: 333.5018\n",
      "Epoch [251/300], Loss: 98.8984\n",
      "Validation Loss: 392.3924\n",
      "Epoch [252/300], Loss: 97.3263\n",
      "Validation Loss: 582.3434\n",
      "Epoch [253/300], Loss: 72.5132\n",
      "Validation Loss: 182.5949\n",
      "Epoch [254/300], Loss: 90.6446\n",
      "Validation Loss: 226.9493\n",
      "Epoch [255/300], Loss: 83.9440\n",
      "Validation Loss: 278.2769\n",
      "Epoch [256/300], Loss: 85.3117\n",
      "Validation Loss: 174.3606\n",
      "Epoch [257/300], Loss: 104.5636\n",
      "Validation Loss: 231.7235\n",
      "Epoch [258/300], Loss: 83.1580\n",
      "Validation Loss: 208.8068\n",
      "Epoch [259/300], Loss: 85.3887\n",
      "Validation Loss: 176.9393\n",
      "Epoch [260/300], Loss: 72.4576\n",
      "Validation Loss: 176.1882\n",
      "Epoch [261/300], Loss: 75.4946\n",
      "Validation Loss: 147.7477\n",
      "Epoch [262/300], Loss: 85.8193\n",
      "Validation Loss: 160.6795\n",
      "Epoch [263/300], Loss: 73.9606\n",
      "Validation Loss: 154.9443\n",
      "Epoch [264/300], Loss: 85.7325\n",
      "Validation Loss: 163.9519\n",
      "Epoch [265/300], Loss: 76.9524\n",
      "Validation Loss: 170.8783\n",
      "Epoch [266/300], Loss: 92.5669\n",
      "Validation Loss: 139.5288\n",
      "Epoch [267/300], Loss: 74.0445\n",
      "Validation Loss: 162.2691\n",
      "Epoch [268/300], Loss: 88.2690\n",
      "Validation Loss: 190.1426\n",
      "Epoch [269/300], Loss: 81.6924\n",
      "Validation Loss: 157.0505\n",
      "Epoch [270/300], Loss: 88.1872\n",
      "Validation Loss: 132.7280\n",
      "Epoch [271/300], Loss: 85.1181\n",
      "Validation Loss: 161.6826\n",
      "Epoch [272/300], Loss: 72.1164\n",
      "Validation Loss: 143.4398\n",
      "Epoch [273/300], Loss: 73.3721\n",
      "Validation Loss: 152.6583\n",
      "Epoch [274/300], Loss: 80.6440\n",
      "Validation Loss: 155.7491\n",
      "Epoch [275/300], Loss: 91.2942\n",
      "Validation Loss: 170.2512\n",
      "Epoch [276/300], Loss: 78.1484\n",
      "Validation Loss: 154.3764\n",
      "Epoch [277/300], Loss: 81.0788\n",
      "Validation Loss: 143.3319\n",
      "Epoch [278/300], Loss: 75.1302\n",
      "Validation Loss: 182.6646\n",
      "Epoch [279/300], Loss: 74.2907\n",
      "Validation Loss: 155.7377\n",
      "Epoch [280/300], Loss: 84.6160\n",
      "Validation Loss: 106.2920\n",
      "Best model saved at epoch 280 with val_loss 106.2920\n",
      "Epoch [281/300], Loss: 81.1364\n",
      "Validation Loss: 204.3663\n",
      "Epoch [282/300], Loss: 74.2421\n",
      "Validation Loss: 135.5830\n",
      "Epoch [283/300], Loss: 62.3771\n",
      "Validation Loss: 142.5037\n",
      "Epoch [284/300], Loss: 73.2564\n",
      "Validation Loss: 167.6111\n",
      "Epoch [285/300], Loss: 73.2792\n",
      "Validation Loss: 151.1770\n",
      "Epoch [286/300], Loss: 68.4579\n",
      "Validation Loss: 151.2024\n",
      "Epoch [287/300], Loss: 68.9856\n",
      "Validation Loss: 175.2116\n",
      "Epoch [288/300], Loss: 71.3005\n",
      "Validation Loss: 164.0381\n",
      "Epoch [289/300], Loss: 63.7206\n",
      "Validation Loss: 119.1531\n",
      "Epoch [290/300], Loss: 72.9199\n",
      "Validation Loss: 165.2429\n",
      "Epoch [291/300], Loss: 70.5571\n",
      "Validation Loss: 165.3763\n",
      "Epoch [292/300], Loss: 77.0903\n",
      "Validation Loss: 146.7504\n",
      "Epoch [293/300], Loss: 80.0186\n",
      "Validation Loss: 109.3298\n",
      "Epoch [294/300], Loss: 78.4325\n",
      "Validation Loss: 161.2829\n",
      "Epoch [295/300], Loss: 83.2997\n",
      "Validation Loss: 139.4698\n",
      "Epoch [296/300], Loss: 75.0746\n",
      "Validation Loss: 146.5358\n",
      "Epoch [297/300], Loss: 76.4166\n",
      "Validation Loss: 129.3927\n",
      "Epoch [298/300], Loss: 64.6752\n",
      "Validation Loss: 129.8381\n",
      "Epoch [299/300], Loss: 69.1340\n",
      "Validation Loss: 149.4865\n",
      "Epoch [300/300], Loss: 67.8315\n",
      "Validation Loss: 170.0611\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# Ruta a las imágenes y etiquetas\n",
    "img_dir = r'C:\\CatFLW dataset\\images'\n",
    "labels_dir = r'C:\\CatFLW dataset\\labels'\n",
    "output_dir = r'C:\\CatFLW dataset\\cropped_images'  # Ruta para guardar los recortes\n",
    "\n",
    "# Crear el directorio de salida si no existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dataset personalizado para cargar imágenes y etiquetas\n",
    "class CatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.labels_dir, img_name.replace('.png', '.json'))\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # Cargar etiquetas\n",
    "        with open(label_path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "            bounding_box = labels['bounding_boxes']  # Coordenadas de la caja delimitadora\n",
    "\n",
    "        # Aplicar las transformaciones de imagen y bounding box\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]  # Actualizar el bounding box\n",
    "        \n",
    "        return image, torch.tensor(bounding_box).float(), img_name  # Devuelve también el nombre del archivo\n",
    "\n",
    "# Aumentaciones para el conjunto de entrenamiento utilizando albumentations\n",
    "augmentation_transforms = A.Compose([\n",
    "    \n",
    "    A.Rotate(limit=30, p=0.5),  # Rotación aleatoria con 50% de probabilidad\n",
    "    A.ColorJitter(p=0.5),  # Cambio en el balance de color, brillo, contraste y nitidez con 50% de probabilidad\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Cambio en  el brillo y contraste con 50% de probabilidad\n",
    "    A.GaussianBlur(p=0.1),  # Aplicación de máscaras de desenfoque con 50% de probabilidad\n",
    "    A.GaussNoise(p=0.1),  # Ruido aleatorio con 50% de probabilidad\n",
    "    A.Resize(224, 224),  # Redimensionar a 224x224\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Transformación básica (sin aumento) para validación\n",
    "basic_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "\n",
    "# Dataset con aumentaciones aplicadas solo en el conjunto de entrenamiento\n",
    "class AugmentedCatFaceDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_dir, transform=None, augment_transform=None):\n",
    "        self.dataset = CatFaceDataset(img_dir, labels_dir, transform)\n",
    "        self.augment_transform = augment_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, bounding_box, img_name = self.dataset[idx]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato numpy array antes de pasarla a Albumentations\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).cpu().numpy()  # Convertir de tensor a numpy array si es necesario\n",
    "\n",
    "        # Aplicar las transformaciones de aumento\n",
    "        if random.random() < 0.5:\n",
    "            augmented = self.augment_transform(image=image, bboxes=[bounding_box])\n",
    "            image = augmented['image']\n",
    "            bounding_box = augmented['bboxes'][0]\n",
    "\n",
    "        # Asegúrate de que la imagen esté en formato [3, 224, 224] antes de devolverla\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.tensor(image).permute(2, 0, 1)  # Convertir de numpy a tensor y reorganizar dimensiones\n",
    "\n",
    "        return image, torch.tensor(bounding_box).float(), img_name\n",
    "\n",
    "# Función de colación personalizada para asegurarse de que los bounding boxes sean tensors\n",
    "def custom_collate_fn(batch):\n",
    "    images, bounding_boxes, img_names = zip(*batch)\n",
    "    \n",
    "    # Convierte las imágenes a tensores\n",
    "    images = torch.stack([img for img in images])\n",
    "    \n",
    "    # Convierte las bounding boxes a tensores\n",
    "    bounding_boxes = torch.stack([torch.tensor(bbox, dtype=torch.float32) for bbox in bounding_boxes])\n",
    "    \n",
    "    return images, bounding_boxes, img_names\n",
    "\n",
    "# Crear el dataset con aumento en el conjunto de entrenamiento\n",
    "augmented_dataset = AugmentedCatFaceDataset(img_dir, labels_dir, transform=basic_transform, augment_transform=augmentation_transforms)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación (80%, 20%)\n",
    "train_size = int(0.8 * len(augmented_dataset))\n",
    "val_size = len(augmented_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(augmented_dataset, [train_size, val_size])\n",
    "\n",
    "# Crear los dataloaders con la función de colación personalizada\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Modelo basado en DenseNet-121\n",
    "class DenseNet121BoundingBox(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121BoundingBox, self).__init__()\n",
    "        self.backbone = models.densenet121(pretrained=True)\n",
    "        self.backbone.classifier = nn.Identity()  # Eliminar la capa fully connected original\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)  # 4 coordenadas para las esquinas de la caja\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)  # La salida es un vector con 4 coordenadas\n",
    "        return x\n",
    "\n",
    "# Crear modelo, optimizador y función de pérdida\n",
    "model = DenseNet121BoundingBox().cuda()  # Mover el modelo a la GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Reduce el LR cuando el val_loss no mejora\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=75, verbose=True)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=None, scheduler=None):\n",
    "    model = model.cuda()  # Asegurarse de que el modelo esté en la GPU\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterar sobre el dataloader de entrenamiento\n",
    "        for images, bounding_boxes, img_names in train_dataloader:\n",
    "            images = images.cuda()  # Mover imágenes a la GPU\n",
    "            bounding_boxes = bounding_boxes.cuda()  # Mover bounding boxes a la GPU\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, bounding_boxes)\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calcular la pérdida promedio por época\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validación (si se proporciona un val_dataloader)\n",
    "        if val_dataloader:\n",
    "            model.eval()  # Modo de evaluación\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_bounding_boxes, _ in val_dataloader:\n",
    "                    val_images = val_images.cuda()\n",
    "                    val_bounding_boxes = val_bounding_boxes.cuda()\n",
    "                    val_outputs = model(val_images)\n",
    "                    val_loss += criterion(val_outputs, val_bounding_boxes).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "            # Guardar el mejor modelo basado en la validación\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_model6.pth')\n",
    "                print(f'Best model saved at epoch {epoch+1} with val_loss {best_loss:.4f}')\n",
    "        \n",
    "            # Ajustar el LR basado en el val_loss usando el scheduler\n",
    "            if scheduler:\n",
    "                scheduler.step(val_loss)  # Reduce el LR si no mejora el val_loss\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "train_model(model, train_dataloader, optimizer, criterion, num_epochs=300, val_dataloader=val_dataloader, scheduler=scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
